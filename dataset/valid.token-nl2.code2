sitemap = oh _ demo ;
try { tb . set age ( 6 ) ; fail ( mixin should have locked this object ) ; } catch ( locked exception ex ) { ok } }
log . debug ( loading rules ) ; node list rule list = rules document . get elements by tag name ( rule ) ;
if ( results . length > 0 & & results [ 0 ] . get score ( ) < abs thresh ) results = new result [ 0 ] ;
vm . set account id ( new account . get account id ( ) ) ;
for ( iterator < map . entry < integer , spdy socket > > i = sockets . entry set ( ) . iterator ( ) ; i . has next ( ) ; ) { map . entry < integer , spdy socket > entry = i . next ( ) ; int stream id = entry . get key ( ) ; if ( stream id > last good stream id & & entry . get value ( ) . is locally initiated ( ) ) { util . end ( entry . get value ( ) , new ioexception ( error code . refused _ stream . to string ( ) ) ) ; i . remove ( ) ; } } }
glide . with ( ctx ) . load ( m image url ) . animate ( r . anim . alpha _ on ) . into ( view holder . image view ) ;
validate namespace name ( namespace ) ;
stream . reset ( ) ; } } else { stream . reset ( ) ; } }
double viewport width = m renderer . get viewport width ( ) , viewport height = m renderer . get default viewport height ( ) ; double inv aspect = viewport height viewport width ; double size ; vector2 scale = new vector2 ( ) ; double half viewport width = viewport width 2 ; double half viewport height = viewport height 2 ; vector3 screen position = new vector3 ( ) ; double screen position pixels _ x , screen position pixels _ y ; camera camera = m renderer . get current scene ( ) . get camera ( ) ; matrix4 view matrix = camera . get view matrix ( ) . clone ( ) , proj matrix = camera . get projection matrix ( ) . clone ( ) ; use program ( m program ) ;
this . display android pay confirmation . on next ( false ) ;
pair < integer , list < string > > count and paths = process list ( temp list , partition idx , count , true ) ; if ( count and paths . get second ( ) = null & & count and paths . get second ( ) . size ( ) > 0 ) { output paths . add all ( count and paths . get second ( ) ) ; } return output paths . iterator ( ) ; }
log . info ( releasing reservation that cannot be satisfied for + application + get application attempt id ( ) + on node + node ) ; unreserve ( reserved scheduler key , node ) ; return false ;
assert can process ( source history mercurial , source , history , mercurial ) ;
string input = - 10h49m789 , - 8h ;
final int size = array . get length ( value ) ;
assert true ( p instanceof aggregate plan node ) ; p = pn . get ( 1 ) . get child ( 0 ) ; assert true ( p instanceof table count plan node ) ; }
conf . set jar by class ( test mini mrclasspath . class ) ;
stop . set ( true ) ; }
string chars = \ t + range ( 0x23 , 0x24 ) + range ( 0x26 , 0x5b ) + range ( 0x5d , 0x73 ) + range ( 0x80 , 0xff ) + ' \ \ ' + ' ' ; final string s = new codepoint set generator ( chars . to char array ( ) ) . of code points length ( random ( ) , 16 , 16 ) ; assert that ( deprecation logger . encode ( s ) , equal to ( s ) ) ;
sslcontext ctx = get context ( ) ; sslserver socket ss = ( sslserver socket ) ctx . get server socket factory ( ) . create server socket ( 0 ) ; sslsocket factory socket factory = ( sslsocket factory ) ctx . get socket factory ( ) ;
return ( e ) realm . get ( ( class < ? extends realm model > ) class spec , class name , row ) ;
create tet layer group ( ) ;
cleanup operation result cleanup operation result = client b . cleanup ( options ) ;
if ( current size > = this . replication queue size capacity | | current nb entries > = this . replication queue nb capacity ) { break ; } try { entry = this . rep log reader . read next and set position ( this . entries array , this . current nb entries ) ; } catch ( ioexception ie ) { log . debug ( break on ioe : + ie . get message ( ) ) ; break ; }
result = services . execute operation ( get protocol get property operation ( maximal , mping , name ) ) ; assert . assert equals ( result . to string ( ) , success , result . get ( outcome ) . as string ( ) ) ; assert . assert equals ( new - value , result . get ( result ) . as string ( ) ) ;
gossip snitch info ( ) ;
conf = new neural net configuration . builder ( ) . graph builder ( ) . add inputs ( in ) . set input types ( input type . convolutional flat ( 10 , 8 , 3 ) ) . add layer ( l0 , new subsampling layer . builder ( ) . kernel size ( 2 , 2 ) . stride ( 1 , 1 ) . padding ( 0 , 0 ) . build ( ) , in ) . add layer ( layer , new convolution layer . builder ( ) . kernel size ( 2 , 2 ) . padding ( 0 , 0 ) . stride ( 1 , 1 ) . build ( ) , l0 ) . add layer ( out , new output layer . builder ( ) . n out ( 10 ) . build ( ) , layer ) . set outputs ( out ) . pretrain ( false ) . backprop ( true ) . build ( ) ;
if ( new file . exists ( ) ) { logger . warning ( error message . general _ write _ failed _ new _ file _ doesnt _ exist . get msg ( new file . get absolute path ( ) ) ) ; }
op return data = new byte [ 24 ] ;
start job tracker ( ) ;
if ( nargs > = max _ jvm _ arity 2 - 1 ) { int slots = nargs ; final int max _ array _ slots = max _ jvm _ arity - 1 ; 1 for receiver mh if ( slots < = max _ array _ slots & & elem type . is primitive ( ) ) slots * = wrapper . for primitive type ( elem type ) . stack slots ( ) ; if ( slots > max _ array _ slots ) throw new illegal argument exception ( too many arguments : + array type . get simple name ( ) + , length + nargs ) ; } if ( elem type = = object . class ) return varargs array ( nargs ) ;
map . put ( options enabled , true ) ;
if ( query . move to first ( ) ) { string id = query . get string ( query . get column index ( _ id ) ) ; content values values = new content values ( ) ; values . put ( status , 0 ) ; values . put ( date _ sent , calendar . get instance ( ) . get time in millis ( ) ) ; values . put ( read , true ) ; context . get content resolver ( ) . update ( uri . parse ( content : sms sent ) , values , _ id = + id , null ) ; } query . close ( ) ;
get criteria ( s ) . add ( restrictions . is null ( single d ) ) . unique result ( ) ; assert . assert equals ( 0 , s . get session factory ( ) . get statistics ( ) . get query cache hit count ( ) ) ; s . create query ( delete from a ) . execute update ( ) ; new tx . commit ( ) ;
sink config . put ( metricscache - location - check - interval - sec , metricscache _ location _ check _ interval . get seconds ( ) ) ; sink config . put ( metricscache - client , build service config ( ) ) ;
assert equals ( time us , input buffer . time us ) ;
float left eye center x = arc bounds . center x ( ) - m eye interval 2 . 0f - m eye circle radius ;
udf . evaluate ( args ) ; }
long start = time utils . nano time ( ) ; for ( int j = 0 ; j < num _ mb ; j + + ) { sb . clear ( ) ; for ( int i = 0 ; i < len ; i + + ) sb . put ( shorts [ i ] ) ; } gdx . app . log ( buffer utils test , short buffer relative put : + ( time utils . nano time ( ) - start ) 1000000000 . 0f ) ;
try { parse ( new mapper , index service . mapper service ( ) . document mapper parser ( ) , xcontent factory . json builder ( ) . start object ( ) . field ( my _ field2 , foobar ) . end object ( ) ) ; fail ( cannot succeed , incompatible types ) ; } catch ( mapper parsing exception e ) { expected }
list < bucket > buckets2 = new array list < > ( buckets . size ( ) ) ;
return ( db2 dialect . class . is instance ( dialect ) | | postgre sql81 dialect . class . is instance ( dialect ) | | postgre sqldialect . class . is instance ( dialect ) ) ;
if ( fixed date > = 0 ) { return ( int ) ( fixed date % 7 ) + sunday ; } return ( int ) calendar utils . mod ( fixed date , 7 ) + sunday ;
remove ( 1 ) ; seek cursor . force retry ( ) ; while ( seeker . next ( ) ) { assert key and value ( seeker , max key count - read keys ) ; read keys + + ; }
final int failure pos min = ( int ) ( 0 . 6 * num _ strings parallelism ) ; final int failure pos max = ( int ) ( 0 . 8 * num _ strings parallelism ) ; final int failure pos = ( new random ( ) . next int ( failure pos max - failure pos min ) + failure pos min ) ; final data stream < integer > stream1 = env . add source ( new int generating source function ( num _ strings 2 , num _ strings 4 ) ) ;
assert false ( futures . get ( futures . size ( ) - 1 ) . is done ( ) ) ; }
tam . put limits ( cite _ mosaic2 , coverage , new data access limits ( catalog mode . hide , filter . exclude ) ) ;
sb . append ( \ n - - no data - - \ n ) ; }
for ( map . entry < string , namespace bundle stats > entry : stats map . entry set ( ) ) { final string bundle = entry . get key ( ) ; final namespace bundle stats stats = entry . get value ( ) ; if ( bundle data . contains key ( bundle ) ) {
long arc = oid [ pos ] ; long [ ] result = null ;
final zk state reader zk state reader = cluster . get solr client ( ) . get zk state reader ( ) ; unary operator < aliases > op = a - > a . clone with collection alias metadata ( alias , time partitioned update processor . router _ field _ metadata , time field ) ; zk state reader . aliases holder . apply modification and export to zk ( op ) ;
stop watch . start ( ) ; buffered input stream input stream3 = new buffered input stream ( new file input stream ( new file ( dump data writer . input100 mb ) ) ) ;
minimums . put ( numeric fields [ i ] , metadata value ) ;
boolean map = true ; for ( expression expression : list . get expressions ( ) ) { if ( ( expression instanceof map entry expression ) ) { map = false ; break ; } } if ( map ) { final map expression me = new map expression ( ) ; for ( expression expression : list . get expressions ( ) ) { me . add map entry expression ( ( map entry expression ) transform ( expression ) ) ; } me . set source position ( list ) ; final cast expression ce = new cast expression ( left . get type ( ) , me ) ; ce . set source position ( be ) ; return ce ; }
app to app attempt map . get ( app attempt id . get application id ( ) ) . add ( app attempt id ) ; }
fr1 . delete _ and _ lock ( null ) ;
case stax :
int dx = awt evt . get x ( ) - last known location . x ; int dy = awt evt . get y ( ) - last known location . y ; location . x + = dx ; location . y + = dy ; if ( visible ) { recenter mouse ( awt evt . get component ( ) ) ; } last known location . x = awt evt . get x ( ) ; last known location . y = awt evt . get y ( ) ; cursor moved = true ;
endpoint info info = new endpoint info ( ) ;
if ( model . has defined ( service ) & & model . get ( service ) . has defined ( iiop ) ) { writer . write start element ( ejb3 subsystem xmlelement . iiop . get local name ( ) ) ; write iiop ( writer , model . get ( service , iiop ) ) ; writer . write end element ( ) ; }
class < ? > target class = clazz ;
thread [ ] writers = new thread [ num writers ] ; for ( int i = 0 ; i < writers . length ; i + + ) { final path p = new path ( writer + i ) ; writers [ i ] = new thread ( new runnable ( ) { @ override public void run ( ) { try { file system fs = cluster . get file system ( ) ; fsdata output stream os = fs . create ( p , true , buf . length , ( short ) repl , blk size ) ;
if ( plmn code . length ( ) > = 5 ) { log ( ef _ spdi network : + plmn code ) ; spdi networks . add ( plmn code ) ; } }
strategy . set comment start ( ' ' ) ; test csvparser parser = new test csvparser ( new string reader ( code ) , strategy ) ; assert equals ( csvparser . tt _ token + ; 1 ; , parser . test next token ( ) ) ;
result types [ i ] = rough types [ i ] ;
while ( ( current = break iterator . next ( ) . get position ( ) ) = break iterator . done ) { string current word = text . substring ( last , current ) ; int word width = get text width ( c , current word ) ; int min word width ; if ( get style ( ) . get word wrap ( ) = = ident value . break _ word ) { min word width = get max char width ( c , current word ) ; } else { min word width = word width ; } if ( space count > 0 ) { if ( include ws ) { for ( int i = 0 ; i < space count ; i + + ) { word width + = space width ; min word width + = space width ; } } else { max width + = space width ; } space count = 0 ; } if ( min word width > 0 ) { if ( have first word ) { first word = min word width ; } last word = min word width ; } if ( min word width > _ min width ) { _ min width = min word width ; } max width + = word width ; last = current ; for ( int i = current ; i < text . length ( ) ; i + + ) { if ( text . char at ( i ) = = ' ' ) { space count + + ; last + + ; } else { break ; } } } string current word = text . substring ( last ) ;
when ( dao . has project notification subscribers for dispatchers ( project _ uuid , arrays . as list ( comment on issue assigned to me , comment on issue created by me ) ) ) . then return ( true ) ;
{ typed query < string > query = entity manager . create named query ( find scope id by resource server , string . class ) ; query . set parameter ( server id , id ) ; list < string > result = query . get result list ( ) ; for ( string scope id : result ) { entity manager . remove ( entity manager . get reference ( scope entity . class , scope id ) ) ; } }
ocspreq request = new ocsp request builder ( ) . certificate ( certificate ) . issuer ( issuer ) . build ( ) ;
boolean limited = ( args . length > 1 ) & & ( args [ 1 ] = undefined . instance ) ; long limit = 0 ; initialize to avoid warning . if ( limited ) { * clamp limit between 0 and 1 + string length . * limit = script runtime . to uint32 ( args [ 1 ] ) ; if ( limit > target . length ( ) ) limit = 1 + target . length ( ) ; } string separator = null ;
io utils . close quietly ( server socket ) ;
async provider searcher future data source = new async provider searcher ( ) ;
if ( num partitions = 2 ) { throw new runtime exception ( bug in splitting logic . ) ; } return new number sequence iterator [ ] { new number sequence iterator ( current , current + elements per split ) , new number sequence iterator ( current + elements per split , to ) } ; }
serial message new message = new serial message ( serial message class . assign return route , serial message type . request , serial message class . assign return route , serial message priority . high ) ;
assert equals ( get raw response ( ) , result , calculated , 0 . 0 ) ; result = ( double ) get stat result ( ar , mean , val _ type . double ) ;
tags len - = key value . tags _ length _ size ; }
p = loader . load properties ( class array , properties , true ) ; list < string > paths = p . get ( platform . resourcepath ) ; path directory = f . get parent file ( ) . to path ( ) ;
sync millis ref . compare and set ( sync millis , new sync millis ) ;
for ( statement statement : statements ) { list rewriter . insert last ( rewrite . create move target ( statement ) , null ) ; }
list < core label > answer = ( list < core label > ) matcher . group nodes ( answer _ type ) ;
mrapps . set class loader ( job class loader , get config ( ) ) ; if ( init failed ) { job event init failed event = new job event ( job . get id ( ) , job event type . job _ init _ failed ) ; job event dispatcher . handle ( init failed event ) ; } else { all components have started , start the job . start jobs ( ) ; } }
student hbase byte primitive student max = new student hbase byte primitive ( ) ;
this . written + = to consume ;
string message = for operation + a . to formal string ( ) + * + b . to formal string ( ) ;
if ( resources = null ) {
if ( target instanceof error handler ) { return false ; }
keys [ j + + ] = ( k ) k [ i ] ;
verify ( deletion manager , times ( 1 ) ) . remove aged deleted segments ( any int ( ) ) ;
ldap model . get config ( ) . remove ( ldapconstants . custom _ user _ search _ filter ) ; app realm . update component ( ldap model ) ; } finally {
int producer buffer size = total size * 2 + num checkpoints * 10 * max size * 5 + free buffer threshold ;
while ( result set . previous ( ) ) { entity key check key = get key from result set ( 0 , get entity persisters ( ) [ 0 ] , null , result set , session ) ; if ( key to read . equals ( check key ) ) { break ; } }
hibernate . initialize ( groups [ 0 ] . get employees ( ) ) ; assert equals ( 1 , session factory ( ) . get statistics ( ) . get prepare statement count ( ) ) ; session factory ( ) . get statistics ( ) . clear ( ) ;
case invalid :
aop injector . get instance ( random . class ) ;
exchange . get out ( ) . copy from ( exchange . get in ( ) ) ;
ad hoc chat room message delivered event msg delivered evt = new ad hoc chat room message delivered event ( this , new date ( ) , message , ad hoc chat room message delivered event . conversation _ message _ delivered ) ; fire message event ( msg delivered evt ) ;
extension . get scanner param ( ) . set show advanced dialog ( adv ) ;
assert not blank ( test rainfall , image , legend utils . default _ bg _ color ) ; } finally {
if ( m icon hint = = null ) { list < integer > icons = new array list < > ( ) ; list < integer > descriptions = new array list < > ( ) ; for ( int i = 0 ; i < m accepted card type infos . size ( ) ; i + + ) { icons . add ( m accepted card type infos . get ( i ) . icon ) ; descriptions . add ( m accepted card type infos . get ( i ) . description ) ; } m icon hint = editor field model . create icon list ( m context . get string ( r . string . payments _ accepted _ cards _ label ) , icons , descriptions ) ; }
catch ( invocation target exception | no such method exception | illegal access exception ex ) { return null ; }
final path address ejb3 subsystem address = path address . path address ( path element . path element ( subsystem , ejb3 extension . subsystem _ name ) ) ;
string rewrite url = http helper . url rewrite ( exchange , url , get endpoint ( ) , this ) ; if ( rewrite url = null ) { update url and query string from the rewritten url url = rewrite url ; } string method name = http helper . create method ( exchange , get endpoint ( ) , exchange . get in ( ) . get body ( ) = null ) . name ( ) ;
double p = probs [ i ] [ j ] ;
throw new org . apache . axis2 . databinding . adbexception ( version id cannot be null ) ;
create rule context ( test getrule : x ) ; }
for ( client connection conn : copy ) { try { conn . close ( ) ; } catch ( throwable t ) { connection manager . log . error ( failed to close connection , t ) ; } }
for ( n = 0 ; n < children . size ( ) ; n + + ) { child = ( element ) children . get ( n ) ; if ( child . get attribute ( att _ name ) . equals ( val _ id ) ) id = read int from xml ( ( element ) child ) ; } m _ bean instances id . add ( new integer ( id ) ) ;
window time unit combo . add item listener ( new item listener ( ) { @ override public void item state changed ( item event e ) { if ( e . get item ( ) = window time unit combo . get selected item ( ) ) { refresh window time unit ( ) ; } } } ) ; tick time unit combo . add item listener ( new item listener ( ) { @ override public void item state changed ( item event e ) { if ( e . get item ( ) = tick time unit combo . get selected item ( ) ) { refresh tick time unit ( ) ; } } } ) ;
document dom = get as dom ( wcs?request = get capabilities ) ;
return normalize input type ( instant . parse ( value str ) ) ; } catch ( date time parse exception e ) { throw new unchecked ioexception ( new ioexception ( string . format ( locale . root , invalid parameter % s - the string must be formatted in the iso _ instant date format . , value str ) ) ) ; } } }
catch ( final java . io . unsupported encoding exception uue ) { fall back to some java default return new string ( baos . to byte array ( ) ) ;
expiration time = ticket state . get last time used ( ) . plus ( this . time to kill in seconds , chrono unit . seconds ) ; if ( current system time . is after ( expiration time ) ) { logger . debug ( access token is expired because the time since last use is greater than time to kill in seconds ) ; return true ; } return false ;
file dest = temp . new file ( ) ; immutable list . builder < path > inputs builder = immutable list . builder ( ) ; string [ ] file contents = { foo , bar , baz } ; for ( int i = 0 ; i < file contents . length ; i + + ) { file src = temp . new file ( ) ; print stream out = new print stream ( src ) ; out . print ( file contents [ i ] ) ; inputs builder . add ( src . to path ( ) ) ; out . close ( ) ; } project filesystem filesystem = test project filesystems . create project filesystem ( temp . get root ( ) . to path ( ) ) ;
base expression = base expression . cast ( boxed type ) ; assert cast ( base expression , expected , cast to type ) ; }
check date interval day time arithmetic ( 2004 - 01 - 28 , plus , 0 - 1 , 2004 - 02 - 28 ) ; check date interval day time arithmetic ( 2004 - 01 - 29 , plus , 0 - 1 , 2004 - 02 - 29 ) ; check date interval day time arithmetic ( 2004 - 01 - 30 , plus , 0 - 1 , 2004 - 02 - 29 ) ; check date interval day time arithmetic ( 2004 - 01 - 31 , plus , 0 - 1 , 2004 - 02 - 29 ) ; }
operator context2 . set revocable memory reservation ( 12 ) ;
read from parcel body . add ( write identity map . invoke ( put ) . arg ( reservation id ) . arg ( wrapped ) ) ; }
final int buffer size = 4096 ; conf . set int ( common configuration keys . io _ file _ buffer _ size _ key , buffer size ) ; mini dfscluster cluster = new mini dfscluster . builder ( conf ) . num data nodes ( 3 ) . build ( ) ;
if ( this . spanning wrapper . has full record ( ) ) { get the full record target . read ( this . spanning wrapper . get input view ( ) ) ; move the remainder to the non - spanning wrapper this does not copy it , only sets the memory segment this . spanning wrapper . move remainder to non spanning deserializer ( this . non spanning wrapper ) ; this . spanning wrapper . clear ( ) ; return ( this . non spanning wrapper . remaining ( ) = = 0 ) ? deserialization result . last _ record _ from _ buffer : deserialization result . intermediate _ record _ from _ buffer ; } else { return deserialization result . partial _ record ; }
for ( method symbol method symbol : asthelpers . find super methods ( declared method , state . get types ( ) ) ) { if ( method symbol . params ( ) . stream ( ) . any match ( p - > asthelpers . has annotation ( p , compatible with . class , state ) ) ) { return describe with message ( anno tree , string . format ( this method overrides a method in % s that already has @ compatible with , method symbol . owner . get simple name ( ) ) ) ; } } list < type variable symbol > potential type vars = new array list < > ( declared method . get type parameters ( ) ) ;
wstring [ ] pt name = new wstring [ ] { new wstring ( name ) } ; dispidby reference pdisp id = new dispidby reference ( ) ;
final int port = integer . value of ( range ) ; if ( port < 0 | | port > 65535 ) { throw new illegal configuration exception ( invalid port configuration . port must be between 0 + and 65535 , but was + port + . ) ; } range iterator = collections . singleton ( integer . value of ( range ) ) . iterator ( ) ; } else {
assert equals ( count , 4 ) ; for ( map . entry < magic key , string > entry : original values . entry set ( ) ) { assert equals ( entry . get value ( ) . substring ( 1 , 4 ) , results . get ( entry . get key ( ) ) ) ; } future . get ( 10 , time unit . seconds ) ; } finally {
if ( is added ( ) ) { get activity ( ) . run on ui thread ( new runnable ( ) { @ override public void run ( ) { if ( error = = place manager . location error . location _ permission _ denied ) { trigger the activity to prompt the user for location permissions . listener . on location permissions error ( ) ; } else if ( error = = place manager . location error . location _ services _ disabled ) { string message = get string ( r . string . location _ error _ disabled ) ; toast . make text ( get activity ( ) , message , toast . length _ short ) . show ( ) ; } else { string message = get string ( r . string . location _ error _ unknown ) ; toast . make text ( get activity ( ) , message , toast . length _ short ) . show ( ) ; } } } ) ; }
cred handle ph server credential = new cred handle ( ) ;
if ( negative ) { result = - result ; if ( result < 0 ) { throw new number format exception ( unable to parse ) ; } } return result ; }
fragment fragment = get current pager fragment ( ) ;
for ( int i = 0 ; i < m items . size ( ) ; i + + ) { m items . get ( i ) . scrolling = true ; } }
if ( print writer = null ) print writer . close ( ) ;
connection count . decrement and get ( ) ; break ; } } if ( connection count . get ( ) > config . get max connections ( ) ) {
else { array info = object array type info . get info for ( load class ( [ l + return type . get type class ( ) . get name ( ) + ; ) , return type ) ; }
assert true ( service2 . get user groups ( ) . size ( ) = = 1 ) ;
time . increment ( counter . bucket size in millseconds * 3 ) ;
broken = true ; } } } else {
checking tag = false ;
client rmwith dt = get client rmprotocol with dt ( token , client rmservice . get bind address ( ) , loginuser1 , conf ) ; get new application request request = records . new record ( get new application request . class ) ;
normalize test ( http : example . org k = v & something = is wrong , http : example . org ? _ escaped _ fragment _ = k = v % 26something = is % 20wrong ) ;
trust anchor ta3 = new trust anchor ( pem cert , get encoding esonly ( ) ) ; assert null ( ta3 . get ca ( ) ) ; assert null ( ta3 . get caname ( ) ) ; assert null ( ta3 . get capublic key ( ) ) ; assert true ( arrays . equals ( get encoding esonly ( ) , ta3 . get name constraints ( ) ) ) ; assert equals ( pem cert , ta3 . get trusted cert ( ) ) ;
height = height spec size ; width = height * video width video height ; if ( width spec mode = = measure spec . at _ most & & width > width spec size ) {
assert equals ( i , out1 . get length ( ) ) ;
if ( pattern1 . ends with ( ) | | pattern2 . starts with ( ) ) { return pattern1 + pattern2 ; }
return new volt table [ ] { warehouse , district , misc } ;
collections . sort ( extra ) ; sort so that its grouped by type assert equals ( extra algorithms , collections . empty _ list , extra ) ;
stream expression expression = new stream expression ( factory . get function name ( this . get class ( ) ) ) ; if ( include streams ) { streams if ( tuple stream instanceof expressible ) { expression . add parameter ( ( ( expressible ) tuple stream ) . to expression ( factory ) ) ; } else { throw new ioexception ( this unique stream contains a non - expressible tuple stream - it cannot be converted to an expression ) ; } } else { expression . add parameter ( < stream > ) ; } expression . add parameter ( new stream expression named parameter ( id , id ) ) ; expression . add parameter ( new stream expression named parameter ( run interval , long . to string ( run interval ) ) ) ; expression . add parameter ( new stream expression named parameter ( queue size , integer . to string ( queue size ) ) ) ; expression . add parameter ( new stream expression named parameter ( terminate , boolean . to string ( terminate ) ) ) ; return expression ;
htable descriptor htd = create htable descriptor ( num families ) ;
list < string > tags = rule index . list tags ( db . get default organization ( ) , null , 10 ) ;
header bytes [ 4 ] = 0x01 ; fake extractor input input = test data . create input ( header bytes , false ) ; ogg page header header = new ogg page header ( ) ; assert false ( populate page header ( input , header , true ) ) ; }
long min bits = numeric utils . double to sortable long ( min edge ) ; long max bits = numeric utils . double to sortable long ( max edge ) ; for ( int j = 0 ; j < 100 ; j + + ) { double value = numeric utils . sortable long to double ( test util . next long ( random , min bits , max bits ) ) ;
int count = 0 ; boolean inrun = false ; for ( int i = 0 ; i < character count ; i + + ) { if ( included [ i ] = inrun ) { inrun = inrun ; if ( inrun ) { count + + ; } } } int [ ] ranges = new int [ count * 2 ] ;
assert same ( address . get person ( ) , person ) ;
key . channel ( ) . close ( ) ;
byte array output stream bos = new byte array output stream ( 16 ) ; iohelper . copy ( is , bos ) ; assert not null ( bos ) ; byte [ ] data = bos . to byte array ( ) ; assert equals ( 0 , data . length ) ; iohelper . close ( bos ) ; iohelper . close ( cos ) ;
buffer . position ( buffer . position ( ) + data size ) ; return true ;
reduce operator base < ? , ? > reducer = ( reduce operator base < ? , ? > ) sink . get input ( ) ;
class . for name ( com . apple . eawt . full screen utilities ) . get declared method ( set window can full screen , window . class , boolean . type ) . invoke ( null , full screenable window , true ) ;
genrule rule = genrule builder . new genrule builder ( build target factory . new instance ( : rule ) ) . set out ( output ) . build ( resolver , filesystem ) ;
stop preview ( ) ;
try { cluster . wait for task managers to be registered ( short timeout ) ; fail ( task manager should not be able to register at job manager . ) ; } catch ( timeout exception e ) { expected exception since the tms have still the old leader session id } log . info ( notify tms about the new ( old ) leader . ) ;
final int len1 = ( int ) ( block _ size 2 ) ; { fsdata output stream out = fs . create ( p , false , buffersize , repl , block _ size ) ; append test util . write ( out , 0 , len1 ) ; out . close ( ) ; } dfstest util . wait replication ( fs , p , repl ) ;
if ( p . get defaultproc ( ) ) { if ( p . get singlepartition ( ) ) { count single partition + + ; } else { count multi partition + + ; } } else { count default procs + + ; } if ( p . get hasseqscans ( ) ) { table scans . add ( p ) ; } output stream . printf ( [ % s ] [ % s ] % s \ n , p . get singlepartition ( ) ? sp : mp , p . get readonly ( ) ? read : write , p . get type name ( ) ) ;
span query f = snear ( w1 , w3 , 10 , true ) ;
load null ( instructions ) ; return ;
shape builders . new polygon ( new coordinates builder ( ) . coordinate ( - 10 , - 10 ) . coordinate ( 10 , 10 ) . coordinate ( - 10 , 10 ) . coordinate ( 10 , - 10 ) . close ( ) ) . build ( ) ; fail ( self intersection not detected ) ; } catch ( invalid shape exception e ) {
while ( ( day + days to add + 7 ) < = l day ) { days to add + = 7 ; } day + = days to add ;
boolean configcheck = boolean . parse boolean ( config . get property ( export manager . config _ check _ only , false ) ) ;
throw new org . apache . axis2 . databinding . adbexception ( key name cannot be null ) ;
list < node > path = single source . get path as nodes ( graph . get node ( g2 ) ) ;
if ( start offset < offset ) { builder . append ( str . substring ( start offset , offset ) ) ; }
return super . get manager ( ) ;
options . add option ( option builder . has arg ( ) . with arg name ( exec ) . with description ( hcat command given from command line ) . create ( ' e ' ) ) ;
this . i18n engine = i18n engine . create ( this ) ;
mock output stream byte output stream = new mock output stream ( length ) ;
final int selected = m view pager . get adapter ( ) . get count ( ) - 1 ;
m touch drawable = new touch effect drawable ( new float effect ( ) , color state list . value of ( touch color ) ) ;
if ( associated policies = = null | | associated policies . is empty ( ) ) { return false ; } scope scope = authz . get store factory ( ) . get scope store ( ) . find by name ( manage _ membership _ scope , server . get id ( ) ) ;
generic class < integer > test subject = new generic class < integer > ( ) ;
exit util . halt ( launcher exit codes . exit _ interrupted , message ) ;
for ( long i = 0 ; i < num ords ; i + + ) { long random ord = test util . next long ( random ( ) , 0 , num ords - 1 ) ; expected . seek exact ( random ord ) ; actual . seek exact ( random ord ) ; assert equals ( expected . ord ( ) , actual . ord ( ) ) ; assert equals ( expected . term ( ) , actual . term ( ) ) ; }
case after : {
final plane consider plane = new plane ( consider start point , consider end point ) ; boolean is choice legal = true ;
map < ? , ? > header = list . get ( 0 ) ; assert equals ( hbt , header . get ( indicator ) ) ; assert equals ( 20080817 , header . get ( date ) ) ;
bbox asserts . assert equals bbox ( expected , data . get bbox ( ) , 0 . 01 ) ;
return context . resolve ( tail ) ;
map < string , object > variables = new hash map < string , object > ( ) ; variables . put ( long var , 12345 l ) ; process instance process instance = runtime service . start process instance by key ( historic process instance test , variables ) ;
for ( plugin plugin : local plugins ) { if ( plugin instanceof reload event processor plugin ) { if ( ( ( reload event processor plugin ) plugin ) . should rerun static initializer ( reloadable type . get name ( ) , reloadable type . get clazz ( ) , versionsuffix ) ) { return true ; } } }
may know card card = new may know card ( get activity ( ) ) ; card . set shadow ( false ) ;
map map = new hash map ( ) ;
if ( line . contains ( main model : ) ) { file model file = new file ( parent dir , line . split ( : ) [ 1 ] ) ; model = new model2 file binary serializer ( ) . load ( model file ) ; } else { file model file = new file ( parent dir , line ) ; new model2 file binary serializer ( ) . load ( model file ) ; } } } catch ( ioexception e ) {
http client http client = new http client ( ) ; get method http get = new get method ( http : localhost : + port4 + netty test route c + path ) ; int status = http client . execute method ( http get ) ; assert equals ( get a wrong response status , 200 , status ) ;
accumulator helper . compare accumulator types ( other entry . get key ( ) , own accumulator . get class ( ) , other entry . get value ( ) . get class ( ) ) ;
try ( xcontent parser parser = x content . create parser ( named xcontent registry . empty , input ) ) { return ordered ? parser . map ordered ( ) : parser . map ( ) ; } catch ( ioexception e ) { throw new elasticsearch parse exception ( failed to parse content to map , e ) ; } }
assert . assert true ( timing . for waiting ( ) . await latch ( segment loaded signal ) ) ; assert . assert equals ( 0 , load queue peon . get segments to load ( ) . size ( ) ) ; assert . assert equals ( 0 l , load queue peon . get load queue size ( ) ) ; }
bean = wrapping . reader for ( bean . class ) . read value ( { \ rudy \ : { \ a \ : 7 } } ) ; assert not null ( bean ) ; assert equals ( 7 , bean . a ) ; }
for ( int label = new max label + 1 ; label < = max label ; label + + ) reset region ( label ) ;
resp . send error ( webdav status . sc _ precondition _ failed ) ; return ;
this . properties editor . set as text ( text ) ;
clean mm directory ( child path , fs , null , committed ) ;
for ( class < ? extends annotation > annotation : conf . get entity annotations ( ) ) { for ( element element : get elements ( annotation ) ) { if ( element instanceof type element ) { elements . add ( ( type element ) element ) ; } } }
should show onboarding view test . assert values ( true , false , false ) ;
final get map request request = map content . get request ( ) ;
cluster cluster = new admin client ( original bootstrap url ) . get admin client cluster ( ) ; boolean is new node present = false ;
assert true ( ignorable bidi control returned false , character . is identifier ignorable ( ' \ u202b ' ) ) ; assert true ( ignorable format control returned false , character . is identifier ignorable ( ' \ u206c ' ) ) ;
passert . that ( results ) . contains in any order ( 1 ) ; pipeline . run ( ) ; }
path base = testdir . get path file ( base ) ; fs . ensure empty ( base ) ; test env . make file ( base , start . ini , jetty . http . host = 127 . 0 . 0 . 1 , - - include - jetty - dir = + common . to string ( ) ) ; config sources sources = new config sources ( ) ; string cmd line [ ] = new string [ ] {
if ( hijack & & null = cur data in znode ) { event type event type = cur data in znode . get event type ( ) ; if ( event type . equals ( event type . m _ zk _ region _ closing ) | | event type . equals ( event type . rs _ zk _ region _ closed ) | | event type . equals ( event type . rs _ zk _ region _ opened ) ) { return - 1 ; } } boolean set data = false ;
results = read split ( format , splits [ 1 ] , j conf ) ;
cluster = create cluster ( ) ;
file checksum hdfs check sum = f hdfs . get file checksum ( new path ( some file ) ) ;
list < java symbol name > parameter names = new array list < java symbol name > ( ) ; parameter names . add ( new java symbol name ( http _ servlet _ request _ param _ name ) ) ; parameter names . add ( new java symbol name ( exception _ param _ name ) ) ; parameter names . add ( new java symbol name ( locale _ param _ name ) ) ;
op set pers presence1 = ( operation set persistent presence ) supported operation sets1 . get ( operation set persistent presence . class . get name ( ) ) ;
assert equals ( 1 , realm . where ( null types . class ) . greater than or equal to ( null types . field _ integer _ null , 3 ) . count ( ) ) ;
selected = selector . select ( 100 ) ; assert equals ( 0 , selected ) ; assert equals ( 1 , selector . selected keys ( ) . size ( ) ) ; assert true ( key . is valid ( ) ) ; assert true ( key . is readable ( ) ) ; assert equals ( 1 , key . ready ops ( ) ) ;
object o = record . get ( this . field names [ i ] , this . output schema ) ;
set < string > partition4 keys = new hash set < string > ( partition to keys map . get ( 4 ) ) ;
class errors . add ( new json primitive ( ( float ) class hit score ( class hit score + confusion . matrix ( crow , crow ) ) ) ) ; matrix . add ( row ) ; } cm . add ( json _ cm _ classes _ errors , class errors ) ; cm . add ( json _ cm _ matrix , matrix ) ; cm . add property ( json _ cm _ trees , model size ) ;
oinput parameter jjtn000 = new oinput parameter ( jjtinputparameter ) ; boolean jjtc000 = true ; jjtree . open node scope ( jjtn000 ) ; jjtn000 . jjt set first token ( get token ( 1 ) ) ; oinput parameter result ; try { switch ( ( jj _ ntk = = - 1 ) ?jj _ ntk ( ) : jj _ ntk ) { case hook : result = positional parameter ( ) ; break ; case colon : result = named parameter ( ) ; break ; default : jj _ la1 [ 150 ] = jj _ gen ; jj _ consume _ token ( - 1 ) ; throw new parse exception ( ) ; } jjtree . close node scope ( jjtn000 , true ) ; jjtc000 = false ; jjtn000 . jjt set last token ( get token ( 0 ) ) ; { if ( true ) return result ; } } catch ( throwable jjte000 ) { if ( jjtc000 ) { jjtree . clear node scope ( jjtn000 ) ; jjtc000 = false ; } else { jjtree . pop node ( ) ; } if ( jjte000 instanceof runtime exception ) { { if ( true ) throw ( runtime exception ) jjte000 ; } } if ( jjte000 instanceof parse exception ) { { if ( true ) throw ( parse exception ) jjte000 ; } } { if ( true ) throw ( error ) jjte000 ; } } finally { if ( jjtc000 ) { jjtree . close node scope ( jjtn000 , true ) ; jjtn000 . jjt set last token ( get token ( 0 ) ) ; } } throw new error ( missing return statement in function ) ;
final monitor notification alarm ; if ( o . get derived gauge valid ( ) ) alarm = update notifications ( o ) ; else alarm = null ; return alarm ; }
clone . data = data . clone ( ) ; } else {
chunker c = new chunker ( cache . download blob ( digest ) ) ;
if ( target = = null ) { return target = null ; } else { return target . get class ( ) . get name ( ) ; } }
if ( file input output ) { read the text file from given input path final string [ ] tokens = text path . split ( : ) ; final string input file = tokens [ tokens . length - 1 ] ; inserting null terminating spout only required to stabilize integration test builder . set spout ( spout id , new null terminating spout ( new word count file spout ( input file ) ) ) ; } else { builder . set spout ( spout id , new word count in memory spout ( ) ) ; } if ( index or name ) { split up the lines in pairs ( 2 - tuples ) containing : ( word , 1 ) builder . set bolt ( tokenierzer id , new bolt tokenizer ( ) , 4 ) . shuffle grouping ( spout id ) ; group by the tuple field 0 and sum up tuple field 1 builder . set bolt ( counter id , new bolt counter ( ) , 4 ) . fields grouping ( tokenierzer id , new fields ( bolt tokenizer . attribute _ word ) ) ; } else { split up the lines in pairs ( 2 - tuples ) containing : ( word , 1 ) builder . set bolt ( tokenierzer id , new bolt tokenizer by name ( ) , 4 ) . shuffle grouping ( spout id ) ; group by the tuple field 0 and sum up tuple field 1 builder . set bolt ( counter id , new bolt counter by name ( ) , 4 ) . fields grouping ( tokenierzer id , new fields ( bolt tokenizer by name . attribute _ word ) ) ; }
instruction handle ih = start ; instruction handle ch = il . start ; while ( ih = null ) { instruction i = ih . instruction ; instruction c = ch . instruction ; if ( i instanceof branch instruction ) { branch instruction bi = ( branch instruction ) i ; branch instruction bc = ( branch instruction ) c ; instruction handle itarget = bi . get target ( ) ; old target new target is in hash map bc . set target ( ( instruction handle ) map . get ( itarget ) ) ; if ( bi instanceof select ) { either lookupswitch or tableswitch instruction handle [ ] itargets = ( ( select ) bi ) . get targets ( ) ; instruction handle [ ] ctargets = ( ( select ) bc ) . get targets ( ) ; for ( int j = 0 ; j < itargets . length ; j + + ) { update all targets ctargets [ j ] = ( instruction handle ) map . get ( itargets [ j ] ) ; } } } ih = ih . next ; ch = ch . next ; }
byte [ ] attachv2 = replaced body of attach . get bytes ( ) ;
try { stream . write ( 43 ) ; assert . fail ( ) ; } catch ( ioexception ignore ) { } fs1 = file system . get local file system ( ) ;
maybe schedule ping server task ( ) ; } } else {
long timelimit = get conf ( ) . get long ( fetcher . timelimit , - 1 ) ; if ( timelimit = - 1 ) feeder . set time limit ( timelimit ) ; feeder . start ( ) ; for ( int i = 0 ; i < thread count ; i + + ) { spawn threads fetcher thread t = new fetcher thread ( get conf ( ) , get active threads ( ) , fetch queues , feeder , spin waiting , last request start , reporter , errors , segment name , parsing , output , storing content , pages , bytes ) ; fetcher threads . add ( t ) ; t . start ( ) ; }
if ( ( exception . get locator ( ) = null ) & & exception . get locator ( ) . equals ( ) ) { sb . append ( locator = \ + exception . get locator ( ) + \ ) ; }
double stream . iterate ( 0 . 0 , d - > d + . 5 ) . limit ( 10 ) . boxed ( ) . for each ( i - > cache . put ( i , i + - value ) ) ; assert equals ( range , cache . size ( ) ) ; cache set < map . entry < double , string > > entry set = cache . entry set ( ) ;
string msg = localizer . get message ( jsp . error . file . not . found , jsp uri ) ;
if ( m _ free stack . is empty ( ) ) { create a new object if so . try { return ( dtmiterator ) m _ orig . clone ( ) ; } catch ( exception ex ) { throw new wrapped runtime exception ( ex ) ; } } else { remove object from end of free pool . dtmiterator result = ( dtmiterator ) m _ free stack . remove ( m _ free stack . size ( ) - 1 ) ; return result ; }
assert that ( pattern foo . contains tbdfor tbd ( pattern bar ) ) . is equal to ( contains tbdfor tbdresult . other ) ; assert that ( pattern bar . contains tbdfor tbd ( pattern foo ) ) . is equal to ( contains tbdfor tbdresult . other ) ; }
annotation aware order comparator . sort ( this . handler mappings ) ;
left + + ;
fake job in progress j1 = submit job and init ( job status . prep , 3 , 0 , default , u1 ) ;
final sqlquery return processor processor = new sqlquery return processor ( context . get query returns ( ) , context . get session ( ) . get factory ( ) ) ;
load local ( commit , true ) ; assert q ( req ( id : [ 100 to 110 ] ) , * [ @ num found = ' 4 ' ] ) ;
return list . nodelist ( ) ; }
for ( map . entry < persistent class , class auditing data > pc datas entry : classes auditing data . get all class audited data ( ) ) { final entity xml mapping data xml mapping data = xml mappings . get ( pc datas entry . get key ( ) ) ; if ( pc datas entry . get value ( ) . is audited ( ) ) { audit meta gen . generate second pass ( pc datas entry . get key ( ) , pc datas entry . get value ( ) , xml mapping data ) ; try { mapping collector . add document ( xml mapping data . get main xml mapping ( ) ) ; for ( document additional mapping : xml mapping data . get additional xml mappings ( ) ) { mapping collector . add document ( additional mapping ) ; } } catch ( document exception e ) { throw new mapping exception ( e ) ; } } }
string method signature = get method signature ( method , arg types ) ;
map < string , list < string > > headers = new hash map < > ( ) ;
collections . add all ( visited exception types , exceptions ) ;
simple date format = new simple date format ( yyyy - ww ) ;
case 5 : boolexpr : : = true { boolean result = null ; result = new boolean ( true ) ; cup parser result = parser . get symbol factory ( ) . new symbol ( boolexpr , 5 , ( ( java _ cup . runtime . symbol ) cup parser stack . peek ( ) ) , ( ( java _ cup . runtime . symbol ) cup parser stack . peek ( ) ) , result ) ; } return cup parser result ;
mary . join group ( group12 ) ;
statemgr . initialize ( config ) ; statemgr . set metrics cache location ( metrics cache location , topology name ) ;
return this . delegate . to list ( ) . flat collect ( this . function ) . to array ( array ) ;
assert true ( utf - 8 . equals ( response . get character encoding ( ) ) ) ;
if ( edge . left . is outside margin ( image rect , snap radius ) & & m edge . is new rectangle out of bounds ( edge . left , image rect , target aspect ratio ) ) { final float offset = edge . left . snap to rect ( image rect ) ; edge . right . offset ( - offset ) ; m edge . adjust coordinate ( target aspect ratio ) ; } if ( edge . right . is outside margin ( image rect , snap radius ) & & m edge . is new rectangle out of bounds ( edge . right , image rect , target aspect ratio ) ) { final float offset = edge . right . snap to rect ( image rect ) ; edge . left . offset ( - offset ) ; m edge . adjust coordinate ( target aspect ratio ) ; }
m db . pm . get groups ( ) . remove ( m group ) ;
symbols = new hash map ( ) ;
final abstract expandable data provider . base data item = m provider . get group item ( group position ) ;
final int regions = 100000 ;
start container request sc request = start container request . new instance ( create clc ( ) , container . get container token ( ) ) ;
calculate item positions ( ) ;
string syntax = scheme + : + strings . after ( uri endpoint . syntax ( ) , : ) ;
list < long > compress durations = new array list < long > ( ) ; byte array output stream compressed stream = new byte array output stream ( ) ; output stream compressing stream ; try { for ( int it time = 0 ; it time < benchmark _ n _ times ; + + it time ) { final long start time = system . nano time ( ) ; compressing stream = algorithm . create compression stream ( compressed stream , compressor codec , 0 ) ; compressing stream . write ( buffer , offset , length ) ; compressing stream . flush ( ) ; compressed stream . to byte array ( ) ; final long finish time = system . nano time ( ) ; add time record if ( it time > = benchmark _ n _ omit ) { compress durations . add ( finish time - start time ) ; } if ( it time + 1 < benchmark _ n _ times ) { not the last one compressed stream . reset ( ) ; } } } catch ( ioexception e ) { throw new runtime exception ( string . format ( benchmark , or encoding algorithm ' % s ' cause some stream problems , name ) , e ) ; } print benchmark result ( length , compress durations , false ) ;
final double point x = line vector x * t + x0 ; final double point y = line vector y * t + y0 ; final double point z = line vector z * t + z0 ; for ( final membership bound : bounds ) { if ( bound . is within ( point x , point y , point z ) ) { return ; } } bounds info . add point ( new geo point ( point x , point y , point z ) ) ; } else if ( bsquared minus > 0 . 0 ) {
if ( username = = null & & auth method = = null ) { return configurer ; }
bitmap b3 = bitmap . create bitmap ( 10 , 10 , null ) ;
blob container . delete blob ( temp blob name ) ; throw ex ; }
motion event cancel event = motion event . obtain ( ev ) ; cancel event . set action ( motion event . action _ cancel ) ; super . on touch event ( cancel event ) ; } return first time interacting | | super . dispatch touch event ( ev ) ; } else {
pipeline threads line = assert is instance of ( pipeline . class , it . next ( ) ) ; iterator < processor > it2 = threads line . get processors ( ) . iterator ( ) ; assert is instance of ( send processor . class , unwrap channel ( it2 . next ( ) ) . get next processor ( ) ) ; assert is instance of ( send processor . class , unwrap channel ( it2 . next ( ) ) . get next processor ( ) ) ; }
public void test schedule task ( ) { log . info ( - - - start : test schedule task - - - ) ;
while ( current index < current line length & & character . is whitespace ( current line . char at ( current index ) ) ) { current index + + ; }
inheritance state inheritance state = inheritance state per class . get ( coll type ) ; persistent class target property persistent class = inheritance type . joined . equals ( inheritance state . get type ( ) ) ? map property . get persistent class ( ) : associated class ; value index value = create formulated value ( map property . get value ( ) , map , target property name , associated class , target property persistent class , building context ) ; map . set index ( index value ) ;
database descriptor . set endpoint snitch ( snitch ) ;
log . info ( not in dev mode . ignoring attempt to build : + targets ) ; return ; }
key builder . put ( row key , 0 , row key . length ) ;
mv . visit type insn ( opcodes . checkcast , types . get internal name ( expected ) ) ;
job log . set executor address ( trigger result . get content ( ) ) ;
selectable pos = look for selectable position ( new pos , false ) ;
rule context . register action ( new spawn action . builder ( ) . use default shell environment ( ) . add transitive inputs ( inputs . build ( ) ) . add outputs ( immutable list . copy of ( outs ) ) . add command line ( flat file builder . build ( ) , param file info . build ( ) ) . set executable ( rule context . get executable prerequisite ( android _ resources _ busybox , mode . host ) ) . set progress message ( compiling android resources for % s , rule context . get label ( ) ) . set mnemonic ( android resource compiler ) . build ( context ) ) ; return resource container . to builder ( ) . set compiled symbols ( compiled symbols ) . set symbols ( output ) . build ( ) ;
send put header ( os , job id , blob type ) ;
if ( is edge table ) { rows = graph . get edges ( ) ; } else { rows = graph . get nodes ( ) ; } for ( element row : rows ) { if ( is edge table ) { edge edge = ( edge ) row ; csv writer . print ( edge . get source ( ) . get id ( ) ) ; csv writer . print ( edge . get target ( ) . get id ( ) ) ; csv writer . print ( edge . is directed ( ) ? directed : undirected ) ; if ( include edge kind column ) { csv writer . print ( edge . get type label ( ) . to string ( ) ) ; } } for ( column column : columns ) { object value = row . get attribute ( column ) ; string text ; if ( value = null ) { if ( value instanceof number ) { text = number _ format . format ( value ) ; } else { text = attribute utils . print ( value , time format , time zone ) ; } } else { text = ; } csv writer . print ( text ) ; } csv writer . println ( ) ; }
if ( zero count1 = zero count2 ) { return zeros delta ; }
rebalance ( ) ;
current call = null ;
select . add group by ( convert exprs to fields ( standard group bys , sql table source ) ) ; standard group bys = new array list < > ( ) ; } if ( sql expr instanceof sqlparens identifier expr ) {
tp . next position ( ) ; bytes ref payload = tp . get payload ( ) ; assert equals ( wrong payload length . , 1 , payload . length ) ; assert equals ( payload . bytes [ payload . offset ] , payload data [ num terms ] ) ; tp . next doc ( ) ; tp . next position ( ) ;
int columns number = prepared ok . columns number ;
if ( text . char at ( 0 ) = ' \ t ' ) { return color + text + reset ; }
_ train = parse _ test _ file ( key . make ( topbottom ) , smalldata jira top bottom n . csv . zip ) ; top float = parse _ test _ file ( key . make ( top20 ) , smalldata jira top20 per . csv . zip ) ; top long = top float . extract frame ( 0 , 1 ) ; bottom float = parse _ test _ file ( key . make ( bottom20 ) , smalldata jira bottom20 per . csv . zip ) ; bottom long = bottom float . extract frame ( 0 , 1 ) ; scope . track ( _ train ) ;
test service grpc . new stub ( in process channel ) . streaming input call ( response observer ) ; assert true ( finish latch . await ( 900 , time unit . milliseconds ) ) ;
create child segment for terminal node ( node , memory ) ;
post body + = content - disposition : form - data ; name = \ description \ + end of line ; if ( include extra headers ) { post body + = content - type : text plain ; charset = + content encoding + end of line + content - transfer - encoding : 8bit + end of line ; } post body + = end of line + description value + end of line + - - + boundary + - - + end of line ; return post body ;
string [ ] columns = new string [ table access . get value ( ) . size ( ) ] ; table access . get value ( ) . to array ( columns ) ; arrays . sort ( columns ) ; per table info . append ( columns : ) . append ( string utils . join ( columns , ' , ' ) ) . append ( \ n ) ; output ordered map . put ( table access . get key ( ) , per table info . to string ( ) ) ; }
return add invalid nonce ( value , exchange . get io thread ( ) ) ;
bytes read = fis . read ( 0 , buffer , 0 , buffer . length ) ; assert that ( bytes read , is ( orig len ) ) ; fis . close ( ) ; byte [ ] data from snapshot = dfstest util . read file buffer ( hdfs , file1snap1 ) ; assert that ( wrong data size in snapshot . , data from snapshot . length , is ( orig len ) ) ; }
if ( shared dirs . size ( ) > 1 ) { throw new ioexception ( multiple shared edits directories are not yet supported ) ; }
node node = f current node . get previous sibling ( ) ;
exception caught = true ;
shape zip output format zip = new shape zip output format ( ) ;
try { itr . next ( ) ; fail ( exception expected ) ; } catch ( final no such element exception e ) { assert not null ( e ) ; }
exceptions attribute . exception entries accept ( ( program class ) clazz , new exception adder ( target class , new exceptions attribute ) ) ;
log . warn ( [ { } ] lookup failed with error { } , { } , remote address , topic , ex . get message ( ) , ex ) ; ctx . write and flush ( new lookup error response ( server error . service not ready , ex . get message ( ) , request id ) ) ; } lookup semaphore . release ( ) ; return null ; } ) ; } else {
final expanding fetch source popped = pop from stack ( ) ; check popped entity ( popped , entity definition ) ; log . tracef ( % s finished root entity : % s , string helper . repeat ( < < , fetch source stack . size ( ) ) , entity definition . get entity persister ( ) . get entity name ( ) ) ; }
int inactive type = a . get int ( r . styleable . circle flow indicator _ inactive type , style _ stroke ) ; int inactive default color = 0x44 ffffff ;
composite exception composite = ( composite exception ) plugin ref . get ( ) ; assert that ( composite . get exceptions ( ) ) . contains exactly ( error ref . get ( ) , e ) ; }
xpath xp = x paths part . get xpath by id ( xpath id ) ;
subscription obj from json = kill bill client . get subscription ( entitlement json . get subscription id ( ) , request options ) ;
reload lists ( new mode ) ;
final int inc = test util . next int ( random ( ) , 1 , expected . size ( ) - 1 - upto ) ;
tn . add index ( idx ) ;
for ( entry < string , node > entry : arg map . entry set ( ) ) { string name = entry . get key ( ) ; if ( names to alias . contains ( name ) ) { if ( name . equals ( this _ marker ) ) { boolean references this = node util . references this ( fn template root ) ;
pattern = pattern . to lower case ( locale . us ) ;
console . edit ( ) ;
for ( pull update future current pull : current pulls ) { current pull . done ( ) ; } } catch ( exception e ) {
mailbox . deliver ( message ) ;
set zk property ( test . key1 , test . value1 - zk ) ; set zk property ( test . key2 , test . value2 - zk ) ; set zk property ( test . key4 , test . value4 - zk ) ; configuration manager . install ( composite config ) ; }
return data _ disconnected ;
{ final rollover response response = client ( ) . admin ( ) . indices ( ) . prepare rollover index ( test _ alias ) . add max index size condition ( new byte size value ( random int between ( 1 , 20 ) , byte size unit . bytes ) ) . get ( ) ; assert that ( response . get old index ( ) , equal to ( test - 1 ) ) ; assert that ( response . get new index ( ) , equal to ( test - 000002 ) ) ; assert that ( should rollover with a small max _ size condition , response . is rolled over ( ) , equal to ( true ) ) ; }
out v = new bytes column vector ( ) ; v = new bytes column vector ( ) ; out v . is repeating = false ; out v . no nulls = true ; v . is repeating = true ; v . no nulls = false ; v . set ref ( 0 , data1 , 0 , data1 . length ) ; batch = new vectorized row batch ( 2 ) ; batch . cols [ 0 ] = v ; batch . cols [ 1 ] = out v ; expr . evaluate ( batch ) ; out col = ( bytes column vector ) batch . cols [ 1 ] ; assert . assert true ( out col . no nulls ) ; assert . assert true ( out col . is repeating ) ; assert . assert equals ( 0 , string expr . compare ( expected , 0 , expected . length , out col . vector [ 0 ] , out col . start [ 0 ] , out col . length [ 0 ] ) ) ;
assert equals ( string . format ( % s path % 1 s , file . separator ) , file utils . ensure trailing slash ( string . format ( % s path , file . separator ) ) ) ;
assert queue closed ( buffer , first , 1 ) ;
write file ( fs , file1 , file _ len ) ; write file ( fs , file3 , file _ len ) ; write file ( fs , file4 , file _ len ) ; set < path > expected results = new tree set < path > ( ) ;
fail ( shard with id + shard routing + expected but missing in indices service and failed shards cache ) ;
string sub directory = file name + file . separator + file . get name ( ) ; boolean can poll more = poll directory ( sub directory , file list , depth ) ; if ( can poll more ) { return false ; } } } else {
this . selector . add action listener ( new action listener ( ) { public void action performed ( final action event evt ) { get selector ( ) . transfer focus ( ) ; } } ) ;
draw ascii panel ( buffer graphics ) ;
assert that ( dom , has xpath ( count ( at : feed at : entry owc : offering ) , equal to ( 3 ) ) ) ;
final cached spice request < string > add listener if pending cached request = create successful request ( test _ class , test _ cache _ key , duration in millis . always _ expired , null ) ; add listener if pending cached request . set processable ( false ) ; request listener stub < string > mock request listener2 = new request listener stub < string > ( ) ;
data gen = new multi threaded action . default data generator ( min col data size , max col data size , min cols per key , max cols per key , families ) ; }
backup = publish entry info ( key , entry . get value ( ) ) ;
logger . info ( node { } : received { } from node but we shouldn ' t have gotten it . , this . get node ( ) . get node id ( ) , command to string ( command ) ) ;
val = get byte at slot ( mac , slot ) ; typ . set state ( val ) ; b decoded _ for log = true ; } else if ( i num bytes = = 2 ) {
add delete on tear down ( new file ( tomcat . basedir , conf ) ) ;
v doc a _ version = v doc a _ db1 . get version ( ) ;
curr byte = bytes [ i + + ] & 255 ;
servicenow . put ( sys _ db _ object , entry . get reference ( ) . get value ( ) ) ;
return collections . empty map ( ) ;
for ( long gen = 1 ; gen < translog . current file generation ( ) ; gen + + ) { assert file is present ( translog , gen ) ; } translog . trim unreferenced readers ( ) ; for ( long gen = 1 ; gen < comitted generation ; gen + + ) { assert file deleted ( translog , gen ) ; } }
assert not null ( there should be some modules returned from this helper , results ) ; assert true ( the first module in this process should be java . exe or javaw . exe , results . get ( 0 ) . sz module ( ) . starts with ( java ) ) ;
if ( in mem stats init ) { log . info ( start recording in memory stats ) ; in mem stats = new in memory stats ( ) ; stats . add listener ( in mem stats ) ; } else { log . info ( stop recording in memory stats ) ; stats . remove listener ( in mem stats ) ; in mem stats . all cleared ( ) ; in mem stats = null ; }
for ( bulk item response bulk item response : bulk response ) { if ( bulk item response . is failed ( ) ) { < 1 > bulk item response . failure failure = bulk item response . get failure ( ) ; < 2 > } }
add arguments ( that . get ( args ) . to string ( ) ) ;
if ( result map . contains key ( id hit date ) ) { log ( id + id hit date + not found . possibliy a duplicate . ) ; }
final default entitlement cancelled add on entitlement = ( default entitlement ) entitlement api . get entitlement for id ( add on entitlement . get id ( ) , call context ) ;
complex [ ] c = cconvolve ( x , x ) ;
assert true ( should always pass , bool . boolean value ( ) ) ; }
boolean explicit select = select = null & & select . get number of children ( ) > 0 ;
counter result result after shutting down anode = remote counter . increment ( ) ; assert . assert not null ( result from remote stateful counter , after shutting down a node was null , result after shutting down anode ) ; assert . assert equals ( unexpected count from remote counter , after shutting down a node , total count before shutting down anode + 1 , result after shutting down anode . get count ( ) ) ; assert . assert false ( result was received from an unexpected node , after shutting down a node , previous invocation node name . equals ( result after shutting down anode . get node name ( ) ) ) ;
this . popup element . get style ( ) . set top ( ( caret location . get y ( ) - this . popup element . get offset height ( ) - text view . get line height ( ) ) + px ) ;
@ suppress warnings ( unchecked ) final map < string , string > data = ( map < string , string > ) result . get or default ( query result , result ) ; assert not null ( data . get ( total size ) ) ;
assert qex ( expecting exception for suffix : + suffix , bad number , req ( q , { term f = foo _ + suffix + } + bad number ) , solr exception . error code . bad _ request ) ;
r . set ( 0 , 0 , w , h ) ; final matrix m = m temp matrix ;
if ( obj = = null | | ( obj instanceof character literal node ) ) { return false ; }
config . set model update period ( 1 ) ; config . set cache update period ( 1 ) ; context . unset ( ) ; context . set ( context , config ) ; manager factory . create ( ) . process ( ) ;
set _ panning ( panning - ( volume _ column & 0x0 f ) ) ;
its icode top = top + 1 + 2 ; }
card2 . notify data set changed ( ) ;
try { iter . close ( ) ; fail ( operation shoul have thrown ) ; } catch ( ioexception e ) { expected }
application = delete unreferenced deployment jobs ( application ) ; store ( application ) ; store missing information even if we fail deployment below
file . get string ids ( ) . write header part ( out ) ; file . get type ids ( ) . write header part ( out ) ; file . get proto ids ( ) . write header part ( out ) ; file . get field ids ( ) . write header part ( out ) ; file . get method ids ( ) . write header part ( out ) ; file . get class defs ( ) . write header part ( out ) ; if ( out . annotates ( ) ) { out . annotate ( 4 , data _ size : + hex . u4 ( data size ) ) ; out . annotate ( 4 , data _ off : + hex . u4 ( data off ) ) ; }
return base name ;
if ( request path . starts with ( ) ) { request path = request path . substring ( 1 ) ; }
random random = new random ( seed ) ;
component c3 = new chart histogram . builder ( histogram , s ) . add bin ( - 1 , - 0 . 5 , 0 . 2 ) . add bin ( - 0 . 5 , 0 , 0 . 5 ) . add bin ( 0 , 1 , 2 . 5 ) . add bin ( 1 , 2 , 0 . 5 ) . build ( ) ;
if ( offset > = end offset ) { if ( was exceed end offset ) return false ; we have do this before to end state ( view ) ; was exceed end offset = true ; return false ; }
sb . append ( \ n \ n ) ;
double x = snapshots . get ( i ) . runtime sec ;
low = middle + 1 ; } else { return true ; } }
assert equals ( 1 , key value cache dir . list files ( ) . length ) ; assert array equals ( value . get bytes ( ) , parse file utils . read file to byte array ( key value cache dir . list files ( ) [ 0 ] ) ) ; }
if ( binding configuration . get refresh interval ( ) = null & & 0 = = binding configuration . get refresh interval ( ) ) { return 0 ; } zwave node node = this . controller . get node ( binding configuration . get node id ( ) ) ;
if ( inherit output ) { pipe ( [ + to string ( ) + : + pid + ] , process . get error stream ( ) , error stream target ( ) ) ; pipe ( [ + to string ( ) + : + pid + ] , process . get input stream ( ) , input stream target ( ) ) ; }
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( unauthorized operation ) ) return null ; unauthorized operation exception e = ( unauthorized operation exception ) super . unmarshall ( node ) ;
em . get transaction ( ) . begin ( ) ; ing1 = em . find ( list uni entity . class , ing1 . get id ( ) ) ; ed2 = em . find ( str test entity . class , ed2 . get id ( ) ) ; ed1 = em . find ( str test entity . class , ed1 . get id ( ) ) ; ing1 . get references ( ) . remove ( ed1 ) ; em . get transaction ( ) . commit ( ) ;
verify denied ( gbl user , get action all , get action1 , get action2 ) ;
this . next ( ) ;
list < string > children = zk . get children ( parent path , false ) ;
if ( blogs = null & & blogs . size ( ) > 0 ) { for ( reader recommended blog blog : blogs ) { stmt . bind long ( 1 , blog . blog id ) ; stmt . bind long ( 2 , blog . follow reco id ) ; stmt . bind long ( 3 , blog . score ) ; stmt . bind string ( 4 , blog . get title ( ) ) ; stmt . bind string ( 5 , blog . get blog url ( ) ) ; stmt . bind string ( 6 , blog . get image url ( ) ) ; stmt . bind string ( 7 , blog . get reason ( ) ) ; stmt . execute ( ) ; } }
a = collections . empty set ( ) ; b = as list ( 4 , 8 , 15 , 16 , 23 , 42 ) ; assert false ( iterators . elements equal ( a . iterator ( ) , b . iterator ( ) ) ) ; assert false ( iterators . elements equal ( b . iterator ( ) , a . iterator ( ) ) ) ; }
versioned < list < store definition > > original store definitions = client . metadata mgmt ops . get remote store def list ( node id ) ; list < store definition > updated store def list = new array list < store definition > ( ) ; store definition old definition = get store definition from list ( original store definitions . get value ( ) , store name to be updated ) ;
osgi class loader . add bundle ( requesting bundle ) ;
model node model a = services a . read whole model ( ) ; string marshalled = services a . get persisted subsystem xml ( ) ;
settings settings = null ; file parent = input dir . input file ; while ( true ) { settings = dir to settings . get ( parent ) ; if ( settings = null ) break ; if ( parent = = null | | parent . equals ( root ) ) break ; parent = parent . get parent file ( ) ; } if ( settings = = null ) settings = default settings ; if ( settings . ignore ) return ;
orecord serializer network v37 serializer = orecord serializer network v37 . instance ;
timestamp ts = new timestamp ( 101 , 0 , 17 , 1 , 2 , 3 , 4 ) ; assert equals ( timestamp . class , bean util . pojo . get property type ( fb , prop name ) ) ; bean util . pojo . set property ( fb , prop name , ts ) ; assert equals ( 2001 - 01 - 17 01 : 02 : 03 . 000000004 , fb . get foo timestamp ( ) . to string ( ) ) ; prop name = foo time ;
if ( opset . equals ( operation set presence . class ) | | opset . equals ( operation set persistent presence . class ) | | ( ( is chat room | | service . is smsenabled ( ) ) & & opset . equals ( operation set basic instant messaging . class ) ) ) { continue ; } if ( is chat room & & opset capabilities = null & & opset capabilities . contains key ( opset . get name ( ) ) ) continue ;
for ( final string server : server array ) { new thread ( new runnable ( ) { @ override public void run ( ) { connect to one server with retry ( client , server ) ; connections . count down ( ) ; } } ) . start ( ) ; }
assert true ( merged throttle . has req num ( ) ) ;
( access flags & ( class constants . acc _ synchronized | class constants . acc _ native | class constants . acc _ abstract ) ) = = 0 ) { code attribute composer . debug = debug = clazz . get name ( ) . equals ( abc def ) & & method . get name ( clazz ) . equals ( abc ) ; target method = method ;
warmup manager . get instance ( ) . destroy spare web contents ( ) ; intent extras intent = new intent ( ) ;
string [ ] names = ( ( data store ) store . get data store ( null ) ) . get type names ( ) ; arrays . sort ( names ) ; tester . click link ( table _ path + : list container : items : 1 : item properties : 2 : component : link , true ) ;
network . unregister task ( this ) ;
map phase = get progress ( ) . add phase ( map , 0 . 667f ) ;
+ + opening paren ; string expansion = null ;
transport . handle remote error ( shard failed request . request id , new node closed exception ( state . nodes ( ) . get local node ( ) ) ) ; assert false ( success . get ( ) ) ; assert null ( failure . get ( ) ) ; assert not null ( ignored failure . get ( ) ) ; }
cloud stack account caller = get current account ( ) ;
set . add ( www . cs . princeton . edu ) ; set . add ( www . cs . princeton . edu ) ; overwrite old value set . add ( www . princeton . edu ) ; set . add ( www . math . princeton . edu ) ; set . add ( www . yale . edu ) ; set . add ( www . amazon . com ) ; set . add ( www . simpsons . com ) ; set . add ( www . stanford . edu ) ; set . add ( www . google . com ) ; set . add ( www . ibm . com ) ; set . add ( www . apple . com ) ; set . add ( www . slashdot . com ) ; set . add ( www . whitehouse . gov ) ; set . add ( www . espn . com ) ; set . add ( www . snopes . com ) ; set . add ( www . movies . com ) ; set . add ( www . cnn . com ) ; set . add ( www . iitb . ac . in ) ; std out . println ( set . contains ( www . cs . princeton . edu ) ) ; std out . println ( set . contains ( www . harvardsucks . com ) ) ; std out . println ( set . contains ( www . simpsons . com ) ) ; std out . println ( ) ;
lpn = compile to fragments ( select * from p2 full join p1 on p1 . a = p2 . a and p2 . a > 0 ) ;
jmx . add ( command line args , mx . get input arguments ( ) ) ;
simple update ( tpf ) ; if ( prof = null ) prof . app step ( app step . spatial update ) ;
m wrapper adapter . set on group expand listener ( m on group expand listener ) ; m on group expand listener = null ; m wrapper adapter . set on group collapse listener ( m on group collapse listener ) ;
return new layer memory report . builder ( layer name , loss layer . class , input type , input type ) . standard memory ( 0 , 0 ) no params . working memory ( 0 , 0 , 0 , 0 ) . cache memory ( memory report . cache _ mode _ all _ zeros , memory report . cache _ mode _ all _ zeros ) no caching . build ( ) ; }
tester . get or create ( parent , * mark as modified = * true ) . add dependency ( other2 ) ; tester . invalidate ( ) ; blocking enabled . set ( true ) ; result = tester . eval ( * keep going = * false , parent ) ; assert that ( result . get ( parent ) . get value ( ) ) . is equal to ( leafother2 ) ; assert that ( wait for changed . get count ( ) ) . is equal to ( 0 ) ; assert that ( threads started . get count ( ) ) . is equal to ( 0 ) ; }
dtm dtm frag = m _ xcontext . get global rtfdtm ( ) ; return transform to rtf ( template parent , dtm frag ) ; }
if ( dom builder . config . is ignore whitespaces between tags ( ) ) { remove last child node if empty text ( parent node , true ) ; }
execute ( controller client , default entity bean optimistic locking ) ; } catch ( ioexception ioe ) {
} packet . set length ( buffer . length ) ; socket . receive ( packet ) ; string t = string from packet ( packet ) ;
. add compilation mode flags ( compilation mode flags . new builder ( ) . set mode ( compilation mode . dbg ) . add compiler flag ( - o0 ) . add compiler flag ( - undebug ) . add compiler flag ( - fno - omit - frame - pointer ) . add compiler flag ( - fno - strict - aliasing ) ) ; stl impl . add stl impl ( toolchain , 4 . 9 ) ; return toolchain ; }
text view text view = ( text view ) view . find view by id ( r . id . text ) ; m circle drawable = new circle ( ) ; m circle drawable . set bounds ( 0 , 0 , 100 , 100 ) ; m circle drawable . set color ( color . white ) ; text view . set compound drawables ( null , null , m circle drawable , null ) ; text view . set background color ( colors [ 2 ] ) ;
cancel ( reason ) ;
d . write byte ( 0 ) ; flags [ 0 ] d . write byte ( 0 ) ; flags [ 1 ] d . write byte ( 0 ) ; flags [ 2 ]
ast ast = node . get ast ( ) ;
try { return content = http . send http get ( http _ request _ url _ prefix + hostname + : + port + sn0 , null ) ; } catch ( exception exp ) { throw new communication api exception ( there was a problem in the http communication with the open sprinkler api : + exp . get message ( ) ) ; } if ( return content = = null | | ( return content . equals ( 0 ) & & return content . equals ( 1 ) ) ) { throw new communication api exception ( there was a problem in the http communication with the open sprinkler api , unexpected api response : + return content ) ; }
throw new rest exception ( string . format ( invalid h2 database file ' % s ' . , database file ) , http status . internal _ server _ error ) ;
java type t = _ target type ; return ctxt . report bad definition ( t , string . format ( deserialization ( of % s ) with builder , external type id , @ json creator not yet implemented , t ) ) ; }
this . affected rows = byte helper . read binary coded length bytes ( data , index ) ;
if ( length > ( internal buffer . length - count ) ) { flush internal ( ) ; } system . arraycopy ( buffer , offset , internal buffer , count , length ) ; count + = length ; }
m src context = src context ;
for ( feed subscription sub : subscriptions . stream ( ) . filter ( s - > s . get category ( ) = = null ) . collect ( collectors . to list ( ) ) ) { opml . get outlines ( ) . add ( build subscription outline ( sub ) ) ; } return opml ;
test url to uri mapping ( \ u0001 , % 01 , % 01 , % 01 , % 01 ) ;
enable availability logging ( platform . availability guard , msg log ) ; platform . life . start ( ) ;
return parameter types [ argument index ] ; move to method info ?
if ( stream _ q . has next ( ) ) { adaptor . add child ( root _ 2 , stream _ q . next node ( ) ) ; } stream _ q . reset ( ) ; adaptor . add child ( root _ 1 , root _ 2 ) ;
return size density ;
} else { referenced classes [ new referenced class index + + ] = first referenced class ;
option . set long opt ( longopt ) ;
integer max features = ( integer ) reader . global ( ) . get ( max features ) ;
zk . create ( ok , new byte [ 0 ] , ids . open _ acl _ unsafe , create mode . persistent ) ; stat stat = zk . exists ( success , null ) ;
siptransaction error event new error event ;
set input limit ( - 1 ) ;
get prefs ( ) . edit ( ) . put string ( key _ pref _ otg , intent . get data ( ) . to string ( ) ) . apply ( ) ; if ( is drawer locked ) m drawer layout . close drawer ( m drawer linear ) ; else on drawer closed ( ) ;
app . add preemption ( container , get clock ( ) . get time ( ) ) ;
if ( next + 1 = = len ) throw new malformed object name exception ( missing termination quote ) ;
mr . stop task tracker ( mr . get task tracker id ( test tt . get name ( ) ) ) ; jip . refresh task counts and wait time ( task type . reduce , job tracker . get clock ( ) . get time ( ) ) ;
st = mail converters . to search term ( ( simple search term ) search term , get camel context ( ) . get type converter ( ) ) ;
string name = get name ( ) ; if ( name = = null ) { return ; } return name ; }
channel _ id = new big integer ( 702b07871fd7955c320b26f15e244e47eed60272124c92b9ebecf0b42f90069b + ab53592ebfeb4f167dbf3ce61513afb0e354c479b1c1b69874fa471293494f77 , 16 ) . to byte array ( ) ;
assert element exist ( keywords , ( keyword ) - > { assert that ( keyword , not null value ( ) ) ; return objects . equals ( keyword . get value ( ) , keyword1 ) & & objects . equals ( keyword . get language ( ) , en ) & & objects . equals ( keyword . get vocabulary ( ) , vocab1 ) ; } ) ;
if ( is jsp servlet ) { old jsp servlet = ( wrapper ) find child ( jsp ) ; if ( old jsp servlet = null ) { remove child ( old jsp servlet ) ; } } super . add child ( child ) ;
if ( character . is letter ( term . char at ( c ) ) ) { return false ; }
assert equals ( 1 , matches1 . length ) ;
if ( is sparse ) { int [ ] ids = new int [ x . length ] ; int nzs = c . get sparse doubles ( x , ids ) ; assert . assert equals ( nzs _ ary . length , nzs ) ; assert . assert array equals ( nzs _ ary , arrays . copy of ( ids , nzs ) ) ; for ( int i = 0 ; i < nzs ; + + i ) { assert . assert equals ( vals [ nzs _ ary [ i ] ] , x [ i ] , 0 ) ; } }
access key = request . get parameter values ( accesskey ) ; if ( null = = access key | | 0 = = access key . length ) { response . send error ( 530 , missing accesskey parameter ) ; return ; } secret key = request . get parameter values ( secretkey ) ;
server server = context . get server from load balancer ( request , null ) ;
send file ( get ftp url ( ) , hello world , report . txt ) ;
for ( route info route : routes ) { if ( network utils . address type matches ( route . m destination . get address ( ) , dest ) ) { if ( ( best route = null ) & & ( best route . m destination . get network prefix length ( ) > = route . m destination . get network prefix length ( ) ) ) { continue ; } if ( route . matches ( dest ) ) best route = route ; } } return best route ;
b = get vectorized row batch3 decimal cols ( ) ; in = ( decimal column vector ) b . cols [ 0 ] ; in . is repeating = true ; expr . evaluate ( b ) ; r = ( decimal column vector ) b . cols [ 2 ] ; assert true ( r . is repeating ) ; assert true ( r . vector [ 0 ] . get hive decimal ( ) . equals ( hive decimal . create ( 3 . 3 ) ) ) ;
assert equals ( test el . get attribute ( name ) , test case ) ;
blocking connect ( node ) ;
client . call procedure ( capped3 _ limit _ rows _ exec . delete , 70 ) ;
for ( int i = active total ; i < active total + pending total ; + + i ) { iter . update ( buckets . get ( i ) . get superbucket ( ) , progress token . finished _ bucket ) ; + + bucket count ; } assert equals ( progress . get active bucket count ( ) , 0 ) ; boolean consistent next = true ;
preview = route utils . preview route ( hello . hello service , 1 . 2 . 3 . 4 , application = morgan , service urls , route , clusters , null ) ;
if ( + + count = = integer . max _ value ) break ;
ice sdp utils . init session description ( our offer , ice agent ) ;
return ( t [ ] ) arrays . copy of ( queue , size , a . get class ( ) ) ;
preconditions . check state ( file count = = 1 , fsimage . format should be called with an uninitialized namesystem , has + file count + files ) ; namespace info ns = nnstorage . new namespace info ( ) ;
try { clazz = class . for name ( mediator name ) ; constructor < ? > constructor = clazz . get declared constructors ( ) [ 0 ] ; constructor . set accessible ( true ) ; return ( realm proxy mediator ) constructor . new instance ( ) ; } catch ( class not found exception e ) { throw new realm exception ( could not find + mediator name , e ) ; } catch ( invocation target exception e ) { throw new realm exception ( could not create an instance of + mediator name , e ) ; } catch ( instantiation exception e ) { throw new realm exception ( could not create an instance of + mediator name , e ) ; } catch ( illegal access exception e ) { throw new realm exception ( could not create an instance of + mediator name , e ) ; }
for ( int i = listeners . length - 2 ; i > = 0 ; i - = 2 ) { if ( listeners [ i ] = = menu drag mouse listener . class ) { lazily create the event : ( ( menu drag mouse listener ) listeners [ i + 1 ] ) . menu drag mouse dragged ( event ) ; } } }
int pos = lexical representation . index of ( ' t ' ) ; int length = ( pos > = 0 ) ? pos : lexical representation . length ( ) ; for ( int i = 0 ; i < length ; + + i ) { char c = lexical representation . char at ( i ) ; if ( c = = ' y ' | | c = = ' m ' ) { throw new illegal argument exception ( invalid day time duration value : + lexical representation ) ; } } return new duration ( lexical representation ) ; }
write short ( e64len + 4 + ( e . extra = null ? e . extra . length : 0 ) ) ;
final file system fs = cluster . get file system ( ) ;
symbol = 0 ;
if ( min result = calc result . null _ result ) { result . add ( ( date ) min . get min ( ) ) ; final max visitor max = new max visitor ( time . get attribute ( ) ) ; collection . accepts ( max , null ) ; result . add ( ( date ) max . get max ( ) ) ; } }
for ( int m = 0 ; m < slots per server ; m + + ) { secondary cost [ i ] [ k * slots per server + m ] = avoid _ cost ; tertiary cost [ i ] [ k * slots per server + m ] = avoid _ cost ; } } } }
assert true ( initializing shard0 . is same allocation ( started shard0 ) ) ;
throw new arithmetic exception ( rounding necessary ) ;
int scaled bounds height = ( int ) ( bounds . height ( ) * aspect ) ; glance from . set ( 0 , - distance on glance , glance . get width ( ) , - distance on glance + scaled bounds height ) ; return glance from . intersect ( 0 , 0 , glance . get width ( ) , glance . get height ( ) ) ;
m list view . smooth scroll to position ( m position ) ;
return collectable item . type . of api string ( type , null ) ;
wmsinfo wms = get geo server ( ) . get service ( wmsinfo . class ) ;
int pos2 = single mode ? name . last index of ( ' . ' ) : name . index of ( ' . ' ) ;
rm . wait for state ( app3 . get application id ( ) , rmapp state . killed ) ;
host . get location in window ( m tmp location ) ; m transparent region . set ( m tmp location [ 0 ] , m tmp location [ 1 ] , m tmp location [ 0 ] + host . m right - host . m left , m tmp location [ 1 ] + host . m bottom - host . m top ) ; host . gather transparent region ( m transparent region ) ;
if ( content instanceof component host ) { final component host host = ( component host ) content ; for ( int i = host . get mount item count ( ) - 1 ; i > = 0 ; i - - ) { final mount item mount item = host . get mount item at ( i ) ; unmount disappearing item child ( context , mount item ) ; } if ( host . get mount item count ( ) > 0 ) { throw new illegal state exception ( recursively unmounting items from a component host , left + some items behind maybe because not tracked by its mount state ) ; } } final component host host = item . get host ( ) ;
validate temp dir creation ( build buffer dir ( root , first dir idx ) ) ;
add nodes ( 10 ) ;
this . get update button ( ) . set enabled ( true ) ;
file status [ ] family status = fs . list status ( new path ( family , mapfiles ) ) ; if ( family status . length > 1 ) { log . debug ( family . to string ( ) + has + family status . length + files . ) ; return false ; } } } }
assert true ( result . contains ( if ( enum value . equals ( this . enum value ) ) ) ) ;
list < person > persons = session . create query ( from person ) . list ( ) ;
refresh registry . default registry ( ) . register ( shared , handler one ) ;
handler . finalize catchup phase ( cp1 ) ;
super ( service principal ) ;
return pop ( ) ;
assert equals ( should get the transfer - encoding as chunked , chunked , headers . get ( transfer - encoding ) ) ;
for ( int i = 0 ; i < n ; i + + ) { assert true ( images . get ( i ) . is opened ( ) = = images . get ( i ) . is closed ( ) ) ; } verify no more interactions ( m data source supplier ) ;
int num entries left = args . get child count ( ) - cur idx ; if ( num entries left < 3 ) { throw new semantic exception ( user provided only 1 entry for the hint with alias + args . get child ( cur idx ) . get text ( ) ) ; } string source = args . get child ( cur idx + + ) . get text ( ) ;
final int drag view index = index of child ( m drag view ) ; final int page under point index = get nearest hover over page index ( ) ;
valve . input watermark ( new watermark ( 0 ) , 2 ) ;
queryable queryable = walker . get session factory helper ( ) . find queryable using imports ( constant . get text ( ) ) ;
object mapper mapper = new object mapper ( ) ; bitstamp order response = mapper . read value ( is , bitstamp order . class ) ; assert that ( response . get error message ( ) ) . is equal to ( minimum order size is 1 ) ; }
assert equals ( bitcoinde order book . get bitcoinde orders ( ) . get bids ( ) [ 0 ] . get price ( ) , new big decimal ( 1200 ) ) ;
current pos = ( math . abs ( end pos ) - 1 ) ; } else {
if ( parameter type . get component type ( ) . is assignable from ( value . get class ( ) . get component type ( ) ) ) { throw new illegal argument exception ( string . format ( primitive array - valued parameter bind value type [ % s ] did not match expected type [ % s ( % s ) ] , value . get class ( ) . get component type ( ) . get name ( ) , parameter type . get name ( ) , extract name ( temporal type ) ) ) ; }
assert that ( scroll . get scroll y ( ) , is ( 0 ) ) ; } } ) ;
root folder . mkdir ( ) ; realm . init ( get application context ( ) ) ; }
cxf endpoint endpoint = context . get endpoint ( cxf : bean : from endpoint , cxf endpoint . class ) ; assert equals ( org . apache . camel . component . cxf . hello service impl , endpoint . get service class ( ) . get name ( ) ) ; assert equals ( data format . pojo , endpoint . get data format ( ) ) ;
data . state . remove ( cache - data ) ;
task service . complete ( task . get id ( ) ) ; }
strategy name = mode _ threadlocal ;
assert equals ( test complex if in loop ( false ) , 0 ) ; assert equals ( test complex if in loop ( true ) , 10 ) ; assert equals ( test complex if in loop2 ( 2 ) , 2 ) ; assert equals ( test complex if in loop2 ( 6 ) , 10 ) ; assert equals ( test complex if in loop3 ( 2 ) , 2 ) ; assert equals ( test complex if in loop3 ( 6 ) , 6 ) ; assert equals ( test complex if in loop3 ( 8 ) , 24 ) ; assert equals ( test loops ( new int [ ] { 1 , 2 , 3 , 4 , 5 , 6 } , 2 ) , 19 ) ; assert true ( test inline ( ) > 20 ) ; assert true ( test inline2 ( ) ) ; return true ;
parameter [ ] parameters = node . get parameters ( ) ; for ( parameter parameter : parameters ) { visit annotations ( parameter ) ; } declare ( node . get parameters ( ) , node ) ; visit class code container ( node . get code ( ) ) ; pop state ( ) ; }
set < string > model class names = model . key set ( ) ;
text field root field = new text field ( rootdir , new metadata map model ( metadata , restutils . root _ key , string . class ) ) ; add ( root field ) ;
property accessor helper . set ( target , column field , source embedded obj ) ;
request = new mock http servlet request ( get , baz ) ; response = new mock http servlet response ( ) ; get servlet ( ) . service ( request , response ) ; assert equals ( 200 , response . get status ( ) ) ; assert equals ( my value , response . get header ( my response header ) ) ; assert equals ( 4 , response . get content length ( ) ) ; assert equals ( body , response . get content as string ( ) ) ; }
test array . skip bytes ( - 4 ) ;
native strings . clear ( ) ;
graph database service db = switch to embedded graph database service ( inserter ) ; try ( transaction tx = db . begin tx ( ) ) { node node = db . get node by id ( node id ) ; for ( relationship relationship : node . get relationships ( ) ) { relationship . delete ( ) ; } node . delete ( ) ; tx . success ( ) ; }
handle special chunk begin ( compute alignment ( 2 ) + ( length * 2 ) ) ; for ( int i = 0 ; i < length ; i + + ) write _ short ( value [ offset + i ] ) ;
m _ element flags . put ( basefont , new elem desc ( 0 | elem desc . empty ) ) ;
rest ( users ) . post ( new ) . consumes ( application xml ) . type ( user jaxb pojo . class ) . to ( mock : input ) ; } } ; }
end ( ) ; }
assert equals ( - 1 , request config . get connect timeout ( ) ) ; }
top hsd . adjust ( ) ;
if ( ( status code = = status code . no _ close ) | | ( status code = = status code . no _ code ) | | ( status code = = status code . failed _ tls _ handshake ) ) { throw new protocol exception ( frame forbidden close status code : + status code ) ; }
coord . receive acknowledge message ( acknowledge checkpoint2 ) ; assert false ( pending . is discarded ( ) ) ; assert false ( pending . is fully acknowledged ( ) ) ; assert false ( savepoint future . is done ( ) ) ;
map < pk , n > cache = new hash map < > ( ) ;
v best = get best ( t , s , offset + i + 1 , len - i - 1 ) ; if ( best = null ) return best ; return ( v ) _ value [ t ] ; } }
string new package prefix ;
blob . upload properties ( get instrumented context ( ) , folder lease ) ;
controller . get configuration ( ) . register config ( properties ) ; boolean init result = controller . initialize ( ) ; if ( init result ) { controller . shutdown ( ) ; system . exit ( - 3 ) ; }
int new constant pool count = shrink constant pool ( program class . constant pool , program class . u2constant pool count ) ;
if ( clauses . size ( ) > 0 & & conj = = conj _ and ) { boolean clause c = clauses . get ( clauses . size ( ) - 1 ) ; if ( c . is prohibited ( ) ) clauses . set ( clauses . size ( ) - 1 , new boolean clause ( c . get query ( ) , occur . must ) ) ; } if ( clauses . size ( ) > 0 & & operator = = and _ operator & & conj = = conj _ or ) { if this term is introduced by or , make the preceding term optional , unless it ' s prohibited ( that means we leave - a or b but + a or b - - > a or b ) notice if the input is a or b , first term is parsed as required ; without this modification a or b would parsed as + a or b boolean clause c = clauses . get ( clauses . size ( ) - 1 ) ; if ( c . is prohibited ( ) ) clauses . set ( clauses . size ( ) - 1 , new boolean clause ( c . get query ( ) , occur . should ) ) ; }
pos + + ; assert . assert equals ( participants chathead adapter . view _ type _ chathead , adapter . get item view type ( pos ) ) ; assert . assert null ( adapter . get item ( pos ) ) ; pos + + ; assert . assert equals ( participants chathead adapter . view _ type _ chathead , adapter . get item view type ( pos ) ) ; assert . assert null ( adapter . get item ( pos ) ) ; pos + + ; assert . assert equals ( participants chathead adapter . view _ type _ chathead , adapter . get item view type ( pos ) ) ; assert . assert null ( adapter . get item ( pos ) ) ;
string country page = countries . get ( country . to lower case ( ) ) ;
analyzed token readings [ ] tokens = sentence . get tokens without whitespace ( ) ;
boolean is transitioning = m is switching state | | ( get layout transition ( ) = null & & get layout transition ( ) . is running ( ) ) ; if ( is transitioning ) { show page indicator at current scroll ( ) ; } update page alpha values ( ) ;
put ( alg . alias . algorithm parameters . + pkcsobject identifiers . des _ ede3 _ cbc , desede ) ;
workspace . set final transition transform ( ) ;
if ( attr array [ attidx _ nonschema ] = null ) ( ( vector ) attr array [ attidx _ nonschema ] ) . clear ( ) ;
if ( location = null ) { this . location = location ; } else { this . location = ; } this . max file size = - 1 ; this . max request size = - 1 ; this . file size threshold = 0 ; }
assert long range split ( 9500 l , 9500 l , 4 , false , arrays . as list ( 0x800000000000251c l , 0x800000000000251c l ) , arrays . as list ( 0 ) ) ;
log step = config . get ( log step att , default _ log _ step ) ;
if ( check bst ( n . left ) ) { return false ; }
path first existing = parent folder . get parent ( ) ; file metadata metadata = store . retrieve metadata ( path to key ( first existing ) ) ; while ( metadata = = null ) {
byte [ ] sc transaction id = headers . get text string ( pdu headers . transaction _ id ) ; if ( null = = sc transaction id ) { return false ; } break ;
if ( support common jsmodules ) { for ( compiler input input : ordered inputs ) { new process common jsmodules ( this ) . process ( * externs * null , input . get ast root ( this ) , * force module detection * false ) ; } } }
throwable failure = service . get failure cause ( ) ;
path sb set = new path ( housemartins ) ; path sb not specified = new path ( inxs ) ; path sb set off = new path ( easyworld ) ; for ( path p : new path [ ] { sb set , sb not specified , sb set off } ) hdfs . mkdirs ( p ) ;
put and wait with family ( row2 , f2 name , htab1 a , htab2 a ) ;
if ( pending input = null | | state = = state . finishing ) { finish pages index ( ) ; return true ; } else { return false ; }
if ( done [ h ] = j ) { done [ h ] = j ; nvals + + ; } } } }
port = 443 ;
assert true ( unsigned longs . compare ( 0x5a4316b8c153ac4d l , 0x6cf78a4b139a4e2a l ) < 0 ) ;
if ( m _ has class ) { output format . set class index ( output format . num attributes ( ) - 1 ) ; } m _ output num atts = output format . num attributes ( ) ;
bean invocation invocation = new bean invocation ( method , args ) ; exchange . get in ( ) . set body ( invocation ) ; }
log . d ( tag , add header ( \ accept - encoding \ , \ identity \ ) ) ;
server capabilities capabilities = registry . initialize ( language service utils . prefix uri ( path ) ) ;
double _ dle _ start = - 1 ; } else { double _ dle _ start = i ; } } else if ( buffer [ i ] = ( byte ) 0x03 ) { non - etx
final analyzer a = new analyzer ( ) { @ override protected token stream components create components ( string field name ) { final tokenizer t = new mock tokenizer ( mock tokenizer . whitespace , false ) ; final token stream t1 = new mock hole injecting token filter ( random ( ) , t ) ; final token stream t2 = new mock graph token filter ( random ( ) , t1 ) ; return new token stream components ( t , t2 ) ; } } ; random random = random ( ) ;
extended urlclass loader ecl = new extended urlclass loader ( urls , parent cl , true ) ;
verify unmodified ( u1 ) ;
if ( scala ) { out . println ( ) ; out . tab ( 1 ) . println ( override def values row : % s [ % s ] = { , out . ref ( row . class . get name ( ) + degree ) , row type ) ; out . tab ( 2 ) . println ( super . values row . as instance of [ % s [ % s ] ] , out . ref ( row . class . get name ( ) + degree ) , row type ) ; out . tab ( 1 ) . println ( } ) ; } else { out . tab ( 1 ) . override inherit ( ) ; out . tab ( 1 ) . println ( public % s < % s > values row ( ) { , out . ref ( row . class . get name ( ) + degree ) , row type ) ; out . tab ( 2 ) . println ( return ( % s ) super . values row ( ) ; , out . ref ( row . class . get name ( ) + degree ) ) ; out . tab ( 1 ) . println ( } ) ; }
this . hi _ = this . max hi _ ;
f dtdvalidator . start element ( f qname , f attr proxy , null ) ;
media source . remove media source ( 3 ) ;
int delta = ( int ) ( pos - chunk pos ) ; if ( delta > 0 ) { read fully ( this , new byte [ delta ] , 0 , delta ) ; } }
for ( field doc field : cd . fields ( false ) ) { for ( annotation desc a : field . annotations ( ) ) { string annotation name = a . annotation type ( ) . qualified type name ( ) ; if ( annotation name . equals ( managed attribute . class . get name ( ) ) ) { is mbean = true ; mbean attribute attr = new mbean attribute ( ) ; attr . name = field . name ( ) ; attr . type = field . type ( ) . simple type name ( ) ; set name desc ( a . element values ( ) , attr ) ; set writable ( a . element values ( ) , attr ) ; mbc . attributes . add ( attr ) ; } } } if ( is mbean ) { collections . sort ( mbc . attributes ) ; collections . sort ( mbc . operations ) ; return mbc ; } else { return null ; }
if ( state = = removed & & first removed = = - 1 ) first removed = index ; index - = probe ; if ( index < 0 ) { index + = length ; } state = _ states [ index ] ;
class c < t , d2 > { } , } , } , } ) . do test ( ) ; }
byte buffer . get ( ) ;
word . set length ( k ) ; k - - ; * note that `ing ' has also been removed * if ( lookup ( ) ) return ;
channel client channel = relay conn insp . get channel ( ) ; inet socket address relay addr = ( inet socket address ) client channel . get remote address ( ) ; socket address client addr = client channel . get local address ( ) ; int relay port = relay addr . get port ( ) ; log . info ( relay selected : + relay port ) ; simple test server connection relay = null ; for ( int i = 0 ; i < relay _ port . length ; + + i ) { if ( relay port = = relay _ port [ i ] ) relay = _ dummy server [ i ] ; }
song _ end = true ;
try { file binary file = get razor archive binary file for ( new file ( parent , basename ) , rev ) ; if ( binary file = null & & binary file . exists ( ) ) { @ todo : implement a unix compress decompression input stream the standard razor implementation uses unix compress , so we need to be able to decompress these files . this gzip based implementation will be useful to sites using gzip as a unix compress replacement ( a supported configuration according to to the razor 4 . x 5 . x manuals ) return new gzipinput stream ( new file input stream ( binary file ) ) ; } file rcs file = get razor archive rcsfile for ( new file ( parent , basename ) ) ; if ( rcs file = null & & rcs file . exists ( ) ) { string rcs path = rcs file . get path ( ) ; return new buffered input stream ( new rcsget ( rcs path , rev ) ) ; } file sccs file = get razor archive sccsfile for ( new file ( parent , basename ) ) ; if ( sccs file = null & & sccs file . exists ( ) ) { ensure command ( sccsrepository . cmd _ property _ key , sccsrepository . cmd _ fallback ) ; return sccsget . get revision ( repo command , sccs file , rev ) ; } } catch ( exception e ) { logger . log ( level . severe , get history get ( + parent + , + basename + , + rev + ) , e ) ; } return null ;
for ( api keys key : api keys . values ( ) ) { if ( key = = api keys . produce | | key = = api keys . join _ group | | key = = api keys . sync _ group | | key = = api keys . sasl _ authenticate ) { assert true ( key + should require delayed allocation , key . requires delayed allocation ) ; } else { assert false ( key + should not require delayed allocation , key . requires delayed allocation ) ; } }
if ( _ log . should log ( log . info ) ) _ log . info ( get job id ( ) + : no peers left , but some are pending pending : + _ state . get pending ( ) . size ( ) + attempted : + _ state . get attempted ( ) . size ( ) + failed : + _ state . get failed ( ) . size ( ) ) ;
return group . equals ( pair . group ) & & name . equals ( pair . name ) ; } catch ( class cast exception e ) {
case token . name : s = ts . get string ( ) ; decompiler . add name ( s ) ; pn = property name ( pn , s , member type flags ) ; break ;
if ( file utils . clean dir ( directory ) ) { log . severe ( failed to clean directory : + directory ) ; return false ; } return true ; }
assert that ( picker8 . pick list ) . contains exactly ( new backend entry ( subchannel3 , get load recorder ( ) , token0003 ) , new backend entry ( subchannel3 , get load recorder ( ) , token0005 ) ) . in order ( ) ;
this . sender = hongbao info [ 0 ] ; this . time = hongbao info [ 1 ] ; this . content = hongbao content ; return true ;
( ( local cluster ) config ) . set new cli ( false ) ;
assert equals ( 6 , list2 . size ( ) ) ;
assert equals ( old anonymous auth data , partial mock current user . get auth data ( ) . get ( parse anonymous utils . auth _ type ) ) ;
final int port = integer . value of ( range ) ; if ( port < 0 | | port > 65535 ) { throw new illegal configuration exception ( invalid port configuration . port must be between 0 + and 65535 , but was + port + . ) ; } range iterator = collections . singleton ( integer . value of ( range ) ) . iterator ( ) ; } else {
list < located block > result = inode = = null ? new array list < located block > ( ) : namesystem . get block locations internal ( inode , offset , length , integer . max _ value ) . get located blocks ( ) ; if ( result = = null ) { return collections . empty list ( ) ; } return collections . unmodifiable list ( result ) ; }
database branch winners branch = new database branch ( ) ; database version header comparator database version header comparator = new database version header comparator ( false ) ; for ( database version header potential winner : database version headers ) { boolean empty winner branch = winners branch . size ( ) = = 0 ; boolean potential winner wins = empty winner branch & & database version header comparator . compare ( potential winner , winners branch . get last ( ) ) > 0 ; if ( empty winner branch | | potential winner wins ) { logger . log ( level . info , adding database version to winning branch : + potential winner ) ; winners branch . add ( potential winner ) ; } else { logger . log ( level . info , ignoring database version : + potential winner ) ; } }
final date time result = ( ( default subscription internal api ) subscription internal api ) . get effective date for new bcd ( new bcd , effective date , internal call context ) ; assert . assert equals ( result , internal call context . to utcdate time ( new local date ( 2012 - 06 - 30 ) ) ) ;
comment adapter . on selected items change listener change listener = new comment adapter . on selected items change listener ( ) { @ override public void on selected items changed ( ) { if ( m action mode = null ) { if ( get selected comment count ( ) = = 0 ) { m action mode . finish ( ) ; } else { update action mode title ( ) ;
notify all ( ) ; wait ( 1000 ) ; } } catch ( interrupted exception e ) {
header as property renderer wrapper . setup default renderer ( my jtable , get columns msg parameters ( ) ) ; my jtable . set preferred scrollable viewport size ( new dimension ( 500 , 70 ) ) ; renderer utils . apply renderers ( my jtable , get renderers ( ) ) ; my scroll pane = new jscroll pane ( my jtable ) ; settings pane = new vertical panel ( ) ; settings pane . set border ( margin2 ) ;
result . append ( ch ) ; } } else if ( ch = = ' - ' ) {
a . set max capacity ( 1 . 0f ) ;
execute operation ( kernel services , operation builder . build ( ) ) ; }
uri uri new = get new uri ( context . uri to resolve , context . base uri ) ; url url = uri new . to url ( ) ; urlconnection url connection ; url connection = open connection ( url ) ;
string organization name = test org ; device policy manager . set organization name ( test component , organization name ) ;
submit application request app request = records . new record ( submit application request . class ) ;
query q = qf . from ( get model factory ( ) . get transaction impl class ( ) ) . having ( amount ) . gt ( 1500 ) . build ( ) ; list < transaction > list = q . list ( ) ;
return class name . replace ( ' . ' , ' ' ) + . class ;
order by = ( order by plan node ) pn . get child ( 0 ) ; list < abstract expression > s = order by . get sort expressions ( ) ; assert equals ( 1 , s . size ( ) ) ; assert equals ( expression type . value _ tuple , s . get ( 0 ) . get expression type ( ) ) ;
res = region . check and mutate ( row1 , fam1 , qf1 , compare op . equal , new binary comparator ( val1 ) , put , lock id , true ) ;
jmsservice modify event post modify event = service events . stream ( ) . filter ( event - > event . get event type ( ) = = jmsevent type . added ) . find first ( ) . or else ( null ) ;
public string to string ( ) { string builder str builder = new string builder ( table id type : = = > ) ; str builder . append ( id clazz ) ; str builder . append ( | table name : = = > ) ; str builder . append ( table name ) ; str builder . append ( | type : = = > ) ; str builder . append ( type ) ; return str builder . to string ( ) ; }
final memory manager memory manager ; try { memory manager = new memory manager ( memory size , task manager services configuration . get number of slots ( ) , task manager services configuration . get network config ( ) . network buffer size ( ) , mem type , pre allocate memory ) ; } catch ( out of memory error e ) { if ( mem type = = memory type . heap ) { throw new exception ( out of memory error ( + e . get message ( ) + ) while allocating the task manager heap memory ( + memory size + bytes ) . , e ) ; } else if ( mem type = = memory type . off _ heap ) { throw new exception ( out of memory error ( + e . get message ( ) + ) while allocating the task manager off - heap memory ( + memory size + bytes ) . try increasing the maximum direct memory ( - xx : max direct memory size ) , e ) ; } else { throw e ; } } return memory manager ;
root . build ( new build node callback ( ) { @ override public void on missing interval ( final node interval cur node , final local date start date , final local date end date ) { output . add ( create node interval ( start date , end date ) ) ; } @ override public void on last node ( final node interval cur node ) {
assert query ( select count ( * ) from lineitem l join nation n on l . suppkey % 5 = n . nationkey % 5 and l . partkey % 3 < n . regionkey and l . partkey % 3 + 1 < n . regionkey and l . partkey % 3 + 2 < n . regionkey ) ;
long new expire time = system . current time millis ( ) + timeout ;
credentials access _ credentials = credentials . get credentials ( request , provider , credentials . type . access ) ;
result = class name + property name . substring ( class name . length ( ) + 1 + redundant string . length ( ) ) ;
map < byte [ ] , string > results = table . coprocessor exec ( ping protocol . class , null , null , new batch . call < ping protocol , string > ( ) { public string call ( ping protocol instance ) { return instance . ping ( ) ; } } ) ;
workspace panel = new workspace panel ( workspace panel , new property model ( model , workspace ) , new resource model ( workspace , workspace ) , true ) ; form . add ( workspace panel ) ; capabilities url = new text param panel ( capabilities url , new property model ( model , capabilities url ) , new param resource model ( capabilities url , abstract wmtsstore page . this ) , true ) ;
final assertion assertion = new assertion impl ( test ) ;
conf . set int ( dfs . replication . interval , 0 ) ;
mutation rm = schema keyspace . make create table mutation ( keyspace , metadata , fbutilities . timestamp micros ( ) ) . build ( ) ; partition update serialized cf = rm . get partition update ( schema . instance . get table metadata ( schema constants . schema _ keyspace _ name , schema keyspace . tables ) ) ; partition update serialized cd = rm . get partition update ( schema . instance . get table metadata ( schema constants . schema _ keyspace _ name , schema keyspace . columns ) ) ; untyped result set . row table row = query processor . resultify ( string . format ( select * from % s . % s , schema constants . schema _ keyspace _ name , schema keyspace . tables ) , unfiltered row iterators . filter ( serialized cf . unfiltered iterator ( ) , fbutilities . now in seconds ( ) ) ) . one ( ) ;
list < bootstrap factory < bootstrap > > cbfs = sctp client channel ( ) ;
mock . expected bodies received ( london ) ; template . send body and header ( file : target messages input , london , exchange . file _ name , london . txt ) ;
assert array equals ( new string [ ] { incoming } , storage dir . list ( ) ) ;
update scrim visibility ( ) ; }
for ( tree resource : try tree . get resources ( ) ) { if ( resource . equals ( prev ) ) { break ; } add if variable ( resource , result ) ; }
ioutils . read fully ( channel , data ) ;
if ( v = = sink ) { found augmented path = true ; break ; } } } }
downstream consumer . set error ( e ) ;
sock fprog prog = new sock fprog ( insns ) ; prog . write ( ) ; long pointer = pointer . native value ( prog . get pointer ( ) ) ; int method = 1 ;
for ( final string server : server array ) { new thread ( new runnable ( ) { @ override public void run ( ) { connect to one server with retry ( server ) ; connections . count down ( ) ; } } ) . start ( ) ; }
int slash = req . index of ( ' ' ) , space = req . last index of ( ' ' ) ; if ( slash = - 1 & & space = - 1 & & space > slash ) return http : + hostname + req . substring ( slash , space ) ;
i = total frames ;
assert true ( hostname port single port . matches ( uri . create ( ha : 1 . 2 . 3 . 4 : 1234 ) ) ) ;
m . execute ( sw , scope ) ; assert equals ( get contents ( root , bundles _ nulllabels . txt ) , sw . to string ( ) ) ; }
for ( int i = 0 ; i < size ; i + + ) { process result ( consumer , result , list . get ( i ) ) ; } return size ; } else if ( results instanceof iterable ) {
list = lazy list . remove ( input , z ) ;
return generated by default as identity ;
list < string > names = entity manager . create query ( select lower ( p . name ) + from person p , string . class ) . get result list ( ) ;
long value = 0 ; try { value = long . parse long ( id ) ; } catch ( number format exception e ) { c . write err message ( error code . er _ no _ such _ thread , invalid connection id : + id ) ; return ; }
data format = new csv data format ( ) . set trailing delimiter ( false ) ;
if ( regular expression . region matches ( index , * * , 0 , 2 ) ) {
file system item target path = get target path ( ) ;
assert . assert equals ( 1 , class under test . get if absent value ( 1 , absent value ) ) ;
annotation metadata builder response type annotation = new annotation metadata builder ( response type . get annotation ( ) ) ; controller builder . add annotation ( response type annotation ) ; return controller builder ;
final path file1 = new path ( filelocal . dat ) ; final file system fs = file system . get ( conf ) ; fsdata output stream stm = create file ( fs , file1 , 1 ) ; stm . write ( data to write ) ;
bitmap info ret = cache . get bitmap info ( key ) ;
short result a , result b = indeterminate ;
for ( int j = 0 ; j < 10 ; + + j ) { count = 0 ; iterator . reset ( ) ;
output . no nulls = no nulls ;
ret [ 1 ] = ( byte ) header . length ; system . arraycopy ( header , 0 , ret , 2 , header . length ) ; return ret ; }
resource bytes = new byte array resource ( 1 2 3 4 5 6 test . get bytes ( ) ) ; long [ ] xyz = { 5 l , 6 l , 7 l } ; tile object to = tile object . create complete tile object ( test : 123123 112 , xyz , epsg : 4326 , image jpeg , parameters , bytes ) ; blob store . put ( to ) ;
verify files equal ( fs , base file , enc file1 , len ) ;
try { writer . append ( test string , - 1 , 0 ) ; fail ( test 1 : index out of bounds exception expected . ) ; } catch ( index out of bounds exception e ) { expected . } try { writer . append ( test string , 0 , - 1 ) ; fail ( test 2 : index out of bounds exception expected . ) ; } catch ( index out of bounds exception e ) { expected . } try { writer . append ( test string , 1 , 0 ) ; fail ( test 3 : index out of bounds exception expected . ) ; } catch ( index out of bounds exception e ) { expected . } try { writer . append ( test string , 1 , test string . length ( ) + 1 ) ; fail ( test 4 : index out of bounds exception expected . ) ; } catch ( index out of bounds exception e ) { expected . } writer . append ( test string , 1 , 3 ) ; writer . flush ( ) ;
type t0 = ta , t1 = tb ; shorter type in t0
if ( host region counter > this . max regions on rs ) { max regions on rs = host region counter ; this . most loaded rsset . clear ( ) ; this . most loaded rsset . add ( current rs ) ; } else if ( host region counter = = this . max regions on rs ) { this . most loaded rsset . add ( current rs ) ; }
if ( included & & args . has flag ( ' s ' ) ) { sender . send message ( chat color . yellow . to string ( ) + players slain . ) ; }
for ( map . entry < string , object > config : new configs . entry set ( ) ) { string key = config . get key ( ) ; object value = config . get value ( ) ; if ( this . source . get ( key ) = = null ) { logger . info ( load config from db : { } = { } , key , value ) ; } else if ( objects . equals ( this . source . get ( key ) , value ) ) { logger . info ( load config from db : { } = { } . old value = { } , key , value , this . source . get ( key ) ) ; } this . source . put ( key , value ) ; }
enums = new string [ ( ( array list < string > ) m attributes . get ( enums ) ) . size ( ) ] ; enums = ( ( array list < string > ) m attributes . get ( enums ) ) . to array ( enums ) ; }
int pos = get stream position of the field ( ctx ) ; in . position ( pos ) ;
out str = run fsck ( conf , 1 , true , ) ; system . out . println ( out str ) ; assert true ( out str . contains ( namenode fsck . corrupt _ status ) ) ; assert true ( out str . contains ( test corrupt block ) ) ; }
for ( keras layer loss layer : loss layers ) { this . layers ordered . add ( loss layer ) ; this . layers . put ( loss layer . get layer name ( ) , loss layer ) ; this . output layer names . add ( loss layer . get layer name ( ) ) ; }
if ( g = pg | | f = pf | | p = pp | | c = pc | | pd = ppd | | pt = ppt ) { log . info ( segs [ i ] + changed input dirs ) ; } pg = g ; pf = f ; pp = p ; pc = c ; ppd = pd ; ppt = pt ;
log . warn ( error while reading + mtab , e ) ;
driver . on close ( new close info ( status code . normal , normal ) ) ;
await ready ( client , node ) ; metadata request . builder builder = new metadata request . builder ( collections . < string > empty list ( ) , true ) ;
if ( current . is primitive ( ) ) { return new reference type ( resolved name , current . get array ( ) ) ; } }
authentication execution info representation execution = find execution by provider ( idp create user if unique authenticator factory . provider _ id , auth mgmt resource . get executions ( first broker login2 ) ) ; assert . assert equals ( cfg rep . get id ( ) , execution . get authentication config ( ) ) ;
result . add ( inst new ) ;
final cpp application application = project . get extensions ( ) . create ( cpp application . class , executable , default cpp application . class , main , project . get layout ( ) , object factory , file operations , configurations ) ; project . get components ( ) . add ( application ) ; project . get components ( ) . add ( application . get debug executable ( ) ) ; project . get components ( ) . add ( application . get release executable ( ) ) ;
partition = p . get partition ( c , hconstants . empty _ byte _ array , 3 ) ;
input stream is = jubi account json test . class . get resource as stream ( example - balance - data . json ) ;
if ( current filter query . equals ( query ) ) filter query finished ( query , true ) ;
if ( view matcher . matches ( child ) ) { return ; } } ui controller . loop main thread for at least ( 50 ) ; } while ( system . current time millis ( ) < end time ) ;
string view name = get fragments folder ( module name ) . concat ( menu ) . concat ( get views extension ( ) ) ;
log . info ( killing job : + id . to string ( ) ) ;
if ( m compact style ) { height = height + status bar height ; } else if ( ( height - status bar height ) < = default header min height ) {
int i = buffer . position ( ) ; ( ( pre encoded http field ) field ) . put to ( buffer , http version . http _ 2 ) ; byte b = buffer . get ( i ) ; indexed = b < 0 | | b > = 0x40 ; if ( _ debug ) encoding = indexed? pre encoded idx : pre encoded ; } else if ( _ _ do _ not _ index . contains ( header ) ) {
certificate exception = true ; }
node list machine l = model . get elements by tag name ( support vector machine ) ;
request request = client . new request ( localhost , server . get local port ( ) ) . timeout ( 5 , time unit . seconds ) ; future response listener listener = new future response listener ( request ) ; request . send ( listener ) ; consume request headers ( socket ) ;
super . run ( - t nat - f ) ;
vector . no nulls = true ;
assert false ( ( ( field mapper ) my field2 mapper ) . field type ( ) . stored ( ) ) ; assert not null ( my field3 mapper ) ;
records . populate cache ( ) ; relationship consistency report report = mock ( relationship consistency report . class ) ; records . cache access ( ) . set cache slot sizes ( check stage . stage6 _ rs _ forward . get cache slot sizes ( ) ) ; super . check ( report , record ) ; if ( check single direction ) { records . cache access ( ) . set forward ( records . cache access ( ) . is forward ( ) ) ; super . check ( report , record ) ; } return report ;
next _ rate . reset ( invalid _ timestamp , 0 ) ;
sink . add test ( hc _ namednodemapsetnameditemwithnewvalue . class ) ;
this . init progress bar ( start date ) ; new messages loader ( start date , get next date from history ( start date ) ) . start ( ) ;
short num non zero registers = add nibble register ( bucket , ( byte ) ( ( 0xff & position of1 ) - register offset ) ) ; set num non zero registers ( num non zero registers ) ; if ( num non zero registers = = num _ buckets ) { set register offset ( + + register offset ) ; set num non zero registers ( decrement buckets ( ) ) ; } }
device config . refresh = ( int ) math . max ( long . parse long ( value ) , refresh interval ) ; logger . debug ( value : { } , value ) ; } } else {
window . set status bar color ( color . parse color ( 20000000 ) ) ; window . set navigation bar color ( activity . get resources ( ) . get color ( theme utils . theme color arr [ app settings . get theme color ( ) ] [ 1 ] ) ) ;
assert equals ( ( double ) i 2 , list . get ( i ) ) ;
add source root ( this . get output directory ( ) ) ; }
return value of ( quotient , scale ) ; }
class . for name ( com . mysql . jdbc . driver ) ;
if ( prefixes & & namespaces ) throw new illegal state exception ( ) ; ns support . reset ( ) ;
assert false ( ( ( field mapper ) my field2 mapper ) . field type ( ) . stored ( ) ) ; assert not null ( my field3 mapper ) ;
name = ( string ) names . get ( index + + ) ;
asset type definition ( pc . get property ( first letter map ) , first letter . class , first letter type . class ) ;
int [ ] a = new int [ ] { 367 } ;
throw h2 o . fail ( create impl should never get called in model parameter schema v2 ) ;
throw new org . apache . axis2 . databinding . adbexception ( version id cannot be null ) ;
if ( path . starts with ( ) ) { path = path . substring ( 2 ) ; } int idx = path . index of ( ' ? ' ) ; if ( idx > - 1 ) { path = path . substring ( 0 , idx ) ; } return path ;
warning printer assume no side effects note printer = new warning printer ( system . out , configuration . note ) ; new assume no side effects checker ( assume no side effects note printer ) . check class specifications ( configuration . assume no side effects ) ;
cluster state = cluster state . builder ( cluster state ) . nodes ( discovery nodes . builder ( ) . add ( new node ( node1 - 5 . x , version . v _ 5 _ 6 _ 0 ) ) ) . build ( ) ; cluster state = cluster state . builder ( cluster state ) . routing table ( allocation . reroute ( cluster state , reroute ) . routing table ( ) ) . build ( ) ; assert that ( cluster state . get routing nodes ( ) . shards with state ( initializing ) . size ( ) , equal to ( 1 ) ) ; assert that ( cluster state . get routing nodes ( ) . shards with state ( unassigned ) . size ( ) , equal to ( 3 ) ) ;
previously granted . remove ( permission ) ;
boolean auxiliary = ( j + 1 < tokens . length & & verb mod . matches ( . * ? + phrase to regex ( tokens [ j ] + + tokens [ j + 1 ] ) + . * + ) ) ? true : false ; string replacement = m . group ( 0 ) . replace first ( thing _ p , unknown _ r ) ;
access token = session . get access token ( ) ;
assert true ( buffer not recycled . , buffer . is recycled ( ) ) ; verify ( buffer , times ( 1 ) ) . recycle ( ) ; }
lenient parse = false ;
if ( top . get precedence ( ) < node . get precedence ( ) ) break ;
template . send body ( direct : start , 42 ) ; } catch ( camel execution exception e ) {
conf . set queues ( q _ c111 , new string [ ] { c1111 } ) ;
assert equals ( foo coder1 max1 , foo coder1 max2 ) ;
int row2 = index2 n columns ; int column2 = ( index2 - row2 * n columns ) % n columns ; cell cell2 = cells [ row2 ] [ column2 ] ;
template . execute ( insert into groups values ( 3 , ' group _ 3 ' ) ) ;
input channel id to cancel = ( input channel id ) msg ;
string label = correction messages . advanced quick assist processor _ replace conditional with if ; image image = java plugin images . get ( java plugin images . img _ correction _ change ) ; astrewrite correction proposal proposal = new astrewrite correction proposal ( label , context . get compilation unit ( ) , rewrite , iproposal relevance . replace _ conditional _ with _ if _ else , image ) ; resulting collections . add ( proposal ) ; return true ;
if ( naming resources = null ) { naming resources . init ( ) ; }
return parameters ;
if ( length = = null | | length > caching resource manager . get max file size ( ) ) { underlying resource . serve ( sender , exchange , completion callback ) ; return ; }
g . set flag ( 0 ) ; if ( g . get parent ( ) = = null ) { stack . add last ( g ) ; } }
object instance = camel context . get registry ( ) . lookup by name ( name ) ;
if ( r . node . next = null ) { q = r ; continue ; }
array list < string > configs = new array list < > ( 1 ) ; configs . add ( drop down model . pg _ config ) ; drop down test util . set available backends ( configs , configs . get ( 0 ) ) ; navigate to start page ( ) ;
queue . add ( new protected media identifier info fetcher ( ) ) ;
if ( old card . get card thumbnail ( ) = null ) { if ( new card . get card thumbnail ( ) = = null ) return true ; else if ( old card . get card thumbnail ( ) . get inner layout ( ) = new card . get card thumbnail ( ) . get inner layout ( ) ) return true ; } else { if ( new card . get card thumbnail ( ) = null ) return true ; }
parser interpreter parser = derive temp parser interpreter ( g , original parser , tokens ) ; if ( stop index > = ( tokens . size ( ) - 1 ) ) { if we are pointing at eof token eof is not in tree , so must be 1 less than last non - eof token stop index = tokens . size ( ) - 2 ; }
reload type ( sub target , 002 ) ;
string text ;
table name table name = table name . value of ( conf . get ( input _ table ) ) ; try { initialize table ( connection factory . create connection ( new configuration ( conf ) ) , table name ) ; } catch ( exception e ) { log . error ( string utils . stringify exception ( e ) ) ; } }
hconnection manager . hbase _ instances . clear ( ) ; hconnection manager . hbase _ instances . put all ( old hbase instances ) ; }
geo point last point = null ; for ( final geo point end : points ) { if ( last point = null ) { final plane normalized connecting plane = new plane ( last point , end ) ; if ( normalized connecting plane = = null ) { continue ; } segments . add ( new path segment ( planet model , last point , end , normalized connecting plane ) ) ; } last point = end ; } if ( segments . size ( ) = = 0 ) { simple circle final geo point point = points . get ( 0 ) ; final segment endpoint only endpoint = new segment endpoint ( point ) ; end points . add ( only endpoint ) ; this . edge points = new geo point [ ] { point } ; return ; }
http method get json = new get method ( cache factory . get rest url ( ) + + key ) ; get json . set request header ( accept , application json ) ; cache factory . get rest client ( ) . execute method ( get json ) ; assert equals ( get json . get status text ( ) , http status . sc _ ok , get json . get status code ( ) ) ; assert equals ( as json ( p ) , get json . get response body as string ( ) ) ;
auto focus again later ( ) ; } } }
server . add to online regions ( regions . get second ( ) ) ;
node traversal . traverse es6 ( compiler , root , new remove global var callback ( ) ) ;
done = watch . taken ( ) > = endpoint . get timeout ( ) ;
long start from = 0 ;
equalizer800 hz seek bar = ( vertical seek bar ) find view by id ( r . id . equalizer800 hz ) ;
instruction = new ldc2 _ w ( cp . add double ( value ) ) ;
m insertable . add ( index , item ) ;
if ( this time < compare time ) { return true ; }
path temp path = new path ( quota dir21 , nqdir32 ) ;
assert true ( bulkload event = null ) ;
char [ ] ins = new char [ len instruction ] ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( too many load balancers ) ) return null ; too many load balancers exception e = ( too many load balancers exception ) super . unmarshall ( node ) ; return e ; }
grid fsbucket . find ( eq ( metadata . content type , image png ) ) . for each ( new block < grid fsfile > ( ) { @ override public void apply ( final grid fsfile grid fsfile ) { system . out . println ( grid fsfile . get filename ( ) ) ; } } ) ;
row update builder builder = new row update builder ( cfs . metadata ( ) , 2 , key ) ; builder . clustering ( string . value of ( 5 ) ) . add ( val , byte buffer util . empty _ byte _ buffer ) . build ( ) . apply unsafe ( ) ; cfs . force blocking flush ( ) ;
if ( first rel = = relation in order by & & ( spec . order by ( ) = null & & ( spec . limit ( ) = null | | spec . offset ( ) = null ) ) ) { order by = order by . copy and replace ( symbols . deep _ copy ) ; spec . order by ( order by ) ; query spec . order by ( null ) ; order by moved = true ; return ; } }
names = new array list < > ( ) ; names . add ( * . o ) ; instance . set items ( names ) ; names = instance . get items ( ) ; assert equals ( 1 , names . size ( ) ) ; assert true ( instance . ignore ( foo . o ) ) ;
segment num = max _ seg _ count ; message length = segment num * segment length ; }
check permissions ( path ) ;
if ( is single step mode ( ) ) { logger . log ( step breakpoint + node id + is already in single step mode , so stepping instead . ) ; step ( ) ; } logger . log ( step breakpoint + node id ) ;
code = new code ; returns the positions of the resized instructions return indexes ; }
throw error . error ( error code . x _ 42562 ) ; }
write packet ( avmedia _ type _ audio , audio _ pkt ) ; return true ;
if ( new col . is identity ( ) & & table . has identity column ( ) & & table . identity column = col index ) { throw error . error ( error code . x _ 42525 ) ; } if ( table . get primary key ( ) . length > 1 ) { new col . set primary key ( old col . is primary key ( ) ) ; if ( array util . find ( table . get primary key ( ) , col index ) = - 1 ) { } } else if ( table . has primary key ( ) ) { if ( old col . is primary key ( ) ) { new col . set primary key ( true ) ; } else if ( new col . is primary key ( ) ) { throw error . error ( error code . x _ 42532 ) ; } } else if ( new col . is primary key ( ) ) { throw error . error ( error code . x _ 42530 ) ; }
assert true ( fail msg ( ) , new file ( build _ dir ) . is directory ( ) ) ;
byte [ ] ba = new byte [ ] { 117 , 110 , 109 , 97 , 112 , 32 , 98 , 117 , 102 , 102 , 101 , 114 } ; return byte buffer . wrap ( ba ) ; }
if ( this . regions in transition in rs . is empty ( ) ) { if ( is online regions empty ( ) ) { log . info ( we were exiting though online regions are not empty , because some regions failed closing ) ; } break ; } threads . sleep ( 200 ) ;
analysis without issues . run ( ) ;
list < core map > numbers = number normalizer . find numbers ( annotation ) ; core map aggregator number aggregator = core map aggregator . get aggregator ( core map attribute aggregator . default _ numeric _ aggregators , core annotations . tokens annotation . class ) ;
int width size and state = resolve size and state ( width size , width measure spec , 0 ) ; width size = width size and state & measured _ size _ mask ;
sql = ( select a , b , c from ttree _ with _ key ) + union ( select a , b , c from ttree _ with _ key order by a , b , c limit 1 ) + order by a , b , c ; ; assert plan determinism core ( sql , true , true , determinism mode . faster ) ;
byte [ ] b = hex to byte ( e2 80 a6 ) ;
return - 99999 ;
observer . on event ( event ) ;
try { holder . reply button . set visibility ( view . gone ) ; } catch ( exception e ) { } holder . screen name = screenname ;
if ( page header . populate ( input , true ) ) { return false ; } int segment index = 0 ; int bytes to skip = page header . header size ; if ( ( page header . type & 0x01 ) = = 0x01 & & packet array . limit ( ) = = 0 ) {
try { iter . remove ( ) ; } catch ( illegal state exception ise ) { continue ; } remote host id to = entry . get key ( ) ; list < out net message > all queued = entry . get value ( ) ; list < out net message > queued = new array list < out net message > ( ) ; long now = _ context . clock ( ) . now ( ) ; synchronized ( all queued ) { for ( out net message msg : all queued ) { if ( now - router . clock _ fudge _ factor > msg . get expiration ( ) ) { _ transport . failed ( msg , took too long in est . mgr ob queue ) ; } else { queued . add ( msg ) ; } } } if ( queued . is empty ( ) ) continue ;
clear items ( ) ; boolean has shared projects = shared projects = null & & shared projects . length ( ) > 0 ;
closeable iterable < cache entry < object , void > > iterable = decorated cache . filter entries ( versioned entry . exclude _ empty _ extract _ value ) . converter ( null value converter . get instance ( ) ) ;
throw new limit exceeded exception ( limit of + end + exceeded . ) ;
string signature = method . get signature ( ) ;
check argument ( redeem script = null , p2 sh script requires redeem script to be spent ) ; return redeem script . get number of signatures required to spend ( ) * sig _ size + redeem script . get program ( ) . length ;
if ( check exists ) { object entry current = ( object entry ) this . table [ index ] ; while ( current = null ) { if ( hash code = = current . cached hash code & & this . comparator . equal ( value , current . value ) ) { final object old value = current . value ; current . value = value ; return true ; } current = ( object entry ) current . get next ( ) ; } }
this . data map = use hash map ? new hash map < object , composite data > ( initial capacity , load factor ) : new linked hash map < object , composite data > ( initial capacity , load factor ) ; }
for ( int i = 0 ; i < x . length ; i + + ) { double tmp = ( derivative [ i ] - cur derivative [ i ] ) ; hdot v [ i ] = h inv * ( tmp ) ; }
selected nodes . add ( n ) ;
this . set endpoint ( https : elasticbeanstalk . us - east - 1 . amazonaws . com ) ;
try { bytes of gateway password = gateway password . get bytes ( utf - 8 ) ; } catch ( unsupported encoding exception e ) { logger . error ( no such encoding , utf - 8 : { } , e . get message ( ) ) ; }
cli . send line ( deployment = + war file . get name ( ) + : add ( content = { url = + war file . to uri ( ) . to url ( ) . to external form ( ) + } ) ) ;
assert equals ( primitive object inspector . primitive category . string , pti . get primitive category ( ) ) ; }
assert false ( m device . find object ( new ui selector ( ) . class name ( pending app widget host view . class ) ) . exists ( ) ) ;
decimal format df = new decimal format ( . ) ; double percent used = ( ( double ) ( used ) ( double ) runtime . max memory ( ) ) * 100 ; simple ordered map < object > mem = new simple ordered map < object > ( ) ; mem . add ( free , human readable units ( runtime . free memory ( ) , df ) ) ; mem . add ( total , human readable units ( runtime . total memory ( ) , df ) ) ; mem . add ( max , human readable units ( runtime . max memory ( ) , df ) ) ; mem . add ( used , human readable units ( used , df ) + ( % + df . format ( percent used ) + ) ) ; jvm . add ( memory , mem ) ;
return elem . get declared annotations ( ) ; }
sanitize env ( environment , container work dir , app dirs , user local dirs , container log dirs , local resources , nm private classpath jar dir ) ; prepare container ( local resources , container local dirs ) ;
long timestamp = in . read long ( ) ; map < string , object > event = maps . new hash map ( ) ;
else { writer . write start element ( jac orbsubsystem constants . poa ) ; this . write attributes ( writer , node , jac orbsubsystem definitions . poa _ attributes ) ; writer . write empty element ( jac orbsubsystem constants . poa _ rp ) ; this . write attributes ( writer , node , jac orbsubsystem definitions . poa _ rp _ attributes ) ; writer . write end element ( ) ; }
if ( id inspector . is partitioned vertex ( vertexid ) ) vertexid = id manager . get canonical vertex id ( vertexid ) ; internal vertex v = null ;
return date utils . add hours ( now , 24 ) ;
j = b . compare to ( mlo ) ;
return ( is negative ) ? - 0 . 0 : 0 . 0 ;
if ( buffer . has homepage url ( ) ) { host datum . set homepage url ( buffer . get homepage url ( ) ) ; }
if ( to = = order . none ) { return false ; }
driver = data source provider . get driver ( driver id ) ;
if ( m has embedded tabs ) { m action view . set embedded tab view ( null ) ; m container view . set tab container ( m tab scroll view ) ; } else { m container view . set tab container ( null ) ; m action view . set embedded tab view ( m tab scroll view ) ; }
if ( args [ i ] = = null ) { continue ; } if ( args [ i ] . get class ( ) . is array ( ) ) {
try { realm . where ( null types . class ) . is null ( null types . field _ long _ not _ null ) . find all ( ) ; fail ( ) ; } catch ( illegal argument exception ignored ) { }
iterator < history record > recs = reader . find by start date ( start date ) ; while ( recs . has next ( ) ) { result . add ( create file record from history record ( recs . next ( ) , c ) ) ; } }
final int level = int value ( node , level ) ;
final books by hash books by hash = new books by hash ( collection ) ;
result + = get author ( ) . length ( ) * 2 ; utf - 16 le
rpc error error = response . get error ( ) ;
for ( int type = 0 ; type < limit ; type + + ) { cache . increment group count ( node id ) ; }
bulk iteration base < ? > iteration = ( bulk iteration base < ? > ) p . get data sinks ( ) . iterator ( ) . next ( ) . get input ( ) ; assert equals ( job name , p . get job name ( ) ) ; assert equals ( default parallelism , p . get default parallelism ( ) ) ;
if ( who . width < = 0 | | who . height < = 0 ) return ; image cache cash = ( image cache ) get cache ( who ) ;
if ( dst . has remaining ( ) ) { return 0 ; } if ( peer app data . position ( ) = 0 ) { read + = copy ( peer app data , dst ) ; return read ; }
set successful taskid ( taskid ) ;
assert not null ( time zone . get default ( ) ) ; assert false ( time zone . get default ( ) . get id ( ) . equals ( etc utc ) ) ; }
try { add and re watch table ( path ) ; } catch ( keeper exception e ) { log . warn ( couldn ' t read zookeeper data for table for path : + path + , not preserving a table . , e ) ; }
for ( repair message message : messages ) message . create message ( ) . serialize ( out , get version ( ) ) ; }
list < load balancer vo > lbs = _ elb vm map dao . list lbs for elb vm ( elb vm . get id ( ) ) ; list < load balancing rule > lb rules = new array list < load balancing rule > ( ) ; for ( load balancer vo lb : lbs ) { list < lb destination > dst list = _ lb mgr . get existing destinations ( lb . get id ( ) ) ; list < lb stickiness policy > policy list = _ lb mgr . get stickiness policies ( lb . get id ( ) ) ; load balancing rule load balancing = new load balancing rule ( lb , dst list , policy list ) ; lb rules . add ( load balancing ) ; } s _ logger . debug ( found + lb rules . size ( ) + load balancing rule ( s ) to apply as a part of elb vm + elb vm + start . ) ; if ( lb rules . is empty ( ) ) { create apply load balancing rules commands ( lb rules , elb vm , cmds ) ; } return true ;
for ( i = 0 ; i < stacks . length ; + + i ) { t = stacks [ i ] ; + + n stack ; if ( t = = frame . long | | t = = frame . double ) { + + i ; } }
assert bit set ( new byte [ 0 ] , { } ) ;
job history . refresh job retention settings ( ) ;
boolean dependency check = true ; try { dependency check = extension validator . validate application ( get resources ( ) , this ) ; } catch ( ioexception ioe ) { log . error ( sm . get string ( standard context . extension validation error ) , ioe ) ; dependency check = false ; } if ( dependency check ) { do not make application available if dependency check fails ok = false ; }
if ( context . is stopping ( ) ) { return ; } hregion info region = policy based chaos monkey . select random item ( regions . to array ( new hregion info [ regions . size ( ) ] ) ) ;
system . out . println ( test crc corruption with default parameters ) ; configuration conf1 = new hdfs configuration ( ) ; conf1 . set int ( dfsconfig keys . dfs _ blockreport _ interval _ msec _ key , 3 * 1000 ) ; dfstest util util1 = new dfstest util . builder ( ) . set name ( test crc corruption ) . set num files ( 40 ) . build ( ) ; thistest ( conf1 , util1 ) ;
int name count = 0 ; int rel count = 0 ; for ( node node : new db . get all nodes ( ) ) { name count + + ; assert that ( node , in tx ( new db , has property ( name ) , true ) ) ; rel count + = iterables . count ( node . get relationships ( direction . outgoing ) ) ; } assert equals ( 16 , name count ) ;
frame layout . layout params params = new frame layout . layout params ( sub action items . get ( i ) . width , sub action items . get ( i ) . height , gravity . top | gravity . left ) ;
buf . get int ( ) ; packet length int packet version ; if ( pkt include version ) { packet version = buf . get int ( ) ; } else { packet version = data transfer protocol . packet _ version _ checksum _ first ; } offset in block = buf . get long ( ) ; get offset of packet in block long seqno = buf . get long ( ) ; get seqno byte boolean field value = buf . get ( ) ;
return new pong ( ) ;
codec pool . return decompressor ( zlib decompressor ) ;
s . get transaction ( ) . begin ( ) ; criteria criteria = s . create criteria ( employee . class ) . add query hint ( maxdop 2 ) . create criteria ( department ) . add ( restrictions . eq ( name , sales ) ) ; results = criteria . list ( ) ; s . get transaction ( ) . commit ( ) ; s . close ( ) ; assert equals ( results . size ( ) , 2 ) ; assert true ( query hint test sqlserver2012 dialect . get processed sql ( ) . contains ( option ( maxdop 2 ) ) ) ; }
discard body data ( ) ;
reset internal ( false ) ;
assert true ( the thrown exception is not the expected one . , e . get message ( ) . starts with ( invalid resource scheduler vcores ) ) ; }
cluster . restart name node ( i , false ) ;
system2 . close ( output ) ; } }
assert equals ( 50 , tp . get maximum pool size ( ) ) ;
assert . assert null ( realm dc0 . get display name ( ) ) ; assert . assert true ( realm dc0 . is registration allowed ( ) ) ; assert . assert null ( realm dc1 . get display name ( ) ) ; assert . assert true ( realm dc1 . is registration allowed ( ) ) ;
int _ args len = 0 ; variant [ ] _ args = null ; dispparams . by reference dp = new dispparams . by reference ( ) ; excepinfo . by reference p excep info = new excepinfo . by reference ( ) ; int by reference pu arg err = new int by reference ( ) ;
if ( previous . has attribute ( cdata - section - elements ) ) { add attribute works as a setter if it already exists add attribute ( cdata - section - elements , previous . get attribute ( cdata - section - elements ) + ' ' + get attribute ( cdata - section - elements ) ) ; }
this . aggregation functions . add ( agg funct ) ; this . fields . add ( field ) ; this . grouping = null ; }
string var name = maybe extract variable name ( body . text ) ; if ( var name = null ) { var names . add ( var name ) ; } } }
default resources ( ) . add ( config name ) ; } catch ( ioexception ex ) {
if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( white ) ) { selected theme index = 0 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( gray ) ) { selected theme index = 1 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( blue ) ) { selected theme index = 2 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( red ) ) { selected theme index = 3 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( green ) ) { selected theme index = 4 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( orange ) ) { selected theme index = 5 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( purple ) ) { selected theme index = 6 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( magenta ) ) { selected theme index = 7 ; } else if ( shared preferences . get string ( now _ playing _ color , blue ) . equals ( black ) ) { selected theme index = 8 ; } else { selected theme index = 0 ; }
file txn iterator file itr = ( file txn iterator ) itr ; long storage size = file itr . get storage size ( ) ; log . info ( txnlog size : + storage size + bytes ) ; assert . assert true ( storage size is greater than zero , ( storage size > 0 ) ) ; long expected zxid = 0 ;
final list < long > list3 = new array list < long > ( ) ; interval . subscribe ( new consumer < long > ( ) { @ override public void accept ( long t1 ) { list3 . add ( t1 ) ; } } ) ; s . advance time by ( 200 , time unit . milliseconds ) ;
envelope e11 = new envelope ( e01 . get min x ( ) , e01 . get max x ( ) , e10 . get min y ( ) , e10 . get max y ( ) ) ; add network link ( folder , e00 , 00 , layer ) ;
for ( edge edge : v1 . get edges ( direction . out , test e ) ) { edge . remove ( ) ; }
close ( channel , succeeded future ( channel ) ) ; }
int old state = m playback . get state ( ) ; long pos = m playback . get current stream position ( ) ; string current media id = m playback . get current media id ( ) ; m playback . stop ( false ) ; playback . set callback ( this ) ; playback . set current media id ( current media id ) ; playback . seek to ( pos < 0 ? 0 : pos ) ; playback . start ( ) ;
card thumbnail circle thumb = new card thumbnail circle ( get activity ( ) ) ; card . add card thumbnail ( thumb ) ; card view native card view = ( card view native ) get activity ( ) . find view by id ( r . id . carddemo _ circleleft ) ;
force animation to finish ( ) ;
test tracker thread tracker = thread . tracker ;
serialization context ser ctx = proto stream marshaller . get serialization context ( remote cache manager ) ; marshaller registration . register marshallers ( ser ctx ) ; ser ctx . register proto files ( file descriptor source . from string ( not _ indexed . proto , not _ indexed _ proto _ schema ) ) ; ser ctx . register marshaller ( new not indexed marshaller ( ) ) ; }
flush store ( store , seq id ) ;
mutation rm = new row update builder ( cfs1 . metadata ( ) , 0 , k ) . clustering ( bytes ) . add ( val , byte buffer . allocate ( ( database descriptor . get commit log segment size ( ) 4 ) - 1 ) ) . build ( ) ;
content response response1 = client . get ( url + ?action = init ) ;
assertion error assertion error = new assertion error ( mismatch message ) ;
first digit = new node ( k2 , k3 , k4 , k5 , k6 , k7 , k8 , k9 ) ; m legal times tree . add child ( first digit ) ;
sphere2 . set radius ( sqrt3 + fast math . zero _ tolerance ) ;
final int servers = 1 ;
task service . complete ( tasks . get ( 0 ) . get id ( ) ) ; task service . complete ( tasks . get ( 1 ) . get id ( ) ) ; tasks = query . list ( ) ; assert equals ( 1 , tasks . size ( ) ) ; assert equals ( task c , tasks . get ( 0 ) . get name ( ) ) ; }
string locale key = locale key ( locale ) ;
bracket start = new int [ max brackets ] ;
throw new parse exception ( value , 0 ) ;
regex string comparator a = new regex string comparator ( a | b ) ; regex string comparator b = regex string comparator . parse from ( a . to byte array ( ) ) ; assert true ( a . are serialized fields equal ( b ) ) ; assert true ( b . get engine ( ) instanceof regex string comparator . java regex engine ) ;
system . out . println ( test labels nout mismatch rnn output layer ( ) : + e . get message ( ) ) ;
return null ; } throw e ; }
set divider ( null ) ;
verify zero interactions ( pool ) ;
if ( kill query = null ) { session state . get kill query ( ) . kill query ( query id , entry . get value ( ) . get msg ( ) ) ; }
assert false ( all names . contains ( org junit test . class ) ) ;
thread local . with initial ( thread . current thread ( ) : : get id ) ; } return select slot ( thread local random . current ( ) . next int ( ) ) ; } ) ; }
client ( ) . prepare index ( test , doc , 1 ) . set routing ( 1 ) . set source ( json builder ( ) . start object ( ) . field ( field1 , value ) . end object ( ) ) . get ( ) ; get response get response = client ( ) . prepare get ( index or alias ( ) , doc , 1 ) . set routing ( 1 ) . set stored fields ( field1 ) . get ( ) ;
if ( addrs . is empty ( ) ) { if ( ipv4 _ addrs . is empty ( ) & & ipv6 _ addrs . is empty ( ) ) { throw new runtime exception ( all addresses have to be either ipv4 or ipv6 : ipv4 addresses = + ipv4 _ addrs + , ipv6 addresses = + ipv6 _ addrs ) ; } return ipv6 _ addrs . is empty ( ) ? stack type . ipv6 : stack type . ipv4 ; } return stack type . unknown ; }
test . set ( calendar . day _ of _ week , calendar . saturday ) ; test . set ( calendar . hour _ of _ day , 10 ) ; set now ( test ) ; assert . assert false ( is monkey time ( monkey ) ) ;
int width = input image . get width ( ) ; int height = input image . get height ( ) ; int [ ] pixels = new int [ width * height ] ; output image . get pixels ( pixels , 0 , width , 0 , 0 , width , height ) ; if ( rgb = null ) { pixels = native image processor . apply rgbcurve ( pixels , rgb , width , height ) ; } if ( ( red = = null & & green = = null & & blue = = null ) ) { pixels = native image processor . apply channel curves ( pixels , red , green , blue , width , height ) ; } try { output image . set pixels ( pixels , 0 , width , 0 , 0 , width , height ) ; } catch ( illegal state exception ise ) { }
else { skip to start of audio if flac tag contains id3header or something before start of official flac header copy it over if ( flac stream . get start of flac in file ( ) > 0 ) { raf . seek ( 0 ) ; raf temp . get channel ( ) . transfer from ( raf . get channel ( ) , 0 , flac stream . get start of flac in file ( ) ) ; raf temp . seek ( flac stream . get start of flac in file ( ) ) ; } raf temp . write bytes ( flac stream reader . flac _ stream _ identifier ) ;
for ( map . entry < string , repository > entry : repositories . entry set ( ) ) { if ( new meta data = = null | | new meta data . repository ( entry . get key ( ) ) = = null ) { logger . debug ( unregistering repository [ { } ] , entry . get key ( ) ) ; close repository ( entry . get value ( ) ) ; } else { survivors . put ( entry . get key ( ) , entry . get value ( ) ) ; } } map < string , repository > builder = new hash map < > ( ) ;
assert equals ( value2 , remote value ) ;
public void test partition random access ( ) { iterator < integer > source = as list ( 1 , 2 , 3 ) . iterator ( ) ;
command + = ( + ( _ lfile . last modified ( ) 1000 ) + 0 \ n ) ;
code generator = new cpp code generator ( ) ; generate or modify project ( opt , code generator ) ; }
assert true ( 0 < callback counter [ 0 ] ) ; assert true ( 0 < callback counter [ 1 ] ) ;
} finally { try { closeables . close ( is , true * swallow ioexception * ) ; } catch ( ioexception e ) {
if ( decoder = null ) { if ( c . is last ( ) ) { content = decode ( content ) ; if ( content . readable ( ) ) { c . set content ( content ) ; ctx . send upstream ( e ) ; } } else { channel buffer last product = finish decode ( ) ;
if ( target = gl target & & ( gl20 . gl _ texture _ cube _ map _ positive _ x < = target & & target < = gl20 . gl _ texture _ cube _ map _ negative _ z & & target = = gl20 . gl _ texture _ 2 d ) ) throw new gdx runtime exception ( invalid target requested : 0x + integer . to hex string ( target ) + , expecting : 0x + integer . to hex string ( gl target ) ) ; }
keycloak user attributes . remove ( email ) ; profile attributes . put all ( keycloak user attributes ) ;
{ server instance instance1 = new server instance ( localhost , 8080 ) ; server instance instance2 = new server instance ( localhost , 8080 ) ;
m resource = 0 ; } }
baos = new byte array output stream ( ) ; b64os = new base64 output stream ( baos , flags , false ) ; for ( int i = 0 ; i < encoded . length ; + + i ) { b64os . write ( encoded [ i ] ) ; } b64os . close ( ) ; actual = baos . to byte array ( ) ; assert equals ( plain , actual ) ;
do { child = get child at ( i + + ) ; if ( child = = null ) { break ; } top = child . get top ( ) ; } while ( top < 0 ) ;
elem = ndefs list . get ( index ) ;
final count down latch latch = new count down latch ( 2 ) ;
node child node = children . get ( node link ) ;
string buffer top = 0 ; this . string = null ; parser . add error ( msg . xml . bad . form ) ; return token . error ; } xml is tag content = true ; xml open tags count - - ; break ; default :
for ( application listener < ? > listener : get application listeners ( ) ) { get application event multicaster ( ) . add application listener ( listener ) ; }
list < test all types . builder > builders = builder . get builder list ( ) ; assert equals ( 0 , builders . get ( 0 ) . get optional int32 ( ) ) ; assert equals ( 1 , builders . get ( 1 ) . get optional int32 ( ) ) ; builders . get ( 0 ) . set optional int32 ( 10 ) ; builders . get ( 1 ) . set optional int32 ( 11 ) ;
prepare listeners ( pre _ load , new default pre load event listener ( ) , listener array ) ;
final int partition state version = partition service . get partition state version ( ) ;
assert that ( actual state ) . overriding error message ( expected session state < % s > but was < % s > . , session state to string ( state ) , session state to string ( actual state ) ) . is equal to ( state ) ; return this ;
for ( queue acl acl : queue acl . values ( ) ) { access type access type = scheduler utils . to access type ( acl ) ; if ( acls . get ( access type ) = = null ) { access control list default acl = queue name . equals ( root ) ? everybody _ acl : nobody _ acl ; acls . put ( access type , default acl ) ; } } queue acls . put ( queue name , acls ) ;
if ( tick = null & & tick . _ seconds = = seconds ) return tick . _ string ;
if ( result = null & & result . is drawer open ( ) ) { result . close drawer ( ) ; } else { super . on back pressed ( ) ; } }
assert . assert true ( visitor . iterations > ( entry count 2 ) & & visitor . iterations < ( entry count 2 ) + fudge factor ) ;
target namespaces . add ( xml event factory . create namespace ( local schema . hbm . get namespace uri ( ) ) ) ; }
path snapshot dir = snapshot description utils . get working snapshot dir ( snapshot , root dir ) ; fstable descriptors . create table descriptor for table directory ( fs , snapshot dir , orig , false ) ; log . debug ( finished copying tableinfo . ) ; return null ;
graph model . destroy view ( result . get view ( ) ) ;
for ( int i = 0 ; i < 5 ; i + + ) { task task = task service . new task ( ) ; task . set name ( i + ) ; task service . save task ( task ) ; }
string subsystem xml = get subsystem xml ( ) ; kernel services services a = this . create kernel services builder ( ) . set subsystem xml ( subsystem xml ) . build ( ) ; model node read operation = get cache read operation ( maximal , local cache resource definition . wildcard _ path . get key ( ) , local , cache resource definition . attribute . statistics _ enabled ) ;
kie session ksession = kc . new kie session ( state agenda group ks ) ;
object layer value = fi . get attribute ( open search access . layer ) ;
m callbacks . on info show first session title ( id , title , marker type , type ) ;
int routing hash = murmur3 hash function . hash ( preference ) ;
workspace . run buck command ( clean ) ;
if ( deployment = = null ) { host log . error ( not a valid xml deployment file at url : + config . m _ path to deployment ) ; volt db . crash local volt db ( not a valid xml deployment file at url : + config . m _ path to deployment , false , null ) ; return new read deployment results ( deployment bytes , deployment ) ; }
native io . posix . mlock ( mapbuf , file size ) ;
for ( int i = 0 ; i < receiver queue size ; i + + ) { string message = my - message - + i ; producer . send ( message . get bytes ( ) ) ; thread . sleep ( 100 ) ; } int remaining msgs = ( 2 * receiver queue size ) - ( 2 * consume msg in parts ) ;
rm . wait for state ( app . get application id ( ) , rmapp state . accepted ) ;
secure random = new secure random ( ) ;
if ( is parse integer only ( ) | | saw decimal ) { break ; }
if ( opt . project names . is empty ( ) ) { system . err . println ( options . get usage ( generator options . class ) ) ; throw new illegal argument exception ( no type of package is specified . ) ; } for ( string project name : opt . project names ) { if ( allowed project names . contains ( project name ) ) { throw new illegal argument exception ( project name + project name + is not allowed . ) ; } } return opt ;
assert true ( repo . add ( key01 ) ) ; assert true ( repo . contains ( key01 ) ) ; }
assert not null ( person ) ; } ) ; do in jpa ( this : : entity manager factory , entity manager - > { log . info ( jpa query cache ) ;
order book order book = bitcoinde adapters . adapt order book ( bitcoinde order book , currency pair . btc _ eur ) ;
split . add ( triangle , first , stride ) ;
assert not null ( leader should exist , current leader ) ; log . debug ( current leader index is + current leader . get index ( ) ) ; byte [ ] znode data = zkutil . get data ( current leader . get watcher ( ) , leader _ znode ) ; assert not null ( leader znode should contain leader index , znode data ) ; assert true ( leader znode should not be empty , znode data . length > 0 ) ; int stored index = bytes . to int ( znode data ) ;
htable t = new htable ( new configuration ( this . conf ) , hconstants . meta _ table _ name ) ; list < byte [ ] > rows = new array list < byte [ ] > ( ) ; result scanner s = t . get scanner ( new scan ( ) ) ; for ( result result : s ) { byte [ ] val = result . get value ( hconstants . catalog _ family , hconstants . regioninfo _ qualifier ) ; if ( val = = null ) { log . error ( no region info for row + bytes . to string ( result . get row ( ) ) ) ; todo figure out what to do for this new hosed case . continue ; } hregion info info = writables . get hregion info ( val ) ; if ( bytes . compare to ( info . get table name ( ) , table name ) = = 0 ) { log . info ( get meta table rows : row - > + bytes . to string binary ( result . get row ( ) ) + info ) ; rows . add ( result . get row ( ) ) ; } } s . close ( ) ; t . close ( ) ; return rows ;
register with server ( activity , acct . get id ( ) , true ) ;
int s len = s arr . length ;
int cross width = cross image view . get drawable ( ) . get intrinsic width ( ) ;
status code = 0 ; start with 0 status code | = ( data . get ( ) & 0x ff ) < < 8 ; status code | = ( data . get ( ) & 0x ff ) ; if ( validate ) { assert valid status code ( status code ) ; }
bootstrap . set pipeline factory ( new telnet client pipeline factory ( ) ) ;
if ( columns . get ( 0 ) . contains ( col ) ) results = results . sub list ( 1 , results . size ( ) ) ; logger . info ( read data time = + string . value of ( system . current time millis ( ) - start ) ) ; start = system . current time millis ( ) ;
image container image container = new image container ( null , request url , cache key , image listener ) ;
empty statement . ignore ( ignored ) ;
fields . add all ( opair . convert from map ( content . to map ( ) ) ) ;
grid fsbucket . find ( eq ( metadata . content type , image png ) ) . for each ( new block < grid fsfile > ( ) { @ override public void apply ( final grid fsfile grid fsfile ) { system . out . println ( grid fsfile . get filename ( ) ) ; } } ) ;
tree . intersect field path ( foo , result ) ;
h = papplet . min ( 2 * textures [ last tex ] . gl height , max size ) ;
for ( long v : negatives2 ) { assert false ( s . lookup ( v ) ) ; } }
add input paths ( job , work ) ;
node first digit = new node ( k0 , k1 ) ; m legal times tree . add child ( first digit ) ;
parse current user controller current user controller = mock ( parse current user controller . class ) ; when ( current user controller . get async ( any boolean ( ) ) ) . then return ( task . < parse user > for result ( null ) ) ; parse core plugins . get instance ( ) . register current user controller ( current user controller ) ; parse user user = new parse user ( ) ;
string value = message . get header ( names . expect ) ;
out . write int ( sf . get snapshot quota ( ) ) ; }
responder = new simple rpc server responder ( this ) ; connection manager = new connection manager ( ) ; init reconfigurable ( conf ) ; this . scheduler . init ( new rpc scheduler context ( this ) ) ; }
return parse comprehension suffix ( new dict comprehension . builder ( ) . set key expression ( entry . get key ( ) ) . set value expression ( entry . get value ( ) ) , token kind . rbrace , start ) ;
integer integer2 = new integer ( 12345 ) ;
if ( source = null & & target = null & & crs . equals ignore metadata ( source , target ) ) { try {
bootstrap . release external resources ( ) ; }
search result = engine . acquire searcher ( test ) ;
if ( cell spacing = = 0 & & amount full > 0 ) {
pos = bucket name . index of ( . . ) ;
upgrade exception ue = assert expected error ( e , wsocket , instance of ( upgrade exception . class ) ) ;
for ( secondary table tab : sec tables . value ( ) ) { add join ( tab , null , null , false ) ; }
try { return value of ( double . value of ( string ) ) ; } catch ( number format exception e ) { matcher matcher = pattern . matcher ( string ) ; if ( matcher . find ( ) ) { boolean negative = - . equals ( matcher . group ( 1 ) ) ; int days = convert . convert ( matcher . group ( 2 ) , int . class ) ; int hours = convert . convert ( matcher . group ( 3 ) , int . class ) ; int minutes = convert . convert ( matcher . group ( 4 ) , int . class ) ; int seconds = convert . convert ( matcher . group ( 5 ) , int . class ) ; int nano = convert . convert ( string utils . right pad ( matcher . group ( 6 ) , 9 , 0 ) , int . class ) ; return new day to second ( days , hours , minutes , seconds , nano , negative ) ; } }
if ( this . is nude ) { de nude ( ) ; }
if ( quot < = rem ) { rem - = quot ; } else { if ( quot - rem < = b long ) { rem + = b long - quot ; quot - = 1 ; } else { rem + = ( b long < < 1 ) - quot ; quot - = 2 ; } }
double minimum = get minimum ( values ) ;
if ( raw base . is assignable from ( subtype . get type ( ) ) ) { yes annotated class curr = annotated class resolver . resolve without super types ( config , subtype . get type ( ) ) ; _ collect and resolve ( curr , subtype , config , ai , collected ) ; } } }
among _ var = find _ among _ b ( a _ 3 , 62 ) ; if ( among _ var = = 0 ) { return false ; }
constructor metadata builder updated constructor builder = new constructor metadata builder ( get declared by metadata id ( ) , constructor builder . build ( ) ) ;
if ( null = dispatcher ) { dispatcher . get event handler ( ) . handle ( new remove cluster node labels ( labels to remove ) ) ; } log . info ( remove labels : [ + string utils . join ( labels to remove . iterator ( ) , , ) + ] ) ;
synchronized ( my rel id2 obj map ) { my rel id2 obj map . remove ( relation id ) ; } if ( result instanceof object name ) { - object name to relation id map synchronized ( my rel mbean obj name2 rel id map ) { my rel mbean obj name2 rel id map . remove ( ( object name ) result ) ; } }
future = buffer . get ( first , 1 , size of pages ( 10 ) ) ; assert false ( future . is done ( ) ) ; future = buffer . get ( second , 0 , size of pages ( 10 ) ) ; assert false ( future . is done ( ) ) ; }
internal knowledge base k base = ( internal knowledge base ) knowledge base factory . new knowledge base ( ) ;
dtoa ( bin exp , fract bits , n significant bits ) ;
relationships part rrp = get relationships part ( part ) ;
{ abstract plan node pn = compile ( select c as tag from t3 union select b from t2 order by 1 limit 3 offset 2 ) ; string [ ] column names = { tag } ; pn = pn . get child ( 0 ) ; check order by node ( pn , column names , new int [ ] { 0 } ) ; assert true ( pn . get child ( 0 ) instanceof union plan node ) ; pn = pn . get inline plan node ( plan node type . limit ) ; check limit node ( pn , 3 , 2 ) ; }
get queues ( ) . remove ( key ) ;
assert equals ( weight grad copy , weight grad ) ;
assert not equals ( near cache config , config . get near cache config ( some near cache ) ) ; }
simple feature collection granules = source . get granules ( query ) ;
chat room op set1 room = op set muc1 . create chat room ( test room name , null ) ; assert not null ( create chat room returned null , op set1 room ) ;
| | java _ specification _ version . matches ( ^ ( 1 \ \ . ) ? ( 9 | [ 0 - 9 ] [ 0 - 9 ] ) ) ; }
instr , instrb , instrc , instr2 , instr4 , lengthb ,
if ( failed . equals ( response . get ( outcome ) . as string ( ) ) ) { assert . assert false ( response . to string ( ) , response . get ( rolled - back ) . as boolean ( true ) ) ; }
if ( ( string . class . is instance ( args [ 0 ] ) & & method . get parameter types ( ) [ 0 ] . equals ( string . class ) ) ) { return false ; } return true ;
if ( key string . equals ( metadata store . stores _ key ) ) { metadata store . update store definitions ( versioned value ) ; }
new collection admin request . move replica ( coll , replica . get name ( ) , cluster . get jetty solr runner ( 1 ) . get node name ( ) ) . process ( cluster . get solr client ( ) ) ; assert true ( cluster state util . wait for all active and live replicas ( cluster . get solr client ( ) . get zk state reader ( ) , 20000 ) ) ; cluster . get jetty solr runners ( ) . get ( 1 ) . stop ( ) ; assert true ( cluster state util . wait for all replicas not live ( cluster . get solr client ( ) . get zk state reader ( ) , 20000 ) ) ;
connected address = address ;
val . set values ( asdfs , new date ( 12312 ) , new long ( 213123 l ) , new date ( 12312 ) ) ;
write buffered image as jpeg ( out , 0 . 75f , image ) ; }
return - cppsemantics . compare by relevance ( tu , f1 , f2 ) ;
metric = new min metric ( stream expression parser . parse ( min ( foo ) ) , factory ) ; expression string = metric . to expression ( factory ) . to string ( ) ; assert equals ( min ( foo ) , expression string ) ;
leinput stream in = new leinput stream ( create input stream ( 0 , chm _ header _ length ) ) ;
device . install files ( files type , install paths ) ; }
send window update ( 3 , 1 < < 30 ) ;
return files compacting . is empty ( ) & & ( store utils . has references ( si . get storefiles ( ) ) | | ( si . get level0 files ( ) . size ( ) > = this . config . get level0 min files ( ) ) | | needs single stripe compaction ( si ) ) ; }
signature = execution signature . from ( execution , cache key , cached count ) ; } else {
float pref width = c . pref width . get ( a ) ; float pref height = c . pref height . get ( a ) ; float min width = c . min width . get ( a ) ; float min height = c . min height . get ( a ) ; float max width = c . max width . get ( a ) ; float max height = c . max height . get ( a ) ; if ( pref width < min width ) pref width = min width ; if ( pref height < min height ) pref height = min height ; if ( max width > 0 & & pref width > max width ) pref width = max width ; if ( max height > 0 & & pref height > max height ) pref height = max height ; if ( colspan = = 1 ) { spanned column min and pref width is added later . float hpadding = c . computed pad left + c . computed pad right ; column pref width [ column ] = math . max ( column pref width [ column ] , pref width + hpadding ) ; column min width [ column ] = math . max ( column min width [ column ] , min width + hpadding ) ; }
if ( lvl ppr . get algn ( ) = null ) { jc jc = factory . create jc ( ) ; string algn = lvl ppr . get algn ( ) . value ( ) ; log . debug ( algn : + algn ) ; if ( algn . equals ( l ) ) { jc . set val ( jc enumeration . left ) ; } else if ( algn . equals ( ctr ) ) { jc . set val ( jc enumeration . center ) ; } else if ( algn . equals ( r ) ) { jc . set val ( jc enumeration . right ) ; } else if ( value . get css text ( ) . to lower case ( ) . equals ( justify ) ) { jc . set val ( jc enumeration . both ) ; } else { log . warn ( how to handle algn : + algn ) ; } p pr . set jc ( jc ) ; }
canvas . rotate ( 45 - m sun ray rotation + ( m is expand sun ray ? i : max _ sun _ ray _ count - i ) * degree _ 360 max _ sun _ ray _ count , arc bounds . center x ( ) , m sun coordinate y ) ; canvas . draw line ( arc bounds . center x ( ) , m sun ray start coordinate y , arc bounds . center x ( ) , m sun ray end coordinate y , m paint ) ;
apply value text style ( data set ) ; m xbounds . set ( m chart , data set ) ;
final list < oozie action > cur actions = presenter . get non latest action ( presenter . get current oozie job ( ) . get graph ( ) ) ;
try { gpu resource handler . pre start ( mock container with gpu request ( 1 , 3 ) ) ; } catch ( resource handler exception e ) { exception = true ; } assert . assert true ( pre start should throw exception , exception ) ;
path current trash = new path ( test _ dir , 2my _ root sub _ dir1 . trash current ) ; fs . mkdirs ( current trash ) ; cmd using shell ( - rmr , shell , current trash ) ; assert true ( fs . exists ( current trash ) ) ; cmd using shell ( - rmr , shell , new path ( test _ dir , 2my _ root ) ) ;
int inactive type = a . get int ( r . styleable . circle flow indicator _ inactive type , style _ stroke ) ; int inactive default color = 0x44 ffffff ;
assume . assume true ( is kdc running ( ) ) ; }
clone arguments = new object [ this . arguments . length ] ; system . arraycopy ( this . arguments , 0 , clone arguments , 0 , this . arguments . length ) ; }
mock rm rm2 = create mock rm ( conf , mem store ) ; rm2 . start ( ) ; nm1 . set resource tracker service ( rm2 . get resource tracker service ( ) ) ; node heartbeat response res = nm1 . node heartbeat ( true ) ; assert . assert equals ( node action . resync , res . get node action ( ) ) ; rmapp rm app = rm2 . get rmcontext ( ) . get rmapps ( ) . get ( app1 . get application id ( ) ) ;
nodes = new string [ h2 o . cloud . size ( ) ] ; for ( int i = 0 ; i < nodes . length ; + + i ) nodes [ i ] = h2 o . cloud . _ memary [ i ] . _ key . to string ( ) ; string builder sb = new string builder ( ) ; to ascii ( sb ) ; log . info ( sb ) ; log . debug ( network tester top - level completed ) ; }
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( too many hosted zones ) ) return null ; too many hosted zones exception e = ( too many hosted zones exception ) super . unmarshall ( node ) ;
byte [ ] data = new byte [ length + 10 ] ; system . arraycopy ( hello _ world _ gzipped , 0 , data , 0 , length ) ; system . arraycopy ( hello _ world _ gzipped , 0 , data , length , 10 ) ;
v . set ref ( 0 , multi byte , 3 , 7 ) ;
write byte ( c > > 6 | 0xc0 ) ; 110xxxxx
try { query . contains ( new long [ ] { - 1 } , one null table , hey , case . insensitive ) ; fail ( - 1 column index ) ; } catch ( array index out of bounds exception ignore ) { }
msg = new map message ( get map context name ( ) , map message . msg _ notify _ mapmember , false , ( serializable ) entry . get key ( ) , null , null , channel . get local member ( false ) , backup ) ; if ( backup = null & & backup . length > 0 ) { get channel ( ) . send ( backup , msg , get channel send options ( ) ) ; }
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( no such streaming distribution ) ) return null ; no such streaming distribution exception e = ( no such streaming distribution exception ) super . unmarshall ( node ) ;
zoo keeper utility factory . close ( cleanup ) ;
tester ( ) . assert that ( new prune window columns ( ) ) . on ( p - > build projected window ( p ,
if ( fs . delete ( snapshot info , false ) ) { string msg = couldn ' t delete snapshot info file : + snapshot info ; log . error ( msg ) ; throw new ioexception ( msg ) ; }
w expr spec . set expression ( rewrite grouping function ast ( get group by for clause ( qb . get parse info ( ) , sel clause name ) , w expr spec . get expression ( ) , cube rollup grp set present ) ) ; } }
return new map producer capabilities ( false , false , false , false , null ) ;
assert rows ( execute ( select distinct a , s , count ( s ) from % s where a = 1 group by a ) , row ( 1 , 1 , 1 l ) ) ;
for ( field doc field : cd . fields ( false ) ) { for ( annotation desc a : field . annotations ( ) ) { string annotation name = a . annotation type ( ) . qualified type name ( ) ; if ( annotation name . equals ( managed attribute . class . get name ( ) ) ) { is mbean = true ; mbean attribute attr = new mbean attribute ( ) ; attr . name = field . name ( ) ; attr . type = field . type ( ) . simple type name ( ) ; set name desc ( a . element values ( ) , attr ) ; set writable ( a . element values ( ) , attr ) ; mbc . attributes . add ( attr ) ; } } } if ( is mbean ) { collections . sort ( mbc . attributes ) ; collections . sort ( mbc . operations ) ; return mbc ; } else { return null ; }
do as super user ( new callable < void > ( ) { @ override public void call ( ) throws exception { try ( connection conn = get connection ( ) ) { final admin admin = conn . get admin ( ) ; quota settings qs = quota settings factory . remove table space limit ( tn ) ; admin . set quota ( qs ) ; assert null ( helper . get table space quota ( conn , tn ) ) ; return null ; } } } ) ;
if ( log . is debug enabled ( ) ) { log . debug ( received all barriers , triggering checkpoint { } at { } , received barrier . get id ( ) , received barrier . get timestamp ( ) ) ; } release blocks and reset barriers ( ) ; notify checkpoint ( received barrier ) ; }
file util . set writable ( storage dir , true ) ;
for ( int i = 0 ; i < contents . length ( ) ; i + + ) { if ( contents . char at ( i ) > 0x ff ) { return utf - 8 ; } } return null ;
run snapshot ( backend . snapshot ( 682375462378 l , 2 , stream factory , checkpoint options . for checkpoint ( ) ) ) ;
rpc error error = response . get error ( ) ;
hregion region = init hregion ( test selective flush with eager , conf ) ; verify in memory flush size ( region ) ;
file latest sym link = new file ( dir , latest ) ; latest sym link . delete ( ) ; file new dirv2 = new file ( dir , version - 2 ) ; create store files ( new dirv2 , 0 , 0 , this . node , 2 ) ; engine . swap files ( new dirv2 . get absolute path ( ) ) ; assert versions exist ( dir , 0 , 1 , 2 ) ;
execute ( delete from % s where a = ? and b = ? and c = ? , 1 , 1 , 0 ) ; assert rows ignoring order ( execute ( select a , b , c , d from mv _ test + i ) , row ( 1 , 0 , 0 , 0 ) , row ( 1 , 0 , 1 , 0 ) , row ( 1 , 1 , 1 , 0 ) , row ( 1 , 1 , 2 , 0 ) ) ;
pause formatter = number format . get instance ( ) ; pause formatter . set maximum fraction digits ( 5 ) ; total time formatter = new time format ( ) ;
final reentrant lock lock = this . lock ;
signed info elem = xmlutils . get next element ( element . get first child ( ) ) ;
do call real method ( ) . when ( controller ) . register with deprecated handler ( method , path , handler , deprecated method , deprecated path , logger ) ; controller . register with deprecated handler ( method , path , handler , deprecated method , deprecated path , logger ) ;
object name route2 = object name . get instance ( org . apache . camel : context = camel - 1 , type = routes , name = \ bar \ ) ;
request to sign = apikey = + encoded api key + & command = list zones ; request to sign = request to sign . to lower case ( ) ; signature = sign request ( request to sign , _ secret key . get ( ) ) ; encoded signature = urlencoder . encode ( signature , utf - 8 ) ; url = developer server + ?command = list zones & apikey = + encoded api key + & signature = + encoded signature ; string [ ] zone names = null ;
final magic key k = get magic key ( ) ; final string v1 = real - data ; final string v2 = stale - data ;
class writer writer = ( class writer ) cv ;
result instance = history service . create historic process instance query ( ) . variable value equals ( azerty ) . single result ( ) ; assert not null ( result instance ) ; assert equals ( process instance3 . get id ( ) , result instance . get id ( ) ) ; process instances = history service . create historic process instance query ( ) . variable value equals ( abcdef ) . list ( ) ;
wms . set max rendering time ( ( integer ) props . get ( max rendering time ) ) ;
class < ? > maria db server prepared statement class = class . for name ( org . mariadb . jdbc . maria db prepared statement client ) ;
set button . add action listener ( new action listener ( ) { public void action performed ( action event e ) { jpopup menu popup = get choose class popup menu ( ) ;
this . parent = new tag adapter ( ( simple tag ) adaptee parent ) ;
for ( relation type slot : relation type . values ( ) ) { if ( slot . canonical name . equals ( name ) | | slot . name ( ) . equals ( name ) ) { cached from string . put ( original name , slot ) ; return optional . of ( slot ) ; } }
int value = parsable byte array . read unsigned fixed point1616 ( ) ;
for ( parsed col info col : m _ display columns ) { tuple value expression tve = new tuple value expression ( col . table name , col . table alias , col . column name , col . alias , col . index , col . differentiator ) ; tve . set type size and in bytes ( col . as schema column ( ) ) ; parsed col info pcol = new parsed col info ( ) ; pcol . table name = col . table name ; pcol . table alias = col . table alias ; pcol . column name = col . column name ; pcol . alias = col . alias ; pcol . expression = tve ; m _ distinct group by columns . add ( pcol ) ; m _ distinct project schema . add column ( col . table name , col . table alias , col . column name , col . alias , tve , col . differentiator ) ; } return groupby element ;
running = job client . run job ( job ) ;
q [ j ] = qhat ; } d7 loop on j
final throwable consumer error = error . get ( ) ;
storage . check consistent namespace ( params . get storage info ( ) ) ;
process instance pi = runtime service . start process instance by key ( expression bean access ) ;
conf . set int ( hbase . hfile . compaction . discharger . interval , 15 * 1000 ) ;
local name tracker = true ; } else {
logger . warn ( skip exception for ddl : { } , caused by { } , data , exception utils . get full stack trace ( e ) ) ;
query . rollback ( ) ; }
input stream crosstool file stream = mock objc support . class . get class loader ( ) . get resource as stream ( mock _ osx _ crosstool _ file ) ;
log . debug ( thread interrupted while performing key id increment , e ) ;
assert equals ( listener was not added , listeners size + 1 , get connection ( 0 ) . get packet listeners ( ) . size ( ) ) ; message msg = new message ( get connection ( 0 ) . get user ( ) , message . type . normal ) ;
final int adjusted scale down = scale down - longword _ decimal _ digits ; final long divide factor = power of ten table [ adjusted scale down ] ; final long multiply factor = power of ten table [ longword _ decimal _ digits - adjusted scale down ] ;
if ( column1 = = column2 ) { return false ; }
key pair generator kpair gen = null ; if ( provider = null & & provider . trim ( ) . is empty ( ) ) kpair gen = key pair generator . get instance ( get algorithm ( asym _ algorithm ) , provider ) ; else kpair gen = key pair generator . get instance ( get algorithm ( asym _ algorithm ) ) ; kpair gen . initialize ( asym _ keylength , new secure random ( ) ) ; key _ pair = kpair gen . generate key pair ( ) ; }
condition . detach ( ) ;
map = transpose ( new int [ ] [ ] { { - 1 , - 1 , - 11 , - 1 , - 1 } , { - 1 , - 1 , - 11 , 0 , - 1 } , { - 1 , 1 , - 11 , - 1 , - 1 } , { - 1 , - 1 , - 11 , - 1 , - 1 } , { - 1 , - 1 , 2 , - 1 , - 1 } , } ) ;
s . get transaction ( ) . begin ( ) ;
collection < string > predef values = field . get predefined values ( ) ;
assert equals ( string , multi . get type ( 0 ) ) ;
byte packet id = eof . packet id ;
buffer = new data output buffer ( ) { public boolean has position ( ) { return false ; } public long position ( ) { throw new unsupported operation exception ( ) ; } } ; serializer . serialize ( with index , buffer ) ;
tx . rollback ( ) ; assert equals ( first value . to string ( ) , mgmt . get ( path ) ) ;
if ( buffer . read id property ( prop name ) ) { continue ; }
field constraint constraint to remove = this . constraints [ idx ] ; if ( constraint to remove instanceof single field constraint ) { final single field constraint sfc = ( single field constraint ) constraint to remove ; field constraint parent = sfc . get parent ( ) ; for ( field constraint child : this . constraints ) { if ( child instanceof single field constraint ) { single field constraint sfc child = ( single field constraint ) child ; if ( sfc child . get parent ( ) = = constraint to remove ) { sfc child . set parent ( parent ) ; break ; } } } } final field constraint [ ] new list = new field constraint [ this . constraints . length - 1 ] ; int new idx = 0 ; for ( int i = 0 ; i < this . constraints . length ; i + + ) { if ( i = idx ) { new list [ new idx ] = this . constraints [ i ] ; new idx + + ; } } this . constraints = new list ;
if ( inheritance state . has parents ( ) ) { return new root class ( metadata building context ) ; } else if ( inheritance type . single _ table . equals ( inheritance state . get type ( ) ) ) { return new single table subclass ( super entity , metadata building context ) ; } else if ( inheritance type . joined . equals ( inheritance state . get type ( ) ) ) { return new joined subclass ( super entity , metadata building context ) ; } else if ( inheritance type . table _ per _ class . equals ( inheritance state . get type ( ) ) ) { return new union subclass ( super entity , metadata building context ) ; } else { throw new assertion failure ( unknown inheritance type : + inheritance state . get type ( ) ) ; }
object ex args [ ] = { constants . _ tag _ reference , constants . _ tag _ manifest } ; throw new domexception ( domexception . wrong _ document _ err , i18n . translate ( xml . wrong content , ex args ) ) ;
continue ; } string type = option . get java type ( ) ;
rating bar . is show title ( is show title ) ; if ( m default color = 0 ) { rating bar . set rating bar color ( m default color ) ; } if ( m title color = 0 ) { rating bar . set title color ( m title color ) ; } if ( m rated color = 0 ) { rating bar . set rated color ( m rated color ) ; } if ( m unrated color = 0 ) { rating bar . set un rated color ( m unrated color ) ; } if ( m outline color = 0 ) { rating bar . set outline color ( m outline color ) ; } if ( m rating max = 0 ) { rating bar . set max rate ( m rating max ) ; } rating bar . init ( ) ;
if ( m _ free stack . is empty ( ) ) { create a new object if so . try { return ( dtmiterator ) m _ orig . clone ( ) ; } catch ( exception ex ) { throw new wrapped runtime exception ( ex ) ; } } else { remove object from end of free pool . dtmiterator result = ( dtmiterator ) m _ free stack . remove ( m _ free stack . size ( ) - 1 ) ; return result ; }
add table ( table _ name ) ; set up segment ( default ) ; _ admin api application = new admin api application ( server instance ) ; _ admin api application . start ( common constants . server . default _ admin _ api _ port ) ; _ web target = client builder . new client ( ) . target ( _ admin api application . get base uri ( ) ) ; }
expect ( mock handler . handle request sync ( fake ind rest request ( foo _ url ) , request context ) ) . and return ( fake ind rest response ( foo _ entity ) ) ; expect ( mock handler . handle request sync ( fake ind rest request ( bar _ url ) , request context ) ) . and return ( fake ind rest response ( bar _ entity ) ) ;
final path snapshotted zone file = new path ( snap1 . to string ( ) + + zone . get name ( ) + + zone file . get name ( ) ) ;
m marker . refresh content ( e , highlight ) ;
match token ( token . semi ) ;
version info . block updates ( ) ; try { cancel apply buffer update = false ; if ( state = state . buffering ) return null ; operation flags & = flag _ gap ; handle case when no log was even created because no updates were received . if ( tlog = = null ) { state = state . active ; return null ; } tlog . incref ( ) ; state = state . applying _ buffered ; } finally { version info . unblock updates ( ) ; } if ( recovery executor . is shutdown ( ) ) { tlog . decref ( ) ; throw new runtime exception ( executor is not running . . . ) ; }
list < integer > c2 = arrays . as list ( new integer [ ] { 1 , 2 , 3 } ) ; list < string > c3 = arrays . as list ( new string [ ] { one , two } ) ; list < int string > c4 = new array list < int string > ( ) ; complex c = new complex ( 1 , test , c2 , c3 , c4 ) ; assert equals ( 1 , soi . get struct field data ( c , fields . get ( 0 ) ) ) ;
i + = parse constants . or _ array . length - 1 ; reduce ( operator stack , filter stack , parse constants . or _ buffer ) ; operator stack . push ( parse constants . or _ buffer ) ; } else if ( check for and ( filter string as byte array , i ) ) {
if ( boss group = null ) { boss group . shutdown gracefully ( ) ; boss group = null ; }
if ( ( management factory . get memory mxbean ( ) . get object pending finalization count ( ) = = 0 ) & & ( mem used now > = mem used prev ) ) { break ; } else { mem used prev = mem used now ; } }
assert equals ( start offset , offset att . start offset ( ) ) ;
return path . get node names without alias ( ) ; }
assert equals ( 1 , realm . where ( null types . class ) . is null ( null types . field _ bytes _ null ) . count ( ) ) ;
int possible segment end = parse16 bit hex segment ( text , current pos , math . min ( current pos + 4 , address end ) ) ;
test dir = new path ( fs . make qualified ( test dir ) . to uri ( ) . get path ( ) ) ; file system . set default uri ( conf , fs . get uri ( ) ) ;
try { role unres list . add ( ( role unresolved ) curr result ) ; } catch ( illegal argument exception exc ) { throw new runtime exception ( exc . get message ( ) ) ; } } }
set max concurrent streams ( 1 ) ; encoder . write settings ack ( ctx , new promise ( ) ) ; assert equals ( 1 , connection . num active streams ( ) ) ;
int sentence blank ranges len = add multi byte char sentence blank ranges ( scratch , 0 ) ; byte [ ] sentence blank ranges = arrays . copy of ( scratch , sentence blank ranges len ) ; assert . assert true ( string expr . character count ( sentence blank ranges ) = = 17 ) ; result = string expr . truncate scalar ( sentence blank ranges , 4 ) ; assert . assert true ( arrays . equals ( arrays . copy of ( sentence blank ranges , 9 ) , result ) ) ; byte [ ] sentence blank ranges portion = arrays . copy of ( sentence blank ranges , sentence blank ranges len - 3 ) ; assert . assert true ( string expr . character count ( sentence blank ranges portion ) = = 16 ) ; result = string expr . truncate scalar ( sentence blank ranges portion , 14 ) ; assert . assert true ( arrays . equals ( arrays . copy of ( sentence blank ranges portion , 23 ) , result ) ) ; sentence blank ranges portion = arrays . copy of range ( sentence blank ranges , 7 , 7 + 17 ) ; assert . assert true ( string expr . character count ( sentence blank ranges portion ) = = 13 ) ; result = string expr . truncate scalar ( sentence blank ranges portion , 11 ) ; assert . assert true ( arrays . equals ( arrays . copy of ( sentence blank ranges portion , 15 ) , result ) ) ; assert . assert true ( string expr . character count ( result ) = = 11 ) ;
war = shrink wrap . create ( web archive . class , simple servlet . war ) ;
indarray true outcome = feature util . to outcome vector ( 0 , 5 ) ; [ 1 , 0 , 0 , 0 , 0 ] indarray predicted outcome = feature util . to outcome vector ( 0 , 5 ) ; [ 1 , 0 , 0 , 0 , 0 ] eval . eval ( true outcome , predicted outcome ) ; assert equals ( 1 , eval . class count ( 0 ) ) ; assert equals ( 1 . 0 , eval . f1 ( ) , 1e - 1 ) ;
final iterator iter = named params . entry set ( ) . iterator ( ) ; int result = 0 ; while ( iter . has next ( ) ) { final map . entry e = ( map . entry ) iter . next ( ) ; final string name = ( string ) e . get key ( ) ; final typed value typed val = ( typed value ) e . get value ( ) ; final int [ ] locations = source . get named parameter locations ( name ) ; for ( int location : locations ) { if ( debug enabled ) { log . debugf ( bind named parameters ( ) % s - > % s [ % s ] , typed val . get value ( ) , name , location + start ) ; } typed val . get type ( ) . null safe set ( ps , typed val . get value ( ) , location + start , session ) ; } result + = locations . length ; } return result ;
response = client . call procedure ( select blah single partition , 2 ) ; assert equals ( client response . success , response . get status ( ) ) ; assert equals ( response . get results ( ) [ 0 ] . fetch row ( 0 ) . get long ( 0 ) , 2 ) ; client . close ( ) ;
assert true ( test listener bean . get events received ( ) . get ( 0 ) instanceof activiti entity event ) ;
assert equals ( tuple count should exactly match sort array size for field + field + sort order + sort dir , select order . size ( ) , tuples . size ( ) ) ;
if ( ( m _ current = = 0 ) & & string at ( 0 , 2 , hs , ) ) { metaph add ( x ) ; m _ current + = 2 ; return true ; } return false ; }
byte [ ] answer = read answer ( ) ; int chk sum = input stream . read ( ) ; if ( logger . is debug enabled ( ) ) { logger . debug ( read data : { } with checksum { } . , bytes to hex string ( answer ) , integer . to hex string ( chk sum ) ) ; }
admin issue client ( ) . do transition ( search random issue ( ) . key ( ) , resolve ) ;
search manager search manager = search . get search manager ( cache ) ;
age = ( integer ) cache2 . get ( age ) ;
assert equals ( row1 , bytes . to string binary ( offheap kv . get row array ( ) , offheap kv . get row offset ( ) , offheap kv . get row length ( ) ) ) ; assert equals ( fam1 , bytes . to string binary ( offheap kv . get family array ( ) , offheap kv . get family offset ( ) , offheap kv . get family length ( ) ) ) ; assert equals ( qual1 , bytes . to string binary ( offheap kv . get qualifier array ( ) , offheap kv . get qualifier offset ( ) , offheap kv . get qualifier length ( ) ) ) ; assert equals ( row1 , bytes . to string binary ( offheap kv . get value array ( ) , offheap kv . get value offset ( ) , offheap kv . get value length ( ) ) ) ; assert equals ( 0 l , offheap kv . get timestamp ( ) ) ; assert equals ( type . put . get code ( ) , offheap kv . get type byte ( ) ) ; kv cell = new key value ( row1 , fam2 , qual2 , 0l , type . put , row1 ) ;
final element plugin element = string to element ( xml ) ;
value option value option = small table generation parameters . get value option ( ) ; int key out of athousand = small table generation parameters . get key out of athousand ( ) ; big table batch stream . reset ( ) ;
assert false ( vector . is repeating ) ;
if ( xml11 char . is xml11 valid ncname ( new prefix ) ) { run time error ( invalid _ qname _ err , new prefix + : + local name ) ; }
neo stores = factory . open all neo stores ( ) ;
assert . assert false ( dbr . compute stream from latest scn for partition ( null , sls , stream from latest scn ) ) ; stream from latest scn = false ;
assert true ( command thread . get ( ) . get name ( ) . equals ( main thread name ) ) ;
throw new illegal data exception ( no intersections found : + this ) ;
if ( destination . equals ( edge . get to ( ) ) ) return next path ; edges added = true ;
@ suppress warnings ( unchecked ) going from raw type back to generics type token < ? > component supertype = component type . get supertype ( supertype . get component type ( ) ) ; @ suppress warnings ( unchecked ) component type is super type , so is array type . type token < ? super t > result = ( type token < ? super t > )
update register sequence number ( retry tran ) ; retry tran . send request ( ) ; return ; }
boolean res = region . check and mutate ( row1 , fam1 , qf1 , compare operator . equal , new binary comparator ( empty val ) , put , true ) ;
if ( realm = null ) { realm . where ( all types . class ) . count ( ) ; }
db . users ( ) . insert permission on user ( db . get default organization ( ) , admin user , administer _ quality _ gates ) ; string result = new request ( ) . set param ( organization , org . get key ( ) ) . execute ( ) . get input ( ) ;
task . iteration ( request . get iteration ( ) ) ;
string title = page . select ( div [ id = article ] > h2 ) . first ( ) . text ( ) ; string content = page . select text ( div artibody , 0 ) ;
method visitor mv = controller . get method visitor ( ) ;
ctx . channel ( ) . read ( ) ; } else { future . channel ( ) . close ( ) ; } } } ) ; }
{ m decr ( ) ; if ( state . failed ) return ; } break ;
req buf . put string ( key type . from key ( key ) . to string ( ) ) . put string ( new buffer . plain buffer ( ) . put public key ( key ) . get compact data ( ) ) ; return req buf ;
final float height = view . get height ( ) ;
if ( in left expression ) accessor = new static method call expression ( static import type , accessor name , argument list expression . empty _ arguments ) ; else accessor = new property expression ( new class expression ( static import type ) , prop name ) ;
sb . delete ( sb . length ( ) - 2 , sb . length ( ) - 1 ) ; return sb . to string ( ) ;
throw new illegal argument exception ( the given token + token + does not map to partition + partition ) ;
key test . set certificate entry ( alias1 , cert [ 0 ] ) ;
assert that ( under test . find by id ( rule1 . get id ( ) ) . get id ( ) ) . is equal to ( rule1 . get id ( ) ) ;
from ( direct : create sobject ) . to ( salesforce : create sobject?s object name = merchandise _ _ c & format = + format ) ;
result . add ( current ) ;
list < store client factory > factories = new array list < store client factory > ( ) ;
ometadata identifier jjtn000 = new ometadata identifier ( jjtmetadataidentifier ) ;
if ( this . current iteration = null & & this . current iteration instanceof workset iteration plan node & & node . get outgoing channels ( ) . size ( ) > 0 ) { workset iteration plan node wspn = ( workset iteration plan node ) this . current iteration ; if ( wspn . get solution set delta plan node ( ) = = pred | | wspn . get next work set plan node ( ) = = pred ) { chaining = false ; } }
switch ( cloud entries . get ( i - 1 ) . get service type ( ) ) { case gdrive : ids [ i ] = 2 + ; break ; case dropbox : ids [ i ] = 3 + ; break ; case box : ids [ i ] = 4 + ; break ; case onedrive : ids [ i ] = 5 + ; break ; }
this . out jar files . add ( out jar files ) ;
assert equals ( new mmap utils . allocation context ( new file ( a ) , potato , mmap utils . allocation type . mmap ) . get context ( ) , a ( potato ) ) ;
return authentication mechanism outcome . not _ attempted ;
try { final string version = system . get property ( java . vm . specification . version ) ; parse the beast . . . if ( version = = null ) { return false ; } string [ ] versions = parse versions ( version ) ; string [ ] target = new string [ ] { 1 , 4 } ; return ( array utilities . compare version arrays ( versions , target ) > = 0 ) ; } catch ( exception e ) { return false ; }
if ( reply = null ) { reply . write no exception ( ) ; } else { strict mode . clear gathered violations ( ) ; } return true ;
return query . get ( 0 ) ;
if ( name . ends with ( . pla ) ) { name = name . substring ( 0 , name . length ( ) - 4 ) ; } content values values = new content values ( 1 ) ;
array list < card > cards = new array list < card > ( ) ;
in order . verify no more interactions ( ) ;
assert empty match ( лижний курорт криниця розташувався в бескидах ) ; assert empty match ( містечко баришівка потрапило до історії ) ;
} else if ( p = = q )
data point dp entity = ( data point ) ( ( hibernate proxy ) dp ) . get hibernate lazy initializer ( ) . get implementation ( ) ; dp entity . set description ( changed ) ; s = open session ( ) ;
if ( stream = null ) { try { stream . close ( ) ; } catch ( ioexception ignore ) { can ' t do much about it } }
height + = incr gap ; y + = incr gap ; } else {
type resolved type = resolve ( implementation , type , parameter index ) ;
unvisited . remove ( to pair ) ; o ( n )
conf1 . set class ( backup restore factory . hbase _ backup _ merge _ impl _ class , backup merge job with failures . class , backup merge job . class ) ; connection conn = connection factory . create connection ( conf1 ) ;
if ( stream id < = last good stream id ) { issue session error ( ctx , e . get channel ( ) , e . get remote address ( ) , spdy session status . protocol _ error ) ; return ; }
string [ ] metadata names = reader . get metadata names ( ) ; assert not null ( metadata names ) ; assert equals ( true , reader . get metadata value ( has _ time _ domain ) ) ; assert equals ( 2008 - 10 - 31 t00 : 00 : 00 . 000 z , 2008 - 11 - 01 t00 : 00 : 00 . 000 z , 2008 - 11 - 02 t00 : 00 : 00 . 000 z , reader . get metadata value ( metadata names [ 0 ] ) ) ; }
create property group ( mongodb , new string [ ] { source , database , username , password } ) ; create property group ( sampler , new string [ ] { script } ) ;
if ( this . nm context . get nmstate store ( ) = null ) { try { this . nm context . get nmstate store ( ) . remove amrmproxy app context ( pipeline . get application attempt id ( ) ) ; } catch ( ioexception e ) { log . error ( error removing amrmproxy application context for + application id , e ) ; } }
int n = this . subplots . size ( ) ; int total weight = 0 ; for ( int i = 0 ; i < n ; i + + ) { xyplot sub = ( xyplot ) this . subplots . get ( i ) ; total weight + = sub . get weight ( ) ; }
multi layer network model now = new transfer learning . builder ( model to fine tune ) . fine tune configuration ( new fine tune configuration . builder ( ) . seed ( rng ) . optimization algo ( optimization algorithm . stochastic _ gradient _ descent ) . updater ( new rms prop ( 0 . 5 ) ) intent : override both weight and bias lr , unless bias lr is manually set also . l2 ( 0 . 4 ) . build ( ) ) . build ( ) ; for ( org . deeplearning4j . nn . api . layer l : model now . get layers ( ) ) { base layer bl = ( ( base layer ) l . conf ( ) . get layer ( ) ) ; assert equals ( new rms prop ( 0 . 5 ) , bl . get iupdater ( ) ) ; }
char iter . set index ( current ( ) ) ; return char iter ;
{ match ( input , equals , follow _ equals _ in _ synpred16 _ dslmap744 ) ; if ( state . failed ) return ; } }
pub sub manager sub mgr = new pub sub manager ( get connection ( 1 ) , get service ( ) ) ; leaf node sub node = ( leaf node ) sub mgr . get node ( node id ) ; item event coordinator < payload item < simple payload > > sub1 handler = new item event coordinator < payload item < simple payload > > ( queue , sub1 ) ;
app3 . get application ( ) . run ( server , config path ) ;
request = client . new request ( http : localhost : + port + mod test?action = test & val = + new max inactive ) ;
log . info ( note : stop data node + target . get value ( ) . get display name ( ) + with internal block + target . get key ( ) ) ;
assert equals ( primitive object inspector . primitive category . string , pti . get primitive category ( ) ) ; }
gold mine . dig out gold ( ) ;
m _ j menu bar = new jmenu bar ( ) ;
map map = maps benchmark state . hash map ;
for ( property property : handler . get ( properties ) . as property list ( ) ) { if ( file name . equals ( property . get name ( ) ) ) { file name = property . get value ( ) . as string ( ) ; break ; } } assert . assert not null ( file name property not found , file name ) ; assert . assert true ( file name . ends with ( test - logging - ear . log ) ) ; }
nsdictionary stack = current object ; current object = new nsdictionary ( ) ; current object . put ( isa , obj . isa ( ) ) ; obj . serialize into ( this ) ; objects . put ( obj . get global id ( ) , current object ) ;
put range map entry ( range map entry . get lower bound ( ) , range to remove . lower bound , map entry below to truncate . get value ( ) . get value ( ) ) ;
string text1 = diff _ text1 ( diffs ) ; return patch _ make ( text1 , diffs ) ; }
partition column name = partition column name . to lower case ( ) ;
json writer . end array ( ) ; }
long num rows = - 1 ; for ( entry < key , value > entry : scanner ) { if ( num rows > 0 ) { throw new presto exception ( function _ implementation _ error , should have received only one entry when scanning for number of rows in metrics table ) ; } num rows = long . parse long ( entry . get value ( ) . to string ( ) ) ; } scanner . close ( ) ; log . debug ( number of rows in table is % d , num rows ) ; return num rows ;
void set resource ( boolean is src , int res id , resources res ) { try { gif drawable d = new gif drawable ( res , res id ) ; if ( is src ) { set image drawable ( d ) ; } else if ( build . version . sdk _ int > = 16 ) { set background ( d ) ; } else { set background drawable ( d ) ; } return ; } catch ( ioexception ignored ) { ignored } catch ( not found exception ignored ) { ignored }
run client compatibility with94 znode test ( table name , test _ util . get configuration ( ) ) ;
versioned < byte [ ] > v0 = new versioned < byte [ ] > ( value , vc3 ) ;
double count = 0 ; for ( int noa = 0 ; noa < m _ num classes ; noa + + ) { count + = the array [ noa ] ; } if ( count < = 0 ) { return m _ zero r . distribution for instance ( i ) ; } for ( int noa = 0 ; noa < m _ num classes ; noa + + ) { the array [ noa ] = count ; } return the array ;
char other separator = ( separator = = system _ separator ? other _ separator : system _ separator ) ;
map < string , object > meta data = null ;
tmhandler metric updater = new metrics updater ( ) ;
path file1 = new path ( system . get property ( test . build . data ) + + long . to string ( block size ) + . dat ) ;
int capacity = compute array list capacity ( elements . length ) ;
if ( target = gl target & & ( gl20 . gl _ texture _ cube _ map _ positive _ x < = target & & target < = gl20 . gl _ texture _ cube _ map _ negative _ z & & target = = gl20 . gl _ texture _ 2 d ) ) throw new gdx runtime exception ( invalid target requested : 0x + integer . to hex string ( target ) + , expecting : 0x + integer . to hex string ( gl target ) ) ; }
compact equals ( sf create ( 12 , 12 ) , true , 12 , 12 ) ;
tx . close ( ) ; }
m layout mode = layout _ normal ;
s . create query ( select cast ( e . the lost number as java . lang . long ) from my entity e ) . list ( ) ;
test needed temps ( function foo ( a ) { a ; a ; } ; foo ( \ \ ) ; , foo , empty _ string _ set ) ;
edit . put long ( key , value ) ;
exchange client . close ( ) ;
assert num docs ( num docs . get ( ) , source _ collection ) ;
return delete result . family _ version _ deleted ; } } } else { if ( visibility utils . is visibility tags present ( cell ) & & timestamp < = family stamp ) {
if ( this . is active ( ) ) { return ; } int sleep multiplier = 1 ;
for ( int node id : all nodes ) { assert equals ( servers [ node id ] . get metadata store ( ) . get rebalancer state ( ) , new rebalancer state ( new array list < rebalance task info > ( ) ) ) ; assert equals ( servers [ node id ] . get metadata store ( ) . get cluster ( ) , final cluster ) ; }
system . arraycopy ( array , 0 , tmp , 0 , index ) ;
t . set type ( ident ) ;
when ( t1 . get service ( ) ) . then return ( new text ( t1 ) ) ;
if ( proto . get last packet in block ( ) & & proto . get data len ( ) = 0 ) return false ;
list < filter > non and list = new array list < filter > ( ) ;
page list . try evict ( page ref , eviction run event . null ) ; this attempt will fail
final string [ ] header = map reader . get header ( true ) ; map < string , object > tuple ;
for ( int i = 0 ; i < 2 ; i + + ) { queue . queue ( mock ( transaction to apply . class ) ) ; verify no more interactions ( applier ) ; }
assert equals ( 1 , seq generator . get database structure ( ) . get initial value ( ) ) ;
block pool manager . add block pool ( bpos ) ;
data output . write string ( unicode ) ; assert equals ( growable byte array data output wrote the wrong length after encode , len + vint len * 2 , data output . get position ( ) ) ; for ( int j = 0 , k = vint len * 2 ; j < len ; j + + , k + + ) { assert equals ( utf8 [ j ] , data output . get bytes ( ) [ k ] ) ; } }
boolean last in run = is last in run ( selected index ) ;
if ( running sum = = target sum ) { total paths + + ; }
throw new org . apache . axis2 . databinding . adbexception ( image owner alias cannot be null ) ;
return intern ( sb . to string ( ) ) ;
live broadcast request . set broadcast type ( all ) . set broadcast status ( all ) ;
else if ( e . get source ( ) = = method ) { boolean is post method = httpconstants . post . equals ( method . get text ( ) ) ; use multipart for post . set enabled ( is post method ) ; }
activity chooser view . set default action button content description ( r . string . abc _ shareactionprovider _ share _ with _ application ) ; activity chooser view . set expand activity overflow button content description ( r . string . abc _ shareactionprovider _ share _ with ) ; return activity chooser view ; }
check open connected ( ) ;
log . debugf ( unable to release jdbc statement [ % s ] , e . get message ( ) ) ;
input stream is = bitcoinium ticker jsontest . class . get resource as stream ( marketdata example - ticker - data . json ) ;
list < geography point value > new loop = new array list < > ( ) ;
instructions . add ( reil helpers . create str ( offset + + , operand size . byte , 1 , operand size . byte , helpers . zero _ flag ) ) ;
if ( info . icon bitmap = = null ) { info . icon bitmap = m icon cache . get default icon ( info . user ) ; }
executions = runtime service . create execution query ( ) . variable value less than or equal ( double var , 55555 . 5555 ) . list ( ) ; assert equals ( 3 , executions . size ( ) ) ; assert equals ( 0 , runtime service . create execution query ( ) . variable value less than or equal ( double var , 12344 . 6789 ) . count ( ) ) ;
app . wait for state ( job , job state . running ) ;
for ( storage directory sd2 : image . get storage ( ) . dir iterable ( name node dir type . image ) ) { file this newest image = fsimage test util . find latest image file ( sd2 ) ; long len = this newest image . length ( ) ; assert equals ( fsimage length , len ) ; }
return long . parse long ( i field value as string ) ;
zip entry zentry = zfile . get entry ( file1 . txt ) ; input stream is = zfile . get input stream ( zentry ) ; byte [ ] rbuf1 = new byte [ 12 ] ; byte [ ] rbuf2 = new byte [ 12 ] ; int r = is . read ( rbuf1 , 0 , 4 ) ; assert equals ( 4 , r ) ; is . mark ( 0 ) ; r = is . read ( rbuf1 ) ; assert equals ( 8 , r ) ; assert equals ( - 1 , is . read ( ) ) ; try { is . reset ( ) ; fail ( ) ; } catch ( ioexception expected ) { }
on connect ( status code . connect _ error ) ;
fields first = false ;
final string embedded name = properties group mapping . get ( property . get name ( ) ) ; if ( audited properties holder . contains ( embedded name ) ) {
tiff header . first ifd offset = stream processor . read packed int ( is , 4 , tiff header . is little endian ) ; length - = 4 ; if ( tiff header . first ifd offset < 8 | | tiff header . first ifd offset - 8 > length ) { flog . e ( tag , invalid offset ) ; return 0 ; } return length ;
postal area converter . clear counts ( ) ; region . evict all ( ) ; session = open session ( ) ;
final value value1 = element converter . get value from properties ( test groups . edge , edge . get properties ( ) ) ;
array list < node > top nodes = new array list < node > ( ) ;
boolean break lines = ( options & do _ break _ lines ) = 0 ;
{ m mod _ assign ( ) ; if ( state . failed ) return ; } break ;
builder holder . get global configuration builder ( ) . class loader ( infinispan class loader ) ; return builder holder ; }
deletion manager . remove aged deleted segments ( 1 ) ;
list . set ( 0 , ( char ) 4 ) ;
java symbol name method name = new java symbol name ( find one ) ;
request . timeout ( time value . time value minutes ( 2 ) ) ; < 1 > request . timeout ( 2m ) ; < 2 >
synchronized ( uuid . class ) { if ( rng = = null ) { rng = new secure random ( ) ; } }
final array list < token filter factory > filters = new array list < token filter factory > ( ) ; abstract plugin loader < token filter factory > filter loader = new abstract plugin loader < token filter factory > ( [ schema . xml ] analyzer filter , false , false ) { @ override protected void init ( token filter factory plugin , node node ) throws exception { if ( plugin = null ) { final map < string , string > params = domutil . to map except ( node . get attributes ( ) , class ) ;
this . serializer = serialize de serialize helper . get serializer ( helper . get topology context ( ) . get topology config ( ) ) ;
return ( ( app compat delegate impl v14 ) delegate ) . map night mode ( mode ) ; }
do in jpa ( this : : session factory , em - > { garage to remove garage = em . find ( garage . class , garage id ) ; em . remove ( to remove garage ) ; } ) ;
header view . set clickable ( true ) ;
instructions . add ( reil helpers . create sub ( base offset + + , dw , tmp result3 , dw , tmp result1 , dw , target register . get value ( ) ) ) ;
for ( cursor cursor : cursor map . values ( ) ) { cursor . destroy ( ) ; } cursor map . clear ( ) ; logger . fine ( mouse destroyed . ) ; }
transaction sample result . add sub result ( res ) ;
try { update resource lists ( ) ; } catch ( xcap exception e ) { parent group . remove contact ( new contact ) ; throw new operation failed exception ( error while creating xcap contact , operation failed exception . network _ failure , e ) ; }
return doc scorer . score ( doc id , freq ) ; }
string response = template . request body and header ( cxfrs : http : localhost : + get port1 ( ) + + get class ( ) . get simple name ( ) + customerservice customers , input , exchange . http _ method , post , string . class ) ; assert not null ( response ) ;
for ( int i = 0 ; i < m stack tabs . length ; i + + ) { if ( m stack tabs [ i ] . is dying ( ) & & m stack tabs [ i ] . get layout tab ( ) . is visible ( ) ) { max offset = math . max ( m stack tabs [ i ] . get scroll offset ( ) , max offset ) ; } } }
c . set bitmap ( preview ) ;
for ( int j = 0 ; j < actual . size ( ) ; j + + ) { if ( curr description . equals ( actual descriptions . get ( j ) ) ) { actual freq + + ; } if ( curr description . equals ( expected descriptions . get ( j ) ) ) { expected freq + + ; } }
ddq . add ( author , lisa ) ; ddq . add ( publish date , 2010 ) ; ddq . add ( author , bob ) ; r = ds . search ( null , ddq , 10 ) ; assert equals ( 2 , r . hits . total hits ) ;
instruction handle ih pi = ih loop ;
list < oidentifiable > managed by a = get managed by2 arrows ( a ) ; assert equals ( 1 , managed by a . size ( ) ) ; assert equals ( p1 , ( ( odocument ) managed by a . get ( 0 ) . get record ( ) ) . field ( name ) ) ; list < oidentifiable > managed by b = get managed by2 arrows ( b ) ;
out . println ( < user name = \ user1 \ > ) ;
if ( conn . equals ( conn . get transport ( ) . get service ( ) ) ) { empty queue ( queue ) ; check max reached ( queue ) ; queue . add ( conn . send global request ( keepalive @ openssh . com , true , new byte [ 0 ] ) ) ; }
assert equals ( 0 , uoi . get tag ( result . union object ) ) ;
run command ( admin , new string [ ] { - clr quota , child dir0 . to string ( ) } , false ) ;
set ( configuration keys . allow _ leading _ wildcard , false ) ; default in 2 . 9
test context test context3b = test context test utils . build test context ( class hierarchy context hierarchy level3b test case . class , context cache ) ;
tee sink token filter tee stream = new tee sink token filter ( new standard filter ( standard tokenizer ( buffer ) ) ) ;
student hbase short wrapper student max = new student hbase short wrapper ( ) ; student max . set age ( ( short ) get max value ( short . class ) ) ; student max . set id ( ( short ) get max value ( short . class ) ) ; student max . set name ( ( string ) get max value ( string . class ) ) ; em . persist ( student max ) ;
enabled . add ( constants . ssl _ proto _ sslv2 hello ) ;
byte [ ] region name = region info . create region name ( table name , start key , region id , false ) ; byte [ ] [ ] fields = region info . parse region name ( region name ) ; assert array equals ( bytes . to string ( fields [ 0 ] ) , table name . get name ( ) , fields [ 0 ] ) ; assert array equals ( bytes . to string ( fields [ 1 ] ) , start key , fields [ 1 ] ) ; assert array equals ( bytes . to string ( fields [ 2 ] ) , bytes . to bytes ( long . to string ( region id ) ) , fields [ 2 ] ) ; assert equals ( 3 , fields . length ) ;
jdk sslengine options . class . get class loader ( ) . load class ( sun . security . ssl . alpnextension ) ;
connection edit part edit part = create or find connection ( new value ) ;
heron server . handle read ( active connections . key set ( ) . iterator ( ) . next ( ) ) ; }
if ( message [ 1 ] = = 9 ) { logger . trace ( mute ( variable 9 ) converted opposite to documentation ) ; state = index = = 0 ? on off type . on : on off type . off ; } else { state = index = = 0 ? on off type . off : on off type . on ; }
user group information . set login user ( null ) ;
if ( food in front ( ) ) { return ; }
if ( y > 0 ) { m _ caret y = y - 1 ; final zy line content prev line content = get line content ( m _ caret y ) ; m _ caret x = prev line content . get text ( ) . length ( ) ; } changed text = get multiline comment ( y , changed text ) ;
assert that ( search ( issue query . create ( ) . assignees ( user1 ) ) . list ( ) ) . has size ( 1 ) ;
final request config . builder request config builder = request config . custom ( ) ; request config builder . set connect timeout ( configuration . get connect timeout ( ) ) ; request config builder . set socket timeout ( configuration . get socket timeout ( ) ) ; final http host proxy = configuration . get proxy ( ) ;
list < media type callback > callbacks = geo server extensions . extensions ( media type callback . class ) ;
final client flow client = auth flow . get authorized client ( ) . register ( logging feature . class ) ; string response entity = flow client . target ( uri ) . path ( photos ) . query param ( file , vacation . jpg ) . query param ( size , original ) . request ( ) . get ( string . class ) ;
n = local variables = = null ? 0 : local variables . size ( ) ; for ( i = 0 ; i < n ; + + i ) { local variables . get ( i ) . accept ( mv ) ; }
if ( text . length ( ) > 0 ) { text . append ( ' \ n ' ) ; }
write and verify ( event loop , fs , f , out ) ;
{ match ( comment ) ; } break ;
boolean recover lease = newdfs . recover lease ( file ) ; assert true ( recover lease ) ; fsdata output stream append = newdfs . append ( file ) ; append . write ( test . get bytes ( ) ) ; append . close ( ) ; } finally {
usage rec response . set size ( usage record . get size ( ) ) ;
input stream [ ] stms = new input stream [ 5 ] ; try { for ( int i = 0 ; i < stms . length ; i + + ) { stms [ i ] = fs . open ( test _ file ) ; } for ( input stream stm : stms ) { ioutils . copy bytes ( stm , new ioutils . null output stream ( ) , 1024 ) ; } } finally { ioutils . cleanup ( null , stms ) ; } assert equals ( 5 , peer cache . size ( ) ) ;
case security _ commands _ supported _ report : handled by zwave security command class initialization case security _ scheme _ report : handled by zwave security command class initialization and is only received
element root = ( element ) node ;
if ( url . starts with ( file : ) ) { try { return files . as resource ( data utilities . url to file ( new url ( url ) ) ) ; } catch ( exception e ) { failure , so fall through } }
assert that ( system . get property ( plugin _ desc _ property _ set _ by _ test _ plugin _ 1 ) , is ( plugin . to string ( ) ) ) ;
run happy path register ( log , callback , remote exception handler , conn , msg , client addr , obj capture , sources resp ) ;
@ suppress warnings ( unchecked )
if ( animator . is running ( ) ) { animator . cancel ( ) ; } animator . set duration ( animation duration in millis ) ;
table < div < hamlet > > table = div . table ( job ) ;
m sample layout4 = ( blur layout ) find view by id ( r . id . blur _ layout4 ) ; view hover4 = layout inflater . from ( m context ) . inflate ( r . layout . hover _ sample4 , null ) ; m sample layout4 . set hover view ( hover4 ) ; m sample layout4 . add child appear animator ( hover4 , r . id . cat , techniques . slide in left ) ; m sample layout4 . add child appear animator ( hover4 , r . id . mail , techniques . slide in right ) ; m sample layout4 . add child disappear animator ( hover4 , r . id . cat , techniques . slide out left ) ; m sample layout4 . add child disappear animator ( hover4 , r . id . mail , techniques . slide out right ) ; m sample layout4 . add child appear animator ( hover4 , r . id . content , techniques . bounce in ) ; m sample layout4 . add child disappear animator ( hover4 , r . id . content , techniques . fade out up ) ; hover4 . find view by id ( r . id . cat ) . set on click listener ( new view . on click listener ( ) { @ override public void on click ( view v ) { intent get web page = new intent ( intent . action _ view , uri . parse ( https : github . com daimajia ) ) ; start activity ( get web page ) ; } } ) ;
region . flushcache ( ) ; region . compact stores ( true ) ; g = new get ( t1 ) ;
return ( inner class . get modifiers ( ) & acc _ static ) = = 0 ; }
rates service . get current rates ( ) ; verify ( client , times ( 1 ) ) . get rates ( currency . get base ( ) ) ;
dirty state = dirty state . verified _ clean ;
assert true ( appender . log contains ( dwarf gold digger wakes up . ) ) ;
app . wait for state ( service . state . stopped ) ; map < task id , task > tasks = job . get tasks ( ) ;
assert equals ( rotated . size ( ) , list . size ( ) ) ;
metadata . set content length ( ciphertext length ( plaintext length ) ) ; }
stack pane sublist container = new stack pane ( ) ;
list < cell > expected1 = new array list < > ( ) ; expected1 . add ( new key value ( row1 , fam2 , null , ts , key value . type . put , null ) ) ; expected1 . add ( new key value ( row1 , fam4 , null , ts , key value . type . put , null ) ) ; res = new array list < > ( ) ; is . next ( res ) ;
dex differ . dex filter ( ) ; info . update ( ) ;
parse eventually queue queue = mock ( parse eventually queue . class ) ;
super . save namespace ( force , uncompressed ) ;
assert first suggestion ( informationnen , , informationen , rule , lt ) ;
e . print stack trace ( ) ; client . stop ( ) ; lifeline . disconnect ( ) ; system . exit ( reason . get exit code ( ) ) ; }
node reports = yarn client . get node reports ( node state . running ) ; priority = priority . new instance ( 1 ) ;
if ( leftovers . position ( ) > 0 ) { int pos = cb . position ( ) ; loop until one char is decoded or there is a decoder error do { byte chr ; if ( bc . remaining ( ) = = 0 ) { int n = ic . real read bytes ( ) ; chr = n < 0 ? - 1 : bc . get ( ) ; } else { chr = bc . get ( ) ; } leftovers . put ( chr ) ; leftovers . flip ( ) ; result = decoder . decode ( leftovers , cb , end of input ) ; leftovers . position ( leftovers . limit ( ) ) ; leftovers . limit ( leftovers . array ( ) . length ) ; } while ( result . is underflow ( ) & & ( cb . position ( ) = = pos ) ) ; if ( result . is error ( ) | | result . is malformed ( ) ) { result . throw exception ( ) ; } bb . position ( bc . position ( ) ) ; leftovers . position ( 0 ) ; }
train all at once ( sequences ) ; sequences . clear ( ) ; }
ensure governor has method ( new method metadata builder ( index method ) ) ;
simple type converter type converter = new simple type converter ( ) ;
table alias map . put ( key . to upper case ( ) , value ) ;
string response = template . request body and header ( cxfrs : http : localhost : + get port1 ( ) + + get class ( ) . get simple name ( ) + customerservice customers , input , exchange . http _ method , post , string . class ) ; assert not null ( response ) ;
if ( this . cache manager = null ) { this . cache manager . stop ( ) ; }
assert true ( this . channel1 . is blocking ( ) ) ;
set < cache entry < object , string > > values inserted = new hash set < > ( ) ; cache < object , string > cache = cache ( 0 , cache _ name ) ; for ( int i = 0 ; i < 3 ; + + i ) { object key = get key tied to cache ( cache ) ; time unit unit = time unit . minutes ; cache . put ( key , key . to string ( ) , 10 , unit , i + 1 , unit ) ; values inserted . add ( new transient mortal cache entry ( key , key . to string ( ) , unit . to millis ( i + 1 ) , unit . to millis ( 10 ) , system . current time millis ( ) ) ) ; } set < cache entry < object , string > > retrieved values = new hash set < > ( ) ;
assert not null ( pr . terms ( f1 ) ) ;
schema filter = to meta data object name ( extraction context . get jdbc environment ( ) . get current schema ( ) ) ;
final resources res = m context . get resources ( ) ;
assert equals ( 0 , proc runnables . size ( ) ) ;
for ( i = 0 ; i < nx ; i + + ) { for ( j = 0 ; j < ny ; j + + ) { if ( ( stdvsx [ i ] * stdvsy [ j ] ) > 0 . 0 ) { system . out . println ( stdv : + stdvs _ nom [ i ] ) ; rr = ( covs [ i ] [ j ] ( math . sqrt ( stdvsx [ i ] * stdvsy [ j ] ) ) ) ; if ( rr < 0 . 0 ) { rr = - rr ; } r + = ( ( prior _ nom [ i ] [ j ] m _ num instances ) * rr ) ; } if there is zero variance for either of the categorical atts then if neither is the class then make this correlation at this level maximally bad i . e . 1 . 0 . if either is the class then maximally bad correlation is 0 . 0 else { if ( att1 = m _ class index & & att2 = m _ class index ) { r + = ( ( prior _ nom [ i ] [ j ] m _ num instances ) * 1 . 0 ) ; } } } }
for ( map . entry < partition key , row update split > entry : splits . entry set ( ) ) { partition key partition key = entry . get key ( ) ; parameter server id ps id = router . get psid ( partition key ) ; if ( ps update data . contains key ( ps id ) ) { ps update data . put ( ps id , new hash map < partition key , list < row update split > > ( ) ) ; } if ( ps update data . get ( ps id ) . contains key ( partition key ) ) { ps update data . get ( ps id ) . put ( partition key , new array list < row update split > ( ) ) ; } ps update data . get ( ps id ) . get ( partition key ) . add ( entry . get value ( ) ) ; }
if ( ext . handle token ( jp , ctxt , prop name , bean ) ) { continue ; }
create client ( test - client , group with clients ) ; set < client > clients = clients info ( group with clients ) ; assert that ( clients ) . has size ( 1 ) ; assert that ( clients . iterator ( ) . next ( ) . get name ( ) ) . is equal to ( test - client ) ; }
} catch ( throwable t ) { suppress checkstyle illegal catch check
float mult = ( sum = 0 ) ? ( 1f sum ) : 0 ;
shape shape1 = geo jsonutils . map2 shape ( val1 ) ;
if ( new java file visitor . is interface ( ) ) { type declaration . set interface ( true ) ; } else { type declaration . set interface ( false ) ; }
return fs . get features ( q ) . features ( ) ;
future < boolean > f = cache factory . get memcached client ( ) . set ( key1 , 0 , v1 ) ;
int count = errors . increment and get ( ) ;
int result = 0 ;
probe slot + = ( + + i ) ;
{ error msg . circular _ variable _ err , r \ u00 e9f \ u00 e9rence de param \ u00 e8tre variable circulaire dans ' ' { 0 } ' ' . } ,
policy = _ entity mgr . find by id ( stickiness policy . class , get entity id ( ) ) ;
if ( n = = 0 ) { nothing to do } else if ( m = = 1 ) { for ( j = 0 ; j < n ; j + + ) { if ( a . char at ( 0 ) = = b . char at ( j ) ) { sb . append ( a . char at ( 0 ) ) ; break ; } } step 2 } else { i = ( int ) math . floor ( ( ( double ) m ) 2 ) ; step 3 int [ ] l1 = alg b ( i , n , a . substring ( 0 , i ) , b ) ; int [ ] l2 = alg b ( m - i , n , reverse string ( a . substring ( i ) ) , reverse string ( b ) ) ; step 4 int k = find k ( l1 , l2 , n ) ; step 5 alg c ( sb , i , k , a . substring ( 0 , i ) , b . substring ( 0 , k ) ) ; alg c ( sb , m - i , n - k , a . substring ( i ) , b . substring ( k ) ) ; }
on view ( with id ( r . id . hello _ name ) ) . check ( matches ( with text ( hello bart ) ) ) ;
map < integer , list < integer > > inconsistent digests = new hash map < integer , list < integer > > ( ) ;
item = ( odd even item ) tester . get component from last rendered page ( form : table : list container : items : 4 ) ;
user names . remove ( client . get id ( ) ) ;
assert true ( cluster . would lower availability ( hri1 , servers [ 6 ] ) ) ;
technique . set shader file ( technique . hash code ( ) + , technique . hash code ( ) + , glsl100 , glsl100 ) ;
set padding ( math . max ( padding , get padding left ( ) ) , math . max ( padding , get padding top ( ) ) , math . max ( padding , get padding right ( ) ) , math . max ( padding , get padding bottom ( ) ) ) ; }
this . dispatcher . await ( ) ; assert true ( app event handler . receive log handling finish event ( ) ) ; app event handler . reset log handling event ( ) ;
if ( limit = = start pos ) { set error state ( parse error state . empty _ column ) ; mark empty column } this . result = new string ( bytes , start pos , limit - start pos , get charset ( ) ) ; return limit ;
size + = java data model . align up ( 15 * jdm . primitive1 ( ) , jdm . memory align ( ) ) ; return size ;
for ( w window : windows ) { reduce fn < k , input t , output t , w > . context direct context = context factory . base ( window , state style . direct ) ; trigger runner . prefetch for value ( window , direct context . state ( ) ) ; }
throw new org . apache . axis2 . databinding . adbexception ( target bucket cannot be null ) ; } else {
if ( s < hend & & e > hstart ) { if ( s < = hstart ) { if ( e > = hend ) { [ hstart , hend [ fully included in [ s , e [ , h removed h = h . next ; } else { [ hstart , hend [ minus [ s , e [ = [ e , hend [ h . start = end ; } } else if ( e > = hend ) { [ hstart , hend [ minus [ s , e [ = [ hstart , s [ h . end = start ; } else { [ hstart , hend [ minus [ s , e [ = [ hstart , s [ + [ e , hend [ handler g = new handler ( ) ; g . start = end ; g . end = h . end ; g . handler = h . handler ; g . desc = h . desc ; g . type = h . type ; g . next = h . next ; h . end = start ; h . next = g ; } } return h ;
event driver factory factory = new event driver factory ( container scope ) ;
relation _ logger . logp ( level . finer , mbean server notification filter . class . get name ( ) , is notification enabled , object name not selected , and all + names deselected , exiting ) ; return false ; } else if ( deselected names . contains ( obj name ) ) {
resource quotas . set namespace bundle resource quota ( property , cluster , namespace , bundle range , quota ) ;
new within ( timeout ) { @ override protected void run ( ) { expect msg class ( register task manager . class ) ;
r = invoke on ( sub instance , m ) ; assert equals ( sub class target . override method , r . return value ) ;
try { replacement = p . matcher ( non bmp string ) . replace all ( _ ) ; } catch ( string index out of bounds exception jdk bug ) { system . out . println ( warning : your jdk is buggy ) ; system . out . println ( pattern . compile ( \ + p . pattern ( ) + \ ) . matcher ( \ ab \ \ u d840 \ \ u dc00 c \ ) . replace all ( \ _ \ ) ; should not throw index out of bounds ) ; }
boolean skip first = false ;
request = body request encoder . finalize request ( ) ;
servlet context . set attribute ( globals . class _ path _ attr , this . classpath ) ; }
seek check ( in , 0 ) ;
if ( is lob ( ) ) return this ; else return new default data type < t > ( this , precision , scale , l , nullability , identity , default value ) ;
unsigned int128 scratch = new unsigned int128 ( ) ; zero fraction part ( scratch ) ; }
final execution environment env = execution environment . get execution environment ( ) ; data set < custom type > ds = collection data sets . get custom type data set ( env ) ;
return create session ( get session id ( ) ) ;
r = ( ( solr index searcher ) o ) . get slow atomic reader ( ) ; } } else {
block replacement = rewrite . get ast ( ) . new block ( ) ; list rewrite replacement rewrite = rewrite . get list rewrite ( replacement , block . statements _ property ) ; replacement rewrite . insert first ( declaration , null ) ; replacement rewrite . insert last ( rewrite . create move target ( target ) , null ) ; rewrite . replace ( target , replacement , group description ) ; return ;
this . authenticator . set user search ( new filter based ldap user search ( ou = people , ( cn = { 0 } ) , get context source ( ) ) ) ;
for ( int position = 0 ; position < num pitch samples - 1 ; position + + ) { while ( ( old rate position + 1 ) * new sample rate > new rate position * old sample rate ) { enlarge output buffer if needed ( 1 ) ; for ( int i = 0 ; i < num channels ; i + + ) { output buffer [ num output samples * num channels + i ] = interpolate ( pitch buffer , position * num channels + i , old sample rate , new sample rate ) ; } new rate position + + ; num output samples + + ; } old rate position + + ; if ( old rate position = = old sample rate ) { old rate position = 0 ; assertions . check state ( new rate position = = new sample rate ) ; new rate position = 0 ; } }
this func . sample method = abstract stochastic caching diff function . sampling method . ordered ; if ( this func . method = = stochastic calculate methods . none specified ) { log . info ( no calculate method has been specified ) ; }
control = xmlbuilder . create ( message ) . a ( from , romeo @ montague . lit orchard ) . a ( to , juliet @ capulet . lit balcony ) . a ( id , zid615d9 ) . a ( type , chat ) . e ( body ) . t ( default language ) . as string ( output properties ) ; message = packet parser utils . parse message ( packet parser utils . get parser for ( control ) ) ;
channel buffer stream res prefix = netty test utils . stream to channel buffer ( relay buffer , cp , 20000 , stats ) ;
pkixname constraint validator name constraint validator = new pkixname constraint validator ( ) ;
list < hregion > daughters = cluster . get regions ( table name ) ;
array adapter < char sequence > adapter = array adapter . create from resource ( this , r . array . animators , android . r . layout . simple _ spinner _ item ) ;
int type length = istr . read _ long ( ) ;
zkt . set disabled table ( table name ) ;
try { while ( m _ queue . is empty ( ) ) { thread . sleep ( 50 ) ; } thread . sleep ( 300 ) ; } catch ( interrupted exception e2 ) { }
return new product ( right , new product ( left . derive ( ) , new exponent ( left , new difference ( right , new constant ( 1 ) ) ) ) ) ;
log . info ( job : + reduce task . get job id ( ) + reduce task : + reduce task . get task id ( ) + all maps finished , adding to task to + finish ) ;
try { build artifacts ( foo ) ; fail ( building ' foo ' was supposed to fail ) ; } catch ( build failed exception e ) { if ( e . get message ( ) . contains ( building ' foo ' is supposed to fail ) ) { throw e ; } make sure the reporter reported the error message . assert contains event ( building ' foo ' is supposed to fail ) ; }
random random = new random ( ) ; list < reference entry < object , object > > reads = lists . new array list ( ) ; iterator < reference entry < object , object > > i = read order . iterator ( ) ; while ( i . has next ( ) ) { reference entry < object , object > entry = i . next ( ) ; if ( random . next boolean ( ) ) { map . get or compute ( entry . get key ( ) ) ; reads . add ( entry ) ; i . remove ( ) ; assert true ( segment . recency queue . size ( ) < = drain _ threshold ) ; } } int undrained index = reads . size ( ) - segment . recency queue . size ( ) ; check and drain recency queue ( map , segment , reads . sub list ( undrained index , reads . size ( ) ) ) ; read order . add all ( reads ) ; check eviction queues ( map , segment , read order , write order ) ;
if ( new start = = new end ) { path . reset ( ) ; l . end section ( apply trim path if needed ) ; return ; } if ( new start > = new end ) { new start - = length ; }
object inspector result oi = eval . initialize ( r . oi ) ; object result o = eval . evaluate ( r . o ) ; object standard result = object inspector utils . copy to standard object ( result o , result oi , object inspector copy option . writable ) ;
final http2 headers headers = dummy headers ( ) ; run in channel ( client channel , new http2 runnable ( ) { @ override public void run ( ) throws http2 exception { http2 client . encoder ( ) . write headers ( ctx ( ) , 3 , headers , 0 , ( short ) 16 , false , 0 , false , new promise ( ) ) ; http2 client . flush ( ctx ( ) ) ; } } ) ;
title = new stream ;
runtime . get runtime ( ) . gc ( ) ;
return rhs . is null type ( ) ;
int rs to kill1 = utility1 . get hbase cluster ( ) . get server with meta ( ) = = 0 ? 1 : 0 ; int rs to kill2 = utility2 . get hbase cluster ( ) . get server with meta ( ) = = 0 ? 1 : 0 ;
for ( int j = 0 ; j < 10 ; + + j ) { count = 0 ; iterator . reset ( ) ;
int i = kernel size . length ;
want jfif = false ; will subsample = false ; } } else if ( image type = null ) {
assert false ( this family scope is set to local , should not be part of replication key scopes , scopes . contains key ( f2 ) ) ; }
blob key key = put ( server , job id1 , data , blob type ) ; assert not null ( key ) ; verify type ( blob type , key ) ;
update j ( json ( [ { ' id ' : ' 1 ' , ' big _ decimal _ td ' : 100000000000000000000000000001234567890 . 0987654321 } ] ) , params ( commit , true ) ) ;
file status [ ] file statuses = wh . get file statuses for unpartitioned table ( db , tbl ) ; return update table stats fast ( tbl , file statuses , made dir , force recompute , environment context ) ;
for ( string field name : sorted fields ) { final object val = message . message ( ) . get ( field name ) ; field values [ idx + + ] = ( ( val = = null ) ? null : val . to string ( ) . replace all ( \ n , \ \ \ \ n ) ) ; field values [ idx + + ] = ( ( val = = null ) ? null : val . to string ( ) . replace all ( \ r , \ \ \ \ r ) ) ; }
qr = a . get array copy ( ) ; m = a . get row dimension ( ) ; n = a . get column dimension ( ) ; rdiag = new double [ n ] ;
if ( player . world . get collision boxes ( player , player . get entity bounding box ( ) . offset ( x , 0 , z ) ) . is empty ( ) ) y = 1 ; } if ( z = 0 | | x = 0 | | y = 0 ) {
+ + current pos ; end of next number = line . index of ( ) , current pos ) ; event . set total ( get memory in kilo byte ( number parser . parse double ( line , current pos , end of next number - current pos - 1 ) , line . char at ( end of next number - 1 ) , line ) ) ; current pos = end of next number ; }
for ( int i = 0 ; i < data . length ; i + + ) { output . write int ( data [ i ] ) ; }
clean current exec chunk ( ) ; }
replace instruction ( clazz , offset , branch instruction , new branch instruction ( instruction constants . op _ ifne , branch instruction . branch offset ) ) ;
multi version consistency control . reset thread read point ( mvcc ) ; s = this . memstore . get scanners ( ) . get ( 0 ) ; assert scanner results ( s , new key value [ ] { kv11 , kv del , kv12 } ) ; }
if ( ( data source . length ( ) = = 0 ) | | is connected ) { nothing to do return ; } persistent store store = database . persistent store collection . get store ( this ) ;
cannot delete child . set writable ( true ) ; }
m _ serializer = ( serializer ) m _ result content handler ; } }
if ( controller . is constructor ( ) ) { mv . visit var insn ( aload , 0 ) ; } else { mv . visit type insn ( new , bytecode helper . get class internal name ( call node ) ) ; }
try { if ( this . scheduler = null ) { this . scheduler . stop ( ) ; } } catch ( exception e ) { logger . error ( error stopping scheduler service , e ) ; }
configure event ( listener . get key data conversion ( ) , listener . get value data conversion ( ) , e , key , value , pre , ctx ) ; listener . invoke ( new event wrapper < > ( key , e ) , is local node primary owner ) ; } }
return new build target ( target os . linux , false , new string [ ] { * * * . c } , new string [ 0 ] , new string [ ] { * * * . cpp } , new string [ 0 ] , new string [ 0 ] , , - c - wall - o2 - mfpmath = sse - msse - fmessage - length = 0 - m32 - f pic , - c - wall - o2 - mfpmath = sse - msse - fmessage - length = 0 - m32 - f pic , - shared - m32 ) ; }
return open default geo ip db ( geo db ) ;
cl = concurrent skip list map . class ;
prefixes = ( set ) uri to prefix . get ( old uri ) ;
fsinfo3 response response2 = nfsd . fsinfo ( xdr _ req . as read only wrap ( ) , security handler , new inet socket address ( localhost , 1234 ) ) ;
if ( endpoint . get configuration ( ) . is stepwise ( ) ) { change current directory ( current dir ) ; }
range validator < double > percentage validator = range validator . range ( 0 . 0 , 1 . 0 ) ; text field < double > memory capacity = new percentage text field ( memory capacity ) ; memory capacity . add ( percentage validator ) ; form . add ( memory capacity ) ; text field < double > memory threshold = new percentage text field ( memory threshold ) ; memory threshold . add ( percentage validator ) ; form . add ( memory threshold ) ; text field < integer > tile threads = new text field < integer > ( tile threads ) ; tile threads . add ( range validator . minimum ( 0 ) ) ; form . add ( tile threads ) ; text field < integer > tile priority = new text field < integer > ( tile priority ) ; tile priority . add ( range validator . minimum ( 0 ) ) ; form . add ( tile priority ) ; form . add ( new check box ( recycling ) ) ; form . add ( new check box ( jpeg acceleration ) ) ; add png encoder editor ( form ) ; check box check box mosaic = new check box ( allow native mosaic ) ; check box check box warp = new check box ( allow native warp ) ; jaiinfo info = ( jaiinfo ) jai model . get object ( ) ; jaiextinfo je = null ;
java type read only repository = null ; if ( entity metadata . is read only ( ) ) { getting read only repository interface annotated with @ roo read only repository set < class or interface type details > read only repositories = get type location service ( ) . find classes or interface details with annotation ( roo _ read _ only _ repository ) ; validate . not empty ( read only repositories , error : you should define a read only repository interface annotated with @ roo read only repository to be able to generate repositories of read only entities . ) ; iterator < class or interface type details > it = read only repositories . iterator ( ) ; while ( it . has next ( ) ) { class or interface type details read only repository details = it . next ( ) ; read only repository = read only repository details . get type ( ) ; break ; } } list < java type > repository custom list = new array list < java type > ( ) ;
final orient vertex in v = oe . get vertex ( direction . in ) ; final string in field name = orient vertex . get connection field name ( direction . in , oe . get label ( ) , graph . is use vertex fields for edge labels ( ) ) ; replace links ( in v . get record ( ) , in field name , old identity , new identity ) ; } else {
xml stax . register ( groups , false , true , true ) ; skip woodstox , include aalto and fast - infoset
string buffer sb = new string buffer ( ) ; sb . append ( chat color . gold ) ; sb . append ( description : ) ; sb . append ( chat color . white ) ; sb . append ( command . get description ( ) ) ; sb . append ( \ n ) ;
try { peeking iterator . remove ( ) ; fail ( remove ( ) should throw illegal state exception after a peek ( ) ) ; } catch ( illegal state exception e ) { * expected * } assert equals ( after remove ( ) throws exception , peek should still be ok , b , peeking iterator . peek ( ) ) ;
assert equals ( 0 , target coverage . get grid geometry ( ) . get grid range ( ) . get low ( 0 ) ) ; assert equals ( 0 , target coverage . get grid geometry ( ) . get grid range ( ) . get low ( 1 ) ) ; assert equals ( 999 , target coverage . get grid geometry ( ) . get grid range ( ) . get high ( 0 ) ) ; assert equals ( 999 , target coverage . get grid geometry ( ) . get grid range ( ) . get high ( 1 ) ) ; } finally {
if ( last member1 . equals ( last member2 ) ) { merge the two chains , with the library members last . if ( last member2 instanceof library member ) { last member1 . set visitor info ( last member2 ) ; } else { last member2 . set visitor info ( last member1 ) ; } }
assert equals ( range . closed ( 2 , 8 ) , range . span ( range . closed open ( 2 , 4 ) ) ) ;
component c = get container ( ) ;
for ( int i = 0 ; i < input . num instances ( ) ; i + + ) convert instance ( input . instance ( i ) ) ; }
if ( this method . get name ( ) . equals ( get hibernate lazy initializer ) ) { return this ; } else { return proceed . invoke ( proxy , args ) ; }
return stream . empty ( ) ; }
assert false ( rb . get initialization status ( ) ) ; assert false ( async request success ) ; utility . start mini cluster ( ) ;
ready = true ; } else if ( aggregate ) { q . append scalar select token ( token ) ; } else { throw new query exception ( aggregate function expected before ( in select ) ; } ready = true ; }
btn position = ( button ) find view by id ( r . id . position _ target ) ;
fill rect ( x + 1 , y + height , width , 1 ) ;
join column [ ] join columns = join table anno . join columns ( ) ;
final int v = integer . parse int ( range ) ; fp = new ofetch plan level ( v , v , level ) ; } } else { if ( level = = - 1 )
headers . put ( camel braintree . group by custom field , null ) ; final com . braintreegateway . result result = request body and headers ( direct : generate _ 1 , null , headers ) ;
vote items list = vote manager . get active vote items list ( ) ;
string attr name = xml . get attribute name ( i ) ;
assert equals ( def , strings . common suffix ( abc \ u d8 ab \ u dcabdef , xyz \ u dcab \ u dcabdef ) ) ;
double frac = ( hour 24 . 0 ) + ( minute 1440 . 0 ) + ( second 86400 . 0 ) + ( millisecond 86400000 . 0 ) ;
answer < stanza > answer = new answer < stanza > ( ) { @ override public stanza answer ( invocation on mock invocation ) throws throwable { return protocol . get responses ( ) . poll ( ) ; } } ;
current buffer = null ;
if ( on dismiss listener = null ) { super activity toast . set on dismiss listener ( style . dismiss tag , style . dismiss token , on dismiss listener ) ; }
string cur file name = snapshots _ prefix + gen loaded ;
parse user current user = new parse user ( ) ; current user . put auth data ( parse anonymous utils . auth _ type , new hash map < string , string > ( ) ) ; current user . set object id ( object id ) ; make it not lazy . parse user partial mock current user = spy ( current user ) ; when ( partial mock current user . get session token ( ) ) . then return ( session token ) ; parse exception link exception = new parse exception ( parse exception . account _ already _ linked , account already linked ) ; do return ( task . < void > for error ( link exception ) ) . when ( partial mock current user ) . link with in background ( any string ( ) , matchers . < map < string , string > > any ( ) ) ; parse current user controller current user controller = mock ( parse current user controller . class ) ; when ( current user controller . get async ( false ) ) . then return ( task . for result ( partial mock current user ) ) ; when ( current user controller . set async ( any ( parse user . class ) ) ) . then return ( task . < void > for result ( null ) ) ; parse core plugins . get instance ( ) . register current user controller ( current user controller ) ; string auth type = facebook ;
data out . write int ( vector length ) ;
job data map job data map = job detail . get job data map ( ) ;
assert equals ( 3 , ( int ) extendable message . get extension ( unittest lite . optional int32 extension lite ) ) ; assert equals ( 11 , ( int ) extendable message . get extension ( unittest lite . optional fixed32 extension lite ) ) ; }
final local date next bill through date = previous bill through date . plus ( billing period . get period ( ) ) ;
usercover switcher . set image drawable ( new account . get background ( ) ) ; userphoto . get global visible rect ( final rect ) ;
query query = query . new builder ( ) . set limit ( int32 value . new builder ( ) . set value ( 1 ) ) . build ( ) ;
float [ ] hue score histogram = new float [ 360 ] ; float high score = - 1 ; int best hue = - 1 ; for ( int y = 0 ; y < height ; y + = sample stride ) { for ( int x = 0 ; x < width ; x + = sample stride ) { int argb = bitmap . get pixel ( x , y ) ; int alpha = 0x ff & ( argb > > 24 ) ; if ( alpha < 0x80 ) { drop mostly - transparent pixels . continue ; } remove the alpha channel . int rgb = argb | 0x ff000000 ; color . color to hsv ( rgb , hsv ) ; bucket colors by the 360 integer hues . int hue = ( int ) hsv [ 0 ] ; if ( hue < 0 | | hue > = hue score histogram . length ) { defensively avoid array bounds violations . continue ; } float score = hsv [ 1 ] * hsv [ 2 ] ; hue score histogram [ hue ] + = score ; if ( hue score histogram [ hue ] > high score ) { high score = hue score histogram [ hue ] ; best hue = hue ; } } }
if ( snapshot index meta data . get aliases ( ) . is empty ( ) ) { index md builder . remove all aliases ( ) ; }
int timeout connection = 30000 ;
delete ( ( int ) index ) ;
clean up constants . init defaults ( store ) ;
if ( tick count > 0 ) { tick count - - ; } if ( tick count > 0 ) { return true ; } return execute ( ) ;
return recent posts query ; }
if ( string utils . is not empty ( value ) ) { try { prop . set property ( name , encryption util . crypt _ algorithm + { + encryption util . encrypt ( value ) + } ) ; prop . save ( ) ; } catch ( exception ex ) { log . error ( ex . to string ( ) , ex ) ; } }
if ( ( properties . get property ( key ) . ends with ( yes ) ) ) { f serializer . set omit xmldeclaration ( true ) ; } else { f serializer . set omit xmldeclaration ( false ) ; } } else if ( ( domconstants . s _ xerces _ properties _ ns + domconstants . s _ xml _ version ) . equals ( key ) ) {
m tv cancel = new text view ( m context ) ; m tv cancel . set gravity ( gravity . center ) ; layout params lp = new layout params ( layout params . match _ parent , layout params . wrap _ content ) ; lp . top margin = dp2px ( 7 ) ; lp . bottom margin = dp2px ( 7 ) ; m tv cancel . set layout params ( lp ) ; ll _ container . add view ( m tv cancel ) ;
headers . put ( camel linked in . start , null ) ;
assert true ( report . get start time ( ) = = 10 ) ;
} finally { ldap utils . close context ( system ldap ctx ) ; } }
g . set color ( fill ) ; g . fill rect ( 0 , 0 , width , height ) ; g . set color ( border ) ;
verify no more interactions ( listener ) ; verify ( listener , timeout ( 100 ) ) . on request finished ( req1 ) ; verify ( listener , timeout ( 10 ) ) . on request finished ( req2 ) ; queue . stop ( ) ; }
find view by id ( r . id . nothing _ to _ show _ placeholder ) . set visibility ( folders . size ( ) < 1 & & is excluded mode ( ) & & hawk . get ( emoji _ easter _ egg , 0 ) = = 0 ? view . visible : view . gone ) ; find view by id ( r . id . ll _ emoji _ easter _ egg ) . set visibility ( folders . size ( ) < 1 & & is excluded mode ( ) & & hawk . get ( emoji _ easter _ egg , 0 ) = = 1 ? view . visible : view . gone ) ; }
assert that ( min element ts , not ( equal to ( commit time ) ) ) ; assert that ( committed . get min timestamp ( ) , equal to ( min element ts ) ) ; assert that ( committed . get synchronized processing output watermark ( ) , equal to ( commit time ) ) ; return committed ;
expr . get value ( e context , string . class ) ;
return unit of work . contains synchronization ( on completion ) ; } else {
ptm . commit ( status ) ; fail ( should have thrown illegal transaction state exception ) ; }
return spins ( fsd . get primary dir ( ) ) | | spins ( fsd . get secondary dir ( ) ) ;
conf . set long ( dfsconfig keys . federation _ store _ connection _ test _ ms , time unit . hours . to millis ( 1 ) ) ;
persistence unit metadata pu metadata = emf impl . get kundera metadata instance ( ) . get application metadata ( ) . get persistence unit metadata ( _ persistence unit ) ; assert . assert equals ( kundera _ client , pu metadata . get client ( ) ) ; assert . assert equals ( true , pu metadata . get exclude unlisted classes ( ) ) ; assert . assert not null ( pu metadata . get persistence unit root url ( ) ) ;
for ( int i = 0 ; i < array clone . length ; i + + ) { object element clone = clone ( array clone [ i ] ) ; if ( element clone = null ) array clone [ i ] = element clone ; } return array clone ;
final put resolver < content values > put resolver = mock ( put resolver . class ) ; final list < content values > content values = singleton list ( mock ( content values . class ) ) ;
materialized result result = read table ( transaction , table handle , column handles , new session ( ) , tuple domain . all ( ) , optional int . empty ( ) , optional . empty ( ) ) ;
channel future future = e . get channel ( ) . write ( response ) ;
joined rooms = multi user chat . get joined rooms ( get connection ( 1 ) , get full jid ( 0 ) ) ; assert false ( joined rooms should be empty , joined rooms . has next ( ) ) ; muc . join ( testbot ) ;
value = wrap number ( number ) ;
conf . set long ( dist block integrity monitor . max _ pending _ jobs , 0 l ) ;
if ( ( contains ( value , 0 , 4 , van , von ) | | contains ( value , 0 , 3 , sch ) ) | | contains ( value , index + 1 , 2 , et ) ) {
final int [ ] snackbar on screen xy = get snackbar location on screen ( ) ;
mru file list . remove ( absolute path ) ;
final batch batch after step1 = batch retriever . fetch batch ( batch name ) ;
kafka server = test utils . create server ( new kafka config ( server properties ( ) ) , new mock time ( ) ) ; map store . reset static map ( ) ;
m content view . remove view ( m child view ) ;
assert equals ( 0 , cluster . get namesystem ( 0 ) . get missing blocks count ( ) ) ; }
ui prefs _ . get ( ) . toolbar visible ( ) . add value change handler ( new value change handler < boolean > ( ) { @ override public void on value change ( value change event < boolean > event ) { show toolbar ( event . get value ( ) ) ; } } ) ; client state updater instance _ = client state updater _ . get ( ) ;
root folder . mkdir ( ) ; realm . init ( get application context ( ) ) ; }
reload type ( sub target , 002 ) ;
list < row > puts = construct put requests ( ) ; table . batch ( puts ) ;
assert . assert equals ( bye world , reply1 . get ( 10 , time unit . seconds ) ) ;
resp . done ( ) ;
json argo tree . register ( groups ) ;
for ( string field name : sorted fields ) { final object val = message . message ( ) . get ( field name ) ; field values [ idx + + ] = ( ( val = = null ) ? null : val . to string ( ) . replace all ( \ n , \ \ \ \ n ) ) ; field values [ idx + + ] = ( ( val = = null ) ? null : val . to string ( ) . replace all ( \ r , \ \ \ \ r ) ) ; }
if ( filter map . contains key ( filter . filter type ( ) ) ) { filter map . put ( filter . filter type ( ) , new array list < map < string , object > > ( ) ) ; }
http entity ok entity = new string entity ( test body , content type . text _ plain ) ;
return index ;
log . warn ( exception while trying to unload the sla namespace , will not try to unload the namespace again . exception : , ex ) ;
verify ( fc , never ( ) ) . do filter ( any ( http servlet request . class ) , any ( http servlet response . class ) ) ;
if ( use time > 0 l ) { vuinfo info = vu map . get ( vu id key ) ; create usage record ( usage types . vpn _ users , use time , start date , end date , account , info . get user id ( ) , info . get user name ( ) , info . get zone id ( ) ) ; }
transport factory . close ( ) ;
byte [ ] family = kv . get family ( ) ;
if ( bytes . compare to ( orphan region range . get first ( ) , start ) > 0 ) { orphan region range . set first ( start ) ; } if ( bytes . compare to ( orphan region range . get second ( ) , end ) < 0 ) { orphan region range . set second ( end ) ; } } } }
if ( parameter instanceof object path ) { if ( type instanceof class & & dbus interface . class . is assignable from ( ( class ) type ) ) parameter = conn . get exported object ( ( ( object path ) parameter ) . source , ( ( object path ) parameter ) . path ) ; else parameter = new path ( ( ( object path ) parameter ) . path ) ; }
final set < string > candidates = new hash set < > ( ) ;
write data to file ( file of read write file channel ) ;
this . control x = event . get x ( ) ; this . control y = event . get y ( ) ; this . is down = true ;
if ( once . get ( ) & & once . compare and set ( false , true ) ) { state . connect ( ) ; } rp . replay ( ) ;
if ( i < m old text . length ( ) ) {
if ( remove ( key , old value ) ) {
gargamel . set distance ( 5 ) ;
if ( ( component description . is stateful ( ) | | component description . is stateless ( ) ) ) { component description . get configurators ( ) . add ( new component configurator ( ) { @ override public void configure ( deployment phase context context , component description description , component configuration configuration ) throws deployment unit processing exception { configuration . add component interceptor ( sbinvocation interceptor . factory , interceptor order . component . jpa _ session _ bean _ interceptor , false ) ; } } ) ; }
values . put ( favorites . icon _ package , ( string ) null ) ; values . put ( favorites . icon _ resource , ( string ) null ) ; values . put ( favorites . icon , ( byte [ ] ) null ) ; return 1 ;
if ( in block comment & & ( line . trim ( ) . starts with ( ) | | line . trim ( ) . starts with ( ) ) ) { support in roo - 1116 line = ; }
final int grantor = 0 ;
f element . set values ( element ) ;
frontend request received request = request1 . get value ( ) ;
for ( int i = starting updates . delete by query list . size ( ) - 1 ; i > = 0 ; i - - ) { update update = starting updates . delete by query list . get ( i ) ; list < object > dbq = ( list < object > ) update . log . lookup ( update . pointer ) ; long version = ( long ) dbq . get ( 1 ) ; string q = ( string ) dbq . get ( 2 ) ; track delete by query ( q , version ) ; }
jpanel left panel = new jpanel ( new grid bag layout ( ) ) ; left panel . set name ( gtkfile chooser . directory list panel ) ;
close socket ( ) ;
ctx . set activation ( activation _ lazy ) ; log . trace ( parsing sslcontext parameters done , returning { } , ctx ) ; return ctx ; }
m _ set test frame = new jframe ( test instances ) ;
sp promote algo . replica repair struct r1 = new sp promote algo . replica repair struct ( ) ; r1 . m _ max sp handle seen = 3 l ;
tester . assert component on ajax response ( table ) ;
require encryption = true ; ssl ctx = create ssl context ( ssl policy factory , config ) ; break ; case optional :
return peer sync : core = + uhandler . core . get name ( ) + url = + my url + ;
string token name = ; int j = i + 2 ;
create new file ( new _ file _ name , test project explorer context menu constants . sub menu new . file , ) ; check default text in code mirror editor for file ( default _ text _ for _ new _ file _ name , new _ file _ name ) ; editor . close file by name with saving ( new _ file _ name ) ;
assert equals ( % , string . format ( locale . us , % % ) ) ;
for ( immutable bit set col mask : child unique key set ) { immutable bit set . builder tmp mask = immutable bit set . builder ( ) ; boolean complete key projected = true ; for ( int bit : col mask ) { if ( map in to out pos . contains key ( bit ) ) { tmp mask . set ( map in to out pos . get ( bit ) ) ; } else {
response future future1 = service . hello async ( motan async multi - 1 - + i ) ;
events _ . fire event ( rsconnect action event . deploy app event ( content path _ , content type _ , previous ) ) ; break ; case rsconnect . content _ type _ document :
set selectable ( false ) ; }
final transaction tx1 = tm ( 0 ) . suspend ( ) ;
advance txn ego ( ) ;
f domconfig properties . set property ( domconstants . s _ xerces _ properties _ ns + domconstants . s _ xml _ version , xml version ) ; f domconfig properties . set property ( domconstants . s _ xsl _ output _ encoding , utf - 16 ) ;
rmnode node1 = mock nodes . new node info ( 1 , resources . create resource ( 1024 , 1 ) ) ;
if ( name . to lower case ( ) . equals ( content - type ) ) { name = exchange . content _ type ; }
word scorer = new linear interpolating scorer ( ir , multi fields . get terms ( ir , body _ ngram ) , body _ ngram , 0 . 85d , new bytes ref ( ) , 0 . 5 , 0 . 4 , 0 . 1 ) ;
xtokens . next token ( ) ;
sql = select varb512 from varbinary table tree where varb512 = x ' 0 a0 b00 ' ; check query plan ( client , sql , explain plan str ) ; validate table column of scalar varbinary ( client , sql , new string [ ] { } ) ;
if ( m last pressed close button = null & & m last pressed close button . is pressed ( ) ) { m last pressed close button . set pressed ( false ) ; }
final iterator < map . entry < context , sparse array < recycle pool > > > it = s mount content pools by context . entry set ( ) . iterator ( ) ; while ( it . has next ( ) ) { final context context key = it . next ( ) . get key ( ) ; if ( is context wrapper ( context key , context ) ) { it . remove ( ) ; } }
try { rm service . submit application ( submit request2 ) ; } catch ( yarn exception e ) { assert . fail ( exception is not expected . ) ; } get applications request get all apps request = get applications request . new instance ( new hash set < string > ( ) ) ;
return application timeout type . value of ( string utils . to upper case ( type . trim ( ) ) ) ; } catch ( runtime exception e ) {
if ( collector info . get collector token ( ) = null ) { use collector address to update token service if its not available . set timeline delegation token ( collector info . get collector token ( ) , collector info . get collector addr ( ) ) ; }
visit code attribute0 ( clazz , method , code attribute ) ;
if ( value = null ) { try { elem . set attribute ( value , value . to string ( ) ) ; } catch ( domexception e ) { elem . set attribute ( value , [ [ [ error : could not be encoded as xml ] ] ] ) ; } } } }
logger . error ( unable to create inet address for < + domain + > , e ) ; return null ; } }
this . value = value ;
while ( constructor class = null & & object stream class . is serializable ( constructor class ) ) { constructor class = constructor class . get superclass ( ) ; }
if ( p . is odd ( ) ) return mod inverse ( p ) ;
assert xpath exists ( wmt _ ms _ capabilities capability layer layer [ name = ' nested ' ] layer [ name = ' cite : bridges ' ] , dom ) ;
new key value ( rows _ one [ 2 ] , families [ 0 ] , qualifiers _ one [ 3 ] , values [ 0 ] ) ,
return from element . get queryable ( ) = null & & from element . get queryable ( ) . is multi table ( ) ;
assert not null ( out ) ;
if ( found = = true ) { extension item type item = wcs20 _ factory . create extension item type ( ) ; item . set namespace ( scaling . namespace ) ; item . set name ( scaling ) ; item . set object content ( scaling ) ; gc . get extension ( ) . get contents ( ) . add ( item ) ; } }
if ( plain text auth provider . class . equals ( clazz ) ) { auth provider = ( auth provider ) clazz . get constructor ( string . class , string . class ) . new instance ( username , password ) ; } else { auth provider = ( auth provider ) clazz . new instance ( ) ; }
buffer = create message frame ( fake message ) ; frame handler ( ) . data ( false , 5 , buffer , message frame length ) ; verify ( frame writer , timeout ( time _ out _ ms ) ) . window update ( eq ( 0 ) , eq ( ( long ) 2 * message frame length ) ) ;
astnode subq = rewrite astfor multi insert ( ast , cbo ctx . node of interest ) ; if ( subq = null ) {
break ; case 0x f0 :
if ( collect property ( property candidate , name . get string ( ) , value ) ) { break ; }
handler . synchronize ( create modify service event ( jms - test - service , global - jms - test - service - updated , null ) ) ;
session s = open session ( ) ; s . close ( ) ; }
for ( int i = 0 , n = text area . get visible lines ( ) ; i < n ; i + + ) { line info info = get line info ( i ) ; if ( info . physical line > line ) { line is invisible? return i - 1 ; return - 1 ; } if ( info . physical line = = line ) { if ( offset > = info . offset & & offset < info . offset + info . length ) { screen line = i ; break ; } } } if ( screen line = = - 1 ) return - 1 ; last screen line p = line ;
final class or interface type details cid = get entity details ( entity ) ;
string field name home = home _ ll ; string field name work = work _ ll ; clear index ( ) ;
if ( ( m _ clusters = = null ) = ( other . m _ clusters = = null ) ) return false ; if ( ( m _ clusters = null ) & & m _ clusters . equals ( other . m _ clusters ) ) return false ; return true ; }
sb . append ( args [ i ] ) ;
logger . log ( level . warning , exception while discovering info for feature + feature + of + item . get entity id ( ) + node : + item . get node ( ) , e ) ;
if ( expect hashinator ) { pw . print ( indent string + hash configuration : ) ; if ( snapshot . m _ hash config = null ) { pw . println ( indent string + present ) ; } else { pw . println ( indent string + not present ) ; snapshot consistent = false ; } }
db utils . execute and close ( connection . prepare statement ( alter table + table _ name + add column + evidence + varchar ( 16777216 ) default ' ' ) ) ;
red5 . set connection local ( null ) ;
{ list < node > nodes to retire = tester . get nodes ( application , node . state . active ) . as list ( ) . sub list ( 0 , 2 ) ; nodes to retire . for each ( node - > tester . patch node ( node . with ( node . status ( ) . with want to retire ( true ) ) ) ) ; system state state = prepare ( application , 2 , 0 , 2 , 0 , default , tester ) ; tester . activate ( application , state . all hosts ) ; list < node > retired nodes = tester . get nodes ( application ) . retired ( ) . as list ( ) ; assert equals ( 2 , retired nodes . size ( ) ) ; assert true ( nodes are retired by system , retired nodes . stream ( ) . all match ( retired by ( agent . system ) ) ) ; }
appender = new dbus event appender ( events , dbus buf , null ) ;
return true ; default : return false ; } }
. add compilation mode flags ( compilation mode flags . new builder ( ) . set mode ( compilation mode . dbg ) . add compiler flag ( - o0 ) . add compiler flag ( - undebug ) ) ; stl impl . add stl impl ( toolchain , 4 . 9 ) ; return toolchain ; }
assert equals ( 3327428144502 l , bloom filter . optimal num of bits ( integer . max _ value , double . min _ value ) ) ; try { bloom filter < string > unused = bloom filter . create ( hash test utils . bad _ funnel , integer . max _ value , double . min _ value ) ; fail ( we can ' t represent such a large bf ) ; } catch ( illegal argument exception expected ) { assert that ( expected ) . has message ( could not create bloom filter of 3327428144502 bits ) ; } }
shutdown disruptor ( false ) ;
current block . status | = ( label . status & label . target ) ; label . frame = current block . frame ; return ;
imodel < map < string , cache configuration > > cache configurations = new property model < map < string , cache configuration > > ( gwc config model , cache configurations ) ;
this . public key cache . clear ( ) ; for ( key info ki : signing certs ) { key name key name = key info tools . get key name ( ki ) ; x509 certificate x509certificate = key info tools . get x509 certificate ( ki ) ; if ( x509certificate = null & & key name = null ) { log . tracef ( registering signing certificate % s , key name . get name ( ) ) ; this . public key cache . put ( key name . get name ( ) , x509certificate . get public key ( ) ) ; } else { log . tracef ( ignoring certificate % s : % s , key name , x509certificate ) ; } }
boolean success = fs . delete ( new path ( ss dir + + snapshot node . ssname + second ) ) ;
assert queue state ( buffer , 0 , first , 0 , 1 ) ;
string old macaddress = properties . get ( plugwise binding constants . property _ mac _ address ) ; string new macaddress = message . get macaddress ( ) . to string ( ) ; if ( old macaddress = = null | | old macaddress . equals ( new macaddress ) ) { properties . put ( plugwise binding constants . property _ mac _ address , new macaddress ) ; update = true ; } return update ; }
assert equals ( activiti event type . historic _ activity _ instance _ created , events . get ( 13 ) . get type ( ) ) ;
buffered code point = cp ;
return result ;
execute ( update % s set m [ ' k ' ] = ? where k = 10 , unset ( ) ) ;
layout params = new view group . layout params ( view group . layout params . wrap _ content , view group . layout params . match _ parent ) ;
if ( type arguments . length > 0 ) { parameterized type parameterized type = ast . new parameterized type ( element type ) ; for ( itype binding type argument : type arguments ) parameterized type . type arguments ( ) . add ( new type ( type argument , ast , imports ) ) ; element type = parameterized type ; }
list < string > ip list = net utils . get local v4 ip list ( ) ; if ( ip list . is empty ( ) ) { return ip list . get ( 0 ) ; } return net utils . loopback _ address _ v4 ; }
current filter = get file filter ( ) ; current file = get selected file ( ) ; set accept all file filter used ( accept all ) ; set file filter ( current filter ) ; set selected file ( current file ) ; m _ dialog type = unhandled _ dialog ;
protocol . get process stdin writer ( ) . begin array ( ) ;
int num = at least ( 31 ) ; for ( int i = 0 ; i < num ; i + + ) { document doc = new document ( ) ; doc . add ( new text field ( f , a b c d b c d c d d , field . store . no ) ) ; w . add document ( doc ) ; doc = new document ( ) ; doc . add ( new text field ( f , a b c d , field . store . no ) ) ; w . add document ( doc ) ; } s = new searcher ( w . get reader ( ) ) ;
return obj . is annotation present ( annot type ) ;
time . increment ( counter . bucket size in millseconds ) ; counter . update rolling max ( type , 30 ) ;
assert equals ( 2 , do delete ( s , from java . lang . object ) ) ;
string single interface enabled prop = util activator . get resources ( ) . get settings string ( single _ window _ interface _ enabled ) ; boolean is enabled = false ;
log . debug ( attempted to add backwards edge : + bytes . to string ( start ) + + bytes . to string ( end ) ) ; return false ;
return ( thread . interrupted ( ) & & t . get exception ( ) = = null ) ;
double bandwidth = distances [ k - 1 ] ;
if ( is block boundary ( n , parent ) ) { block stack . add ( new basic block ( peek ( block stack ) , n ) ) ; } return true ; }
return next . txn id ;
system . get property ( foo ) ; indent : 14 exp : 12 warn
assert true ( duration > 0 ) ; } ) ; }
engine . searcher search result = engine . acquire searcher ( test ) ; matcher assert . assert that ( search result , engine searcher total hits matcher . engine searcher total hits ( 1 ) ) ; matcher assert . assert that ( search result , engine searcher total hits matcher . engine searcher total hits ( long point . new exact query ( _ seq _ no , 2 ) , 1 ) ) ; search result . close ( ) ; }
int moving node idx = 1 ; big integer token new token = new big integer token ( 21267647932558653966460912964485513216 ) ; big integer token [ ] tokens = init tokens ( ) ; big integer token [ ] tokens after move = init tokens after move ( tokens , moving node idx , new token ) ; pair < set < range < token > > , set < range < token > > > ranges = calculate stream and fetch ranges ( tokens , tokens after move , moving node idx ) ; assert equals ( ranges . left . iterator ( ) . next ( ) . left , tokens after move [ moving node idx ] ) ; assert equals ( ranges . left . iterator ( ) . next ( ) . right , tokens [ moving node idx ] ) ; assert equals ( no data should be fetched , ranges . right . size ( ) , 0 ) ;
deployapp ( application2 , cluster spec2 , flavor d1 , tester , 2 ) ;
list < router address > addresses = new array list < router address > ( _ manager . get addresses ( ) ) ;
throw new flyway exception ( unable to instantiate jdbc driver : + driver class + = > check whether the jar file is present , e ) ; } }
errors error = errors . for exception ( t ) ; string message = error . message ( ) . equals ( t . get message ( ) ) ? null : t . get message ( ) ; return new api error ( error , message ) ; }
assert equals ( hconstants . no _ seqnum , sida . get lowest sequence id ( encoded _ region _ name ) ) ;
zkt . set enabled table ( table name ) ;
for ( pull update future current pull : current pulls ) { current pull . done ( ) ; } } catch ( exception e ) {
final int count = m velocity view pager . get adapter ( ) . get count ( ) ;
kosmos file system . initialize ( uri . create ( kfs : ) , conf ) ; base dir = new path ( system . get property ( test . build . data , tmp ) + kfs - test ) ; }
final path foo2 = new path ( root , foo2 ) ; hdfs . rename ( foo , foo2 ) ;
invalidate transport ( transport , address ) ; retry count = log transport error and throw exception if needed ( retry count , current cluster name , te ) ; } catch ( remote illegal lifecycle state exception e ) { socket address address = e . get server address ( ) ; failed servers = update failed servers ( address , failed servers ) ;
current size + = size ;
params = new hash map < object , object > ( ) ; params . put ( person id , 1 ) ; params . put ( age , 30 ) ; results = execute select query ( find by id and age , params ) ; assert . assert equals ( 0 , results . size ( ) ) ;
form . set value ( tabs : panel : keywords : new keyword , keyword2 ) ;
scanner . mark ( ) ; scanner . find ( end _ tag _ name ) ; string tag name = scanner . region ( ) ; visitor . on start javadoc tag ( tag name ) ; scanner . skip ( whitespace _ with _ eol ) ;
among _ var = find _ among _ b ( a _ 2 , 46 ) ;
document doc = get as dom ( wfs?request = get feature & version = 1 . 1 . 0 & service = wfs & type name = + get layer id ( system test data . buildings ) ) ;
string temp path = system . get property ( java . io . tmpdir ) ; boolean temp path has sep end = ( temp path = = null ? false : temp path . ends with ( file . separator ) ) ; string home path = system . get property ( user . home ) ;
if ( d . width > = 640 ) { set location ( ( d . width - size . width ) 2 , ( d . height - size . height ) 2 ) ; } else { set location ( 0 , 0 ) ; set size ( d ) ; } show ( ) ;
mock . message ( 0 ) . body ( ) . not ( body ( ) . contains ( a ) ) ; template . send body ( direct : start , hello ) ;
if ( tracing ) { log . trace ( encountered pruned proxy ) ; }
igps1 . parameterize channel ( c1 , dop change1 , input1 mode , input1breaks pipeline ) ;
executor . submit ( new runnable ( ) { @ override public void run ( ) { if ( verify connection ( cassandra host ) ) { if ( ( ( cassandra client factory ) client factory ) . add cassandra host ( cassandra host ) ) { downed host queue . remove ( cassandra host ) ; } } } } ) ;
colibri conference iq . channel rtp channel = get rtp channel ( local channels info , content name ) ;
exe = execute ( update my _ client - - config ' + config file . get name ( ) + ' - o - s enabled = true - e oidc ) ; assert exit code and stream sizes ( exe , 1 , 0 , 1 ) ;
pfs [ 1 ] = new synthesized plan fragment ( ) ;
index . consistency check ( ) ;
indarray predictions = nd4j . create ( new double [ ] { 0 . 001 , 0 . 101 , 0 . 201 , 0 . 301 , 0 . 401 , 0 . 501 , 0 . 601 , 0 . 701 , 0 . 801 , 0 . 901 } , new int [ ] { 10 , 1 } ) ; indarray actual = nd4j . create ( new double [ ] { 0 , 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 } , new int [ ] { 10 , 1 } ) ;
if ( columns . length = referenced entity . get identifier ( ) . get column span ( ) ) { throw new annotation exception ( a foreign key refering + referenced entity . get entity name ( ) + from + associated class . get entity name ( ) + has the wrong number of column . should be + referenced entity . get identifier ( ) . get column span ( ) ) ; }
standard evaluation context e context = test scenario creator . get test evaluation context ( ) ;
load null ( instructions ) ; return ;
primary key pk = new primary key ( table ) ;
assert equals ( ship strategy type . partition _ hash , iteration . get input1 ( ) . get ship strategy ( ) ) ;
queued thread pool thread pool = ( queued thread pool ) web server . get thread pool ( ) ; thread pool . set daemon ( true ) ; if ( max threads = - 1 ) { thread pool . set max threads ( max threads ) ; } session manager sm = web app context . get session handler ( ) . get session manager ( ) ;
assert equals ( 2 , result . get partitions not in ms ( ) . size ( ) ) ;
connection id = get connection id ( ) ; notification connected notif = new jmxconnection notification ( jmxconnection notification . opened , this , connection id , client notif seq no + + , successful connection , null ) ;
trigger fired latch = new count down latch ( 2 ) ; cloud solr client solr client = cluster . get solr client ( ) ;
address . certificate pinner ( ) . check ( address . url ( ) . host ( ) , unverified handshake . peer certificates ( ) ) ;
auth scope scope = new auth scope ( url . get host ( ) , url . get port ( ) ) ; username password credentials creds = new username password credentials ( user , password ) ; client . get state ( ) . set credentials ( scope , creds ) ; client . get params ( ) . set authentication preemptive ( true ) ; session id = create session ( ) ;
final map < string , string > expected headers = new hash map < string , string > ( ) ;
final long task manager memory mb = 1024 ;
file client cert chain file = test utils . load cert ( client . pem ) ;
double [ ] [ ] convolved = convolve ( intensity , m kernel ) ;
assert equals ( src , normalizer . normalize ( src , normalizer . form . nfc ) ) ;
m space measured = true ;
try { for ( rebalance task info current plan : plans ) { int async id = admin client . rebalance ops . rebalance node ( current plan ) ; assert not same ( got a valid rebalance async id , - 1 , async id ) ; get admin client ( ) . rpc ops . wait for completion ( current plan . get stealer id ( ) , async id , 300 , time unit . seconds ) ;
string msg = möglicherweise fehlende grammatische übereinstimmung zwischen artikel , adjektiv und + nomen bezüglich kasus , numerus oder genus . beispiel : ' mein kleiner haus ' + statt ' mein kleines haus ' ;
for ( agent download info download info : download info list ) { if ( version . version . compare to ( download info . get version ( ) ) > 0 ) { cached agent download info = download info ; return download info ; } }
get mock endpoint ( mock : a ) . expected message count ( 1 ) ; get mock endpoint ( mock : b ) . expected message count ( 1 ) ;
final byte array input stream entity = new byte array input stream ( request context . has entity ( ) ? request context . get entity ( ) . to string ( ) . get bytes ( ) : no - entity . get bytes ( ) ) ; final int response status = request context . get headers ( ) . get first ( response - status ) = null ? ( int ) request context . get headers ( ) . get first ( response - status ) : 200 ;
local ok ( request id , database ) ; return null ;
assert equals ( metadata . get producer name ( ) , producer name ) ;
if ( m icons cache . contains key ( record number ) ) { m current icon = m icons cache . get ( record number ) ; post icon ( ) ; return ; }
string container name = get container from authority ( uri ) ;
hazelcast instance hz instance = mock ( hazelcast instance . class ) ; when ( hz instance . get distributed object ( any string ( ) , any string ( ) ) ) . then throw ( new client service not found exception ( mock exception ) ) ; client icache manager client cache manager = new client icache manager ( hz instance ) ;
exec root . get relative ( base dir . get child ( coverage prefix + . dat ) ) . delete ( ) ;
map < object , object > parameters = new hash map < object , object > ( ) ; parameters . put ( abstract grid format . read _ gridgeometry2 d . get name ( ) . to string ( ) , new grid geometry2 d ( new general grid envelope ( destination size ) , destination envelope in source crs ) ) ; final grid coverage2 d coverage = coverage reader . read ( coverage utils . get parameters ( coverage reader . get format ( ) . get read parameters ( ) , parameters , true ) ) ; if ( coverage = = null ) { logger . log ( level . fine , failed to read coverage - continuing ) ; return null ; }
s . clear ( ) ;
nd . add normalized line ( line ) ;
headerbuf . put ( ( byte ) ' b ' ) ;
this . written + = to consume ;
return trim start ( string escape utils . unescape html4 ( str . replace all ( < ( . | \ n ) * ? > , ) ) ) ; }
font2x = font . color marked ( bitmap cache . get ( assets . fonts2 x ) , 14 , 0x00000000 , bitmap text . font . latin _ full ) ;
long last msg = system . current time millis ( ) ;
string orig name = ds tpl . get name ( ) ;
int h = key = = null ? 0 : key . hash code ( ) ; h ^ = h > > > 20 ^ h > > > 12 ; h ^ = h > > > 7 ^ h > > > 4 ; return h & this . table . length - 1 ; }
local variable type table attribute . u2local variable type table length = remove empty local variable types ( local variable type table attribute . local variable type table , local variable type table attribute . u2local variable type table length , code attribute . u2max locals ) ; }
result & = relative _ layout _ direction ; }
throw new org . apache . axis2 . databinding . adbexception ( virtualization type cannot be null ) ;
remote session first session = activate and assert ok ( 90l , 0l , clock ) ;
assert read test data ( null , 0 , 1 ) ;
try { reader . set property ( lexical _ handler _ property , handler ) ; reader . set feature ( namespace _ prefixes _ feature , true ) ; } catch ( saxexception e ) {
jzvideo player . go on play on pause ( ) ; }
if ( r _ c ( ) ) { return false ; }
if ( module commands = null & & module commands . contains ( command . get class ( ) ) ) output . write byte ( 1 ) ; else output . write byte ( 0 ) ; output . write short ( command . get command id ( ) ) ;
if ( operation . get security ( ) = = null ) { for ( security requirement security : securities ) { operation . security ( security ) ; } } path path = swagger . get path ( operation path ) ;
cb . append ( \ \ ) ;
instructions . add ( reil helpers . create and ( offset + 10 , result size , result , target size , mask size , target size , truncated result ) ) ;
when ( mock trigger . should fire ( any trigger context ( ) ) ) . then return ( false ) ;
quads . add ( new switch test quad ( \ mary smi th \ , mergeformat , \ mary smi th \ ) ) ;
assert null ( template ( ) . request body ( direct : delete sobject , result . get id ( ) ) ) ;
mark parameter used ( program method , 0 ) ; }
final key frame key frame = new key frame ( duration . millis ( 2000 ) , new key value ( block . opacity property ( ) , 0 , interpolator . linear ) , new key value ( block . layout xproperty ( ) , block x , interpolator . linear ) , new key value ( block . layout yproperty ( ) , block y , interpolator . linear ) ) ;
tree set < string > names = get sorted directory listing ( ) ;
list tasks request list tasks request = new list tasks request ( ) ; list tasks request . set actions ( test action * ) ; list tasks response response = test node . transport list tasks action . execute ( list tasks request ) . get ( ) ; assert equals ( 0 , response . get tasks ( ) . size ( ) ) ;
artifact foo = create derived artifact ( foo ) ; artifact bar = create derived artifact ( bar ) ; register action ( new test action ( test action . no _ effect , parallel builder test . < artifact > as set ( ) , as set ( foo ) ) ) ; register action ( new test action ( test action . no _ effect , lists . < artifact > new array list ( foo , foo ) , as set ( bar ) ) ) ; build artifacts ( bar ) ; }
if ( get threads ( ) = = 0 ) start threads ( 1 ) ;
if ( indexing buffer setting = = null | | indexing buffer setting . ends with ( % ) ) { we only apply the min max when % value was used for the index buffer : byte size value min indexing buffer = min _ index _ buffer _ size _ setting . get ( this . settings ) ; byte size value max indexing buffer = max _ index _ buffer _ size _ setting . get ( this . settings ) ; if ( indexing buffer . get bytes ( ) < min indexing buffer . get bytes ( ) ) { indexing buffer = min indexing buffer ; } if ( max indexing buffer . get bytes ( ) = - 1 & & indexing buffer . get bytes ( ) > max indexing buffer . get bytes ( ) ) { indexing buffer = max indexing buffer ; } } this . indexing buffer = indexing buffer ; this . inactive time = shard _ inactive _ time _ setting . get ( this . settings ) ;
throw new internal error ( ) ; }
int p2 = get precedence ( ops . sub , ops . add ) ;
byte tmp = engine state [ i ] ;
book keeper client . delete ledger ( ledger . get ledger id ( ) ) ;
durability test ( method , durability . sync _ wal , durability . skip _ wal , 0 , false , false , false ) ;
for ( i = ilbc _ constants . delay _ ds ; i < length in ; i + = ilbc _ constants . factor _ ds ) { coef _ ptr = 0 ; in _ ptr = in _ idx + i ; state _ ptr = ilbc _ constants . filterorder _ ds - 2 ; o = ( float ) 0 . 0f ; stop = ( i < ilbc _ constants . filterorder _ ds ) ? i + 1 : ilbc _ constants . filterorder _ ds ; if ( i < ilbc _ constants . filterorder _ ds ) { stop = i + 1 ; } else { stop = ilbc _ constants . filterorder _ ds ; } for ( j = 0 ; j < stop ; j + + ) { o + = coef [ coef _ ptr ] * in [ in _ ptr ] ; coef _ ptr + + ; in _ ptr - - ; } for ( j = i + 1 ; j < ilbc _ constants . filterorder _ ds ; j + + ) { o + = coef [ coef _ ptr ] * state [ state _ ptr ] ; coef _ ptr + + ; state _ ptr - - ; } out [ out _ ptr ] = o ; out _ ptr + + ; * out _ ptr + + = o ; }
result = 1 ;
uri = constants . s _ extensions _ redirect _ url ; lib = org . apache . xalan . lib . redirect ; m _ predef extensions . add ( new extension namespace support ( uri , handler class name , new object [ ] { uri , lang , lib } ) ) ; uri = constants . s _ extensions _ pipe _ url ;
file utils . delete directory ( init operation options . get local dir ( ) ) ; file utils . delete directory ( ( ( local transfer settings ) init operation options . get config to ( ) . get transfer settings ( ) ) . get path ( ) ) ; }
bytes = dimension value . get bytes ( ) ; dos . write int ( bytes . length ) ; dos . write ( bytes ) ; baos . close ( ) ; dos . close ( ) ; return baos . to byte array ( ) ; }
try { rename ( src , dst , false , true , true , rename . overwrite ) ; assert . fail ( expected exception was not thrown ) ; } catch ( ioexception ex ) { }
tiles gloss . add ( null ) ;
for ( element element : env . get elements annotated with ( bind array . class ) ) { if ( superficial validation . validate element ( element ) ) continue ; try { parse resource array ( element , builder map , erased target names ) ; } catch ( exception e ) { log parsing error ( element , bind array . class , e ) ; } }
when ( json response mock . as dto ( user dto . class ) ) . then return ( user mock ) ;
buf . append ( call drop _ table _ or _ view ( ' ) . append ( table name ) . append ( ' ) \ n ) ;
override one method swapped oom = ( override one method ) xbf . get bean ( override one method swapped return values ) ; test bean tb = swapped oom . get prototype dependency ( ) ; assert equals ( david , tb . get name ( ) ) ; tb = swapped oom . protected override singleton ( ) ; assert equals ( jenny , tb . get name ( ) ) ; }
if ( match depth > 0 | | xml tag matcher = = null | | xml tag matcher . matcher ( ) . matches ( ) ) { new tokens . add ( token ) ; if ( debug ) { log . info ( clean xml : token added as : + token . word ( ) ) ; } if ( in utterance ) { token . set ( core annotations . utterance annotation . class , utterance index ) ; if ( current speaker = null ) token . set ( core annotations . speaker annotation . class , current speaker ) ; } if ( mark single sentence ) { token . set ( core annotations . forced sentence until end annotation . class , true ) ; mark single sentence = false ; } if ( token annotations = null ) { chunk annotation utils . copy unset annotations ( token annotations , token ) ; } } else if ( debug ) { log . info ( clean xml : ignoring tokens because match depth = + match depth + ; xml tag matcher = + xml tag matcher ) ; }
assert equals ( this is a test where < b > foo < b > is highlighed and should be highlighted , best fragments [ 0 ] ) ;
string result = alg2 oid map . get ( alg name . to upper case ( locale . us ) ) ; if ( result = null ) { return result ; }
if ( try lb provisioning ) { retry = false ;
conn1 . disconnect ( ) ;
headers . put ( elasticsearch constants . param _ operation , elasticsearch operation . get by id ) ;
used ( line _ joiner . join ( * * @ const * var jscomp = { } ; , * * @ const * jscomp . scope = { } ; , * * , * @ param { function } type , * @ param { object } object , * @ return { object } , * , jscomp . reflect object = function ( type , object ) { return object ; } ; , * * @ constructor * function a ( ) { * * @ private * this . foo = 1 ; } , use ( jscomp . reflect object ( a , { foo : ' foo ' } ) ) ; ) ) ;
worker task . iteration ( ) ;
string a = me . get exchanges ( ) . get ( 0 ) . get in ( ) . get body ( string . class ) ; string b = me . get exchanges ( ) . get ( 1 ) . get in ( ) . get body ( string . class ) ; string c = me . get exchanges ( ) . get ( 2 ) . get in ( ) . get body ( string . class ) ; string d = me . get exchanges ( ) . get ( 3 ) . get in ( ) . get body ( string . class ) ; string line = a + b + c + d ; log . info ( order : { } , line ) ;
tasks to exclude . add ( tid ) ; }
if ( time format . equals ( time format . double ) ) { window time unit combo . set visible ( false ) ; tick time unit combo . set visible ( false ) ; }
assert false ( unnecessary field is set . , proto . has error msg ( ) ) ;
actual = new byte [ 8192 ] ; stm . read fully ( actual ) ; check and erase data ( actual , 0 , expected , pread test 2 ) ;
state map . remove ( action ) ; throw new action execution function exception ( e ) ; }
synchronized ( this ) { thread . sleep ( 1000 ) ; } to . assert is satisfied ( 3000 ) ; }
nonce manager chore = this . nonce manager . create cleanup scheduled chore ( this ) ; }
throw new error data decoder exception ( filename not found ) ;
if ( subject = = null | | subject . is empty ( ) ) { put extra ( intent , subject , activity . get string ( r . string . msg _ default _ mms _ subject ) ) ; } else { put extra ( intent , subject , subject ) ; }
on complete runnable . run ( ) ;
switch ( z controller . get controller type ( ) ) { case suc : case primary : case secondary : record . readonly = true ; break ; default : record . readonly = true ; break ; } records . add ( record ) ; record = new open habconfiguration record ( domain , apiversion , api version , true ) ;
search response = client ( ) . prepare search ( ) . set query ( multi match query ( the quick brown , field1 , field2 ) . cutoff frequency ( 3 ) . operator ( operator . and ) ) . get ( ) ;
query result = execute ( usa , select from v ) ;
create index ( create index if not exists myindex on % s ( value1 ) ) ; assert true ( wait for index ( keyspace , table name , myindex ) ) ;
for ( layer info layer : get catalog ( ) . get layers ( ) ) { if ( cite . equals ( layer . get resource ( ) . get store ( ) . get workspace ( ) . get name ( ) ) & & geometryless . equals ( layer . get name ( ) ) ) { assert equals ( did not find + layer . get name ( ) , 1 , xpath . get matching nodes ( wms : layer [ wms : name = ' + layer . get name ( ) + ' ] , dom ) . get length ( ) ) ; } else { assert equals ( found unexpected + layer . get name ( ) , 0 , xpath . get matching nodes ( wms : layer [ wms : name = ' + layer . get name ( ) + ' ] , dom ) . get length ( ) ) ; } }
awscredentials credentials = null ;
set on key listener ( new on key listener ( ) { @ override public boolean on key ( view v , int key code , key event event ) { boolean is shift plus tab = key code = = key event . keycode _ tab & & event . has modifiers ( key event . meta _ shift _ on ) ; return is shift plus tab & & folder . this . is focused ( ) & & last child . request focus ( ) ; } } ) ;
field modifiers field = field . class . get declared field ( modifiers ) ; modifiers field . set accessible ( true ) ; modifiers field . set int ( field , field . get modifiers ( ) & modifier . final ) ; field . set accessible ( true ) ; final data serializable factory factory = ( data serializable factory ) field . get ( null ) ; replicated map data serializable factory = factory ;
type = type . substring ( 0 , parm ) . trim ( ) ; if ( type . to lower case ( ) . starts with ( text ) ) { set charset from content type parameters ( param list ) ; } }
if ( step . get child count ( ) > 1 ) { arguments context arguments = step . arguments ( ) ; if ( arguments . get child count ( ) > 2 ) { list < argument context > argument context list = arguments . argument ( ) ; args = lists . new array list with expected size ( argument context list . size ( ) ) ; for ( argument context argument context : argument context list ) { args . add ( convert expr ( argument context . expression ( ) , scope . get root ( ) ) ) ; } } } result = operator node . create ( sequence operator . pipe , result , scope . resolve path ( name ) , args ) ;
int item pos = 0 ; view child ; icon menu view . layout params child layout params = null ;
task task = task service . create task query ( ) . process definition key like ( % \ \ % % ) . single result ( ) ;
assert graph strings ( get analyzer ( generate _ word _ parts | generate _ number _ parts | split _ on _ case _ change | split _ on _ numerics ) , a - b - c - 9 - d , a b c 9 d ) ;
map . put ( key , value1 ) ; final count down latch latch = new count down latch ( 1 ) ; new thread ( new runnable ( ) { public void run ( ) { map . lock ( key ) ; latch . count down ( ) ; } } ) . start ( ) ; assert true ( latch . await ( 20 , time unit . seconds ) ) ; future < string > f1 = map . remove async ( key ) ; try { assert equals ( value1 , f1 . get ( 0 l , time unit . seconds ) ) ; } catch ( timeout exception e ) { expected return ; } fail ( failed to throw timeout exception with zero timeout ) ;
decompressor decomp1 = codec pool . get decompressor ( codec ) ; decompressor decomp2 = codec pool . get decompressor ( codec ) ; assert equals ( lease _ count _ err , 2 , codec pool . get leased decompressors count ( codec ) ) ; codec pool . return decompressor ( decomp2 ) ; assert equals ( lease _ count _ err , 1 , codec pool . get leased decompressors count ( codec ) ) ; codec pool . return decompressor ( decomp1 ) ; assert equals ( lease _ count _ err , 0 , codec pool . get leased decompressors count ( codec ) ) ; codec pool . return decompressor ( decomp1 ) ; assert equals ( lease _ count _ err , 0 , codec pool . get leased compressors count ( codec ) ) ;
if ( ( output ptr + 6 * remaining chars ) > output end ) { _ flush buffer ( ) ; return _ output tail ; } return output ptr ;
resource manager gateway rm gateway = mock ( resource manager gateway . class ) ; when ( rm gateway . register task executor ( any string ( ) , any ( resource id . class ) , any ( slot report . class ) , any ( time . class ) ) ) . then return ( completable future . completed future ( new task executor registration success ( new instance id ( ) , rm resource id , 10 l ) ) ) ; rpc . register gateway ( rm address , rm gateway ) ;
transaction util . do in jpa ( this : : entity manager factory , entity manager - > { final unique group unique group = new unique group ( ) ; final group member group member = new group member ( ) ; unique group . add member ( group member ) ; entity manager . persist ( unique group ) ; entity manager . persist ( group member ) ; unique group id = unique group . get id ( ) ; group member id = group member . get id ( ) ; } ) ;
if ( new string = = null ) { return string ; }
assert equals ( 1 , compiler . m _ warnings . size ( ) ) ;
int previous position = m first position - 1 ; fill up ( previous position , get next child ups bottom ( previous position ) ) ;
dest = grow buffer ( dest , dest index , size needed ) ;
concurrent skip list set < integer > unique values incremented = new concurrent skip list set < > ( ) ;
int data length = length - 1 ;
assert equals ( 1 , results . size ( ) ) ; assert equals ( 3 , ( ( list ) results . get ( results . size ( ) - 1 ) ) . size ( ) ) ;
filter pipeline . dispatch ( servlet request , servlet response , filter chain ) ; return null ; } } ) ; } catch ( ioexception e ) {
file texture data data = new file texture data ( gdx . files . internal ( data premultiplied _ alpha _ test . png ) , null , null , false ) ;
final table name table name = table name . value of ( name . get method name ( ) ) ;
expected results . remove all ( collections . singleton list ( header ) ) ; assert equals ( expected results , read from source ( source , options ) ) ;
if ( block damage modifier component = = null | | block damage modifier component . skip per block effects ) { dust particle effect if ( entity . has component ( location component . class ) & & block . is debris on destroy ( ) ) { entity builder dust builder = entity manager . new builder ( core : dust effect ) ; todo : particle system stuff should be split out better - this is effectively a stealth dependency on core from the engine if ( dust builder . has component ( location component . class ) ) { dust builder . get component ( location component . class ) . set world position ( entity . get component ( location component . class ) . get world position ( ) ) ; dust builder . build ( ) ; } } sound to play for destroyed block block sounds sounds = block . get sounds ( ) ; if ( sounds . get destroy sounds ( ) . is empty ( ) ) { static sound sound = random . next item ( sounds . get destroy sounds ( ) ) ; entity . send ( new play sound event ( sound , 0 . 6f ) ) ; } }
return ( prev type = = character . decimal _ digit _ number | | prev type = = character . letter _ number | | prev type = = character . other _ number ) ;
intent intent = new intent ( ) ; intent . set class name ( this , com . didi . virtualapk . demo . aidl . book manager activity ) ; start activity ( intent ) ;
alloc response = am client . allocate ( 0 . 1f ) ;
view . on click listener collection state button on click listener = new view . on click listener ( ) { @ override public void on click ( view view ) { if ( ( ( radio button ) view ) . is checked ( ) ) { return ; } item collection state old collection state = m collection state ; switch ( view . get id ( ) ) { case r . id . todo : m collection state = item collection state . todo ; break ; case r . id . doing : m collection state = item collection state . doing ; break ; case r . id . done : m collection state = item collection state . done ; break ; } if ( m collection state = old collection state ) { on collection state changed ( ) ; } } } ;
if ( m callback = null ) { m callback . on destroy action mode ( action mode ) ; }
m seek bar x . set progress ( 10 ) ; m seek bar y . set progress ( 100 ) ;
boolean . write boolean ( block builder , i % 2 = = 0 ) ;
process extra class path attrs ( ) ;
throw new illegal state exception ( string . format ( neither % s nor % s was able to load an application context from % s . , name ( get xml loader ( ) ) , name ( get annotation config loader ( ) ) , merged config ) ) ; }
test simple values ( fieldname , double . class , - 42 . 5 d , 51 . 3 d , 3 . 1415 d ) ;
execute ( delete from % s where a = ? and b = ? , 1 , 2 ) ; assert rows ignoring order ( execute ( select a , b , c , d from mv _ test ) , row ( 0 , 0 , 1 , 0 ) , row ( 0 , 1 , 1 , 0 ) , row ( 1 , 0 , 1 , 1 ) , row ( 1 , 1 , 1 , 0 ) ) ;
if ( fixed date > = 0 ) { return ( int ) ( fixed date % 7 ) + sunday ; } return ( int ) calendar utils . mod ( fixed date , 7 ) + sunday ;
if ( link style = = linker . linkable dep type . shared ) { root deps . put ( dep . get build target ( ) , dep ) ; native linkables . put ( dep . get build target ( ) , dep ) ; }
assert that ( tz rounding . round ( time ( 2015 - 03 - 27 t17 : 00 : 00 , tz ) ) , is date ( time ( 2015 - 03 - 27 t00 : 00 : 00 , tz ) , tz ) ) ;
if ( aggregate columns order . add ( c . get field index ( ) ) ) { propagate collations . add ( c . copy ( rel . get group set ( ) . nth ( c . get field index ( ) ) ) ) ; }
if ( agent . is disabled ( ) ) { return new denied agent work ( agent . get uuid ( ) ) ; }
not full . signal ( ) ;
properties query profile properties = new query profile properties ( query profile ) ; properties ( ) . chain ( query profile properties ) ;
if ( container instanceof collection ) { collection < ? > collection = ( collection < ? > ) container ; we do the fetches in series because it makes it easier to fail on the first error . task < void > task = task . for result ( null ) ; for ( final object item : collection ) { task = task . on success task ( new continuation < void , task < void > > ( ) { @ override public task < void > then ( task < void > task ) throws exception { return fetch include async ( store , item , path , db ) ; } } ) ; } return task ; } else if ( container instanceof jsonarray ) { final jsonarray array = ( jsonarray ) container ; we do the fetches in series because it makes it easier to fail on the first error . task < void > task = task . for result ( null ) ; for ( int i = 0 ; i < array . length ( ) ; + + i ) { final int index = i ; task = task . on success task ( new continuation < void , task < void > > ( ) { @ override public task < void > then ( task < void > task ) throws exception { return fetch include async ( store , array . get ( index ) , path , db ) ; } } ) ; } return task ; }
node icon = validator . get icon ( ) ;
assert equals ( sampler . get url ( ) , res . get url ( ) ) ;
assert null ( header should have been removed , exchange . get in ( ) . get header ( header _ 1 ) ) ; } } ) . to ( mock : result ) ; } } ; }
assert that ( pf . get proxy ( ) , instance of ( time stamped . class ) ) ;
push ( r , start ) ; r = stack . poll ( ) ; }
result = read output ( new url ( base url , jmx?get = java . lang : type = memory : : heap memory usage ) ) ;
check argument ( get raw type ( ) . is assignable from ( subclass ) , % s isn ' t a subclass of % s , subclass , this ) ;
writer . check size ( ) ;
reaching uses = new maybe reaching variable use ( cfg , t . get scope ( ) , compiler , scope creator ) ;
if ( set . remove ( value ) ) { may need to change representation if ( previous size = = 2 ) { - > singleton list list < node < t > > list = collections . singleton list ( set . iterator ( ) . next ( ) ) ; return update field ( predecessor set , list ) ; } else if ( previous size = = 1 + arraylist _ threshold ) { - > array list collection < node < t > > new set = new array list < > ( arraylist _ threshold ) ; new set . add all ( set ) ; return update field ( predecessor set , new set ) ; } return true ; } return false ;
int fetch partition key count = 0 ; store < byte array , byte [ ] , byte [ ] > store = get store ( 0 , test store name ) ; for ( entry < byte array , byte [ ] > entry : entry set . entry set ( ) ) { store . put ( entry . get key ( ) , new versioned < byte [ ] > ( entry . get value ( ) ) , null ) ; if ( is key partition ( entry . get key ( ) , 0 , test store name , fetch partitions list ) ) { fetch partition key count + + ; } } iterator < byte array > fetch it = get admin client ( ) . bulk fetch ops . fetch keys ( 0 , test store name , fetch partitions list , null , false ) ;
project . set state ( state . active ) ; _ project dao . update ( project id , project ) ; return project ;
action . remove properties ( master , entity id ) ;
if ( m app . get shared preferences ( ) . get boolean ( common . first _ run , true ) = = true ) { show album art scanning dialog ( ) ; m app . get shared preferences ( ) . edit ( ) . put boolean ( common . first _ run , false ) . commit ( ) ; }
log . info ( network list was specified by the user . searching for a match . . . ) ; for ( inet address ip : ips ) { log . info ( considering + ip . get host address ( ) + . . . ) ; for ( user specified network n : network list ) { if ( n . inet address on network ( ip ) ) { log . info ( matched + ip . get host address ( ) ) ; local = ip ; self _ address = local ; return self _ address ; } } } log . err ( no interface matches the network list from the - network option . exiting . ) ;
m media items . add ( i + 1 , move media item ) ;
string dead letter uri = element . get attribute ( dead letter uri ) ;
class node . get fields ( ) . remove ( stored node ) ;
this . log class name = log adapter class name ;
synchronized ( this ) { thread . sleep ( 1000 ) ; } to . assert is satisfied ( 3000 ) ; }
kie session ksession = ks . new kie container ( ks . get repository ( ) . get default release id ( ) ) . new kie session ( ) ; return ksession ;
if ( mapred ) { return do map reduce ( fs , to compact dirs , compact once ) ; } else { return do client ( fs , to compact dirs , compact once ) ; } }
f . add string ( test properties . get size ( ) . to string ( ) ) ;
org . apache . hadoop . conf . configuration hadoop conf = default _ compat . get context configuration ( context ) ;
new default mockito session builder ( ) . init mocks ( null ) . start mocking ( ) . finish mocking ( ) ;
preconditions . check state ( start pos > = 0 ) ; if ( equals with single loop from ( cycle , candidate cycle , start pos ) ) { found = true ; break ; } }
if ( i > 1 & & lemma helper . has lemma ( tokens [ i - 1 ] , arrays . as list ( світовий ) , : f : ) & & lemma helper . has lemma ( tokens [ i - 2 ] , arrays . as list ( другий , перший ) , : f : ) ) { log exception ( ) ; return true ; }
region to region server map . put ( region info , server ) ; if ( server = = null ) return ;
rpc metrics rpc metrics = server . get rpc metrics ( ) ;
fit width + = category ; } else if ( range contains reserved ( rop reg , category ) ) { fit width = - 1 ; break ; } else if ( ssa regs mapped . get ( ssa reg ) & & can map reg ( ssa spec , rop reg ) & & seen . get ( ssa reg ) ) {
string type string = shell context . get parameters ( ) . get ( entity ) ;
scanner . reseek ( rows _ three [ 1 ] ) ;
emission checker . await next expected value ( ) ; put users blocking ( users for insert ) ;
identity token = new identity token ( ) ;
kvs = get data ( family , row , col1 , 1 ) ;
key value set . add ( id = test ) ; key value set . add ( name = example ) ; expected map . put ( id , test ) ;
jsonobject stage plans = input object . get jsonobject ( stage plans ) ; if ( stage plans = null & & stage plans . length ( ) > 0 ) { for ( string stage name : jsonobject . get names ( stage plans ) ) { jsonobject stage plan = stage plans . get jsonobject ( stage name ) ; this . stages . get ( stage name ) . extract vertex ( stage plan ) ; } } }
assert . assert true ( kill bill client . get overdue state for account ( account json no tag . get account id ( ) , request options ) . get is clear state ( ) ) ;
if ( sequence . default [ i ] = null ) { values [ i ] = sequence . default [ i ] ; }
assert smaller ( warning ( e2 ) , error ( e1 ) ) ;
if ( uncompressed direct buf len < = 0 ) { bzip2 consumed all input keep uncompressed buf = false ; uncompressed direct buf . clear ( ) ; uncompressed direct buf off = 0 ; uncompressed direct buf len = 0 ; } else { keep uncompressed buf = true ; }
system . arraycopy ( content , 0 , new content , 0 , entry offset ) ;
undecoded chunk . reader index ( last position ) ;
throw new runtime exception ( get jar invocation failed . , e ) ;
replication mapping = admin client . replica ops . get replication mapping ( 3 , new cluster , store def ) ;
vt = client . call procedure ( @ ad hoc , select t1 . pk , t1 . name , t2 . pk , t2 . name + from + tbl + as t1 , t as t2 + where t1 . poly > = t2 . poly + order by t1 . pk , t2 . pk ) . get results ( ) [ 0 ] ;
list < table permission > tbl perms = get table permissions ( table ) . get group ( group name ) ;
thread thread2 = thread factory . new thread ( monitored runnable ) ; check thread pool name ( thread2 , 2 ) ; assert equals ( thread . get name ( ) . substring ( 0 , thread . get name ( ) . last index of ( ' - ' ) ) , thread2 . get name ( ) . substring ( 0 , thread . get name ( ) . last index of ( ' - ' ) ) ) ;
{ direction8 = ( token ) match ( input , direction , follow _ direction _ in _ expr96 ) ; direction8 _ tree = ( common tree ) adaptor . create ( direction8 ) ; root _ 0 = ( common tree ) adaptor . become root ( direction8 _ tree , root _ 0 ) ; } break ;
for ( int j = merge start ; j < = merge end ; j + + ) { merge size = merge size + chunks [ j ] . get chunk size ( ) ; }
client . create and set data ( id path , host id . get bytes ( utf _ 8 ) ) ;
final string payment state name = payment smhelper . get errored state for transaction ( transaction type . authorize ) . to string ( ) ; test listener . push expected event ( next event . payment _ plugin _ error ) ; payment dao . update payment and transaction on completion ( account . get id ( ) , null , payment . get id ( ) , transaction type . authorize , payment state name , payment state name , payment . get transactions ( ) . get ( 0 ) . get id ( ) , transaction status . unknown , requested amount , account . get currency ( ) , foo , bar , internal call context ) ; test listener . assert listener status ( ) ; final list < payment transaction model dao > payment transaction history before janitor = get payment transaction history ( transaction external key ) ;
protected boolean get current implementation ( ) throws throwable { return is watch feature required ( facet ) ; }
client protos . client service . blocking interface ri = mockito . mock ( client protos . client service . blocking interface . class ) ;
for ( int i = change listeners . length - 1 ; i > 0 ; i - - ) { if ( change listeners [ i ] = null & & change listeners [ i ] . get class ( ) . get name ( ) . contains ( combo box popup control ) ) { date picker . focused property ( ) . remove listener ( change listeners [ i ] ) ; break ; } } } catch ( illegal access exception e ) {
int initial count for primary = 0 ; int initial count for other table = 0 ; for ( path file : files ) { string table name = file . get parent ( ) . get parent ( ) . get parent ( ) . get name ( ) ; check to which table this file belongs if ( table name . equals ( other table ) ) initial count for other table + + ; else if ( table name . equals ( string _ table _ name ) ) initial count for primary + + ; } assert true ( didn ' t archive files for : + string _ table _ name , initial count for primary > 0 ) ;
if ( i < m text . length ( ) ) { if ( character utils . stay here ( i , different list ) ) { int alpha = ( int ) ( 255f char time * ( progress - char time * i most count ) ) ; if ( alpha > 255 ) alpha = 255 ; if ( alpha < 0 ) alpha = 0 ; float size = m text size * 1f char time * ( progress - char time * i most count ) ; if ( size > m text size ) size = m text size ; if ( size < 0 ) size = 0 ; m paint . set alpha ( alpha ) ; m paint . set text size ( size ) ; float width = m paint . measure text ( m text . char at ( i ) + ) ; canvas . draw text ( m text . char at ( i ) + , 0 , 1 , offset + ( gaps [ i ] - width ) 2 , start y , m paint ) ; } offset + = gaps [ i ] ; }
double cpu capacity = ( usable cpu cpu usage by msg rate ) ( default quota . get msg rate in ( ) + default quota . get msg rate out ( ) ) ;
if ( current key hash offset = current position in data file ) { print error ( verbose , there seems to be a gap in the data file . + key hash + keys hash read + , offset from index file : + current key hash offset + , current position in data file : + current position in data file ) ; problems detected + + ; current position in data file = current key hash offset ; }
if ( assume online ) { assume . assume true ( server online . get ( port ) ) ; } else { assume . assume true ( server offline . get ( port ) ) ; } rest template client = new rest template ( ) ;
misc utilities . save backup ( file , 5 , null , , backup dir ) ;
drawer utils . handle footer view ( this , new view . on click listener ( ) { @ override public void on click ( view v ) { idrawer item drawer item = ( idrawer item ) v . get tag ( ) ; drawer utils . on footer drawer item click ( drawer builder . this , drawer item , v , true ) ; } } ) ;
numeric utils . int to sortable bytes ( random ( ) . next int ( ) , packed bytes , 0 ) ;
scale down ten array8 round up ( z , ten scale ) ;
int length = s . read int ( ) ;
servlet output stream out = response . get output stream ( ) ; baos . write to ( out ) ; out . flush ( ) ; }
map < string , string > origin = new hash map < string , string > ( ) ;
assert that ( new entry . state ) . is equal to ( evaluation state . built ) ;
m _ config repository . add change listener ( this ) ;
quota = 10 l ; client . quota mgmt ops . set quota for node ( store name , quota type , node id , quota ) ; get quota = long . parse long ( client . quota mgmt ops . get quota for node ( store name , quota type , node id ) . get value ( ) ) ; assert equals ( quota , get quota ) ; thread . sleep ( 5 ) ;
db . execute ( await _ population ) . close ( ) ;
cfw . add invoke ( byte code . invokestatic , org mozilla javascript context , to string , ( ljava lang object ; ) ljava lang string ; ) ; cfw . add ( byte code . iconst _ 0 ) ; cfw . add invoke ( byte code . invokevirtual , java lang string , char at , ( i ) c ) ; cfw . add ( byte code . ireturn ) ; } else if ( ret type . is primitive ( ) ) {
stream record record = new stream record ( ) ;
return verify diff ( cat original , cat updated , null , null , true , false , true ) ;
indarray temp = ( ( ndarray writable ) list . get ( 0 ) . get ( 0 ) ) . get ( ) ; int [ ] shape = array utils . clone ( temp . shape ( ) ) ; shape [ 0 ] = min values ; arr = nd4j . create ( shape ) ; } else { arr = nd4j . create ( min values , count length ( list . get ( 0 ) ) ) ; } } else if ( details . one hot ) {
mock zook keeper . fail now ( code . sessionexpired ) ; configuration cache . clusters list cache ( ) . clear ( ) ; try { clusters . get clusters ( ) ; fail ( should have failed ) ; } catch ( rest exception e ) { assert equals ( e . get response ( ) . get status ( ) , status . internal _ server _ error . get status code ( ) ) ; } mock zook keeper . fail now ( code . sessionexpired ) ;
del . set attribute ( attribute2 , null ) ; assert . assert null ( del . get attribute ( attribute2 ) ) ; assert . assert equals ( 1 , del . get attributes map ( ) . size ( ) ) ; assert . assert null ( del . get attributes map ( ) . get ( attribute2 ) ) ;
if ( feature info . name = = null ) { if ( feature info . req gl es version = feature info . gl _ es _ version _ undefined ) { return get major version ( feature info . req gl es version ) ; } else { return 1 ; lack of property means open gl es
arrays . sort ( new string [ ] { y , w , y , e , s , u , h , o , d , t , d , f , z , j , c , k , f , z , o , e , r , t , v , d , l , r , w , u , v , a , m , o } , c ) ;
if ( exponent . signum = = 0 ) return ( m . equals ( one ) ? zero : one ) ; if ( this . equals ( one ) ) return ( m . equals ( one ) ? zero : one ) ;
int end = authority . index of ( ] ) ;
storage . read properties ( sd , start opt ) ;
if ( id = null ? id . equals ( that . id ) : that . id = null ) { return false ; } return true ;
file repo actions dir = new file ( test connection . get path ( ) + actions ) ; file repo databases dir = new file ( test connection . get path ( ) + databases ) ; file repo multichunks dir = new file ( test connection . get path ( ) + multichunks ) ; file repo temporary dir = new file ( test connection . get path ( ) + temporary ) ; file repo transactions dir = new file ( test connection . get path ( ) + transactions ) ;
bugly . init ( get application context ( ) , 900019352 , false ) ; set content view ( r . layout . activity _ main ) ; plugin status text = ( text view ) find view by id ( r . id . layout _ control _ accessibility _ text ) ; plugin status icon = ( image view ) find view by id ( r . id . layout _ control _ accessibility _ icon ) ; handle material status bar ( ) ; explicitly load preferences ( ) ;
if ( logger . is debug enabled ( ) ) logger . debug ( port + currently tried port + seems in use . ) ; currently tried port = network utils . get random port number ( ) ; if ( logger . is debug enabled ( ) ) logger . debug ( retrying bind on port + currently tried port ) ; } }
new uri . set query ( null ) ; sb . append ( new uri . to string ( ) . replace all ( \ \ . , \ \ . ) ) ; if ( query = null ) { string query pattern = ( \ \ ? + query + ) ? ; sb . append ( query pattern ) ; } return sb . to string ( ) ;
con . set timestamp ( now ) ; if ( get pool properties ( ) . is log abandoned ( ) ) {
node empty node = ir . number ( 0 ) ;
cxftest support . get port1 ( ) ;
load amrmtoken secret manager state ( rm state ) ;
out gen = create json generator ( conf , output trace path ) ;
ecfield f2m f = new ecfield f2m ( 1999 , a copy ) ;
get menu inflater ( ) . inflate ( r . menu . menu _ how _ to _ use , menu ) ; return super . on create options menu ( menu ) ; }
int p8 = get precedence ( ops . or ) ; assert true ( p1 < p2 ) ; assert true ( p2 < p3 ) ; assert true ( p3 < p4 ) ; assert true ( p4 < p5 ) ; assert true ( p5 < p6 ) ; assert true ( p6 < p7 ) ; assert true ( p7 < p8 ) ; }
log . error ( foo , throwable ) ; log . warn ( foo , throwable ) ; }
metadata inbound headers = new metadata ( ) ;
if ( uri . ends with ( ) ) { uri = uri + ; }
rtn = edge direction . undirected ;
if ( m controller . is out of range ( year , month , day ) ) { m month num paint . set color ( m disabled day text color ) ; } else if ( m selected day = = day ) { m month num paint . set typeface ( typeface . create ( typeface . default , typeface . bold ) ) ; m month num paint . set color ( m selected day text color ) ; } else if ( m has today & & m today = = day ) { m month num paint . set color ( m today number color ) ; } else { m month num paint . set color ( is highlighted ( year , month , day ) ? m highlighted day text color : m day text color ) ; } canvas . draw text ( string . value of ( day ) , x , y , m month num paint ) ;
tx . close ( ) ;
fragment manager fragment manager = get fragment manager ( ) ; fragment transaction fragment transaction = fragment manager . begin transaction ( ) ; m notifications detail list fragment = notifications detail list fragment . new instance ( note id ) ; m notifications detail list fragment . set footer view ( m layout buttons ) ; fragment transaction . replace ( m comment content layout . get id ( ) , m notifications detail list fragment ) ; fragment transaction . commit allowing state loss ( ) ; }
{ final file file = new file ( xsd ) ; if ( file . exists ( ) ) { return new input source ( new buffered input stream ( new file input stream ( file ) ) ) ; } } return null ;
for ( map . entry < long , client interface handle manager > e : m _ cihm . entry set ( ) ) { the internal ci adapters report negative connection ids and aren ' t included in public stats . if ( e . get key ( ) > 0 ) { long admin mode = e . get value ( ) . is admin ? 1 : 0 ; long read wait = e . get value ( ) . connection . read stream ( ) . data available ( ) ; long write wait = e . get value ( ) . connection . write stream ( ) . get outstanding message count ( ) ; long outstanding txns = e . get value ( ) . get outstanding txns ( ) ; client _ stats . put ( e . get key ( ) , new pair < string , long [ ] > ( e . get value ( ) . connection . get hostname or ip ( ) , new long [ ] { admin mode , read wait , write wait , outstanding txns } ) ) ; } } return client _ stats ;
batch = make string batch for col col compare ( ) ;
time unit . milliseconds . sleep ( 500 ) ;
current buffer . flip ( ) ; return new send frame header ( remaining in buffer , current pooled , false , trailer ) ; } else {
int t _ scanline _ size = ( src . get width ( ) + 7 ) 8 ; if ( ( t _ scanline _ size % 4 ) = 0 ) t _ scanline _ size + = 4 - ( t _ scanline _ size % 4 ) ; pad scanline to 4
skeleton control skeleton control = new skeleton control ( skeleton ) ; model . add control ( skeleton control ) ; root node . attach child ( model ) ;
new format . set format ( 1 2 ) ;
string line = in . read line ( ) ; log . debug ( response - line : + line ) ; assert . assert that ( line , starts with ( http 1 . 1 200 ok ) ) ; boolean chunked = false ;
final task in chain task in chain = this . chained tasks . get ( root of termination criterion ) ;
new select multiple ( ) ;
source = rp . get source p ( ) ;
assert equals ( ' t ' , ci . first ( ) ) ;
int [ ] no duplicates = { 350 , 400 , 450 } ;
component registry . wire dependencies ( partitioner ) ;
for ( long i = 1 ; i < = 3 ; i + + ) { product product = new product ( ) ; product . set name ( string . format ( product % d , i ) ) ; entity manager . persist ( product ) ; }
if ( ( node . compare document position ( next sibling ) & node . document _ position _ contained _ by ) = = 0 ) { throw new illegal argument exception ( cannot create a domresult when the next sibling is not contained by the node . ) ; } }
set < string > keys = get aggregation repository ( ) . get keys ( ) ;
try { mbean server = get mbean server connection ( 30 , time unit . seconds ) ; } catch ( exception ex ) { destroy karaf process ( ) ; throw new lifecycle exception ( cannot obtain mbean server connection , ex ) ; }
section data . skip bytes ( 14 ) ;
verify ( m mock updatable view1 ) . display user action result ( m mock model , m user actions [ 0 ] , true ) ; verify ( m mock updatable view2 ) . display user action result ( m mock model , m user actions [ 0 ] , true ) ; }
if ( ds delta = = 0 ) { return type space deltas ; }
server socket . set reuse address ( inet socket address . get port ( ) = 0 ) ; server socket . bind ( inet socket address , 50 ) ; port = server socket . get local port ( ) ;
get ( cdf wfs?request = release lock & version = 1 . 1 . 0 & lock id = + lock id ) ; assert equals ( wfs : wfs _ transaction response , dom . get document element ( ) . get node name ( ) ) ; assert equals ( 1 , dom . get elements by tag name ( wfs : success ) . get length ( ) ) ; }
timeline filter list metric filter list = new timeline filter list ( ) ; metric filter list . add filter ( new timeline compare filter ( timeline compare op . greater _ or _ equal , metric3 , 0 l ) ) ; result = reader . get entities ( new timeline reader context ( cluster1 , user1 , flow1 , 1 l , app1 , app , null ) , new timeline entity filters . builder ( ) . metric filters ( metric filter list ) . build ( ) , new timeline data to retrieve ( ) ) ; assert . assert equals ( 2 , result . size ( ) ) ;
measure mt = info . get linearization tolerance ( ) ; if ( mt = = null ) { return null ; }
project explorer . select item ( project _ name ) ; menu . run command ( git , commit ) ; git . wait and run commit with push ( commit _ message , origin master ) ; loader . wait on closed ( ) ; git . wait git status bar with mess ( test git constants . commit _ message _ success ) ; events . click project events tab ( ) ; events . wait expected message ( test git constants . commit _ message _ success ) ; events . wait expected message ( push _ msg ) ;
color _ tex . get texture data ( ) [ 0 ] = 255 < < 24 | ( ( int ) ( r * 255 ) ) < < 16 | ( ( int ) ( g * 255 ) ) < < 8 | ( int ) ( b * 255 ) ; color _ tex . update dynamic texture ( ) ; gl state manager . set active texture ( open gl helper . lightmap tex unit ) ;
return factory . create ( ) ;
setup child ( child , position , children bottom or top , flow , children left , selected , m is scrap [ 0 ] ) ; return child ; }
message edit text . set on key listener ( ( view , keycode , key event ) - > { if ( messenger ( ) . is send by enter enabled ( ) ) { if ( key event . get action ( ) = = key event . action _ down & & keycode = = key event . keycode _ enter ) { on send button pressed ( ) ; return true ; } } return false ; } ) ;
if ( is external storage document ( uri ) ) { final string doc id = documents contract . get document id ( uri ) ; final string [ ] split = doc id . split ( : ) ; final string type = split [ 0 ] ; if ( primary . equals ignore case ( type ) ) { return environment . get external storage directory ( ) + + split [ 1 ] ; }
int branch offset = branch targets . instruction offset ( 0 ) - offset ;
assert not null ( out ) ; assert not null ( out . get out ( ) ) ; list < map < string , object > > row list = out . get out ( ) . get body ( list . class ) ; assert not null ( out body could not be converted to a list - was : + out . get out ( ) . get body ( ) , row list ) ; assert equals ( 3 , row list . size ( ) ) ; map < string , object > row = row list . get ( 0 ) ;
m pending saved state . m reverse layout = reverse layout ; }
{ sb . append ( url ) ; }
throw new ioexception ( could not create storage directory for blob store in ' + base dir + ' . ) ;
if ( application context . contains bean ( xml camel context configurer ) ) { xml camel context configurer configurer = application context . get bean ( xml camel context configurer , xml camel context configurer . class ) ; if ( configurer = null ) { configurer . configure ( application context , ctx ) ; } } } catch ( exception e ) {
light weight edge = true ;
output . append ( out edit . output text ) ; } else {
if ( controller . get service container ( ) . get service ( context names . bind info for ( alias ) . get binder service name ( ) ) = = null ) { install alias binder service ( controller . get service container ( ) , bind info , alias ) ; } }
buffer utils . byte buffer indexed copy ( buffer out , out offset , temp buffer out , 0 , ld8 kconstants . l _ enc _ frame ) ; in offset + = ld8 kconstants . l _ frame ;
string filename = system . get property ( user . dir ) + out _ footnote add . docx ; word mlpackage . save ( new java . io . file ( filename ) ) ; system . out . println ( saved + filename ) ; }
set indices ( triangle ) ; vertex0 . x = m radius top * math . cos ( angle0 + side * angle _ delta ) ; vertex0 . y = m height 2 . 0 ; vertex0 . z = m minor top * math . sin ( angle0 + side * angle _ delta ) ; vertex1 . x = m radius top * math . cos ( angle0 + ( side + 1 ) * angle _ delta ) ; vertex1 . y = vertex0 . y ; vertex1 . z = m minor top * math . sin ( angle0 + ( side + 1 ) * angle _ delta ) ; vertex2 . x = m radius base * math . cos ( angle0 + side * angle _ delta ) ; vertex2 . y = - vertex0 . y ; vertex2 . z = m minor base * math . sin ( angle0 + side * angle _ delta ) ; scratch0 . subtract and set ( vertex0 , vertex1 ) ;
assert false ( target shard0a . is relocation target of ( source shard0b ) ) ;
string home = delegate . get environment ( ) . get ( kotlin _ home ) ;
return group . equals ( pair . group ) & & name . equals ( pair . name ) ; } catch ( class cast exception e ) {
clear op write ( ) ;
assert to string ( cat . name = ?1 or cust . name . first name = ?2 or kitten . name = ?1 , cat . name . eq ( kitty ) . or ( cust . name . first name . eq ( hans ) ) . or ( kitten . name . eq ( kitty ) ) ) ; }
object value to suppress ;
set weighted data ( m data ) ;
sv source state = map . remove and get old ( source ) ;
if ( own keys . get key group id ( ) = = 0 ) { api encryption key identity key = own keys . get identity key ( ) . to api key ( ) ; array list < api encryption key > keys = managed list . of ( own keys . get keys ( ) ) . map ( private key . to _ api ) ; array list < api encryption key signature > signatures = managed list . of ( own keys . get keys ( ) ) . map ( private key . sign ( own keys . get identity key ( ) ) ) ; log . d ( tag , creation of new key group ) ; api ( new request create new key group ( identity key , configuration . supported , keys , signatures ) ) . then ( new consumer < response create new key group > ( ) { @ override public void apply ( response create new key group response ) { own keys = own keys . set group id ( response . get key group id ( ) ) ; encryption keys storage . add or update item ( 0 , own keys . to byte array ( ) ) ; on main keys ready ( ) ; } } ) . failure ( new consumer < exception > ( ) { @ override public void apply ( exception e ) { log . w ( tag , keys upload error ) ; log . e ( tag , e ) ; just ignore } } ) ; } else { on main keys ready ( ) ; }
return new simple authentication info ( token . get principal ( ) , token . get credentials ( ) , get name ( ) ) ;
conf = new job conf ( fs config , dfsiotest . class ) ; conf . set job name ( dfstest - reading ) ; file output format . set output path ( conf , new path ( dfs _ output + reading ) ) ; file input format . set input paths ( conf , new path ( dfs _ input ) ) ; conf . set input format ( sequence file input format . class ) ; conf . set output key class ( text . class ) ; conf . set output value class ( text . class ) ; conf . set mapper class ( read mapper . class ) ; conf . set reducer class ( reduce . class ) ; conf . set num reduce tasks ( 1 ) ;
sync millis ref . compare and set ( sync millis , new sync millis ) ;
assert glob matches ( f * * , * = > * food barnacle , fool barnacle ) ;
file system fs = file system . get local ( conf ) ;
final props common private = new props ( null , this . test plugin dir path + commonprivate . properties ) ;
for ( container id container id : containers to remove ) { log . warn ( remove container + container id + with incomplete records ) ; try { remove container ( container id ) ; todo : kill and cleanup the leaked container } catch ( ioexception e ) { log . error ( unable to remove container + container id + in store , e ) ; } } return containers ;
jaxbelement < ctrel > subdoc = create subdoc ( mdp , subdocx ) ;
system . arraycopy ( plclpc , 0 , this . prev lpc , 0 , ilbc _ constants . lpc _ filterorder + 1 ) ;
m cache . clear all ( ) ; assert equals ( - 1 , m cache . get size ( ) ) ; assert false ( unexpected3 . exists ( ) ) ; assert null ( get resource ( key2 ) ) ; assert null ( get resource ( key3 ) ) ; }
admin . snapshot ( bytes . to string ( snapshot name1 ) , bytes . to string ( table name ) , snapshot description . type . flush ) ; log . info ( = = = after snapshot with 1000 rows ) ; log fstree ( ) ;
verify allowed ( create namespace , superuser , user _ global _ admin , user _ group _ admin ) ;
message bytes = c9 : 00 : 55 ;
stack map frame [ ] stack map frames = new stack map frame [ frame count ] ;
path . parent ( ) . add date ( raw measure . get ( ) . get long value ( ) ) ;
} else { log . error ( error occurred while altering column type of table { } , caused by : . , table info . get table name ( ) , irefor add column ) ; throw new schema generation exception ( error occurred while adding column into table + table info . get table name ( ) , irefor add column , cassandra , database name ) ; } }
throw keeper exception ; }
spdy http headers . set stream id ( http response , stream id ) ;
assert num docs ( num docs . get ( ) , source _ collection ) ;
props . set property ( jdbc4 connection . querytimeout _ unit , milliseconds ) ;
if ( description . is exclude class interceptors ( identifier ) ) { for ( interceptor description interceptor description : class interceptors ) { string interceptor class name = interceptor description . get interceptor class name ( ) ; list < interceptor factory > around invokes = user around invokes by interceptor class . get ( interceptor class name ) ; if ( around invokes = null ) { user around invokes . add all ( around invokes ) ; } if ( requires timer chain ) { list < interceptor factory > around timeouts = user around timeouts by interceptor class . get ( interceptor class name ) ; if ( around timeouts = null ) { user around timeouts . add all ( around timeouts ) ; } } } }
merchandise = template ( ) . request body and header ( direct : apex call get with id , null , salesforce endpoint config . apex _ query _ param _ prefix + id , test id , merchandise _ _ c . class ) ; assert not null ( merchandise ) ;
final string mask result = environment . get next variable string ( ) ;
reader xml config = new string reader ( < ?xml version = \ 1 . 0 \ encoding = \ utf - 8 \ ? > + < config name = \ function - test \ > + < intarr operation = \ append \ > 1 < intarr > + < intarr operation = \ append \ > 2 < intarr > + < config > ) ; config payload user config = config payload . from builder ( new dom config payload builder ( null ) . build ( get document ( xml config ) ) ) ; assert payload ( { \ intarr \ : [ \ 1 \ , \ 2 \ ] } , user config ) ; }
details view params . width = details view position . width ( ) ; details view params . height = details view position . height ( ) ; switch views ( details view , details place holder view , details view params ) ; }
string [ ] domain = compute metrics ? _ output . _ domains [ _ output . _ domains . length - 1 ] : adapt frm . last vec ( ) . domain ( ) ;
double xl , xu , inc = 1 ; double x = ( int ) mean ( ) ; if ( p < cdf ( x ) ) { do { x - = inc ; inc * = 2 ; } while ( p < cdf ( x ) ) ; xl = x ; xu = x + inc 2 ; } else { do { x + = inc ; inc * = 2 ; } while ( p > cdf ( x ) ) ; xu = x ; xl = x - inc 2 ; } return quantile ( p , xl , xu ) ;
if ( contains unicode escape ) { value = process unicode escapes ( value ) ; if ( value = = null ) { report error ( get position ( index ) , invalid escape sequence ) ; return create token ( token type . error , begin token ) ; } }
assert false ( expected non - cfs after merge , w . newest segment ( ) . info . get use compound file ( ) ) ; merge policy lmp = w . get config ( ) . get merge policy ( ) ; lmp . set no cfsratio ( 1 . 0 ) ;
sqlexception sex fbt2 = new sqlexception ( , 08xxx , 666666666 ) ; data access resource failure exception darf fbt = ( data access resource failure exception ) sext . translate ( task , sql - fbt2 , sex fbt2 ) ; assert equals ( sex fbt2 , darf fbt . get cause ( ) ) ; }
final mock relay connection relay conn1 = new mock relay connection ( sources response , register response , null , server idx ) ;
roi manager . use native crs ( native crs ) ;
msg printer . print saving patterns ( ) ;
mp4 box header header = new mp4 box header ( data ) ; mp4 data box databox = new mp4 data box ( header , data ) ; data size = header . get data length ( ) ; content = databox . get content ( ) ; }
json val = string . value of ( ( ( date ) val ) . get time ( ) ) ; } else {
url = new url ( http : example . com . nn ) ; assert equals ( nn , urlutil . get domain name ( url ) ) ; url = new url ( http : ) ;
attitude . set boy ( boy ) ; attitude . set country ( country ) ; attitude . set likes ( true ) ; boy . get country attitudes ( ) . add ( attitude ) ; s . persist ( boy ) ; s . get transaction ( ) . commit ( ) ; s . clear ( ) ; transaction tx = s . begin transaction ( ) ;
if ( f . get type ( ) = sqlstmt . class ) continue ; int modifiers = f . get modifiers ( ) ;
if ( cfs . get live sstables ( ) . is empty ( ) ) throw new configuration exception ( found system keyspace files , but they couldn ' t be loaded ) ;
lia node . retract left tuple ( fh2 . get first left tuple ( ) , context , ksession ) ;
instructions . add ( reil helpers . create ldm ( offset , arch size , esi , operand size , temp ) ) ;
set < process executor . option > options = enum set . of ( process executor . option . expecting _ std _ out , process executor . option . is _ silent ) ; process executor . result result = process executor . launch and execute ( process executor params , options , * stdin * optional . empty ( ) , * time out ms * optional . empty ( ) , * time out handler * optional . empty ( ) ) ;
test block ( ) ;
if ( has _ domain ) { buf . append ( ; domain = ) ; quote only or append ( buf , domain , quote _ domain ) ; }
block cache bc = new cache config ( conf ) . get block cache ( ) ; assert not null ( bc ) ; cache stats cs = bc . get stats ( ) ; long start hit = cs . get hit count ( ) ; long start miss = cs . get miss count ( ) ; long start evicted = cs . get evicted count ( ) ;
test impl ( new long [ ] { 1 , 0 , 1 , 1 } , new int [ ] { 0 , 0 , 0 , 0 } , 1 , 4 , 1 , 0 ) ;
int icon vertical position = ( canvas . size ( ) . y - texture . get height ( ) ) 2 ;
set cdata section elements ( v ) ;
match ( number path . class , bbyte2 ) ;
return get storefiles size ( store file - > store file . is hfile ( ) ) ;
return kind . to string ( ) ;
mapped statement select pet = configuration . get mapped statement ( select pet ) ; assert not null ( select pet ) ; }
assert . assert equals ( 1 , sources schemas map . size ( ) ) ;
char [ ] output = new char [ input . length ( ) ] ;
map < string , pair < long , long > > usage map = new hash map < string , pair < long , long > > ( ) ;
job1 . set int ( mrjob config . index _ cache _ memory _ limit , 0 ) ; string input = the quick brown fox \ nhas many silly \ n + red fox sox \ n ; path in dir = new path ( testing distinct input ) ; path out dir = new path ( user alice output ) ; test mini mrclasspath . configure word count ( fs , job1 , input , 2 , 1 , in dir , out dir ) ; run job as user ( job1 , alice _ ugi ) ; }
int indirection = get _ offset ( ) ; string rep id = read _ repository id ( ) ; if ( repository id cache = = null ) repository id cache = new cache table ( orb , false ) ; repository id cache . put ( rep id , indirection ) ;
client . register ( test rx invoker provider . class , rx invoker provider . class ) ; string s = target ( client ) . request ( ) . rx ( test rx invoker . class ) . get ( ) ; assert true ( provided rx invoker was not used . , s . starts with ( rx test invoker ) ) ; }
grid . set widget ( 1 , 0 , new label ( restore . rdata into workspace at startup ) ) ; grid . set widget ( 1 , 1 , restore workspace _ = new yes no ask default ( false ) ) ;
thread . sleep ( script . get length ( ) + 1000 ) ; logger . get logger ( ) . fine ( all nodes leave ) ;
return new file input stream ( resource file ) ;
assert true ( ( results [ 0 ] . get long ( outstanding _ response _ messages ) + results [ 0 ] . get long ( outstanding _ transactions ) ) > 0 ) ;
g . draw line ( right , 6 , right , bottom ) ;
send go away ( error _ connect _ error ) ; } }
adapter . set group layout id ( list _ card _ layout _ resource id ) ; adapter . set card list view ( this ) ;
good dirs disk utilization percentage = 0 ;
helper . partition tables by quota target ( quotas , tables with quotas , namespace tables with quotas ) ; table name rpc quota table = helper . create table ( ) ; test _ util . get admin ( ) . set quota ( quota settings factory . throttle table ( rpc quota table , throttle type . read _ number , 6 , time unit . minutes ) ) ;
if ( memory bytes limit = = 0 ) { circuit break ( label , bytes ) ; } long new used ;
connections . await ( ) ; }
set content cache ( true ) ; }
artwork dao artwork dao = muzei database . get instance ( context ) . artwork dao ( ) ; artwork artwork = artwork dao . get artwork by id ( artwork id ) ; if ( artwork = = null ) { return ; } if ( artwork . image uri = = null ) { the easy case : this is a unique image uri and we can just delete the single row . revoke document permission ( document id ) ; artwork dao . delete ( context , artwork ) ; } else { the hard case : we ' re actually deleting every row with that image uri list < artwork > artwork to delete = artwork dao . get artwork by image uri ( artwork . image uri ) ; if ( artwork to delete = = null ) { return ; } for ( artwork art : artwork to delete ) { we want to make sure every document being deleted is revoked revoke document permission ( artwork _ document _ id _ prefix + art . id ) ; } artwork dao . delete by image uri ( context , artwork . image uri ) ; }
for ( int i = 0 ; i < procs . length ; + + i ) { prepare procedure ( procs [ i ] ) . set proc id ( next proc id ( ) ) ; }
if ( test result . is success ( ) ) { should report log summary after tests = true ; report result summary ( add to , test result ) ; } } }
mutable object iterator < int pair > probe1 = new uniform int pair generator ( num _ keys , probe _ vals _ per _ key , true ) ;
daemon checkpoint thread = new daemon ( new secondary name node ( tconf ) ) ; checkpoint thread . start ( ) ; }
return rx changes observer . observe changes ( content resolver , uris , content observer handler , build . version . sdk _ int ) ;
float pref width = c . pref width . get ( a ) ; float pref height = c . pref height . get ( a ) ; float min width = c . min width . get ( a ) ; float min height = c . min height . get ( a ) ; float max width = c . max width . get ( a ) ; float max height = c . max height . get ( a ) ; if ( pref width < min width ) pref width = min width ; if ( pref height < min height ) pref height = min height ; if ( max width > 0 & & pref width > max width ) pref width = max width ; if ( max height > 0 & & pref height > max height ) pref height = max height ; if ( colspan = = 1 ) { spanned column min and pref width is added later . float hpadding = c . computed pad left + c . computed pad right ; column pref width [ column ] = math . max ( column pref width [ column ] , pref width + hpadding ) ; column min width [ column ] = math . max ( column min width [ column ] , min width + hpadding ) ; }
event loop group = new nio event loop group ( ) ;
assert null ( rule . get ( source jar ) ) ;
values = inflight . values ( ) . stream ( ) ; } else {
get list view ( ) . set choice mode ( list view . choice _ mode _ single ) ;
assert equals ( schedule result . get blocked ( ) . is done ( ) , i = 60 ) ;
return ( ret ) odocument helper . get field value ( this , i field name ) ;
byte [ ] p = new byte [ 48 ] ; p [ 0 ] = ( byte ) ( leap indicator < < 6 | version < < 3 | mode ) ;
assert equals ( new bytes ref ( t ) , leaf . terms ( field ) . iterator ( ) . next ( ) ) ;
record operation . created callback = ( orecord callback < long > ) created callback ;
return new margin layout params ( layout params . match _ parent , layout params . wrap _ content ) ;
return new batch create result < long , greeting > ( null ) ;
try { new active ping . socket . set network interface ( network interface . get by name ( get current link properties ( ) . get interface name ( ) ) ) ; } catch ( exception e ) { loge ( send dns ping : : error binding to socket + e ) ; } new active ping . packet id = ( short ) s random . next int ( ) ;
blocker . trigger ( ) ;
impl . bind ( n [ 0 ] , obj , bt ) ; } } else {
x = left - ( available width - actual width ) ;
describe link = new geo server ajax form link ( describe coverage ) { @ override protected void on click ( ajax request target target , form form ) { version . process input ( ) ; coverage . process input ( ) ; final string coverage name = wcsrequest builder panel . this . get coverage . coverage ; if ( coverage name = null ) { response window . set default model ( new model ( get describe xml ( coverage name ) ) ) ; response window . show ( target ) ; } } } ; describe link . set enabled ( false ) ; describe link . set output markup id ( true ) ;
temp order . add ( insert after + 1 , ordering ) ;
int first = has limit | | query parameters . get row selection ( ) . get first row ( ) = = null ? 0 : query parameters . get row selection ( ) . get first row ( ) ; int max = has limit | | query parameters . get row selection ( ) . get max rows ( ) = = null ? - 1 : query parameters . get row selection ( ) . get max rows ( ) ; list tmp = new array list ( ) ;
if ( values . get bool ( 8 , false ) ) { parse wrapper layout super . parse ( values ) ; } else { convert old layout throw new ioexception ( unsupported obsolete format ) ; } }
mockito . verify ( listener1 ) . receive ( mockito . any ( ) ) ;
running = job client . run job ( job ) ;
conf . set int ( raid node . raid _ parity _ initial _ repl _ key , 1 ) ; utils . load test codecs ( conf , stripe length , 1 , 3 , destraid , destraidrs ) ; conf . set boolean ( dfs . permissions , false ) ;
long [ ] closed transaction flags = meta data store . get last closed transaction ( ) ;
body shell = context . get wml object factory ( ) . create body ( ) ;
float [ ] s start angles = new float [ ] { 225 , 45 } ;
xmpperror pe error pe = get error pe ( ) ; if ( error pe = = null ) { error pe = new xmpperror pe ( error ) ; add child extension ( error pe ) ; } error pe . set error ( error ) ; }
frame handler ( ) . window update ( 3 , header _ length + 20 ) ; verify ( frame writer , timeout ( time _ out _ ms ) ) . data ( eq ( false ) , eq ( 3 ) , any ( buffer . class ) , eq ( header _ length + 20 ) ) ; stream . cancel ( status . cancelled ) ;
action config action config = module config . find action config id ( action id ) ; if ( action config = = null ) { if ( log . is debug enabled ( ) ) { log . debug ( no action id found for + action id ) ; } return null ; } string path = action config . get path ( ) ;
for ( string variable name : variable names ) { if ( transient variabes = null & & transient variabes . contains key ( variable name ) ) { requested variables . put ( variable name , transient variabes . get ( variable name ) ) ; variable names to fetch . remove ( variable name ) ; } else if ( used variables cache . contains key ( variable name ) ) { requested variables . put ( variable name , used variables cache . get ( variable name ) ) ; variable names to fetch . remove ( variable name ) ; } } if ( fetch all variables ) { get variables ( ) will go up the execution hierarchy , no need to do it here also , the cached values will already be applied too map < string , variable instance > all variables = get variable instances ( ) ; for ( string variable name : variable names to fetch ) { requested variables . put ( variable name , all variables . get ( variable name ) ) ; } return requested variables ; } else { go up if needed variable scope parent = get parent variable scope ( ) ; if ( parent = null ) { requested variables . put all ( parent . get variable instances ( variable names to fetch , fetch all variables ) ) ; } fetch variables on this scope list < variable instance entity > variables = get specific variables ( variable names to fetch ) ; for ( variable instance entity variable : variables ) { requested variables . put ( variable . get name ( ) , variable ) ; } return requested variables ; }
_ threshold integration value = 1 . 0d ; }
string range list = ; range list + = ( m _ the instances . class index ( ) + 1 ) ;
if ( stored version . compare to ( new version ( 2 . 0 . 34 ) ) < 0 ) for ( psetting setting : privacy manager . get setting list ( 0 , null ) ) if ( meta . c type template . equals ( setting . type ) ) { util . log ( null , log . warn , deleting + setting ) ; privacy manager . set setting ( setting . uid , setting . type , setting . name , null ) ; }
big integer big integer = fast big integer value unscaled ( fast signum , result0 , result1 , result2 ) ; return big integer . remainder ( big _ integer _ unsigned _ int _ max _ value ) . int value ( ) ;
f configuration = config ;
token update token = create container token ( create container id ( 1 ) , 1 , dummy _ rm _ identifier , context . get node id ( ) , user , builder utils . new resource ( 1024 , 1 ) , context . get container token secret manager ( ) , null , execution type . guaranteed ) ; list < token > update tokens = new array list < token > ( ) ; update tokens . add ( update token ) ; container update request update request = container update request . new instance ( update tokens ) ; container update response update response = container manager . update container ( update request ) ; assert . assert equals ( 1 , update response . get successfully updated containers ( ) . size ( ) ) ;
assert same ( counter , runnable ref . get ( ) ) ; runnable ref . set ( null ) ; idle main looper ( 1 , minutes ) ;
assert true ( origin . has next ( ) ) ;
for ( accumulator j : resolver input ( count , true ) ) builder . add ( j ) ;
assert that ( values ( tokens ( ' \ \ 1b \ \ 1 ' ) ) ) . is equal to ( string ( \ 1b \ 1 ) newline eof ) ;
if ( fast path data = = null ) fast path data = new fast path data ( ) ;
register action ( mapping modes , act name , cmd type , new shortcut [ ] { shortcut } , arg type ) ;
this . cluster . get node by id ( node id ) ; this . new cluster = new admin client . get admin client cluster ( ) ; if ( new cluster . get number of nodes ( ) > 1 ) { new node id = node id ; } else { new node id = new cluster . get node ids ( ) . iterator ( ) . next ( ) . int value ( ) ; }
if ( apply filter ( node , node filter . show _ processing _ instruction ) ) { return ; }
if ( cursor . move to first ( ) ) { tmp = build node from row ( cursor ) ; stack . push ( tmp ) ; }
final byte buffer [ ] bufs = buffers ; unset buffers ( ) ; if ( is clone ) return ;
safe max = - 1 ; safe min = integer . max _ value ; }
assert illegal arguments ( chown , us er , path ) ;
warnings checker box = new jcheck box ( language . text ( preferences . show _ warnings ) ) ;
init ( compression . algorithm . lzo . get name ( ) , memcmp , 2605 , 2558 ) ;
coord . receive decline message ( new decline checkpoint ( jid , attempt id1 , checkpoint id ) ) ; coord . receive decline message ( new decline checkpoint ( jid , attempt id2 , checkpoint id ) ) ; assert true ( checkpoint . is discarded ( ) ) ; coord . shutdown ( job status . finished ) ;
list < acl entry > acl spec = lists . new array list ( acl entry ( access , user , fs action . read _ execute ) , acl entry ( access , group , fs action . read _ execute ) , acl entry ( access , other , fs action . read _ execute ) , acl entry ( access , user , user name , fs action . all ) ) ;
keys . add first ( key ) ; return copy adaptation sets ; }
assert equals ( 0 , history service . create historic process instance query ( ) . variable value equals ( long var , 12345 l ) . count ( ) ) ;
for ( string managed trigger name : managed trigger names ) { if ( copy . contains key ( managed trigger name ) ) { scheduled triggers . remove ( managed trigger name ) ; } }
data set < tuple1 < long > > vertices = env . read csv file ( vertices path ) . types ( long . class ) ; data set < tuple2 < long , long > > edges = env . read csv file ( edges path ) . field delimiter ( ) . types ( long . class , long . class ) . flat map ( new connected components . undirect edge ( ) ) ;
if ( sort . get limit ( ) > 0 ) { if ( sort . get offset ( ) > 0 ) { facet results iter = iterables . skip ( facet results iter , sort . get offset ( ) ) ; } facet results iter = iterables . limit ( facet results iter , sort . get limit ( ) ) ; } else if ( sort . get limit ( ) = = 0 ) { return new linked list < facet bucket > ( ) ; } return facet results iter ;
editor antialias box = new jcheck box ( language . text ( preferences . use _ smooth _ text ) ) ;
byte [ ] buf = new byte [ buffer _ length ] ;
string type string = shell context . get parameters ( ) . get ( entity ) ;
map binder binding < ? > map binder binding = get map binder binding ( elements ) ;
if ( answer = null & & answer instanceof camel context aware ) { ( ( camel context aware ) answer ) . set camel context ( this ) ; } return answer ;
list < call > calls = entity manager . create query ( select c + from call c + where c . duration between 5 and 20 , call . class ) . get result list ( ) ; end : : hql - between - predicate - example [ ] assert equals ( 1 , calls . size ( ) ) ; } ) ; }
file child1 = temporary folder . new file ( data file1 . txt ) ; file child2 = temporary folder . new file ( another _ file . bin ) ; file luigi file = temporary folder . new file ( _ luigi ) ; file success = temporary folder . new file ( _ success ) ; create temp files ( new byte [ size ] , child1 , child2 , luigi file , success ) ;
public abstract enum com example buck a b extends java lang enum implements java lang runnable { , , access flags 0x4409 ,
len + + ; if ( out . length > 127 ) { len + + ; for ( int cur = out . length > > 8 ; cur > 0 ; len + + ) { cur = cur > > 8 ; } } len + = out . length ; return len ;
return m media provider . query ( m objects uri , id _ projection , storage _ where , new string [ ] { integer . to string ( storage id ) } , null ) ;
view view = view cache . get ( next position ) ;
string file name = memento . get string ( tag _ path ) ; if ( common utils . is empty ( file name ) ) { make sure that core is initialized dbeaver core . get instance ( ) ; ifile file = resources plugin . get workspace ( ) . get root ( ) . get file ( new path ( file name ) ) ; if ( file = null ) { return new erdeditor input ( file ) ; } } return null ;
return new uri ( value ) ;
assert names ( roles . client level ( client uuid ) . list all ( ) , client - role , client - composite ) ; assert names ( roles . client level ( client uuid ) . list available ( ) , client - role2 ) ; assert names ( roles . client level ( client uuid ) . list effective ( ) , client - role , client - composite , client - child ) ;
test file length = 0 ; }
string buffer buf = new string buffer ( ) ; field f = clazz . get field ( product ) ; buf . append ( f . get ( null ) ) ; buf . append ( ' ; ' ) ; f = clazz . get field ( language ) ;
among _ var = find _ among _ b ( a _ 3 , 62 ) ;
input = null ; }
writer . update binary doc value ( new term ( id , doc0 ) , bdv , to bytes ( 5 l ) ) ;
document . add ( lucene field ) ;
records to load + = 1 ; new adn record loader ( phone ) . load from ef ( ef _ mailbox _ cphs , ef _ ext1 , 1 , obtain message ( event _ get _ cphs _ mailbox _ done ) ) ; break ;
string append = get attribute ( append ) ;
set selected ( mute ) ;
mock configuration property source source = new mock configuration property source ( ) ; source . put ( foo . value - bean . int - value , 123 ) ; source . put ( foo . value - bean . string - value , foo ) ; this . sources . add ( source . non iterable ( ) ) ; bind result < example nested bean without setter or type > bean = this . binder . bind ( foo , bindable . of ( example nested bean without setter or type . class ) ) ; assert that ( bean . is bound ( ) ) . is false ( ) ; }
assert equals ( 6 , cycle . size ( ) ) ; collection < list < string > > edges = multimaps . as map ( cycle ) . values ( ) ; assert true ( edges . contains ( immutable list . of ( a , b ) ) ) ; assert true ( edges . contains ( immutable list . of ( b , c ) ) ) ; assert true ( edges . contains ( immutable list . of ( c , a ) ) ) ; }
int new screen id = 0 ; for ( db entry entry : items ) { if ( entry . screen id = new screen id ) { entry . screen id = new screen id ; these values does not affect the item position , but we should set them to something other than - 1 . entry . cell x = new screen id ; entry . cell y = 0 ; update ( entry ) ; } new screen id + + ; if ( feature flags . no _ all _ apps _ icon & & m idp . is all apps button rank ( new screen id ) ) { new screen id + + ; } } return apply operations ( ) ;
attribute source last tok = matched . is empty ( ) ? first tok : matched . get last ( ) ; boolean include orig = result . include orig ( ) ; attribute source orig tok = include orig ? first tok : null ;
height = height spec size ; width = ( int ) ( height * display aspect ratio ) ; } else {
generic udafevaluator evaluator = aggr desc . get generic udafevaluator ( ) ; array list < expr node desc > parameters = aggr desc . get parameters ( ) ;
assert equals ( default _ pubkeys , get current pubkey blacklist ( ) ) ;
operator expression expr3 = new operator expression ( expression type . operator _ is _ null , tve1 , null ) ;
apply transitive equivalence ( m _ where outer list , m _ where inner list , m _ where inner outer list ) ;
directory reader reader = directory reader . open ( d ) ;
protocol . get process stdin writer ( ) . begin array ( ) ;
break ; } else if ( else branch = null & & statement must exit parent ( then branch ) ) { child . remove child ( else branch ) ; n . add child after ( else branch , child ) ; compiler . report change to enclosing scope ( n ) ; } } }
if ( ignore view = null ) { cell and span c = solution . map . get ( ignore view ) ; if ( c = null ) { c . cell x = cell x ; c . cell y = cell y ; } } rect r0 = new rect ( cell x , cell y , cell x + span x , cell y + span y ) ; rect r1 = new rect ( ) ; for ( view child : solution . map . key set ( ) ) { if ( child = = ignore view ) continue ; cell and span c = solution . map . get ( child ) ; layout params lp = ( layout params ) child . get layout params ( ) ; r1 . set ( c . cell x , c . cell y , c . cell x + c . span x , c . cell y + c . span y ) ; if ( rect . intersects ( r0 , r1 ) ) { if ( lp . can reorder ) { return false ; } m intersecting views . add ( child ) ; } } solution . intersecting views = new array list < view > ( m intersecting views ) ;
n . set parent ( this ) ; n . set level ( this . level + 1 ) ; node prev = children map . put ( n . get name ( ) , n ) ; if ( prev = null ) { for ( int i = 0 ; i < children . size ( ) ; i + + ) { if ( children . get ( i ) . get name ( ) . equals ( n . get name ( ) ) ) { children . set ( i , n ) ; return false ; } } } children . add ( n ) ; num of leaves + + ; return true ;
vehicle managed vehicle = ( vehicle ) s . merge ( vehicle ) ; check new vehicle ( managed vehicle ) ; s . flush ( ) ;
assert normalize ( cos ( 1 . 0 ) , is literal ( 0 . 5403023058681398 , data types . double ) ) ; assert normalize ( cos ( cast ( 2 . 0 as float ) ) , is literal ( - 0 . 4161468365471424 , data types . double ) ) ; assert normalize ( cos ( 3 ) , is literal ( - 0 . 9899924966004454 , data types . double ) ) ; assert normalize ( cos ( cast ( 4 as integer ) ) , is literal ( - 0 . 6536436208636119 , data types . double ) ) ; assert normalize ( cos ( cast ( 5 as short ) ) , is literal ( 0 . 28366218546322625 , data types . double ) ) ;
int first null = arrays . as list ( sortable types ) . index of ( null ) ; return first null = - 1 ? arrays . copy of range ( sortable types , 0 , first null ) : sortable types ; }
int part id = master . get key ( ) ; if ( m _ removed partitions at promotion time . contains ( part id ) ) { tm log . info ( during promotion partition + master . get key ( ) + was cleaned up . skipping . ) ; continue ; } string dir = leader elector . election dir for partition ( volt zk . leaders _ initiators , part id ) ; partition callback cb = new partition callback ( part id , master . get value ( ) ) ;
for ( int i = 0 ; i < expected size ; i + + ) { out . write byte ( expected data [ i ] ) ; } assert equals ( expected size , out . size ( ) ) ; assert array equals ( expected data , bytes reference . to bytes ( out . bytes ( ) ) ) ; out . close ( ) ;
if ( fields from class . contains ( field ) ) { if ( field = = null ) { extra names from map . add ( < null field > ) ; } else { option definition option definition = null ; try {
properties props = new properties ( ) ; props . put all ( factory . get jpa vendor adapter ( ) . get jpa property map ( ) ) ; props . put all ( factory . get jpa property map ( ) ) ; resource monitoring = data . get ( monitoring ) ;
record = proxy . read from client ( ) ; assert . assert equals ( tlsrecord . type . handshake , record . get type ( ) ) ; bytes = record . get bytes ( ) ; chunk1 = new byte [ 2 * bytes . length 3 ] ; system . arraycopy ( bytes , 0 , chunk1 , 0 , chunk1 . length ) ; chunk2 = new byte [ bytes . length - chunk1 . length ] ; system . arraycopy ( bytes , chunk1 . length , chunk2 , 0 , chunk2 . length ) ; proxy . flush to server ( 100 , chunk1 ) ;
assert equals ( 1 , customers . size ( ) ) ; } ) ; }
start row = bytes . to bytes ( start key ) ;
path watcher . config base dir config = new path watcher . config ( dir ) ; base dir config . set recurse depth ( path watcher . config . unlimited _ depth ) ; base dir config . add exclude hidden ( ) ; base dir config . add include glob relative ( * * . txt ) ; path watcher . watch ( base dir config ) ; try { capture . set finish trigger ( 3 ) ; path watcher . start ( ) ; assert true ( capture . finished latch . await ( long _ time , time unit . milliseconds ) ) ; map < string , path watch event type [ ] > expected = new hash map < > ( ) ; expected . put ( a . txt , new path watch event type [ ] { added } ) ; expected . put ( b b . txt , new path watch event type [ ] { added } ) ; expected . put ( c d d . txt , new path watch event type [ ] { added } ) ; capture . assert events ( expected ) ; time unit . milliseconds . sleep ( wait _ time ) ; capture . assert events ( expected ) ; } finally { path watcher . stop ( ) ; }
if ( ( feature source instanceof collection feature source ) & & feature source . get data store ( ) instanceof wfsdata store ) { layer info . set type ( published type . remote ) ; } else { layer info . set type ( published type . vector ) ; } return layer info ;
float best = float . max _ value ; final float hit radius2 = m hit radius * m hit radius ; for ( int i = 0 ; i < m target drawables . size ( ) ; i + + ) {
answer = create jms message ( cause , session ) ; } else { object helper . not null ( camel message , message ) ;
if ( imports = null ) { ( ( node . page directive ) node ) . add import ( imports ) ; } } else if ( local name . equals ( include _ directive _ action ) ) {
job timer = management service . create timer job query ( ) . single result ( ) ; management service . move timer to executable job ( timer . get id ( ) ) ; management service . execute job ( timer . get id ( ) ) ;
union type numbers = ( union type ) create union type ( number _ type , number _ object _ type ) ; assert false ( numbers . is subtype ( number _ type ) ) ; assert false ( numbers . is subtype ( number _ object _ type ) ) ; assert false ( numbers . is subtype ( eval _ error _ type ) ) ; union type strings = ( union type ) create union type ( string _ object _ type , string _ type ) ;
log . debug ( > > > > { } { } , endpoint , exchange ) ;
socket . set so linger ( true , 0 ) ; control calls close ( ) method ,
file handler h6 = new file handler ( % t log string % u . log ) ;
dummy master dummy master = new dummy master ( zk , master ) ;
super . test group by6 ( ) ;
recorder . record api ( get method descriptor ( ) , args [ 0 ] , 0 ) ;
cp = integer . parse int ( e . substring ( 1 ) ) ; } return new string ( new int [ ] { cp } , 0 , 1 ) ; }
e = new saxparse exception ( err , null ) ;
. with function name ( search , cloud solr stream . class ) . with function name ( facet , facet stream . class ) . with function name ( update , update stream . class ) . with function name ( jdbc , jdbcstream . class ) . with function name ( topic , topic stream . class ) . with function name ( commit , commit stream . class ) . with function name ( random , random stream . class ) . with function name ( knn , knn stream . class )
request . set media renderer ( renderer configuration . get default conf ( ) ) ;
codec util . read crc ( input ) ; }
ijava element new match element = ( ijava element ) new match . get element ( ) ; ijava element primary element = new match element . get primary element ( ) ; isource range range = null ; if ( primary element . exists ( ) & & primary element instanceof isource reference ) { try { range = ( ( isource reference ) primary element ) . get source range ( ) ; } catch ( java model exception e ) { can live without source range } } return range ;
string downstream latest commit = setup external config repo ( downstream external config repo , external _ git _ config _ repo _ referencing _ first ) ;
test data . build ogg header ( 0x02 , 0 , 1000 , 0x01 ) , test util . create byte array ( 0x08 ) , laces first packet ,
activity description desc2 = dbhelper . create activity description ( user , 101 , 200 , dao session ) ; list = dbhelper . find activity decriptions ( user , 10 , 100 , dao session ) ; assert equals ( 1 , list . size ( ) ) ;
for ( int i = to inc + 1 ; i < result . length ; i + + ) { if ( i > = fuzzy key meta . length | | fuzzy key meta [ i ] = = 0 * non - fixed * ) { result [ i ] = order . min ( ) ; } } }
while ( body bytes . readable ( ) ) { string body line = read line ( body bytes , content length ) ; log . debug ( read body line [ { } ] , body line ) ; current message . add body line ( body line ) ; }
if ( resource rep . get redirect uris ( ) = null ) { set < string > origins = new hash set < string > ( ) ; for ( string redirect uri : resource rep . get redirect uris ( ) ) { logger . debugv ( add redirect - uri to origin : { 0 } , redirect uri ) ; if ( redirect uri . starts with ( http ) ) { string origin = uri utils . get origin ( redirect uri ) ; logger . debugv ( adding default client origin : { 0 } , origin ) ; origins . add ( origin ) ; } } if ( origins . size ( ) > 0 ) { client . set web origins ( origins ) ; } }
if ( found = null ) { creators . add property creator ( found , * is creator * false , found props ) ; basic bean description bbd = ( basic bean description ) bean desc ; also : add properties , to keep error messages complete wrt known properties . . . for ( settable bean property prop : found props ) { property name pn = prop . get full name ( ) ; if ( bbd . has property ( pn ) ) { bean property definition new def = simple bean property definition . construct ( ctxt . get config ( ) , prop . get member ( ) , pn ) ; bbd . add property ( new def ) ; } } }
service registry standard registry = new standard service registry builder ( ) . build ( ) ; metadata sources sources = new metadata sources ( standard registry ) ;
final orient vertex in v = oe . get vertex ( direction . in ) ; final string in field name = orient vertex . get connection field name ( direction . in , oe . get label ( ) , graph . is use vertex fields for edge labels ( ) ) ; replace links ( in v . get record ( ) , in field name , old identity , new identity ) ; } else {
workspace . replace file contents ( res meta - inf res1 . json , res1 , replaced ) ;
return 8795078f199c478165fe18db82625747 ; case digits :
int ourslot = append node ( w0 , w1 , w2 , w3 ) ;
path jar path = workspace . get path ( lib jar ) ; byte [ ] bytes = files . read all bytes ( jar path ) ; for ( int back offset = 7 ; back offset < = 10 ; back offset + + ) { bytes [ bytes . length - back offset ] = 0x77 ; } files . write ( jar path , bytes ) ; project workspace . process result result = workspace . run buck build ( : wrapper _ 01 ) . assert failure ( ) ;
if ( to start from > base _ tx _ id & & to start from < = to end at ) { monitor . start streaming transactions ( to start from , packer identifier ) ; extract transactions ( to start from , filter visitor ( visitor , to end at ) ) ; monitor . finish streaming transactions ( to end at , packer identifier ) ; } } ; return new transaction stream response < > ( response , store id . get ( ) , transactions , resource releaser . no _ op ) ; }
this . hi _ = this . max hi _ ; } else {
assert . assert equals ( 13 , args . size ( ) ) ;
if ( len < short _ write ) { int room = _ output end - _ output tail ; if ( len > room ) { _ flush buffer ( ) ; } system . arraycopy ( text , 0 , _ output buffer , _ output tail , len ) ; _ output tail + = len ; } else { otherwise , better just pass through : _ flush buffer ( ) ; _ writer . write ( text , 0 , len ) ; }
if ( hdo = = null ) hdo = true ;
if ( layer definition filter = = null ) { layer definition filter = filter . include ; } combined = ff . and ( layer definition filter , user requested filter ) ; feature type constraint [ ] feature type constraints = layer . get layer feature constraints ( ) ;
assert that ( store ( ) . get traces ( query request . builder ( ) . build ( ) ) ) . contains exactly ( as list ( span ) ) ;
bin . read ( new byte [ header size ] , 0 , header size ) ;
string builder sb = new string builder ( ) ; sb . append ( - - bundle list - - \ n ) ; for ( bundle b : bundle context . get bundles ( ) ) { sb . append ( string . format ( % 1 5s , [ + b . get bundle id ( ) + ] ) ) . append ( ) . append ( string . format ( % 1 - 70s , b . get symbolic name ( ) ) ) . append ( | ) . append ( string . format ( % 1 - 20s , b . get version ( ) ) ) . append ( | ) ; try { b . start ( ) ; sb . append ( started | ) ; } catch ( bundle exception e ) { sb . append ( * failed * | ) . append ( e . get message ( ) ) ; } sb . append ( b . get location ( ) ) . append ( \ n ) ; } sb . append ( - - \ n \ n ) ; logger . fine ( sb . to string ( ) ) ; final resource config resource config = create resource config ( ) ;
if ( dbg ) log . d ( tag , sending a dhcp renewal + this ) ;
oos . write object ( init load paths ) ;
} } else { pcap handle = null ; } }
local workspace . set ( workspace ) ; request wrapped request = callback . init ( request ) ; assert that ( wrapped request , not null value ( ) ) ; assert that ( wrapped request . get http request ( ) , not null value ( ) ) ; assert that ( wrapped request . get http request ( ) . get context path ( ) , is ( geoserver some workspace ) ) ; assert that ( wrapped request . get http request ( ) . get parameter ( layer ) , is ( some workspace : some layer ) ) ; assert that ( wrapped request . get http request ( ) . get parameter map ( ) , not null value ( ) ) ; assert that ( wrapped request . get http request ( ) . get parameter map ( ) . get ( layer ) , is ( new string [ ] { some workspace : some layer } ) ) ; assert that ( wrapped request . get http request ( ) . get parameter values ( layer ) , is ( new string [ ] { some workspace : some layer } ) ) ; }
string sink classname = conf . get ( hconstants . replication _ sink _ service _ classname , hconstants . replication _ service _ classname _ default ) ;
multiple = true ;
if ( kerberos . equals ignore case ( c . get ( http server . http _ ui _ authentication , null ) ) ) { builder . set username conf key ( http server . http _ spnego _ authentication _ principal _ key ) . set keytab conf key ( http server . http _ spnego _ authentication _ keytab _ key ) . set kerberos name rules key ( http server . http _ spnego _ authentication _ krb _ name _ key ) . set signature secret file key ( http server . http _ authentication _ signature _ secret _ file _ key ) . set security enabled ( true ) ; } this . http server = builder . build ( ) ; }
check equals and hash code ( create test query builder ( ) , this : : copy query , this : : change name or boost ) ;
protocol provider service protocol provider = gui activator . get preferred account ( ) ; if ( protocol provider = null ) dialog . set selected account ( protocol provider ) ;
integer count = value bag . get ( expected ) ;
assert true ( false ) ; } catch ( ioexception ioe ) { log . info ( great + string utils . stringify exception ( ioe ) ) ; } }
for ( client client : cluster ( ) . get clients ( ) ) { get mappings response current mapping = client . admin ( ) . indices ( ) . prepare get mappings ( index ) . add types ( type ) . set local ( true ) . get ( ) ; assert that ( previous mapping . get mappings ( ) . get ( index ) . get ( type ) . source ( ) , equal to ( current mapping . get mappings ( ) . get ( index ) . get ( type ) . source ( ) ) ) ; }
fs permission default permission = fs permission . get dir default ( ) . apply umask ( lfs . get umask ( ) ) ; final file status fs = new file status ( 0 , true , 1 , 0 , system . current time millis ( ) , 0 , default permission , , , new path ( local log dirs [ 0 ] . get absolute path ( ) ) ) ; do return ( fs ) . when ( spylfs ) . get file status ( is a ( path . class ) ) ; do return ( local log dir paths ) . when ( dirs handler ) . get log dirs for cleanup ( ) ; log handler . handle ( new log handler app started event ( app id , user , null , app acls ) ) ;
system . out . print ( transferring data from + input path + to + output path + . . . ) ; ioutils . copy ( is , os ) ; system . out . println ( done ) ;
log . e ( tag , external storage is read - only ) ;
require non null ( columns , columns is null ) ;
if ( boolean . get boolean ( numeric _ points _ sysprop ) ) system . set property ( numeric _ docvalues _ sysprop , true ) ; jsontest util . fail repeated keys = true ;
_ sax . end element ( uri , local name , qname ) ;
awscredentials credentials = null ;
assert null ( ce manies . get role ( ) ) ;
} else if ( region event desc = null ) { region events . add ( region event desc ) ; } else { edits . add ( entry ) ; } }
final list < element > results2 list = lists . new array list ( results2 ) ;
charset charset = resources . get charset ( ) ;
return sigma > 1e - 6 ;
assert constructor throws ( latitude out of range , 100 , - 91 . 0 ) ;
image = reader . read ( 1 ) ;
return http helper . read request body from servlet request ( request , http message . get exchange ( ) ) ;
assert equals ( member value ok , result . get name buf ( ) ) ;
lr . add field ( click id , new log field ( log field . type _ string , lp . get next cb ( ) ) ) ;
query = new query ( ?query = hello & ranking . profile = default ) ;
m file system . get status ( file path ) ; assert . fail ( string . format ( expected file % s being deleted but it was not . , file path ) ) ; } catch ( file does not exist exception e ) {
http method params params = method . get params ( ) ;
toolchains . add ( create x86 toolchain ( 4 . 8 , - fstack - protector , cpp configuration . tool . gcovtool ) ) ;
list < html anchor > album links = ( list < html anchor > ) page . get by xpath ( tr [ @ class = ' album ' ] a ) ;
http get get = new http get ( default server . get default server url ( ) + path inner symlink page . html ) ;
data store info data store = catalog . get data store by name ( data store - name ) ;
container request node level request2 = new container request ( capability , new string [ ] { host2 , host3 } , null , priority . new instance ( 1 ) , false ) ;
cut < c > that = ( cut < c > ) obj ; try { int compare result = compare to ( that ) ; return compare result = = 0 ; } catch ( class cast exception ignored ) { } }
full http response res = new default full http response ( http version . http _ 1 _ 1 , http response status . created ) ;
renderer configuration rc = get renderer configuration by uaahh ( header line ) ; assert equals ( expected no matching renderer to be found for header \ + header line + \ , instead renderer \ + ( rc = null ? rc . get renderer name ( ) : ) + \ was recognized . , null , rc ) ; } }
if ( value . starts with ( \ ) & & value . ends with ( \ ) ) { return string . class ; }
latch . enable ( ) ; future < void > evict = evict with future ( key1 ) ; latch . wait to block ( 30 , time unit . seconds ) ;
for ( int i = 0 ; i < 2 ; + + i ) { assert null ( get tracker client ( strategy , null , new request context ( ) , 0 , null ) ) ; } strategy = get strategy ( ) ;
return ( e ) elements [ head ] ;
list < simple entity > list = session . by multiple ids ( simple entity . class ) . enable session check ( true ) . multi load ( ids ( 56 ) ) ; assert equals ( 56 , list . size ( ) ) ;
if ( options . is extern exports enabled ( ) | | options . extern exports path = null ) { passes . add ( extern exports ) ; }
profile e = new profile ( e , basic cred a ) ;
boolean subtype ; try { final class resp class = response . get class ( ) ; final exception [ ] caugh exception = new exception [ 1 ] ; access control context stack = access controller . get context ( ) ; class c = java security access . do intersection privilege ( new privileged action < class < ? > > ( ) { @ override public class < ? > run ( ) { try { reflect util . check package access ( resp type ) ; class loader cl = resp class . get class loader ( ) ; return class . for name ( resp type , true , cl ) ; } catch ( exception e ) { caugh exception [ 0 ] = e ; } return null ; } } , stack , acc ) ; if ( caugh exception [ 0 ] = null ) { throw caugh exception [ 0 ] ; } subtype = c . is instance ( response ) ; } catch ( exception e ) { subtype = false ; if ( tracing ) { modelmbean _ logger . logp ( level . finer , required model mbean . class . get name ( ) , mth , exception : , e ) ; } } if ( subtype ) wrong type = true ;
encrypted private key info epki = new encrypted private key info ( encoded copy ) ;
double threshold chkpt pct = 50 . 0 ;
data set < tuple2 < long , double > > line items = env . read csv file ( args [ 2 ] ) . field delimiter ( | ) . line delimiter ( \ n ) . include fields ( 100001 ) . types ( long . class , double . class ) . name ( lineitem ) ; data set < tuple2 < long , integer > > filter o = orders . flat map ( new filter o ( ) ) . name ( mapper _ name ) ;
final string driver url = ( string ) args [ 0 ] ;
if ( rule factory . get generation config ( ) . is include constructors ( ) ) { add empty constructor jclass . constructor ( jmod . public ) ; } }
assert metrics ( absolute proximity : 0 . 1 proximity : 1 head : 0 tail : 0 , a a a , a ) ; assert metrics ( absolute proximity : 0 . 1 proximity : 1 head : 0 tail : 0 gap length : 0 , a a b c c , a a b c c ) ; assert metrics ( absolute proximity : 0 . 1 proximity : 1 head : 0 tail : 0 gap length : 0 , a a b c c , a b c ) ; assert metrics ( absolute proximity : 0 . 1 proximity : 1 head : 0 tail : 0 gap length : 0 , a b a b , a b a b ) ; assert metrics ( absolute proximity : 0 . 0903 proximity : 0 . 9033 head : 0 tail : 0 gap length : 1 , a b a b , a b x a b ) ;
from ( direct : marshal ) . marshal ( format ) . to ( mock : json ) ;
return false ; indent : 4 exp : 4
token manager . start threads ( ) ; token manager . stop threads ( ) ; string token str form = token manager . get delegation token ( client ugi . get short user name ( ) , client ugi . get short user name ( ) ) ; token < delegation token identifier > t = new token < delegation token identifier > ( ) ; t . decode from url string ( token str form ) ;
buf = new string builder ( ) ;
int center = canvas size 2 ; if ( has selector & & is selected ) { draw the selector stroke & apply the selector filter , if applicable outer width = selector stroke width ; center = ( canvas size - ( outer width * 2 ) ) 2 ; paint . set color filter ( selector filter ) ; canvas . draw circle ( center + outer width , center + outer width , ( ( canvas size - ( outer width * 2 ) ) 2 ) + outer width - 4 . 0f , paint selector border ) ; } else if ( has border ) { if no selector was drawn , draw a border and clear the filter instead . . . if enabled outer width = border width ; center = ( canvas size - ( outer width * 2 ) ) 2 ; paint . set color filter ( null ) ; rect f rekt = new rect f ( 0 + outer width 2 , 0 + outer width 2 , canvas size - outer width 2 , canvas size - outer width 2 ) ; canvas . draw arc ( rekt , 360 , 360 , false , paint border ) ; canvas . draw circle ( center + outer width , center + outer width , ( ( canvas size - ( outer width * 2 ) ) 2 ) + outer width - 4 . 0f , paint border ) ; } else clear the color filter if no selector nor border were drawn paint . set color filter ( null ) ;
string file format = config . get string ( key . file _ format , constant . file _ format _ text ) ; string delimiter in str = config . get string ( key . field _ delimiter ) ;
if ( sol . find ( ) ) return null ;
text = replace meta characters ( text ) ; fb . replace ( offset , length , text , attrs ) ;
if ( background color = null ) { graphics2 d buffer graphics2 d = ( graphics2 d ) buffer graphics ; buffer graphics2 d . set composite ( alpha composite . clear ) ; buffer graphics . fill rect ( 0 , 0 , buffer image . get width ( null ) , buffer image . get height ( null ) ) ; buffer graphics2 d . set composite ( alpha composite . src ) ; } else { buffer graphics . set color ( background color ) ; buffer graphics . fill rect ( 0 , 0 , buffer image . get width ( null ) , buffer image . get height ( null ) ) ; }
final get g = new get ( row name ) ;
if ( pushed back watermark . is present ( ) ) { bag state < windowed value < input t > > pushed back = non keyed state internals . state ( state namespaces . global ( ) , pushed back tag ) ; long min = long . max _ value ; for ( windowed value < input t > value : pushed back . read ( ) ) { min = math . min ( min , value . get timestamp ( ) . get millis ( ) ) ; } set pushed back watermark ( min ) ; }
scheduler app . reset allowed locality level ( prio , node type . node _ local ) ;
end _ names . add element ( s ) ;
long start time = new date ( ) . get time ( ) ; while ( uploaded file . exists ( ) & & ( new date ( ) . get time ( ) - start time ) < 120000 ) { thread . sleep ( 1000 ) ; } assert true ( uploaded file . exists ( ) ) ; cleaner . set expiration delay ( 300000 ) ; }
assert null ( get serialized value ( kv state , 3 , key serializer , namespace , int serializer . instance , value serializer ) ) ;
list < key value > kvs = generator . generate test key values ( 60 , use tags ) ;
configs . add ( new test config ( new test doc ( doesnt _ exist , new test field setting [ ] { } , new string [ ] { } ) . index ( doesn ' t _ exist ) . alias ( doesn ' t _ exist ) , new string [ ] { doesnt _ exist } , true , true , true ) . expected exception ( org . elasticsearch . index . index not found exception . class ) ) ; refresh ( ) ;
boos = new basic object output stream ( baos ) ;
rest configuration ( ) . component ( undertow ) . host ( localhost ) . port ( get port ( ) ) ; from ( direct : start ) . to ( rest : put : users { id } ) ;
uimanager . put ( class loader , get class ( ) . get class loader ( ) ) ;
r = region . get ( g , null ) ; check result ( r , c0 , c0 , t2 ) ;
if ( qb . get sub query predicate def ( ) = null ) { throw new semantic exception ( error msg . unsupported _ subquery _ expression . get msg ( sub queries in original tree . get ( 0 ) , nested sub query expressions are not supported . ) ) ; }
fs . mkdirs ( hdfs dir path ) ; }
default : mv . visit multi anew array insn ( read class ( u + 1 , c ) , b [ u + 3 ] & 0x ff ) ; u + = 4 ; break ; }
layer [ ] layers from model ; if ( model instanceof multi layer network ) layers from model = ( ( multi layer network ) model ) . get layers ( ) ; else layers from model = ( ( computation graph ) model ) . get layers ( ) ;
aggregation builder = null ;
if ( is ok ) { output collector < k3 , v3 > null collector = new output collector < k3 , v3 > ( ) { public void collect ( k3 key , v3 value ) throws ioexception { null } } ; start application ( null collector , reporter . null ) ; }
canvas . draw oval ( create right eye ball ( arc bounds , m right eye ball offset y ) , m paint ) ; canvas . restore to count ( save count ) ;
get byte array input stream ( ) . close ( ) ; }
string use naming property = system . get property ( catalina . use naming ) ; if ( ( use naming property = null ) & & ( use naming property . equals ( false ) ) ) { use naming = false ; } return use naming ; }
verify ( http downloader ) . download ( any ( uri . class ) , arg that ( new has file name ( test - 1 . 0 . jar . tmp ) ) ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( invalid replication group state ) ) return null ; invalid replication group state exception e = ( invalid replication group state exception ) super . unmarshall ( node ) ;
fsapp attempt app = scheduler . get scheduler app ( att id1 ) ;
hdfs . create snapshot ( dir , s1 ) ;
col num1 = - 1 ;
result . append ( ' x ' , ' s ' ) ;
among _ var = find _ among _ b ( a _ 4 , 43 ) ;
assert equals ( resource . new instance ( 8 * gb , 1 ) , queue . get amresource limit ( ) ) ; assert equals ( resource . new instance ( 2 * gb , 1 ) , queue . get user amresource limit ( ) ) ;
list < ? > children = get source connections ( ) ; connection edit part part to remove = null ; for ( iterator < ? > iter = children . iterator ( ) ; iter . has next ( ) ; ) { connection edit part part = ( connection edit part ) iter . next ( ) ; if ( part . get model ( ) = = old value ) { part to remove = part ; break ; } } if ( part to remove = null ) remove source connection ( part to remove ) ;
get all ( cache , as list ( 46 ) ) ;
execute ( insert into % s json ? , { \ k \ : 0 , \ setmap \ : { \ [ 0 , 1 , 2 ] \ : true , \ [ 3 , 4 , 5 ] \ : false } } ) ; assert rows ( execute ( select json k , setmap from % s ) , row ( { \ k \ : 0 , \ setmap \ : { \ [ 0 , 1 , 2 ] \ : true , \ [ 3 , 4 , 5 ] \ : false } } ) ) ;
close blocked reader channel2 ( target buf ) ;
if ( field set . query commands ( ) . is empty ( ) ) { for ( string qc : field set . query commands ( ) ) { ii b . command ( new index info config . indexinfo . command . builder ( ) . indexname ( field set . get name ( ) ) . command ( qc ) ) ; } return ; }
case start :
final count down latch start latch = new count down latch ( ( shared semaphore . number of permits . get ( ) * 2 ) + 1 ) ;
get completed snapshots request request = get completed snapshots request . new builder ( ) . build ( ) ;
synchronized ( fd lock ) { if ( close pending | | ( fd = = null ) | | fd . valid ( ) ) { return true ; } else { return false ; } }
if ( dom builder . config . is ignore whitespaces between tags ( ) ) { remove last child node if empty text ( parent node , true ) ; }
write install app ( m pebble protocol . encode app info req ( ) ) ; } else { finish install ( false ) ;
build target publishable target a = build target factory . new instance ( : a ) . with flavors ( java library . maven _ jar ) ; build target publishable target b = build target factory . new instance ( : b ) . with flavors ( java library . maven _ jar ) ; build target target c = build target factory . new instance ( : c ) ; build target target d = build target factory . new instance ( : d ) ; target node < ? , ? > transitive dep node = java library builder . create builder ( target d ) . add src ( paths . get ( d . java ) ) . build ( ) ; target node < ? , ? > dep node = java library builder . create builder ( target c ) . add src ( paths . get ( c . java ) ) . add dep ( target d ) . build ( ) ;
int expected entry id = 1 ;
instructions . add ( new insn node ( opcodes . return ) ) ; if ( this . class node . methods = = null ) { this . class node . methods = new array list < method node > ( ) ; } this . class node . methods . add ( method node ) ; }
string [ ] s = { a , b , c } ; string joined = launchable task . join ( s , - - ) ; assert . assert equals ( a - - b - - c , joined ) ; }
int type ;
unique id + + ;
pages . for each ( serialized page reference : : dereference page ) ; }
this . memstore = new mem store ( ) ;
for ( kv < ? extends unbounded source < output t , checkpoint mark t > , checkpoint mark t > restored : state for checkpoint . get ( ) ) { local split sources . add ( restored . get key ( ) ) ; local readers . add ( restored . get key ( ) . create reader ( serialized options . get ( ) , restored . get value ( ) ) ) ; }
set num examples act ( get num examples ( ) ) ;
read parameters = wcsutils . replace parameter ( read parameters , boolean . true , abstract grid format . use _ jai _ imageread ) ;
fs . unset storage policy ( foo ) ; fs . unset storage policy ( bar ) ; fs . unset storage policy ( wow ) ; try { fs . unset storage policy ( fooz ) ; } catch ( exception e ) { assert true ( e instanceof file not found exception ) ; }
return ios = null ? new encrypted peer ( peer , ios ) : peer ;
if ( vertices = = null | | index > = vertices . length ) { pgraphics . show warning ( no _ such _ vertex _ error + ( + index + ) , set texture uv ( ) ) ; return ; } vertices [ index ] [ pgraphics . u ] = u ;
return md ;
distributed log manager new dlm = create new dlm ( conf , name ) ; subscriptions store new store = new dlm . get subscriptions store ( ) ; await . result ( new store . advance commit position ( subscriber2 , commit position3 ) ) ; new store . close ( ) ; new dlm . close ( ) ; committed positions = await . result ( store . get last commit positions ( ) ) ;
jstorm unit test runner . submit topology ( trident topology . build ( ) , config , 120 , null ) ;
for ( ofreezable storage component index engine : frozen indexes ) index engine . release ( ) ; throw oexception . wrap exception ( new ostorage exception ( error on freeze of storage ' + name + ' ) , e ) ;
get media player2 ( ) . reset ( ) ;
if ( is out of range ( layout state . get current position ( ) ) ) { return ; }
assume . assume true ( fs . has metadata store ( ) ) ; string root dir = do test consistent list located status after put ; fs . mkdirs ( path ( root dir ) ) ; final int [ ] num of paths = { 0 , 1 , 5 } ;
member adder member adder = new member adder ( target class , field optimization info copier ) ; program class . fields accept ( member adder ) ;
odistributed server log . error ( this , node name , null , direction . none , cannot re - balance the cluster for database ' % s ' because the lock manager is not available ( err = % s ) , database name , e . get message ( ) ) ;
this . cycle start tick = now ;
try { print writer new print writer = ( value ) ? new print writer ( system . out ) : null ; driver manager . set log writer ( new print writer ) ; } catch ( exception e ) { }
byte [ ] content = c . do final ( this . encrypted content ) ;
em . get transaction ( ) . begin ( ) ; ing1 = em . find ( list uni entity . class , ing1 . get id ( ) ) ; ed2 = em . find ( str test entity . class , ed2 . get id ( ) ) ; ed1 = em . find ( str test entity . class , ed1 . get id ( ) ) ; ing1 . get references ( ) . add ( ed2 ) ; em . get transaction ( ) . commit ( ) ;
if ( new java file visitor . is interface ( ) ) { type declaration . set interface ( true ) ; } else { type declaration . set interface ( false ) ; }
assert equals ( 1 , terms enum . total term freq ( ) ) ; postings enum dp enum = terms enum . postings ( null , postings enum . all ) ; assert true ( dp enum . next doc ( ) = doc id set iterator . no _ more _ docs ) ; dp enum . next position ( ) ; assert equals ( 8 , dp enum . start offset ( ) ) ; assert equals ( 8 , dp enum . end offset ( ) ) ; assert equals ( doc id set iterator . no _ more _ docs , dp enum . next doc ( ) ) ;
for ( process factory pf : factories ) { pf = apply filters ( pf ) ; if ( pf = null ) { result . add ( pf ) ; } } return result ; }
oos . flush ( ) ; byte array input stream bin = new byte array input stream ( baos . to byte array ( ) ) ; object input stream ois = new object input stream ( bin ) ; l = new executable list < sorted executable list test . an executable > ( ) ; l . read external ( ois ) ; assert . assert equals ( 4 , l . size ( ) ) ;
string text ;
session factory remote factory = second node environment ( ) . get session factory ( ) ; account dao dao0 = new account dao ( use jta , local factory ) ; account dao dao1 = new account dao ( use jta , remote factory ) ; integer id = new integer ( 1 ) ; dao0 . create account ( dao0 . get smith ( ) , id , new integer ( 5 ) , dual node test . local ) ;
mark push back len = push back len ;
m group = pm . create group ( ) ;
transaction manager . begin ( ) ; try { t result = callable . call ( ) ;
assert equals ( 3 , history service . create historic detail query ( ) . variable updates ( ) . process instance id ( process instance . get id ( ) ) . count ( ) ) ;
frame layout . layout params params = new frame layout . layout params ( view group . layout params . match _ parent , view group . layout params . wrap _ content ) ;
assert that ( get mapper ( a : gen ) . get ( tools , build type . label _ list ) ) . contains exactly ( label . parse absolute ( a : bdep ) ) ;
context . set temp directory ( tmp dir ) ; return ;
content response response1 = client . get ( http : localhost : + port1 + context path + servlet mapping + ?action = init ) ;
else { results = new results impl ( ctx . configuration ( ) ) ; consume result sets ( ctx , listener , results , intern , e ) ; } return result = null ? result . size ( ) : 0 ; }
htd . set value ( coprocessor 1 , jar file on hdfs1 . to string ( ) + | + cp name1 + | + coprocessor . priority _ user ) ;
for ( int j = range end ; j > = range start ; j - - ) { the list . remove ( j ) ; }
start x + = ratio * ( dip4 + dip3 2 ) ;
int boostrap method count = read unsigned short ( u + 8 ) ;
send _ bits ( ( stored _ block < < 1 ) + ( eof? 1 : 0 ) , 3 ) ; send block type copy _ block ( buf , stored _ len , true ) ; with header }
exchange helper . set failure handled ( exchange ) ;
jstype expression non null site object = new jstype expression ( js doc info parser . parse type string ( itemplate array ) , < es6 template literals . java > ) ;
menu item restore item = new menu item ( tools . get label ( messages . get string ( gui menu show main window ) ) ) ; restore item . add action listener ( rmb listener ) ; popup . add ( restore item ) ;
realm . delete realm ( new realm configuration . builder ( context ) . build ( ) ) ; try { new realm configuration . builder ( context ) . asset file ( asset _ file . realm ) . in memory ( ) . build ( ) ; fail ( ) ; } catch ( realm exception ignored ) { }
engine grant . set grantee ( sacl . grantee _ allusers ) ;
client rmproxy service = create client rmproxy service ( ) ;
. set hint ( javax . persistence . query . timeout , 2000 )
assert same ( r3 , r4 ) ; assert equals ( base ref count , r4 . get ref count ( ) ) ; sr3 . close ( ) ; assert equals ( base ref count , r4 . get ref count ( ) ) ; sr4 . close ( ) ; assert equals ( base ref count - 1 , r4 . get ref count ( ) ) ; solr query request sr5 = req ( q , foo ) ;
assert equals ( inherited properties , super class . to string ( ) ) ; }
set visibility ( gone ) ; } else {
if ( fail _ reason = null ) out . write utf ( fail _ reason ) ; }
rval = domain . equals ( network utils . numeric to inet address ( domain ) . get host address ( ) ) ;
if ( state . has tx state with changes ( ) ) { if ( check index state ( descriptor , state . tx state ( ) . index diff sets by label ( descriptor . schema ( ) . get label id ( ) ) ) ) { return population progress . none ; } } return store layer . index get population progress ( descriptor . schema ( ) ) ;
vector3 control point = vector3 . subtract and create ( m points . get ( 1 ) , m points . get ( 0 ) ) ; double old distance = m points . get ( 1 ) . distance to ( m points . get ( 2 ) ) ; double new distance = new points . get ( 1 ) . distance to ( new points . get ( 2 ) ) ; control point . multiply ( new distance old distance ) ; new points . set ( 0 , vector3 . subtract and create ( m points . get ( 1 ) , control point ) ) ;
return new constant exchange attribute ( - ) ; } else if ( c . equals ( token ) ) {
if ( pk = = null ) { return ; }
system . out . println ( pattern : + m _ pattern . to string ( ) ) ;
student double primitive student = new student double primitive ( ) ; student . set age ( ( short ) get random value ( short . class ) ) ; student . set id ( ( double ) get random value ( double . class ) ) ; student . set name ( ( string ) get random value ( string . class ) ) ; em . persist ( student ) ; em . close ( ) ; }
if ( bundle properties . get jvmversion ( ) = null ) { write key string pair ( jvmversion , bundle properties . get jvmversion ( ) , java dict ) ; }
system . out . println ( \ n k - shingling ) ; s1 = my string , \ n my song ; s2 = another string , from a song ; cosine cosine = new cosine ( 4 ) ; system . out . println ( cosine . get profile ( s1 ) ) ; system . out . println ( cosine . get profile ( s2 ) ) ; cosine = new cosine ( 2 ) ;
bis = new _ byte array input stream ( buf ) ;
test run on populated list ( ) ;
if ( tabbed pane . get selected index ( ) < tabbed pane . get component count ( ) - 1 ) { int index = tabbed pane . get selected index ( ) ;
java type interface type = new java type ( repository package . get fully qualified package name ( ) . concat ( . ) . concat ( repository type . get simple type name ( ) ) . concat ( custom ) , repository type . get module ( ) ) ;
store . close ( ) ;
if ( uniques . size ( ) = = 1 ) { return uniques . iterator ( ) . next ( ) ; } boolean query result = new boolean query ( true ) ; for ( final query query : uniques ) result . add ( query , boolean clause . occur . should ) ; return result ;
assert true ( zktable read only . is enabled table ( zkw , table name ) ) ; }
assert . assert true ( string comparators . alphanumeric . compare ( 1 . 3 , 1 . 5 ) < 0 ) ;
message . set body ( < ?xml version = \ 1 . 0 \ ? > < hi > hello world < hi > ) ; message . set header ( foo , 123 ) ; string out = message helper . dump as xml ( message ) ;
boolean is vc = f standalone & & ( f seen external dtd | | f seen external pe ) ; scan attribute value ( default val , non normalized default val , at name , f attributes , 0 , is vc , el name , false ) ; }
int lline = editor . offset to logical position ( start ) . line ;
if ( item configuration . get item command ( ) . equals ( maconline ) ) { data in value = data in value . replace all ( - , : ) ; }
xbf . get bean ( resource2 , resource test bean . class ) ;
database parent dir . delete ( ) ;
string input separator = sep = = null ? \ t : sep ; string input = ignore1 \ n + ignore2 \ n + ignore3 \ n + col1 + input separator + col2 + input separator + col3 \ n + sub1 + input separator + sub2 + input separator + sub3 \ n + skip1 \ n + data1 + input separator + data2 + input separator + data3 ; try { prepare options ( sep , - 1 , 1 , 3 , 2 , false , false ) ; parse one file ( sut , new string reader ( input ) ) ; } catch ( exception e ) { assert . fail ( exception during file parse , e ) ; } assert . assert equals ( project . column model . columns . size ( ) , 3 ) ;
orig pde file . delete ( ) ;
for ( rebalance task info partition plan : plans ) { get server ( partition plan . get stealer id ( ) ) . get metadata store ( ) . put ( metadata store . server _ state _ key , metadata store . voldemort state . rebalancing _ master _ server ) ; get server ( partition plan . get stealer id ( ) ) . get metadata store ( ) . put ( metadata store . rebalancing _ steal _ info , new rebalancer state ( lists . new array list ( rebalance task info . create ( partition plan . to json string ( ) ) ) ) ) ; }
if ( available < = 0 ) { available = 1 ; } if ( available > in buf . length ) { available = super . read ( in buf , 0 , in buf . length ) ; } else { available = super . read ( in buf , 0 , available ) ; }
mocked scheduler . add nodes to worker list ( arrays . as list ( donor id ) ) ;
delete no error checking delete = new delete no error checking ( ) ; verify exception ( solr client , delete , name ) ;
test dirs . add ( path ( root dir + dir - + index + default _ delay _ key _ substring ) ) ;
under lying uri = decode har uri ( name , conf ) ;
if ( non continuous layout divider = = null ) { set non continuous layout divider ( create default non continuous layout divider ( ) , true ) ; } else { set non continuous layout divider ( non continuous layout divider , true ) ; }
final path hbase s2 dir = snapshot test helper . create snapshot ( fs , hbase snap root dir , hbase snap2 name ) ; final path hbase s2 path = new path ( hbase s2 dir , hbase file name ) ; final file checksum hbase file cksum s2 = fs . get file checksum ( hbase s2 path ) ;
reset audio processors ( ) ;
assert verify fail ( new routing spec ( ) . add table ( new routing table spec ( mytable ) . add route ( new route spec ( foo ) . add hop ( bar baz cox ) ) ) , new application spec ( ) , arrays . as list ( for hop 1 in route ' foo ' in routing table ' mytable ' ; failed to completely parse ' bar baz cox ' . ) ) ;
sql type descriptor sql type descriptor = new integer type descriptor ( ) { @ override public boolean can be remapped ( ) { return false ; } } ;
string [ ] all rsrc paths array = all rsrc paths . split ( \ \ s + ) ; assert . assert equals ( new hash set < > ( arrays . as list ( all rsrc paths array ) ) . size ( ) , all rsrc paths array . length ) ; string all rsrc2 paths = get url ( http : localhost : + get port ( ) + test context get resource paths . jsp?path = rsrc2 ) . to string ( ) ;
assert true ( s . create query ( select new org . hibernate . test . legacy . s ( s . count , s . address ) from simple s ) . list ( ) . size ( ) = = 1 ) ;
prev state = admin . set normalizer on ( initial state ) . get ( ) ;
assert . assert equals ( searching for pattern : ' + pattern + ' in log file ( ' + log file path . to string ( ) + ' ) , expected , has found ) ;
try { key store . builder . new instance ( key store . get default type ( ) , null , fl , my pp ) ; fail ( illegal argument exception must be + thrown for incorrect protection parameter ) ; } catch ( illegal argument exception e ) { }
registry . terminate ( session , session termination reason . client _ stopped _ session ) ;
get menu inflater ( ) . inflate ( r . menu . detail , menu ) ; return true ; }
app attempt removed scheduler event app removed event1 = new app attempt removed scheduler event ( application . get application attempt id ( ) , rmapp attempt state . finished , false ) ; resource manager . get resource scheduler ( ) . handle ( app removed event1 ) ; check resource usage ( nm1 , nm2 ) ;
services . set need refresh ( ) ; }
user dc0 . set first name ( brad ) ;
assert . assert equals ( num _ results , l . size ( ) ) ;
reader reader = resources . get resource as reader ( org apache ibatis submitted ancestor _ ref mybatis - config . xml ) ; sql session factory = new sql session factory builder ( ) . build ( reader ) ; reader . close ( ) ;
filter source . set contact source index ( this . mcl source . get index ( ) + 1 ) ; } }
if ( i < target tokens . length ) { upper case part = target tokens [ i ] ; i + + ; }
hash map < string , project > projects = new hash map < > ( ) ; projects . put ( foo , foo ) ; projects . put ( bar , bar ) ; runtime environment env = runtime environment . get instance ( ) ; env . set projects ( projects ) ; list < string > descs = env . get project names ( ) ;
assert equals ( 1 , payments . size ( ) ) ; } ) ; }
jaxrsclient jaxrs client = new jaxrsclient ( ) ; book store book store = jaxrs client . get book store ( ) ; book store . add book ( new book ( camel user guide , 124 l ) ) ;
query = new query ( http request . create test request ( ?model . default index = title & model . language = de , method . get ) , profile . compile ( null ) ) ; assert equals ( default , query . get model ( ) . get default index ( ) ) ; assert equals ( de , query . get model ( ) . get language ( ) . language code ( ) ) ; }
transaction . set pass to listener ( ) ;
headers . set value ( server ) . set string ( server ) ;
int [ ] recents = new int [ cache width ] ; system . out . println ( write test : ) ;
rect . paint ( canvas . get offline image ( ) , canvas . get offline graphics ( ) ) ;
dequeue key events ( - 1 , new focus owner ) ;
assert equals ( cos . get byte count ( ) , content _ length _ value ) ;
if ( new items size > 0 ) { log . v ( on load more performing adding % s new items on page = % s , new items size , get endless current page ( ) ) ; int position = m top endless ? m scrollable headers . size ( ) : get global position of ( m progress item ) ; add items ( position , new items ) ; }
assert ( type start = = - 1 | | type end = - 1 ) ;
byte [ ] send buffer = new byte [ 100 ] ;
if ( methods = = null ) methods = new hashtable ( ) ; object m = methods . get ( name ) ;
set < string > set = key . is static member ( ) ? static setters : setters ;
pms conf . set renderer force ip ( playstation 3 @ 192 . 168 . 1 . 1 ) ;
if ( hadoop config file . exists ( ) ) { hadoop config file . delete ( ) ; }
for ( tuple row : query ( ) . from ( survey ) . select ( new qid name ( survey . id , survey . name ) , survey . id , survey . name ) . fetch ( ) ) { assert equals ( 3 , row . size ( ) ) ; assert equals ( id name . class , row . get ( 0 , object . class ) . get class ( ) ) ; assert equals ( integer . class , row . get ( 1 , object . class ) . get class ( ) ) ; assert equals ( string . class , row . get ( 2 , object . class ) . get class ( ) ) ; } }
service name jacc service name = get jacc service name ( deployment unit ) ; final service target service target = phase context . get service target ( ) ; service builder < ? > builder = service target . add service ( jacc service name , service ) ; if ( parent du = null ) {
for ( string table name : indexes . key set ( ) ) { db upgrade utils . drop keys if exist ( conn , table name , indexes . get ( table name ) , false ) ; }
return roo java type . roo _ thymeleaf _ main _ controller ; }
if ( n = = 8 ) { int x = buffer ; fill buffer ( ) ; return ( char ) ( x & 0xff ) ; }
mockito . when ( table . get sd ( ) ) . then return ( sd ) ;
for ( int i = 0 ; i < total messages ; i + + ) { string message = message predicate + i ; producer . send ( message . get bytes ( ) ) ; log . info ( producer produced + message ) ; }
long storage type consumed = fnode . as directory ( ) . get directory with quota feature ( ) . get space consumed ( ) . get type spaces ( ) . get ( storage type ) ;
list < group tree entry > final result = new linked list < > ( ) ;
path my file = new path ( test mkdirs my file ) ;
for ( detail level event listener listener : detail level event listeners ) { listener . on detail level changed ( ) ; }
versioned < byte [ ] > v6 conflict early = new versioned < byte [ ] > ( value2 , vc2 ) ;
big decimal bd ; big integer bi = new big integer ( 12345678901234567890123456789012345 ) ; big integer nbi = new big integer ( - 12345678901234567890123456789012345 ) ; mc = new math context ( 31 , rounding mode . up ) ; bd = new big decimal ( bi , - 10 , mc ) ; assert equals ( incorrect value , 1 . 234567890123456789012345678902 e + 44 , bd . to string ( ) ) ;
clazz = ( ( ometadata internal ) database . get metadata ( ) ) . get immutable schema snapshot ( ) . get class ( word ) ;
boolean changed = ( scale = s ) ;
final list < script chunk > chunks = tx in . get connected output ( ) . get script pub key ( ) . get chunks ( ) ; if ( chunks . is empty ( ) & & chunks . get ( 0 ) . data = null & & chunks . get ( 0 ) . data . length > 0 ) { try {
lab2 : do { v _ 2 = limit - cursor ; lab3 : do {
assert equals ( file2 , rr . get current value ( ) . to string ( ) ) ;
new scale - = i ; if ( i < last pow ) {
assert true ( arrays . equals ( x , x ) ) ; assert true ( arrays . equals ( y , y ) ) ; assert true ( arrays . equals ( x , y ) ) ; assert true ( arrays . equals ( y , x ) ) ;
iterator = map all plugin . values ( ) . iterator ( ) ; while ( iterator . has next ( ) ) {
if ( null = store ) { store . close ( ) ; }
for ( ; tlc index < f components . length ; tlc index + + ) { text line component tlc = f components [ tlc index ] ; int num chars in ga = tlc . get num characters ( ) ; int line break = tlc . get line break index ( start pos - tlc start , width ) ; if ( line break = = num chars in ga & & tlc index < f components . length ) { width - = tlc . get advance between ( start pos - tlc start , line break ) ; tlc start + = num chars in ga ; start pos = tlc start ; } else { return tlc start + line break ; } } if ( f component limit < f chars . length ) { format more text and try again if ( have layout window ) { out of window + + ; } generate components ( pos , f chars . length ) ; return calc line break ( pos , max advance ) ; }
status transition . transition ( data , topologyid , false , status type . startup ) ;
output stream . flush ( ) ;
system . run finalization ( ) ; }
sdf . set time zone ( america _ los _ angeles ) ;
level = get lvl from heading style ( s . get name ( ) . get val ( ) ) ;
val1 . set values ( def , ghi , jkl ) ;
result = route utils . route ( hello . hello service , 1 . 2 . 3 . 4 , dubbo = 2 . 0 . 0 & version = 3 . 0 . 0 & revision = 3 . 0 . 0 & methods = get port , say & application = kylin , service urls , routes , clusters , null ) ; assert equals ( service urls , result ) ;
if ( action . get type ( ) = = action type . rename ) { if ( actions . contains key ( action . get new name ( ) ) & & actions . get ( action . get new name ( ) ) . get type ( ) = = action type . skip ) { action = new entry action ( action type . skip , action ) ; } if ( entries . contains key ( action . get new name ( ) ) ) { action = new entry action ( action type . skip , action ) ; } } return action ;
manifest manifest = manifest classpath ( with relative . jar ) ;
if ( value instanceof byte | | value instanceof short | | value instanceof integer | | value instanceof long ) { return value ( value . long value ( ) ) ; }
verify dr table signature ( false , create table a ( c1 integer not null , c2 timestamp not null ) ; partition table a on column c1 ; \ n + create table b ( c1 bigint not null , c2 float not null ) ; partition table b on column c1 ; \ n + create table c ( c1 tinyint not null , c2 varchar ( 3 ) not null ) ; partition table c on column c1 ; \ n + dr table a ; dr table b ; dr table c ; \ n , create table c ( c1 tinyint not null , c2 varchar ( 3 ) not null ) ; partition table c on column c1 ; \ n + create table a ( c1 integer not null , c2 timestamp not null ) ; partition table a on column c1 ; \ n + create table b ( c1 bigint not null , c2 smallint not null ) ; partition table b on column c1 ; \ n + dr table a ; dr table b ; dr table c ; \ n ) ;
str = clean ( str ) ; if ( str . length ( ) = = 0 ) { return str ; }
reg = geom . vert leq ( e lo . sym . org , e up . sym . org ) ? reg up : reg lo ; if ( reg up . inside | | reg . fix upper edge ) { if ( reg = = reg up ) { e new = mesh . _ _ gl _ mesh connect ( v event . an edge . sym , e up . lnext ) ; if ( e new = = null ) throw new runtime exception ( ) ; } else { gluhalf edge temp half edge = mesh . _ _ gl _ mesh connect ( e lo . sym . onext . sym , v event . an edge ) ; if ( temp half edge = = null ) throw new runtime exception ( ) ; e new = temp half edge . sym ; } if ( reg . fix upper edge ) { if ( fix upper edge ( reg , e new ) ) throw new runtime exception ( ) ; } else { compute winding ( tess , add region below ( tess , reg up , e new ) ) ; } sweep event ( tess , v event ) ; } else { * the new vertex is in a region which does not belong to the polygon . * we don ' ' t need to connect this vertex to the rest of the mesh . * add right edges ( tess , reg up , v event . an edge , v event . an edge , null , true ) ; }
if ( ( metadata schema list = null ) & & metadata schema list . is empty ( ) ) { for ( register response metadata entry e : metadata schema list ) { schema id id = new schema id ( e . get crc32 ( ) ) ; if ( _ metadata schemas set . add ( schema registry service . default _ metadata _ schema _ source , e . get version ( ) , id , e . get schema ( ) ) ) { log . info ( added metadata schema version + e . get version ( ) + , schema id = 0x + id ) ; } else { if ( is debug enabled ) { string msg = metadata schema version + e . get version ( ) + , schema id = 0x + id + already exists ; dbus log accumulator . add log ( msg , log ) ; } } } } else { if ( is debug enabled ) { string msg = metadata schema is empty ; dbus log accumulator . add log ( msg , log ) ; } } _ event decoder = new dbus event avro decoder ( _ schema set , _ metadata schemas set ) ;
assert equals ( network . get layer ( 0 ) . get param ( w ) , network2 . get layer ( 0 ) . get param ( w ) ) ;
result = route utils . route ( hello . hello service , 1 . 2 . 3 . 4 , dubbo = 2 . 0 . 0 & version = 3 . 0 . 0 & revision = 3 . 0 . 0 & methods = get port , say , ghost method & application = kylin , service urls , routes , clusters , null ) ;
header content encoding = entity . get content encoding ( ) ;
for ( int i = 1 ; i < bfields . size ( ) ; i + + ) { byte [ ] bfield = bfields . get ( i ) ; bfield [ 3 ] = inc package id ( ) ; buf = sc . write to buffer ( bfield , buf ) ; }
long last created mod time = long . min _ value ;
query query = new query ( ) ; result result = new result ( query ) ; result . hits ( ) . add ( create hits ( source1 , 3 ) ) ; result . hits ( ) . add ( create hits ( source3 , 12 ) ) ; new organizer ( ) . organize ( page , new deterministic resolver ( ) . resolve ( page , query , result ) , result ) ;
super . set image icon ( image icon . get image ( ) ) ; this . is default image = false ; this . current image = image icon . get image ( ) ;
b . next = l . successors . next . next ; l . successors . next . next = b ; }
& & ( position + tok length = = buf length | | is identifier part fast ( buffer . char at ( position + tok length ) ) ) ) return true ; else return false ; }
graph . cancel ( ) ;
assert next report ( in order , lb request observer , load report interval millis , client stats . new builder ( ) . set num calls started ( 2 ) . set num calls finished ( 1 ) pick2 . add calls finished with drop ( client stats per token . new builder ( ) . set load balance token ( token0001 ) . set num calls ( 1 ) pick2 . build ( ) ) . build ( ) ) ; pick result pick3 = picker . pick subchannel ( args ) ;
print ( t , visit , ? , : , null ) ;
cluster specific configuration . set ( conf vars . llap _ daemon _ service _ hosts . varname , @ + cluster name trimmed ) ; cluster specific configuration . set ( conf vars . hive _ zookeeper _ quorum . varname , localhost ) ; cluster specific configuration . set int ( conf vars . hive _ zookeeper _ client _ port . varname , mini zoo keeper cluster . get client port ( ) ) ; log . info ( initializing { } llap instances for mini llap cluster with name = { } , num instances , cluster name trimmed ) ;
wms . set max request memory ( ( integer ) props . get ( max request memory ) ) ;
m recycler view . add item decoration ( new flexible item decoration ( get activity ( ) ) . with default divider ( ) ) ;
constructor < map template > capacity constructor = template class . get constructor ( int . class ) ; map template map = capacity constructor . new instance ( input . size ( ) ) ; assert equals ( map , collections . empty map ( ) ) ; map . put all ( input ) ; assert equals ( input , map ) ; map . clear ( ) ; assert equals ( size , input . size ( ) ) ;
final int n selectors = send mtfvalues1 ( n groups , alpha size ) ;
deliver result ( m apps ) ; }
assert . assert true ( passivation interceptor . get post activate target ( ) = = null ) ;
int lower = found index ;
if ( constructor keys . remove ( key ) ) { return false ; }
@ suppress warnings ( unchecked ) ordering < e > natural order = ( ordering ) ordering . < comparable > natural ( ) ; return copy of internal ( natural order , elements ) ;
int index = pair . first ;
paint focus ( g , b , view rect , text rect , icon rect ) ;
assert equals ( 1 , aoig . get column types ( ) . size ( ) ) ; type info type info = aoig . get column types ( ) . get ( 0 ) ; assert true ( type info instanceof primitive type info ) ; primitive type info pti = ( primitive type info ) type info ;
if ( null = = m best reading | | location . get accuracy ( ) < m best reading . get accuracy ( ) ) {
if ( object utils . equals ( prop1 . get ( key ) , prop2 . get ( key ) ) ) { return false ; }
rotation = ratio * ( check _ bottom _ angle + arrow _ top _ line _ angle ) ;
final int failure pos min = ( int ) ( 0 . 6 * num _ strings parallelism ) ; final int failure pos max = ( int ) ( 0 . 8 * num _ strings parallelism ) ; final int failure pos = ( new random ( ) . next int ( failure pos max - failure pos min ) + failure pos min ) ; final data stream < integer > stream1 = env . add source ( new int generating source function ( num _ strings 2 , num _ strings 4 ) ) ;
return find all classes in package ( base package name , class filter . of ( class name filter , class tester ) ) ;
system . out . println ( test labels nout mismatch rnn output layer ( ) : + e . get message ( ) ) ;
intent = new intent ( ) . put extra ( whatever , 77 ) ;
list < string > paths = new array list < string > ( ) ; for ( int i = 0 ; i < 10000 ; i + + ) { string path = zk1 . create ( path base + ch - , null , ids . open _ acl _ unsafe , create mode . persistent _ sequential ) ; paths . add ( path ) ; } my watcher child watcher = new my watcher ( ) ;
long gen = segment infos . get last commit generation ( dir ) ;
shard routing state new state ; do { new state = random from ( shard routing state . values ( ) ) ; } while ( new state = = other routing . state ( ) ) ; unassigned info unassigned info = other routing . unassigned info ( ) ;
id = buffer . read byte ( ) & 0x ff | ( buffer . read byte ( ) & 0x ff ) < < 8 | ( buffer . read byte ( ) & 0x ff ) < < 16 ;
version code = parts . get ( 1 ) . split ( , 2 ) [ 0 ] ;
if ( m _ tracer = null ) super . fire char event ( chars , start , length ) ; return ;
this . lexer . spor ht ( ) ;
spans = get paragraph spans ( sp , start , end , line background span . class ) ;
svn material svn = u . wf ( new svn material ( url , username , password , false ) , folder1 ) ; u . checkin in order ( svn , s1 , s2 ) ; git material git = u . wf ( new git material ( git ) , folder2 ) ; u . checkin file ( git , g1 , new file ( some _ file . txt ) , modified action . modified ) ; u . checkin file ( git , g2 , new file ( some _ new _ file . txt ) , modified action . modified ) ; schedule test util . added pipeline p1 = u . save config with ( p1 , u . m ( svn ) ) ; schedule test util . added pipeline p2 = u . save config with ( p2 , u . m ( p1 ) , u . m ( svn ) , u . m ( git ) ) ; string p1 _ 1 = u . run and pass ( p1 , s1 ) ; string p2 _ 1 = u . run and pass ( p2 , p1 _ 1 , s1 , g1 ) ; string p2 _ 2 = u . run and pass ( p2 , p1 _ 1 , s1 , g2 ) ;
m _ weighting atts values = new double [ m _ atts to weight on . length ] ; m _ vals = new double [ m _ training data . num attributes ( ) ] ; m _ pred inst = new dense instance ( 1 . 0 , m _ vals ) ; m _ pred inst . set dataset ( m _ training data ) ; system . err . println ( executing row number + m _ row number ) ;
block placement status with upgrade domain bps = new block placement status with upgrade domain ( bpsd , upgrade domains , 4 , 3 ) ;
set < string > received sites = new hash set < string > ( ) ;
assert equals ( master count , m actual count ) ;
disruptor . after ( handler2 ) ;
for ( uri uri : name dirs ) { directory layout looks like : test data dfs name n current { fsimage , edits , . . . } file name dir = new file ( uri . get path ( ) ) ; file dfs dir = name dir . get parent file ( ) ; assert equals ( dfs dir . get name ( ) , dfs ) ; make sure we got right dir set the md5 file to all zeros file image file = new file ( name dir , storage . storage _ dir _ current + + nnstorage . get image file name ( 0 ) ) ; md5 file utils . save md5 file ( image file , new md5 hash ( new byte [ 16 ] ) ) ; only need to corrupt one if corrupt all if ( corrupt all ) { break ; } }
assert that ( first db state . move to first ( ) ) . is true ( ) ; test item test item = test item . from cursor ( first db state ) ;
if ( r _ r1 ( ) ) { return false ; } switch ( among _ var ) { case 0 : return false ; case 1 :
assert xpath evaluates to ( lithostratigraphic . unit . 1679161021439938381 , gsml : mapped feature [ @ gml : id = ' + id + ' ] gsml : specification gsml : geologic unit @ gml : id , doc ) ;
string [ ] song ids array = new string [ m song dbids . size ( ) ] ; m song dbids . to array ( song ids array ) ;
overloaded methods = new obj array ( ) ;
file status [ ] family status = fs . list status ( new path ( family , mapfiles ) ) ; if ( family status . length > 1 ) { log . debug ( family . to string ( ) + has + family status . length + files . ) ; return false ; } } } }
adjust toolbar ( scroll state ) ;
buff . append ( html _ newline ) ; break ; default : buff . append ( ( char ) c ) ; break ; } }
if ( hcat auth util . is authorization enabled ( context . get conf ( ) ) ) { authorize ( table , privilege . create ) ; }
global zk ( ) . set data ( path ( policies , property , cluster , namespace ) , json mapper ( ) . write value as bytes ( policies node . get key ( ) ) , policies node . get value ( ) . get version ( ) ) ; policies cache ( ) . invalidate ( path ( policies , property , cluster , namespace ) ) ; log . info ( [ { } ] successfully updated the message ttl on namespace { } { } { } , client app id ( ) , property , cluster , namespace ) ; } catch ( keeper exception . no node exception e ) {
string body = get response body ( conn ) ;
uid = shexec1 . get output ( ) . replace all ( \ n , ) ; } catch ( exception e ) {
hook = new angel app master shutdown hook ( app master ) ; shutdown hook manager . get ( ) . add shutdown hook ( hook , shutdown _ hook _ priority ) ; app master ugi . do as ( new privileged exception action < object > ( ) { @ override public object run ( ) throws exception { app master . init and start ( ) ; return null ; } } ) ;
under test . advance processing time ( new instant ( 30 ) ) ; assert that ( under test . remove next processing timer ( ) , equal to ( processing time2 ) ) ; assert that ( under test . remove next processing timer ( ) , null value ( ) ) ; }
_ header less body data = a body without headers . get bytes ( ) ;
entry event data event = ( entry event data ) dispatcher event ; entry event type type = entry event type . get by type ( event . get event type ( ) ) ; string map name = event . get map name ( ) ; occurrence map . add ( format ( imap ' % s ' % s , map name , type ) , 1 ) ; return 1 ;
if ( namenode = null ) { rpc . stop proxy ( namenode ) ; } namenode = null ;
out = new object output stream ( output stream ) ;
resource manager resource manager = new mock rm ( ) ; ( ( async dispatcher ) resource manager . get rmcontext ( ) . get dispatcher ( ) ) . start ( ) ; resource manager . get rmcontext ( ) . get state store ( ) . start ( ) ; resource manager . get rmcontext ( ) . get container token secret manager ( ) . roll master key ( ) ; final rmcritical thread uncaught exception handler ex handler = new rmcritical thread uncaught exception handler ( resource manager . get rmcontext ( ) ) ; final rmcritical thread uncaught exception handler spy rtehandler = spy ( ex handler ) ;
int res = tool runner . run ( conf , client , argv ) ; assert equals ( client exited with nonzero status , 0 , res ) ; client . check monitor ( ) ; }
boolean is attribute = node . get node type ( ) = = node . attribute _ node ;
bind all composite attributes ( source document , embeddable source , component binding ) ; if ( embeddable source . get parent reference attribute name ( ) = null ) { component binding . set parent property ( embeddable source . get parent reference attribute name ( ) ) ; } if ( embeddable source . is unique ( ) ) { final array list < column > cols = new array list < column > ( ) ; final iterator itr = component binding . get column iterator ( ) ; while ( itr . has next ( ) ) { final object selectable = itr . next ( ) ; skip formulas . ugh , yes terrible naming of these methods : ( if ( column . class . is instance ( selectable ) ) { continue ; } cols . add ( ( column ) selectable ) ; } todo : we may need to delay this component binding . get owner ( ) . get table ( ) . create unique key ( cols ) ; }
options = get adb options ( false ) ;
assert equals ( 8 , paramter counts . size ( ) ) ;
admin . modify table ( table name , htd ) ;
if ( done signal . get count ( ) = = 0 ) { logger . info ( all tasks completion signaled . . . returning ) ; return null ; }
this . system id = f . to uri ( ) . to asciistring ( ) ; }
buf . append ( ( ? : ) ) ;
sb . append ( ( char ) b1 ) . append ( ( char ) b2 ) . append ( ( char ) b3 ) ;
slurm cmd . add all ( transformed args ) ; string [ ] slurm cmd array = slurm cmd . to array ( new string [ 0 ] ) ; log . log ( level . info , executing job [ + topology working directory + ] : , arrays . to string ( slurm cmd array ) ) ; string builder stderr = new string builder ( ) ; boolean ret = run process ( topology working directory , slurm cmd array , stderr ) ; return ret ; }
g . draw line ( m _ nodes [ p ] . m _ center , m _ nodes [ p ] . m _ top + m _ nodes [ p ] . m _ height , m _ nodes [ c ] . m _ center , m _ nodes [ c ] . m _ top ) ; }
return new cstate change ( m _ factory . create node clicked middle state ( m _ node , event ) , true ) ; }
m tab text colors = a . get color state list ( r . styleable . tab layout _ tab text color ) ; }
initializer class map . clear ( ) ; type initializer map . clear ( ) ; ok = true ;
assert equals ( 6 , result . get total epochs ( ) ) ;
command line parser parser = new posix parser ( ) ; command line cmd = null ; try { cmd = parser . parse ( options , args ) ; } catch ( parse exception e ) { system . err . println ( could not parse arguments ) ; system . exit ( - 1 ) ; return ; avoid warning } int kv limit = integer . max _ value ;
ticker ticker = market data service . get ticker ( currency pair . btc _ usd ) ; string btcusd = ticker . get last ( ) . to string ( ) ; system . out . println ( current exchange rate for btc usd : + btcusd ) ;
for ( int i = 0 ; i < t . get child count ( ) ; i + + ) { _ find all nodes ( t . get child ( i ) , index , find tokens , nodes ) ; } }
b . next = current block . successors ;
if ( replica = = null ) { return null ; }
for ( int i = 0 ; i < num threads ; i + + ) { all [ i ] = new incrementer ( region , i , i , increments per thread ) ; expected total + = ( i * increments per thread ) ; }
if ( use shutdown hook ) { if ( shutdown hook = = null ) { shutdown hook = new catalina shutdown hook ( ) ; } runtime . get runtime ( ) . add shutdown hook ( shutdown hook ) ; if juli is being used , disable juli ' s shutdown hook since shutdown hooks run in parallel and log messages may be lost if juli ' s hook completes before the catalina shutdown hook ( ) log manager log manager = log manager . get log manager ( ) ; if ( log manager instanceof class loader log manager ) { ( ( class loader log manager ) log manager ) . set use shutdown hook ( false ) ; } } if ( await ) { await ( ) ; stop ( ) ; }
kmlencoder encoder = new kmlencoder ( ) ;
double height via hql = ( double ) s . create query ( select p . height inches from person p where p . name = ' emmanuel ' ) . unique result ( ) ; assert equals ( height _ inches , height via hql , 0 . 01d ) ; double expiry via hql = ( double ) s . create query ( select u . password expiry days from user u where u . name = ' steve ' ) . unique result ( ) ; assert equals ( password _ expiry _ days , expiry via hql , 0 . 01d ) ;
if ( xactivity manager service . can on demand ( ) ) return o result ;
verify ( context ) . finalize headers ( result ) ;
if ( local messages . where ( ) . equal to ( message item . fields . stanza _ id , remote message . get stanza id ( ) ) . equal to ( message item . fields . text , remote message . get text ( ) ) . count ( ) > 0 ) { log manager . i ( this , sync . removing message with same stanza id and text . remote message : + text : + remote message . get text ( ) + timestamp : + remote message . get timestamp ( ) + delay timestamp : + remote message . get delay timestamp ( ) + stanza id : + remote message . get stanza id ( ) ) ; iterator . remove ( ) ; continue ; } long remote message delay timestamp = remote message . get delay timestamp ( ) ; long remote message timestamp = remote message . get timestamp ( ) ;
try { serial port = port id . open ( open hab - smarthomatic , default _ port ) ; } catch ( port in use exception e ) { throw new initialization exception ( e ) ; } try { input stream = serial port . get input stream ( ) ; } catch ( ioexception e ) { throw new initialization exception ( e ) ; }
if ( nclobs = = null ) { nclobs = new array list < nclob > ( ) ; } nclobs . add ( nclob ) ; }
assume can connect to ( host , port ) ; final count down latch latch = new count down latch ( 1 ) ;
list < node address > list = get filtered non seed node list ( get node addresses ( peer manager . get reported peers ( ) ) , new array list < > ( ) ) ; collections . shuffle ( list ) ; list < node address > filtered persisted peers = get filtered non seed node list ( get node addresses ( peer manager . get persisted peers ( ) ) , list ) ; collections . shuffle ( filtered persisted peers ) ; list . add all ( filtered persisted peers ) ; list < node address > filtered seed node addresses = get filtered list ( new array list < > ( seed node addresses ) , list ) ; collections . shuffle ( filtered seed node addresses ) ; list . add all ( filtered seed node addresses ) ; log . debug ( number of peers in list for connect to more peers : { } , list . size ( ) ) ;
private int min child ( int i ) { int lo bound = d * i + 1 , hi bound = d * i + d ; int min = lo bound ; for ( int cur = lo bound ; cur < = hi bound ; cur + + ) { if ( cur < n & & greater ( min , cur ) ) min = cur ; } return min ; }
set id ( _ encap . read _ string ( ) ) ;
m authenticator = new authenticator ( this ) ;
int end idx = qualified class name . last index of ( package _ separator ) ; int iterations = 0 ; while ( begin idx + ( qualified class name . length ( ) - end idx ) < = max length without ellipsis ) { alternate appending packages at beginning and end until we reach max length if ( iterations % 2 = = 0 ) { int tmp = qualified class name . index of ( package _ separator , begin idx + 1 ) ; if ( tmp = = - 1 | | tmp + ( qualified class name . length ( ) - end idx ) > max length without ellipsis ) { break ; } begin idx = tmp ; } else { int tmp = qualified class name . last index of ( package _ separator , end idx - 1 ) ; if ( tmp = = - 1 | | begin idx + ( qualified class name . length ( ) - tmp ) > max length without ellipsis ) { break ; } end idx = tmp ; } iterations + + ; }
for ( ; i < sb . length ( ) ; i + + ) { if ( sb . char at ( i ) = = end char ) break ; }
view v = get child at ( i ) ; layout params layout params = ( layout params ) v . get layout params ( ) ; int gravity = layout params . gravity ; if ( direction = = linear layout . vertical ) { if ( ( gravity & gravity . left ) = 0 ) { if gravity left is set . . . gravity & = gravity . left ; unset left gravity | = gravity . bottom ; and set bottom } } else { if ( ( gravity & gravity . bottom ) = 0 ) { etc gravity & = gravity . bottom ; gravity | = gravity . left ; } }
if ( response . is committed ( ) ) { throw new illegal state exception ( sm . get string ( application dispatcher . forward . ise ) ) ; } try { response . reset buffer ( ) ; } catch ( illegal state exception e ) { throw e ; }
try { empty . get long ( 1 ) ; fail ( ) ; } catch ( exception e ) { } ; assert equals ( - 1 , empty . get active row index ( ) ) ; assert false ( empty . advance row ( ) ) ;
system . out . println ( part 2 demo . ) ;
stream = run and pull ( second machine , match ( a : person ) where id ( a ) = + id + return count ( * ) ) ;
event dispatcher . dispatch event ( new integra status event ( get integra time ( ) , get status byte1 ( ) , get status byte2 ( ) ) ) ; return true ;
from ( direct : start ) . choice ( ) . when ( ) . xpath ( employee ) . to ( bean : normalizer?method = employee to person ) . when ( ) . xpath ( customer ) . to ( bean : normalizer?method = customer to person ) . end ( ) . to ( mock : result ) ;
set attribute ( layer value , workspace , gs2 ) ;
session . clear connections ( ) ; }
request delete = new request . builder ( ) . delete ( ) . url ( test url ( automation clients 772 groups 5 ) ) . build ( ) ; response http response = mutual ssl client . new call ( delete ) . execute ( ) ;
assert equals ( 0 , dp . timestamp ( ) % 1000 ) ;
assert that ( put results . number of updates ( ) ) . is equal to ( 0 ) ;
p = database . new instance ( java complex test class . class ) ; p . set name ( chuck ) ; p . set map object ( relatives ) ; for ( string reference relativ : relatives . key set ( ) ) { assert . assert equals ( relatives . get ( reference relativ ) , p . get map object ( ) . get ( reference relativ ) ) ; } database . save ( p ) ; p . get map object ( ) . key set ( ) . size ( ) ; rid = database . get identity ( p ) ; database . close ( ) ;
assert equals ( 1 , join with solution set node . get outgoing channels ( ) . size ( ) ) ; assert equals ( ship strategy type . forward , join with solution set node . get outgoing channels ( ) . get ( 0 ) . get ship strategy ( ) ) ; new job graph generator ( ) . compile job graph ( o plan ) ; }
final callable < void > callable = ( ) - > { try { final principal principal = who am ibean . get caller principal ( ) ; assert not null ( ejb 3 . 1 fr 17 . 6 . 5 the container must never return a null from the get caller principal method . , principal ) ; assert equals ( user1 , principal . get name ( ) ) ; } catch ( runtime exception e ) { e . print stack trace ( ) ; fail ( ejb 3 . 1 fr 17 . 6 . 5 the ejb container must provide the caller’s security context information during the execution of a business method ( + e . get message ( ) + ) ) ; } return null ; } ;
scratch dir path = new path ( hive conf . get var ( conf , hive conf . conf vars . localscratchdir ) ) ; verify scratch dir ( conf , fs , scratch dir path , expected fspermission , user name , true ) ;
if ( arrays . equals ( a1 , a . a1 ) ) return false ;
xml = < wfs : lock feature + service = \ wfs \ + version = \ 1 . 0 . 0 \ + expiry = \ 10 \ + xmlns : cdf = \ http : www . opengis . net cite data \ + xmlns : ogc = \ http : www . opengis . net ogc \ + xmlns : wfs = \ http : www . opengis . net wfs \ + > + < wfs : lock type name = \ cdf : locks \ > + < ogc : filter > + < ogc : feature id fid = \ + fid + \ > + < ogc : filter > + < wfs : lock > + < wfs : lock feature > ;
m media recorder . prepare ( ) ; m media recorder . start ( ) ; if ( m lock . try acquire ( 6 , time unit . seconds ) ) { log . d ( tag , media recorder callback was called : ) ) ; thread . sleep ( 400 ) ; } else { log . d ( tag , media recorder callback was not called after 6 seconds . . . : ( ) ; }
assert equals ( cursor . get throttle mark delete ( ) , new throttle rate ) ;
reference counter . increment and get ( ) ; return this ;
calendar start timestamp = get support ( ) . from time bytes ( arrays . copy of range ( value , 7 , value . length ) ) ; set start timestamp ( start timestamp ) ; gb . toast ( get context ( ) . get string ( r . string . fetch activity operation _ about _ to _ transfer _ since , date format . get date time instance ( ) . format ( start timestamp . get time ( ) ) ) , toast . length _ long , gb . info ) ; } else { log . warn ( unexpected activity metadata : + logging . format bytes ( value ) ) ; handle activity fetch finish ( ) ; } } else if ( value . length = = 3 ) {
if ( params . child len = = 0 ) return false ; else return true ;
switch ( owning class . get nesting kind ( ) ) { case local : case anonymous : return false ; default : return owning class . is inner ( ) ; } }
int started = time . current time ( ) ; int server start time = session . get provider ( cluster provider . class ) . get cluster startup time ( ) ; for ( user session model orig session : orig sessions ) { user session model user session = session . sessions ( ) . get user session ( realm , orig session . get id ( ) ) ; for ( authenticated client session model client session : user session . get authenticated client sessions ( ) . values ( ) ) { session manager . create or update offline session ( client session , user session ) ; } } reset session ( ) ;
final list < string > urls = new array list < > ( waiting requests . key set ( ) ) ; randomness . shuffle ( urls ) ; final list < count down latch > latches = new array list < > ( ) ; for ( final string url : urls ) { latches . add ( finish request ( url ) ) ; } for ( final count down latch latch : latches ) { latch . await ( ) ; }
return temp ; }
throw new unsupported operation exception ( bad code in handle datafile parameters ) ;
assert equals ( old offsets . get ( type system . ss int member ) , type system . ss int member . get bit offset ( ) . get ( ) ) ; assert equals ( old offsets . get ( type system . ss uint member ) , type system . ss uint member . get bit offset ( ) . get ( ) ) ; assert equals ( old offsets . get ( type system . ss array member ) , type system . ss array member . get bit offset ( ) . get ( ) ) ;
return msg ;
return new array list < > ( view . key set ( ) ) ; }
string builder builder = new string builder ( ) ; builder . append ( * ) ; builder . append ( ? ) ; builder . append ( constants . scan _ column + = + column _ 1 ) ; builder . append ( & ) ; builder . append ( constants . scan _ start _ row + = aaa ) ; builder . append ( & ) ; builder . append ( constants . scan _ end _ row + = aay ) ; response response = client . get ( + table + builder . to string ( ) , constants . mimetype _ json ) ; assert equals ( 200 , response . get code ( ) ) ; int count = 0 ;
dbus event key long key = new dbus event key ( 54321 l ) ;
byte [ ] byte content = jnlp file content . get bytes ( utf - 8 ) ;
display scale factor = config . display scale small screen if retina * scale ; } } else {
ioutils . close stream ( mirror out ) ;
reg exception handler . handle exception ( ex ) ;
pulsar resource description rd = create resource description ( memory mb , cpu percent , b in mbps , b out mbps , threads ) ; set < resource unit > rus = new hash set < resource unit > ( ) ;
path manifest path = get manifest dir ( spec path , txn id , stmt id , union suffix ) ;
int lfamilylength = left . get family length ( ) ;
if ( wrapping = = null ) enable _ map _ wrapping = true ; else enable _ map _ wrapping = boolean . value of ( wrapping ) ;
add days and check for completion ( 2 , next event . block ) ; check odstate ( od3 ) ; allow payments and reset overdue to clear by paying all unpaid invoices ( false ) ;
log . i ( tag , gcm registration token : + token ) ;
disposable details disposable = model . get story ( story id ) . subscribe ( story - > { view . hide loader ( ) ; view . show story ( story ) ; view . set read ( story . is read ( ) ) ; } ) ;
text = text . replace all ( \ \ q + html _ newline + \ \ e ( ( \ \ q + html _ newline + \ \ e ) + ? ) \ \ q + html _ blockquote _ end + \ \ e , html _ blockquote _ end + 1 ) ; text = ascii _ pattern _ for _ hr . matcher ( text ) . replace all ( < hr > ) ;
return runner . get partition id ( ) = = op . get partition id ( ) ; }
m _ with class + = instance . weight ( ) ;
access plan temp . get child ( 0 ) . add and link child ( dist node ) ;
thread . sleep ( 5 * 1000 ) ;
return map iterate . flip ( this ) ; }
for ( int i = 0 ; i < 8 ; i + + ) { object sr = sr class . new instance ( ) ; next bytes method . invoke ( sr , bytes ) ; int [ ] seed = ( int [ ] ) seed field . get ( sr ) ; if the first integer is not zero , it is fixed . if ( seed [ 0 ] = 0 ) { return ; success } } fail ( fallback sha1 prng _ secure random impl should not clobber seed internally ) ;
list < string > values = arrays . as list ( 1 . 0 , 3 . 5 , 45 . 153 , 925 . 12 , - 2 . 121 , - 3 . 745 , - 412 . 153 , - 5 . 12 ) ; file data = file ( file name ( whitespace . csv ) ) ;
add executor helper ( host , port ) ;
if ( _ closure vars . contains ( variable ref ) ) { _ closure vars . add ( variable ref ) ; _ needs sort record factory = true ; }
return mod system . get entity by id ( type , 0 , 0 ) . get class ( ) . get simple name ( ) + spawner ;
util . get all ( util . cmd ( cached store , dk ) . with limit ( 10 ) . build ( ) ) ;
if ( configured retired & & wanted state . above ( retired state ) ) { return retired state ; } return wanted state ;
for ( int i = 0 ; i < size ; i + + ) { map1 . put ( keys . get ( i ) , i ) ; } near cache near cache1 = ( ( near cached map proxy impl ) map1 ) . get near cache ( ) ;
super . draw first pass shape ( g2 , pass , series , item , shape ) ; }
if ( container is initialization in progress ( project , container path ) ) { return container _ initialization _ in _ progress ; } map project containers = ( map ) this . containers . get ( project ) ;
sslengine engine = ssl factory . create ssl engine ( localhost , 0 ) ;
string live nodes info = ( string ) ( mbs . get attribute ( mxbean name , live nodes ) ) ;
this . subclass overriding implementation = true ; }
final endpoint endpoint = context . get endpoint ( disruptor : test . a ) ; final exchange exchange = endpoint . create exchange ( ) ; exchange . get in ( ) . set header ( cheese , 123 ) ; final producer producer = endpoint . create producer ( ) ;
f . format ( simulate wah : % b \ n , simulate wah ) ;
configured . get and set ( false ) ;
descriptor descriptor = typical data . get descriptor ( ) ; extension registry . extension info extension info = registry2 . find extension by number ( descriptor , 1001 ) ; assert not null ( extension info ) ; extension registry lite registry lite = extension registry lite . new instance ( ) ;
if ( media player = null ) { media player . release ( ) ; media player = null ; } }
list < key value > kvs = generator . generate test key values ( 60 , use tags ) ;
assigned _ slot _ updater . set ( this , null ) ;
byte [ ] ip bytes = addr . get address ( ) ;
final http cookie cookie = ref tag utils . find ref tag cookie for project ( project , cookie manager , shared preferences ) ; assert null ( cookie ) ;
if ( conditional = = value . always ) { break ; }
if ( local describe subnets = = null ) { throw new org . apache . axis2 . databinding . adbexception ( property cannot be null ) ; }
publisher . initialize ( ) ;
annotation metadata builder java type adapter = new annotation metadata builder ( java type . xml _ javatype _ adapter ) ;
final htable descriptor thread desc = new htable descriptor ( table name . value of ( name . get method name ( ) ) ) ;
v . property ( vertex property . cardinality . list , name , john ) ;
if ( setting manager . get instance ( ) . get main activity tag should change ( ) ) { change the tag fragment for ( int i = 0 ; i < tag adapter . get count ( ) & & i < co coin fragment manager . tag choose fragments . size ( ) ; i + + ) { if ( co coin fragment manager . tag choose fragments . get ( i ) = null ) co coin fragment manager . tag choose fragments . get ( i ) . update tags ( ) ; } and tell others that main activity has changed setting manager . get instance ( ) . set main activity tag should change ( false ) ; }
test ( { function * f ( ) { yield 1 ; } } , { var f = function * ( ) { yield 1 ; } ; } ) ;
return http : + server address macro registrar . macro _ name _ template . replace ( % , def _ port ) + + current project relative path macro . get name ( ) ;
system . out . printf ( avg 95 % % latency % . 2f % . 2fms \ n , avg latcy , kp latcy ) ; }
conf . set ( yarn configuration . rm _ scheduler , scheduler type ) ; if ( ongoing invariant file = null ) { conf . set ( yarn configuration . rm _ scheduler _ monitor _ policies , metrics invariant checker . class . get canonical name ( ) ) ; conf . set ( metrics invariant checker . invariants _ file , ongoing invariant file ) ; conf . set boolean ( metrics invariant checker . throw _ on _ violation , true ) ; } sls = new slsrunner ( conf ) ;
setup . set up ( ) ;
for ( right tuple new blocker = root blocker ; new blocker = null ; new blocker = ( right tuple ) right it . next ( new blocker ) ) {
return parameter types [ argument index ] ; move to method info ?
word mlpackage . save ( new java . io . file ( system . get property ( user . dir ) + out _ bookmarks text inserter . docx ) ) ; }
m photo grid = root . find view by id ( r . id . grid ) ; m selected photo = root . find view by id ( r . id . selection ) ; m feedback bar = root . find view by id ( r . id . feedback ) ; m spring configurator view = ( spring configurator view ) root . find view by id ( r . id . spring _ configurator ) ;
required not null ( parameters , factory build parameters ) ;
this . main frame . init bounds ( ) ;
xsparticle decl base content = ( xsparticle decl ) base type . get particle ( ) ;
filter holder holder = null ; if ( servlet filter holder . get filter ( ) = null ) { holder = new filter holder ( servlet filter holder . get filter ( ) ) ; } else if ( servlet filter holder . get filter class ( ) = null ) { holder = new filter holder ( servlet filter holder . get filter class ( ) ) ; } else { throw new ise ( filter [ % s ] for path [ % s ] didn ' t have a filter ? , servlet filter holder , servlet filter holder . get path ( ) ) ; } if ( servlet filter holder . get init parameters ( ) = null ) { holder . set init parameters ( servlet filter holder . get init parameters ( ) ) ; }
byte [ ] output = new byte [ 100 ] ; def . set input ( input ) ; def . finish ( ) ; def . deflate ( output ) ; inf . set input ( output ) ; int compressed data length = inf . inflate ( input ) ; assert equals ( 16 , inf . get total in ( ) ) ; assert equals ( compressed data length , inf . get total out ( ) ) ; assert equals ( 16 , inf . get bytes read ( ) ) ; }
assert true ( expl , expl . contains ( = sort field < double ( popularity ) > value = 20 . 0 ) ) ;
object node version = node capability . get or default ( capability type . browser _ version , node capability . get ( capability type . version ) ) ; if ( value . equals ( node version ) ) { return false ; } break ; default :
if ( throwable = e ) { throwable . add suppressed ( e ) ; }
original import iter . remove ( ) ;
m matrix change listener = null ;
authenticator . set user attributes ( new string [ ] { uid } ) ;
textfield . set text ( x ) ;
writer . create ( ) ;
override = null ;
listeners . put ( * , null ) ; mbean exporter exporter = new mbean exporter ( ) ; thrown . expect ( illegal argument exception . class ) ; exporter . set notification listener mappings ( listeners ) ; }
boolean ok = true ; for ( int j = 0 ; ok & & ( j < protolength ) ; j + + ) { ok = ( buffer . char at ( index + j ) = = protoname . char at ( j ) ) ; } if ( ok ) { ok = ( buffer . char at ( index + protolength ) = = ' ' ) ; } return ok ;
org . voltdb . utils . volt file . reset subroot for this process ( ) ; volt project builder builder = get builder for test ( ) ; builder . set httpdport ( 0 ) ; int sites per host = 2 ; int host count = 3 ; int k factor = 2 ; local cluster cluster = new local cluster ( rejoin . jar , sites per host , host count , k factor , backend target . native _ ee _ jni , false ) ;
s . push export buffer ( 23 , foo , false , false ) ; assert equals ( s . size in bytes ( ) , 20 ) ;
op return data = new byte [ ] { ( byte ) 0x00 } ; vote items list = voting manager . get vote item list from op return data ( op return data ) ; assert false ( vote items list . has voted on any item ( ) ) ;
configured target target = iterables . get only element ( get analysis result ( ) . get targets to build ( ) ) ; assert that ( target . get label ( ) . to string ( ) ) . is equal to ( aout label ) ; artifact aout = iterables . get only element ( target . get provider ( file provider . class ) . get files to build ( ) ) ;
vector steps vector = new vector ( ) ;
seed [ frame _ length ] = ois . read int ( ) ; seed [ frame _ length + 1 ] = ois . read int ( ) ; seed [ frame _ length + 14 ] = ois . read int ( ) ; seed [ frame _ length + 15 ] = ois . read int ( ) ; }
wrapper . set servlet security annotation scan required ( true ) ;
builder . add property value ( transaction attribute source , new root bean definition ( org . springframework . transaction . annotation . annotation transaction attribute source ) ) ;
string descriptor = class util . internal method descriptor ( type , parse comma separated list ( argument , true , true , true , false , true , false , false , false , null ) ) ; if ( atlas proguard constants . close _ arguments _ keyword . equals ( next word ) ) { throw new parse exception ( expecting separating ' + atlas proguard constants . argument _ separator _ keyword + ' or closing ' + atlas proguard constants . close _ arguments _ keyword + ' before + reader . location description ( ) ) ; }
logger . info ( initializing health check callback ) ; service status . set service status callback ( new service status . service status callback ( ) { @ override public service status . status get service status ( ) {
assert divide all signs ( new int [ ] { 0x00000003 , 0x00000000 , 0x80000000 , 0 } , new int [ ] { 0x00000001 , 0x00000000 , 0x20000000 , 0 } ) ; assert divide all signs ( new int [ ] { 0x00000003 , 0x00000000 , 0x00008000 , 0 } , new int [ ] { 0x00000001 , 0x00000000 , 0x00002000 , 0 } ) ; assert divide all signs ( new int [ ] { 0 , 0 , 0x00008000 , 0x00007fff } , new int [ ] { 1 , 0 , 0x00008000 , 0 } ) ;
string live callback id = ( live callback context = null ) ? live callback context . get callback id ( ) : null ;
int id = counter . increment and get ( ) ;
final resource jar res = ks . get resources ( ) . new byte array resource ( jar ) ; return ks . get repository ( ) . add kie module ( jar res ) ; }
if ( inner iterator = null ) { inner iterator . close ( ) ; }
gen . write string field ( id , vertex . get id ( ) . to string ( ) ) ;
final string topic = test - topic ; final int partition = 3 ; final byte [ ] payload = new byte [ ] { 1 , 2 , 3 , 4 } ; final list < consumer record < byte [ ] , byte [ ] > > records = arrays . as list ( new consumer record < > ( topic , partition , 15 , payload , payload ) , new consumer record < > ( topic , partition , 16 , payload , payload ) , new consumer record < > ( topic , partition , 17 , payload , payload ) ) ;
tint int hash map id map = new tint int hash map ( num nodes , 1f ) ;
super . on sub menu selected ( null ) ;
params = null ;
gbalarm alarm = gbalarm . create single shot ( 0 , true , calendar ) ; alarm . store ( ) ; if ( gbapplication . is running lollipop or later ( ) ) { set alarm via alarm manager ( context , calendar . get time in millis ( ) ) ; } int hours = calendar . get ( calendar . hour _ of _ day ) ;
int param length = 0 ;
run4done = true ;
throw try to unwrap injector exception ( e ) ;
drawable drawable1 = drawable test utils . mock drawable ( ) ; callback . set drawable ( drawable1 ) ; assert same ( drawable1 , fade drawable . get drawable ( index ) ) ;
compose array range ( data , op , instr ctx ) ;
assert translated lines ( translation , - ( nsstring * ) test2 ; ) ;
string message = certificate revocation of serial 0x + serial . to string ( 16 ) ; system . out . println ( message ) ; annotated exception e = new annotated exception ( message ) ; throw new cert path validator exception ( e . get message ( ) , e , cert path , 0 ) ; } } }
layout params = new view group . layout params ( view group . layout params . wrap _ content , view group . layout params . match _ parent ) ;
xml tree . append child ( new element , element , this ) ; return this ; }
final int timeout ms = 100 ; final string name = pinpoint ; final string expected fallback message = hystrix test helper . fallback hello ( name ) ; hystrix command < string > hello command = say hello command . create for timeout ( command group , name , timeout ms ) ; string actual message = hello command . execute ( ) ; assert . assert equals ( expected fallback message , actual message ) ; hystrix test helper . wait for span data flush ( timeout ms ) ;
assert false ( true ) ; } catch ( search phase execution exception e ) {
count ( ) ;
for ( cluster connection cluster : clusters ) { try { cluster . close ( ) ; } catch ( exception e ) { exceptions . add ( e ) ; } } return exceptions ; }
stream result result = new stream result ( new string writer ( ) ) ;
try { factory . set feature ( javax . xml . xmlconstants . feature _ secure _ processing , true ) ; } catch ( transformer configuration exception e ) { log . warn ( transformer factory doesn ' t support the feature { } with value { } , due to { } . , new object [ ] { javax . xml . xmlconstants . feature _ secure _ processing , true , e } ) ; }
department department = entity manager . find ( department . class , 1 l ) ; log . infof ( fetched department : % s , department . get id ( ) ) ; assert equals ( 3 , department . get employees ( ) . size ( ) ) ; end : : fetching - strategies - fetch - mode - join - example [ ] } ) ; }
int next byte = input . read ( ) ;
partition drgateway dr gateway = partition drgateway . get instance ( m _ partition id , node drgateway , start action ) ; if ( async command log enabled ) { configure durable unique id listener ( dr gateway , true ) ; } final partition drgateway mp pdrg ;
g2 . set rendering hint ( rendering hints . key _ text _ antialiasing , rendering hints . value _ text _ antialias _ on ) ;
final test procedure proc1 = new test procedure ( 10 , 1 , new byte [ ] { 65 } ) ;
do test header limits ( 1 , 32 * 1024 , failure mode . connection _ reset ) ;
long offset = 0 ; int segment size = settings . get segment size ( ) ; for ( ; ; ) { dbcstatistics statistics = data container . read data ( transfer source , session , consumer , data filter , offset , segment size , dbsdata container . flag _ none ) ; if ( statistics = = null | | statistics . get rows fetched ( ) < segment size ) {
final abstract exporter delegate < input stream > export delegate = new spring boot zip exporter delegate ( this . get archive ( ) ) ;
nl . append ( ' \ n ' ) ;
if ( rows > = max rows ) { break ; }
test types ( line _ joiner . join ( * * @ interface * var i = function ( ) { } ; , * * @ abstract * i . prototype . foo = function ( ) { } ; ) ) ;
int count = m . size ( ) ;
drawable drawable1 = drawable test utils . mock drawable ( ) ; callback . set drawable ( drawable1 ) ; assert same ( drawable1 , fade drawable . get drawable ( index ) ) ;
files . move ( incoming file . to path ( ) , storage file . to path ( ) ) ; incoming file = null ;
int line number = - 1 ;
shuffle . close ( ) ;
check authenticated identity ( response ) ;
if ( tables exists ( ) ) { create tables ( ) ; } else { check compatibility ( ) ; } init from database ( ) ; } catch ( sqlexception e ) {
test subscriber . assert value ( changes . new instance ( table2 ) ) ; test subscriber . unsubscribe ( ) ; }
article dao article dao = application injector . get instance ( article dao . class ) ;
string prefix = m _ prefix map . lookup prefix ( ns ) ;
parser . reset ( ) ;
assert equals ( 1 , realm . where ( null types . class ) . is not null ( null types . field _ lo _ list + . + null types . field _ boolean _ null ) . count ( ) ) ;
headers . put ( camel box . message , camel _ test _ file _ comment ) ; final com . box . sdk . box file result = request body and headers ( direct : addfilecomment , null , headers ) ; assert not null ( add file comment result , result ) ;
try { acl authorization strategy . security check ( child acl , acl authorization strategy . change _ ownership ) ; fail ( it should have thrown not found exception ) ; } catch ( not found exception expected ) { }
if ( payload exists ) { ts payload reader payload reader = ts payload readers . get ( pid ) ; if ( payload reader = null ) { if ( discontinuity found ) { payload reader . seek ( ) ; } ts packet buffer . set limit ( end of packet ) ; payload reader . consume ( ts packet buffer , payload unit start indicator ) ; ts packet buffer . set limit ( limit ) ; } } ts packet buffer . set position ( end of packet ) ;
snapshots service . check index closing ( current state , indices to close ) ; meta data . builder md builder = meta data . builder ( current state . meta data ( ) ) ;
if ( sound option ) { set notification sound ( context , extras , m builder ) ; }
int rounds = rounds _ default ; boolean rounds custom = false ; if ( salt = = null ) { throw new illegal argument exception ( salt must not be null ) ; } final matcher m = salt _ pattern . matcher ( salt ) ; if ( m = = null | | m . find ( ) ) { throw new illegal argument exception ( invalid salt value : + salt ) ; } if ( m . group ( 3 ) = null ) { rounds = integer . parse int ( m . group ( 3 ) ) ; rounds = math . max ( rounds _ min , math . min ( rounds _ max , rounds ) ) ; rounds custom = true ; }
if ( key code = = vk _ tab ) { return false ; }
else if ( value instanceof query part ) throw field expected ( value ) ; else return val ( value ) ;
conf . put ( property key . user _ rpc _ retry _ max _ num _ retry , 60 ) ;
assert . assert that ( error when appending , had error . get ( ) , is ( false ) ) ;
if ( file . delete ( ) ) { return true ; }
doc . add ( new sorted doc values field ( null _ value , new bytes ref ( null ) ) ) ;
init context first time ( ) ;
if ( this . message = null ) { for ( final map . entry < string , list < string > > entry : this . message . entry set ( ) ) { string key = entry . get key ( ) ; list value = new array list ( ) { { add all ( entry . get value ( ) ) ; } } ; communication . get message ( ) . put ( key , value ) ; } } return communication ;
this . props . put ( process job . command , xls - al ) ; try { this . job . run ( ) ; } catch ( final runtime exception e ) { assert . assert true ( true ) ; e . print stack trace ( ) ; }
load meta ( ) ; for ( int i = 0 ; master . get server manager ( ) . count of region servers ( ) < 1 ; + + i ) { log . info ( waiting for rs to join ) ; threads . sleep ( 250 ) ; }
_ canonical name = * : * ;
resolve info result = package manager . resolve activity ( intent1 , - 1 ) ;
common component common = new common component ( ) ; log . info ( initializing + common . get class ( ) . get name ( ) ) ; ctx . set attribute ( org . eclipse . jetty . test . jmx . common , common ) ;
return get state ( ) = = open _ state ? 1 : - 1 ;
publish status ( protocol provider , presence status . extended _ away _ threshold , presence status . away _ threshold ) ;
list < ? extends group > groups = joust sim buddy list . get groups ( ) ; iterator < ? extends group > groups iter = groups . iterator ( ) ;
double d = c . remove ( a , 123 ) ;
checker . destroy ( ) ; checker . process ( collections . singleton list ( new file ( some file name ) ) ) ;
assert equals ( s2 a _ oper _ msi _ l1 c _ tl _ sgs _ _ 20160117 t141030 _ a002979 _ t32 tpl _ n02 . 01 , json . read ( . products [ 0 ] . id ) ) ;
string domain cfg content = file utils . read file to string ( domain cfg ) ;
final short sign1 = get short ( is ) ;
mockito . verify ( spy nn , mockito . at least once ( ) ) . add block ( mockito . any string ( ) , mockito . any string ( ) , mockito . < extended block > any ( ) , mockito . < datanode info [ ] > any ( ) , mockito . any long ( ) , mockito . < string [ ] > any ( ) , mockito . < enum set < add block flag > > any ( ) ) ; mockito . verify ( spy nn , mockito . at least once ( ) ) . complete ( mockito . any string ( ) , mockito . any string ( ) , mockito . < extended block > any ( ) , any long ( ) ) ; append test util . check ( fs , file , 10000 ) ;
new block . set block id ( new block . get block id ( ) + 1 ) ;
if ( r _ mark _ s u ( ) ) { break lab7 ; } } while ( false ) ;
num . ceil ( ) ;
if ( xbmc provider . is in bound ( item name ) ) { return ; } string xbmc instance = xbmc provider . get xbmc instance ( item name ) ;
final document document = xml utils . read xml ( get file manager ( ) . get input stream ( wsdl path ) ) ;
y buffer . get ( nv21 , 0 , y size ) ; v buffer . get ( nv21 , y size , v size ) ; u buffer . get ( nv21 , y size + v size , u size ) ; return nv21 ;
int constant _ pool _ count = read unsigned short ( 8 ) ; items = ( int [ ] ) resize array ( items , constant _ pool _ count ) ; int index = 10 ;
list < map < string , object > > tmp = tlog files downloaded ;
if ( new window size < = initial receive window size 2 & & spdy data frame . is last ( ) ) { delta window size = initial receive window size - new window size ; spdy session . update receive window size ( stream id , delta window size ) ; spdy window update frame spdy window update frame = new default spdy window update frame ( stream id , delta window size ) ; channels . write ( ctx , channels . future ( e . get channel ( ) ) , spdy window update frame , e . get remote address ( ) ) ; }
scan . set attribute ( attribute1 , null ) ;
tag buffer . write ( body output stream . to byte array ( ) ) ;
return exchange . get context ( ) . get type converter ( ) . convert to ( string . class , exchange , bytes ) ; }
string preloaded param value = get param value ( parameters , current param name ) ;
sys info windows mock tester = new sys info windows mock ( ) ;
ss . m progress = this . m progress ; ss . m target progress = this . m target progress ; ss . is spinning = this . is spinning ; ss . spin speed = this . spin speed ; ss . bar width = this . bar width ; ss . bar color = this . bar color ; ss . rim width = this . rim width ; ss . rim color = this . rim color ; ss . circle radius = this . circle radius ; ss . linear progress = this . linear progress ; ss . fill radius = this . fill radius ; return ss ;
if ( ( session = = null | | engine _ was _ closed ) & & ( handshake status . equals ( sslengine result . handshake status . need _ wrap ) | | handshake status . equals ( sslengine result . handshake status . need _ task ) ) ) { return new sslengine result ( get engine status ( ) , handshake status , 0 , 0 ) ; } if ( src . remaining ( ) < record protocol . get min record size ( ) ) { return new sslengine result ( sslengine result . status . buffer _ underflow , get handshake status ( ) , 0 , 0 ) ; }
if ( has warned buffer overflow ) { if ( log . is debug enabled ( ) ) { log . debug ( buffer size + buffer size + has been exceeded and the input stream + will not be repeatable until the next mark . freeing buffer memory ) ; } has warned buffer overflow = true ; } buffer = null ;
search . set start result ( first result ) ;
c = dfs . get content summary ( quota dir1 ) ;
if ( bee line . get opts ( ) . get show db in prompt ( ) ) { if ( cmd line . to lower case ( ) . starts with ( use ) ) { return new use command hook ( cmd line ) ; } else if ( cmd line . to lower case ( ) . starts with ( connect ) ) { return new connect command hook ( cmd line ) ; } else if ( cmd line . to lower case ( ) . starts with ( go ) ) { return new go command hook ( cmd line ) ; } else { return null ; } } else { return null ; }
web settings . set layout algorithm ( layout algorithm . narrow _ columns ) ; set over scroll mode ( over _ scroll _ never ) ;
assert true ( column metadata . is hidden ( ) ) ;
registry . put ( current category , unmodifiable map ( parsers ) ) ;
run client compatibility with94 znode test ( table name , test _ util . get configuration ( ) ) ;
d . find element ( by . xpath ( html body a ) ) . click ( ) ;
if ( version helper . get version sdk int compat ( ) < version helper . version _ jellybean & & buffered reader = null ) { try { buffered reader . close ( ) ; } catch ( ioexception e ) { e . print stack trace ( ) ; } } }
assert equals ( 0 , parsable byte array . get position ( ) ) ;
assert equals ( character . unicode block . samaritan , character . unicode block . of ( 0x0800 ) ) ;
byte [ ] thrift column value = c . get value ( ) ;
m map . set built in zoom controls ( true ) ; m map . set multi touch controls ( true ) ; m map . set min zoom level ( 3 ) ; m map . set max zoom level ( 19 ) ; latest osm can go to 21 m map . get tile provider ( ) . create tile cache ( ) ; if ( m compass overlay = = null ) { m compass overlay = new compass overlay ( get activity ( ) , new internal compass orientation provider ( get activity ( ) ) , m map ) ; }
taxonomy writer tw = new directory taxonomy writer ( index dir ) ;
predicate < zip entry > main dex filter = zip entry predicates . class file filter ( classes in main dex ) ;
final int base size = 16 ; final int rotated = ( int ) math . ceil ( base size * math . sqrt ( 2 ) ) ; final int size = ( rotated + 1 + 1 + 1 ) * 4 ; assert equals ( size , img . get height ( ) ) ; assert equals ( size , img . get width ( ) ) ; buffered image expected = image io . read ( kmltest . class . get resource ( square - blue - 16 - x4 - 45deg . png ) ) ;
assert equals ( - 3 , client . echo ( 3 ) ) ;
chaos . start ( ) ;
check hadoop conf ( test . property1 , null ) ;
assert xpath evaluates to ( - 92 . 99954926766114 , 4 . 52401492058674 , 200 . 0 , kml : placemark kml : point kml : coordinates , doc ) ;
tuple ds . max by ( - 1 ) ;
db . users ( ) . insert project permission on user ( user2 , user role . admin , project1 ) ;
final int start = references . index of ( ' < ' ) ;
final int sig size per input = 106 ;
assert true ( version type . internal . is version conflict for writes ( versions . not _ found , 10 , random boolean ( ) ) ) ;
string builder encoded value = new string builder ( value . length ( ) * 2 ) ; int length = value . length ( ) ; int last = length - 1 ;
data output . write unsigned short ( program class . u2interfaces count ) ; for ( int index = 0 ; index < program class . u2interfaces count ; index + + ) { data output . write unsigned short ( program class . u2interfaces [ index ] ) ; }
return super . explain ( create normalized weight ( query , true ) , doc ) ;
int index = current page ;
{ math type = int ; } break ; case 9 :
get capabilities ( ) . test with fail ( data ) ;
apph . validate ( duration , ( config . duration > 0 ) ) . validate ( poolsize , ( config . pool size > 0 ) ) . validate ( ratelimit , ( config . rate limit > 0 ) ) . validate ( latencytarget , ( config . latency target > 0 ) ) ;
assert no warning ( goog . module ( ' example ' ) ; var { x } = goog . require ( ' y ' ) ; ) ;
file ctx . add ( new code generator ( ) { @ override public void generate ( jcode sb out ) { for ( int i = 0 ; i < neurons . length ; i + + ) { string col info clazz = mname + _ bias _ + i ; out . i ( ) . p ( neuron bias values for ) . p ( neurons [ i ] . get class ( ) . get simple name ( ) ) . p ( layer ) . nl ( ) ; double [ ] bias = i = = 0 ? null : new double [ model _ info ( ) . get _ biases ( i - 1 ) . size ( ) ] ; if ( i > 0 ) { for ( int j = 0 ; j < bias . length ; + + j ) bias [ j ] = model _ info ( ) . get _ biases ( i - 1 ) . get ( j ) ; } jcode gen . to class with array ( out , null , col info clazz , bias ) ; } } } ) ;
final detail ast ast if = mock ast ( token types . literal _ if , if , mockfile , 2 , 2 ) ;
float new value = get target value ( ) ; if ( send event mode . should send event ( value , new value ) ) { event . prepare ( id , new value , delta ) ; event . set target info ( target , target block pos , hit position , hit normal ) ; for ( entity ref entity : input entities ) { entity . send ( event ) ; if ( event . is consumed ( ) ) { break ; } } send event to subscribers ( delta , target ) ; }
map message msg = null ; if ( rentry = null & & rentry . is diffable ( ) & & ( is dirty | | complete ) ) { rentry . lock ( ) ; try {
mru cache work queue . add active work item ( new mrucache work item ( cache key , false ) ) ;
gold mine . dig out gold ( ) ;
process task queue ( ) ; for ( selection key k : selector . keys ( ) ) { close ( k ) ; }
tester . assert response ( request ( application v4 tenant tenant1 application application1 deploying , 6 . 1 . 0 , request . method . post ) , new file ( application - deployment . json ) ) ;
assert rows ( execute ( update % 1 s set version = 3 where id = 0 if version = 1 ; ) , row ( false , 2 ) ) ;
verify contents ( cache , job id , key , data ) ;
this . queue processor = new queue processor thread ( this . azk props . get boolean ( azkaban _ queueprocessing _ enabled , true ) , this . azk props . get long ( azkaban _ active _ executor _ refresh _ in _ ms , 50000 ) , this . azk props . get int ( azkaban _ active _ executor _ refresh _ in _ num _ flow , 5 ) , this . azk props . get int ( azkaban _ max _ dispatching _ errors _ permitted , this . active executors . size ( ) ) ) ; this . queue processor . start ( ) ; }
if ( file time = - 1 ) { new entry . set time ( file time ) ; if found set it into output file . }
undecoded chunk . reader index ( reader index ) ; throw new not enough data decoder exception ( ) ; } }
ctx = request . start async ( request , response ) ; } ctx . set timeout ( 0 ) ; scheduler . schedule ( new dispatch back ( ctx ) , 500 , time unit . milliseconds ) ; }
out . close ( ) ;
if ( r0 . priority = r1 . priority | | r0 . preferred order = r1 . preferred order | | r0 . is default = r1 . is default ) { return query . get ( 0 ) ; }
if ( port > 0 ) { this . port = port ; }
joined args . add ( unmapped key ) ; unmapped key = arg ; } else {
os = new byte array output stream ( ) ;
final int offset = calc element offset ( current producer index , mask ) ; so element ( offset , e ) ; store store return true ; awesome : ) }
string tmp path = strip quotes ( to tree . get text ( ) ) ;
position1 + = chunk length ; position2 + = decompressed ; compress . set input ( raw . get bytes ( ) , position1 , raw . get bytes ( ) . length - position1 ) ; compress . finish ( ) ; compressed = compress . deflate ( buf , 0 , 512 , deflater . no _ flush ) ; decompress . set input ( buf , 0 , compressed ) ;
assert . assert true ( temp mode . cached = = neighbors join . get input2 ( ) . get temp mode ( ) ) ; job graph generator jgg = new job graph generator ( ) ;
string jvm name = management factory . get runtime mxbean ( ) . get name ( ) ; try { return long . value of ( jvm name . split ( @ ) [ 0 ] ) ; } catch ( number format exception e ) { ignore } return null ;
this . cancellable flush task = start flush task ( flush interval , scheduler ) ; this . on close = on close ; }
string project dir path = file system item . create file ( project file ) . get parent path string ( ) ; if ( value . starts with ( project dir path ) ) return value ; else return null ; } } ; }
persister . set encrypt password fields ( false ) ;
try { final string map _ json = apos to quotes ( { ' no nulls ' : { ' a ' : null } } ) ; mapper . read value ( map _ json , new type reference < null content fail < map < string , string > > > ( ) { } ) ; fail ( should not pass ) ; } catch ( invalid null exception e ) { verify exception ( e , property \ no nulls \ ) ; }
if ( t0 . get type ( ) = = token type . keyword & & t1 . get type ( ) = = token type . space & & t2 . get type ( ) = = token type . keyword ) { if ( ( ( token string . equals ( order ) | | token string . equals ( group ) | | token string . equals ( connect ) ) & & token2 string . equals ( by ) ) | | ( ( token string . equals ( start ) ) & & token2 string . equals ( with ) ) ) { t0 . set string ( t0 . get string ( ) + + t2 . get string ( ) ) ; arg list . remove ( index + 1 ) ; arg list . remove ( index + 1 ) ; } }
root . build ( new build node callback ( ) { @ override public void on missing interval ( final node interval cur node , final local date start date , final local date end date ) { output . add ( create node interval ( start date , end date ) ) ; } @ override public void on last node ( final node interval cur node ) {
task task = task service . new task ( ) ; task service . save task ( task ) ; task service . add candidate user ( task . get id ( ) , user ) ;
double d a ;
for ( jaxb hbm joined subclass entity type joined subclass entity binding : mapping binding . get joined subclass ( ) ) { process top level sub class binding ( mapping document , joined subclass entity binding ) ; }
metrics . finish app attempt ( app . get application id ( ) , app . is pending ( ) , app . get user ( ) ) ; check apps ( queue source , 1 , 0 , 0 , 0 , 0 , 0 , true ) ; metrics . finish app ( user , rmapp state . failed ) ;
assert clear result ( map , , , 0 ) ;
push message ( data , true , wait for ack ) ; exception = null ; } catch ( ioexception xx ) { exception = xx ; close socket ( ) ; } } } finally {
iterator iterator = visible series keys . iterator ( ) ;
assert true ( utils . get used memory bytes ( ) > 0 ) ;
if ( partition handling manager . get availability mode ( ) = availability mode . available & & command . is one phase commit ( ) & & ctx . has modifications ( ) ) { for ( object key : ctx . get affected keys ( ) ) { partition handling manager . check write ( key ) ; } } return invoke next then accept ( ctx , command , post tx command check ) ;
values _ by _ target _ kind . put if absent ( target . get target kind ( ) , value ) ; return value ;
int size = this . static attributes . size ( ) ; size + = ( model = null ? model . size ( ) : 0 ) ; size + = ( path vars = null ? path vars . size ( ) : 0 ) ; map < string , object > merged model = new linked hash map < > ( size ) ; merged model . put all ( this . static attributes ) ; if ( path vars = null ) { merged model . put all ( path vars ) ; }
file slave dir = new file ( test root dir , slave ) ;
list < string > segments = uri . get path segments ( ) ;
grammars . get include ( ) . add ( include ) ;
if ( args . length > 2 ) { rewrite to option cmd args [ 2 ] = - w ; err . println ( ' ls path [ watch ] ' has been deprecated . + please use ' ls [ - w ] path ' instead . ) ; parser parser = new posix parser ( ) ; try { cl = parser . parse ( options , cmd args ) ; } catch ( parse exception ex ) { throw new cli parse exception ( ex ) ; } args = cl . get args ( ) ; }
file target file = new file ( container dir , sym link ) ; file sys dir = new file ( local dir , resource localization service . nm _ private _ dir ) ;
test _ util . start mini zkcluster ( ) ; tables seem enabled by default test _ util . restart hbase cluster ( 3 ) ; zoo keeper watcher zkw = hbase testing utility . get zoo keeper watcher ( test _ util ) ;
if ( m action mode helper . destroy action mode if can ( ) ) return ;
data [ 1 ] = ( byte ) ( ( server hello length > > 16 ) & 0x ff ) ;
expr node column desc parent col = expr node desc utils . get column expr ( parent expr ) ;
player handler . remove callbacks and messages ( null ) ;
return this . dom = = other . dom ; }
float flexible range = m flexible space image height - m action bar size ; int min overlay transition y = m action bar size - m overlay view . get height ( ) ; view helper . set translation y ( m overlay view , scroll utils . get float ( - scroll y , min overlay transition y , 0 ) ) ; view helper . set translation y ( m image view , scroll utils . get float ( - scroll y 2 , min overlay transition y , 0 ) ) ;
sticky header decoration decoration = new sticky header decoration ( new sticky header adapter ( this ) ) ;
super ( partition key ) ;
if ( single _ valued [ index ] & & elems . length > 1 ) throw single valued exception ( ) ;
remove from buffer ( 1 ) ;
key character map kcm = key character map . load ( key character map . virtual _ keyboard ) ; char am char ; char pm char ; for ( int i = 0 ; i < math . max ( m am text . length ( ) , m pm text . length ( ) ) ; i + + ) { am char = m am text . to lower case ( locale . get default ( ) ) . char at ( i ) ; pm char = m pm text . to lower case ( locale . get default ( ) ) . char at ( i ) ; if ( am char = pm char ) { key event [ ] events = kcm . get events ( new char [ ] { am char , pm char } ) ;
if ( original drivers . contains ( driver ) ) { driver names . add ( driver . get class ( ) . get canonical name ( ) ) ; } driver manager . deregister driver ( driver ) ; }
if ( ch = ' \ \ ' ) { back count = 0 ; } reprocess = false ;
if ( document . get referenced content ( ) = null & & document . get referenced content ( ) . is empty ( ) ) { sequence . add elements ( document . get referenced content ( ) ) ; } else { if ( tokenizer factory = = null ) instantiate tokenizer factory ( ) ; list < string > tokens = tokenizer factory . create ( document . get content ( ) ) . get tokens ( ) ; for ( string token : tokens ) { if ( token = = null | | token . is empty ( ) ) continue ; vocab word word = new vocab word ( 1 . 0 , token ) ; sequence . add element ( word ) ; } }
if ( n = = null ) { self . set peer state ( ( proposed leader = = self . get id ( ) ) ? server state . leading : learning state ( ) ) ; vote end vote = new vote ( proposed leader , proposed zxid , proposed epoch ) ; leave instance ( end vote ) ; return end vote ; }
operation status status = get bdb database ( ) . delete ( transaction , key entry ) ;
renderable . mesh part . mesh = mesh ;
context sub3 = init ctx . create subcontext ( java : zero ) ;
if ( protocol provider . get account id ( ) . is hidden ( ) & & protocol provider . get account id ( ) . is config hidden ( ) ) return ;
sent block . set ( false ) ; }
if ( provided = = null ) continue ; column specification expected = make arg spec ( receiver ks , receiver cf , fun , i ) ; if ( provided . test assignment ( keyspace , expected ) . is assignable ( ) ) throw invalid request ( type error : % s cannot be passed as argument % d of function % s of type % s , provided , i , fun . name ( ) , expected . type . as cql3 type ( ) ) ; }
nu process builder pb png = new nu process builder ( arrays . as list ( timeout , conv timeout , pdftocairo , - png , - singlefile , - r , timed out | | twice total objects ? 72 : 150 , - f , string . value of ( page ) , - l , string . value of ( page ) , presentation . get absolute path ( ) , temp png . get absolute path ( ) . substring ( 0 , temp png . get absolute path ( ) . last index of ( ' . ' ) ) ) ) ; pdf2 png page converter handler pb png handler = new pdf2 png page converter handler ( ) ;
if ( am . is annotation present ( consumes . class ) ) { return extract media types ( am . get annotation ( consumes . class ) ) ; } return default consumed types ;
item . set has unique id ( false ) ; }
return sendto bytes ( fd , bytes , byte offset , byte count , flags , inet address , port ) ;
get callback ( ) . message data received ( msgs [ i ] ) ;
array list < rename > option list = new array list < rename > ( ) ; if ( req . get overwrite dest ( ) ) { option list . add ( rename . overwrite ) ; } else if ( req . has move to trash ( ) ) { option list . add ( rename . to _ trash ) ; } if ( option list . is empty ( ) ) { option list . add ( rename . none ) ; } try { server . rename2 ( req . get src ( ) , req . get dst ( ) , option list . to array ( new rename [ option list . size ( ) ] ) ) ; } catch ( ioexception e ) { throw new service exception ( e ) ; } return void _ rename2 _ response ;
rpc manager . invoke remotely async ( collections . singleton list ( member ) , copy , default sync options ) . when complete ( ( responses , throwable ) - > { if ( throwable = null ) { all future . complete exceptionally ( throwable ) ; } else { successful response response = get successful response or fail ( responses , all future , rsp - > all future . complete exceptionally ( outdated topology exception . instance ) ) ; if ( response = = null ) { return ; } object response value = response . get response value ( ) ; merging completable future . move list items to future ( response value , all future , my offset ) ; all future . count down ( ) ; } } ) ;
this . get params panel ( ) . get params table ( ) . repaint ( ) ;
if ( style . has xaxis ( ) ) canvas . draw line ( m inner chart left , axis position , m inner chart right , axis position , style . get chart paint ( ) ) ;
text body body = new text body ( body _ text ) ;
video url = intent . get data ( ) . to string ( ) ;
result result = results . no content ( ) ; result = lang . set language ( to , result ) ;
for ( int i = 0 ; i < 10 ; i + + ) { validation demo . union field with inline record union = new validation demo . union field with inline record ( ) ; union . set my enum ( my enum . foofoo ) ; validation demos . add ( new validation demo ( ) . set string a ( this string is too long to pass validation . ) . set string b ( string b ) . set union field with inline record ( union ) ) ; }
product . get features ( ) . remove ( 0 ) ; feature feature new = new feature ( ) ; feature new . set name ( feature 2 ) ; feature new . set product ( product ) ; product . get features ( ) . add ( feature new ) ; session . persist ( feature new ) ; session . get transaction ( ) . commit ( ) ; session . close ( ) ; session = open session ( ) ;
long remaining = math . min ( n , this . content length - this . pos ) ;
marshaller registration . register marshallers ( proto stream marshaller . get serialization context ( remote cache manager ) ) ; return cache manager ; }
result + = ( ) ;
try { check compaction policy ( conf , htd ) ; } catch ( ioexception e ) { warn or throw exception for failure ( false , conf _ key , e . get message ( ) , e ) ; }
int horizontal offset = math . round ( ( anchor tab . get draw x ( ) + anchor tab . get width ( ) ) * m context . get resources ( ) . get display metrics ( ) . density ) - m tab menu . get width ( ) - ( ( margin layout params ) tab view . get layout params ( ) ) . left margin ;
attribute = new disk attribute ( attribute . get name ( ) ) ;
int l = e - s ;
assert false ( rb . get initialization status ( ) ) ; assert false ( async request success ) ; utility . start mini cluster ( ) ;
out . close ( ) ;
int alt3 = 3 ;
additiona annotations . add ( new annotation metadata builder ( join _ table , join table attributes ) ) ; } else if ( join columns builders . is empty ( ) ) {
this . data source = ( data source ) bean ; }
throw new transformer exception ( can ' t clone node : + dtm . get node name ( node ) ) ; } }
free stack . add ( obj ) ;
logger . trace ( unexpected exception on closing cci result set , ex ) ;
if ( record . slot = = m last slot requested ) { m get day slots time . clear ( ) ; synchronized ( wait object ) { wait object . notify ( ) ; } }
j = this . bit length % byte . size ;
for ( int i = 0 ; i < 2 ; i + + ) { tasks [ i ] = test tasks . unending ( task + i ) ; results [ i ] = ( remote task runner . run ( tasks [ i ] ) ) ; } wait for both workers to have unacked tasks ( ) ;
return local delete security group response . get pull parser ( my _ qname ) ; }
mustache . execute ( new string writer ( ) , new object ( ) ) ;
byte [ ] x = new byte [ block _ size ] ; pack . long to big endian ( at length * 8 , x , 0 ) ; pack . long to big endian ( total length * 8 , x , 8 ) ; g hashblock ( s , x ) ;
schedule . initialize schedule ( crawl db update util . dummy url , from db ) ;
methods . put ( implementation , ignore ) ; }
m bluring task . cancel ( true ) ; m bluring task = null ; }
more zero frame . additional variables accept ( clazz , method , code attribute , offset , this ) ;
return get short ( this . m context . get string ( res id ) , default value ) ;
json writer . object ( ) ; json writer . key ( type ) . value ( feature ) ; f type = simple feature . get feature type ( ) ; types = f type . get attribute descriptors ( ) ;
for ( int i loop = 0 ; i loop < count ; i loop + + ) { float draw long = long offset + ( i loop * three radius ) ; if ( m orientation = = horizontal ) { d x = draw long ; d y = short offset ; } else { d x = short offset ; d y = draw long ; } only paint fill if not completely transparent if ( m paint page fill . get alpha ( ) > 0 ) { canvas . draw circle ( d x , d y , page fill radius , m paint page fill ) ; } only paint stroke if a stroke width was non - zero if ( page fill radius = m radius ) { canvas . draw circle ( d x , d y , m radius , m paint stroke ) ; } }
add page ( buffer , create page ( 1 ) ) ;
long position ; if ( format > = format _ version2 ) position = tvx . read long ( ) ; else position = tvd . read vlong ( ) ; for ( int i = 1 ; i < = found ; i + + ) position + = tvd . read vlong ( ) ; mapper . set document number ( doc num ) ;
string container name = common utils . is empty ( catalog name ) ? catalog name : schema name ;
evaluation result < string value > result = tester . eval ( * keep going = * true , a key ) ;
options data data = get options data internal ( options class ) ; o options instance ; try { constructor < o > constructor = data . get constructor ( options class ) ; preconditions . check not null ( constructor , no options class constructor available ) ; options instance = constructor . new instance ( ) ; } catch ( reflective operation exception e ) { throw new illegal state exception ( error while instantiating options class , e ) ; } list < option definition > option definitions = options data . get all option definitions for class ( options class ) ;
context . set user attribute ( attribute , attribute values in context ) ;
deferred region . put ( new put ( null ) ) ; verify hlog count ( wal , 1 ) ;
g . set color ( lh . get style ( ) . get color ( lh . get context ( ) , color type . text _ foreground ) ) ;
span size lookup . set start position ( m span size lookup . get start position ( ) ) ; this . m span size lookup = span size lookup ;
return output . replace ( ' ' , ' \ ' ' ) ; }
response . set timeout ( 1500 , time unit . seconds ) ;
assert equals ( expected year , year value ) ;
if ( pattern1 . ends with ( ) | | pattern2 . starts with ( ) ) { return pattern1 + pattern2 ; }
do answer ( new answer < void > ( ) { @ override public void answer ( invocation on mock invocation on mock ) throws throwable { buffer buffer = ( buffer ) invocation on mock . get arguments ( ) [ 0 ] ; deserializer . set next buffer ( buffer ) ; while ( deserializer . has unfinished data ( ) ) { record deserializer . deserialization result result = deserializer . get next record ( record ) ; if ( result . is full record ( ) ) { output list . add ( record . create copy ( ) ) ; } if ( result = = record deserializer . deserialization result . last _ record _ from _ buffer | | result = = record deserializer . deserialization result . partial _ record ) { break ; } } return null ; } } ) . when ( mock writer ) . write buffer ( any ( buffer . class ) , any int ( ) ) ; outputs . add ( mock writer ) ;
execute ( select addresses from % s where id = ? , user id _ 1 ) ;
if ( g camera native setup = = null ) { try { g camera native setup = camera . class . get declared method ( native _ setup , object . class , int . class , string . class , boolean . class ) ; g camera method type = 4 ; } catch ( no such method exception e ) { ignore } } if ( g camera native setup = null ) { g camera native setup . set accessible ( true ) ; } for ( method mth : audio record . class . get declared methods ( ) ) { if ( mth . get name ( ) . equals ( native _ check _ permission ) & & mth . get parameter types ( ) . length = = 1 & & mth . get parameter types ( ) [ 0 ] = = string . class ) { g audio record native check permission = mth ; mth . set accessible ( true ) ; break ; } }
list < tuple value expression > tves = expression util . get tuple value expressions ( expr ) ; assert ( m _ parent stmt = null ) ; for ( tuple value expression tve : tves ) { int orig id = tve . get orig stmt id ( ) ; if ( m _ stmt id = orig id & & m _ parent stmt . m _ stmt id = orig id ) { throw new planning error exception ( subqueries do not support aggregation of parent statement columns ) ; } } m _ parameter tve map . put ( param idx , expr ) ; return pve ;
parallel edges = true ;
int registry count = server context . get registry ( ) . sync up ( ) ;
if ( strings . is null or empty ( group ) ) { sb . append ( , \ group \ : ) ; sb . append ( strings . double quote ( group ) ) ; }
verify ( get resolver ) . perform get ( stor iocontent resolver , query ) ;
assert . assert true ( passivation interceptor . get pre passivate target ( ) instanceof bean with serialization issue ) ; assert . assert true ( ( ( bean with serialization issue ) passivation interceptor . get pre passivate target ( ) ) . has been passivated ( ) ) ;
boolean restart = ( m _ current mp read only & & m _ rand . next double ( ) < mprestartchance ) ; complete transaction message msg = make complete txn msg ( m _ current mp read only , restart , restart ) ; if ( restart ) { m _ mp in progress = false ; m _ mpi txn ego = m _ mpi txn ego . make next ( ) ; } return msg ;
path to snapshots map . get ( snapshot path ) . remove ( snapshot old name ) ;
read test data ( test _ data , test _ data . length - 1 , c . length _ unset , 1 , 0 , 1 , false ) ;
bm = m app . decode sampled bitmap from resource ( r . drawable . transparent _ drawable , 450 , 450 ) ;
list < trd > trds = provider . linkage third data ( selected first index , selected second index ) ;
return hard concurrency limit ; }
segment descriptor desc1 = sd ( task , 2010 p1 d , 0 ) ;
assume . assume true ( fs . has metadata store ( ) ) ; final int [ ] num of paths = { 0 , 2 } ;
assert equals ( 1 , subtitle . get next event time index ( 1000000 ) ) ;
assert contains event ( error workspace test build : 11 : 10 : in deps attribute of + skylark _ rule rule test : skyrule : ' test : jlib ' does not have mandatory providers : + ' some _ provider ' ) ;
sbuf . append ( message pattern . substring ( i , j ) ) ;
master . stop async ( ) . await terminated ( ) ;
system . out . println ( startup of primary in the same dir as the secondary . ) ;
bindy simple skip fields test . order order = ( bindy simple skip fields test . order ) unmarshall result . get received exchanges ( ) . get ( 0 ) . get in ( ) . get body ( ) ;
for ( map . entry < string , object > property entry : filled hit . fields ( ) . entry set ( ) ) { hit to fill . set field ( property entry . get key ( ) , property entry . get value ( ) ) ; } } hit to fill . set filled ( summary class = = null ? default _ summary _ class : summary class ) ; } }
map binder binding < ? > map binder binding = get map binder binding ( elements ) ;
final byte [ ] der = get oidtest bytes ( ) ;
if ( any . equals ( service ) ) { if ( any . equals ( method ) ) { logger . warning ( invalid rule + rule + , when namespace + is * then also layer must be * . skipping rule + rule ) ; return null ; } }
assert true ( results . command . is executed in thread ( ) ) ; }
superclass test ( object , object , unknown ) ;
if ( profile . get is failing ( ) | | ( profile . get is active ( ) ) ) continue ;
test tracker thread tracker = thread . tracker ;
return verify diff ( cat original , cat updated , null , null , expect apply catalog diff to ee , false , true ) ;
list < edge > edges = new linked list < > ( ) ;
this . find all by ids in with global search method = get find all by ids in global search method ( ) ;
if ( nullability [ position ] ) { return false ; } }
player = new exo player impl ( renderers , track selector , load control ) ;
items [ 0 ] = item . notification ;
create uo w ( camel exchange ) ; try { get processor ( ) . process ( camel exchange ) ; } catch ( exception e ) { get exception handler ( ) . handle exception ( e ) ; } finally { done uo w ( camel exchange ) ; } object body = get response body ( http exchange , camel exchange ) ;
log . debug ( validating uri based configuration ) ;
set timely color ( black white color ) ;
get support action bar ( ) . set title ( r . string . action _ tag _ editor ) ;
assert equals ( belief system type . defeasible . get id ( ) , config . get property ( belief system type option . property _ name ) ) ;
s = text ; yyreset ( zz reader ) ; yybegin ( yyinitial ) ; return yylex ( ) ; }
input stream is = camp bxadapter test . class . get resource as stream ( marketdata example - ticker - data . json ) ;
pick subchannel args args1 = mock ( pick subchannel args . class ) ; metadata headers1 = new metadata ( ) ; headers1 . put ( grpclb constants . token _ metadata _ key , lbtoken _ _ old ) ; when ( args1 . get headers ( ) ) . then return ( headers1 ) ; assert same ( b1 . result , picker . pick subchannel ( args1 ) ) ; verify ( args1 ) . get headers ( ) ; assert that ( headers1 . get all ( grpclb constants . token _ metadata _ key ) ) . contains exactly ( lbtoken0001 ) ;
menu . find item ( r . id . menu _ search ) . set visible ( text utils . is empty ( m filter ) | | m adapter . get item count ( ) > 0 ) ; if ( m adapter . get item count ( ) > 0 ) { super . prepare options menu ( menu ) ; } }
set fab anchor ( translation x , translation y ) ;
check singleton node ( service bnode1 uri , singleton service activator . service _ b _ preferred _ node ) ; check singleton node ( service bnode2 uri , singleton service activator . service _ b _ preferred _ node ) ;
fold ( function f ( ) { + try { while ( x ) { throw 1 } } finally { alert ( 1 ) } throw 1 } , function f ( ) { + try { while ( x ) { break } } finally { alert ( 1 ) } throw 1 } ) ; fold same ( function f ( ) { try { throw a } finally { a = 2 } throw a ; } ) ;
in . reset reader index ( ) ; return ; }
new port range = new port range ( global _ base _ port , global _ max _ port ) ; log . info ( single test process using ports from { } . , new port range ) ; }
m ticker = new runnable ( ) { public void run ( ) { if ( m ticker stopped ) return ; m calendar . set time in millis ( system . current time millis ( ) ) ; set text ( date format . format ( m format , m calendar ) ) ; invalidate ( ) ; long now = system clock . uptime millis ( ) ; long next = now + ( 1000 - now % 1000 ) ; m handler . post at time ( m ticker , next ) ; } } ; m ticker . run ( ) ;
list < annotation metadata builder > annotations = new array list < annotation metadata builder > ( ) ;
rule = new partition by string ( ) ; rule . set partition length ( 512 ) ; rule . set partition count ( 2 ) ; rule . init ( ) ;
assert equals ( 0 , dn . get all namespace services ( ) . length ) ;
f = ( field ) doc . get field value ( ssto ) ; assert not null ( should have ssto , f ) ; assert not null ( should have string value , f . string value ( ) ) ; assert null ( should not have token stream value , f . token stream value ( ) ) ; f = ( field ) doc . get field value ( sind ) ; assert not null ( should have sind , f ) ; assert null ( should not have string value : ' + f . string value ( ) + ' , f . string value ( ) ) ; assert not null ( should have token stream value , f . token stream value ( ) ) ; assert u ( commit ( ) ) ;
bloom filter . merge bloom filter bytes ( bf1 bytes , 0 , bf1 bytes . length , bf2 bytes , 0 , bf2 bytes . length ) ;
int weight = random ( ) . next int ( 1 < < 24 ) ; keys [ i ] = new input ( key , weight ) ; slow completor . add ( new term freq payload2 ( key , analyzed key , weight ) ) ;
trace exchange formatter my formatter = context . get registry ( ) . lookup by name and type ( log formatter , trace exchange formatter . class ) ;
assert analyzes to ( a , 안녕하세요 한글입니다 , new string [ ] { 안녕하세요 , 한글입니다 } ) ; }
region = get region ( s . get region info ( ) . get region name ( ) ) ;
int base station latitude = cdma cell location . invalid _ lat _ long ;
if ( session info . get allow full ui ( ) ) { project popup menu project menu = new project popup menu ( session info , commands _ ) ; add right widget ( project menu . get toolbar button ( ) ) ; }
system . out . println ( utils for tests . run job fail ( this . create job conf ( ) , in dir , out dir ) . get id ( ) ) ; keep trying = true ; for ( int tries = 0 ; tries < 30 & & keep trying ; tries + + ) { thread . sleep ( 50 ) ; keep trying = ( notification servlet . counter = = 6 ) ; } assert equals ( 6 , notification servlet . counter ) ; assert equals ( 0 , notification servlet . failure counter ) ; }
show modifiers ( int . class ) ;
chart . get plot grid ( ) . show vertical lines ( ) ;
if ( is at least one active call peer ( conference call . get call peers ( ) ) ) return true ;
instance info same instance = create local out of service instance ( local _ region _ instance _ 1 _ hostname ) ;
preconditions . check state ( batch . selected in use ) ; if ( is last group batch ) { return ; }
assert true ( was not supposed to be a major compaction , num files2 > 1 ) ;
form . add ( advanced param panel = build advanced panel ( advanced panel ) ) ;
synchronized ( dirs ) { int sz = dirs . size ( ) ; if ( sz > 0 ) { for ( tracker tracker : dirs . values ( ) ) { int cnt = tracker . ref cnt . get ( ) ; for ( int i = 0 ; i < cnt ; i + + ) { tracker . ref cnt . decrement and get ( ) ; df . release ( tracker . dir ) ; } } } } close thread . join ( ) ;
return text encoding ;
for ( int i = listeners . length - 2 ; i > = 0 ; i - = 2 ) { if ( listeners [ i ] = = menu drag mouse listener . class ) { lazily create the event : ( ( menu drag mouse listener ) listeners [ i + 1 ] ) . menu drag mouse released ( event ) ; } }
resolver . resolve all ( hostname ) . sync uninterruptibly ( ) ; observer = lifecycle observer factory . observers . poll ( ) ;
throw new illegal state exception ( no free or removed slots available . key set full? ) ; }
slice _ from ( ance ) ;
data index + + ;
assert xpath evaluates to ( 1 , count ( csw : record [ dc : identifier = ' urn : uuid : 9a669547 - b69b - 469f - a11f - 2d875366bbdc ' ] ) , d ) ; assert xpath evaluates to ( 1 , count ( csw : record [ dc : identifier = ' urn : uuid : 94bc9c83 - 97f6 - 4b40 - 9eb8 - a8e8787a5c63 ' ] ) , d ) ; }
rebalance plan = cluster test utils . make plan ( z1z3z5 current , z1z3z5 stores , z1z3z5 shuffle , z1z3z5 stores ) ; assert equals ( rebalance plan . get plan ( ) . size ( ) , 1 ) ; assert true ( rebalance plan . get primaries moved ( ) > 0 ) ; assert true ( rebalance plan . get partition stores moved ( ) > 0 ) ; assert equals ( rebalance plan . get partition stores moved xzone ( ) , 0 ) ; zone moves = rebalance plan . get zone move map ( ) ; assert true ( zone moves . get ( 1 , 1 ) > 0 ) ; assert true ( zone moves . get ( 1 , 3 ) = = 0 ) ; assert true ( zone moves . get ( 1 , 5 ) = = 0 ) ; assert true ( zone moves . get ( 3 , 1 ) = = 0 ) ; assert true ( zone moves . get ( 3 , 3 ) > 0 ) ; assert true ( zone moves . get ( 3 , 5 ) = = 0 ) ; assert true ( zone moves . get ( 5 , 1 ) = = 0 ) ; assert true ( zone moves . get ( 5 , 3 ) = = 0 ) ; assert true ( zone moves . get ( 5 , 5 ) > 0 ) ;
view group . layout params layout params = pinned view . get layout params ( ) ; if ( layout params = = null ) { layout params = generate default layout params ( ) ; pinned view . set layout params ( layout params ) ; } int height mode = measure spec . get mode ( layout params . height ) ;
try ( docker connection connection = connection factory . open connection ( docker daemon uri ) . method ( post ) . path ( api version path prefix + commit ) . query ( container , params . get container ( ) ) ) { add query param if not null ( connection , repo , params . get repository ( ) ) ; add query param if not null ( connection , tag , params . get tag ( ) ) ; add query param if not null ( connection , comment , ( params . get comment ( ) = = null ) ? null : urlencoder . encode ( params . get comment ( ) , utf - 8 ) ) ; add query param if not null ( connection , author , ( params . get author ( ) = = null ) ? null : urlencoder . encode ( params . get author ( ) , utf - 8 ) ) ; final docker response response = connection . request ( ) ; if ( created . get status code ( ) = response . get status ( ) ) { throw get docker exception ( response ) ; } return parse response stream and close ( response . get input stream ( ) , container committed . class ) . get id ( ) ; }
return response . ok ( ) . build ( ) ;
list < string > local role name list = curr rel . get value ( ) ;
japplemenubar . japple menu bar . hide ( ) ;
iiop info = iiop info . substring ( naming constants . iiop _ length ) ;
hash map properties = new hash map ( ) ;
conf2 . set ( mapred . job . tracker , test hdfsserver ports . name _ node _ host + 0 ) ; conf2 . set ( mapred . job . tracker . http . address , test hdfsserver ports . name _ node _ http _ host + 0 ) ; started = can start job tracker ( conf2 ) ; assert true ( started ) ; should start now } finally {
jar file jar file = new jar file ( path + native jar , true ) ;
log . debug ( wake + event ) ;
int id = channel . get int ( ) ; byte in use flag = channel . get ( ) ; boolean in use = false ; if ( ( in use flag & record . in _ use . byte value ( ) ) = = record . in _ use . byte value ( ) ) { in use = true ; } else if ( in use flag = record . not _ in _ use . byte value ( ) ) { throw new ioexception ( illegal in use flag : + in use flag ) ; } label token record record = new label token record ( id ) ; record . set in use ( in use ) ; record . set name id ( channel . get int ( ) ) ; int nr type records = channel . get int ( ) ; for ( int i = 0 ; i < nr type records ; i + + ) { dynamic record dr = read dynamic record ( channel ) ; if ( dr = = null ) { return null ; } record . add name record ( dr ) ; } return new command . label token command ( null , record ) ;
assert that ( rule . tags ( ) ) . contains only ( misra ) ;
access flags = ( access flags & opcodes . acc _ private ) ; } }
ds1 . join ( ds2 ) . where ( my string ) . equal to ( new key selector < custom type , integer > ( ) { @ override public integer get key ( custom type value ) throws exception { return value . my int ; } } ) ;
int [ ] cols = ast col slice . col _ select ( dst . names ( ) , cols _ numlist ) ;
schemas . add ( schema ) ;
for ( client connection conn : copy ) { try { conn . close ( ) ; } catch ( throwable t ) { connection manager . log . error ( failed to close connection , t ) ; } }
assert versions ( table , new long [ ] { t2 , t1 , t0 } ) ;
if ( m selected icon paint . get alpha ( ) = min _ alpha & & model . m selected icon = null & & model . m selected icon . is recycled ( ) ) m icons canvas . draw bitmap ( model . m selected icon , model . m icon matrix , m selected icon paint ) ;
index descriptor existing index1 = index descriptor factory . for label ( label id1 , key1 ) ;
return context . get result ( ) ;
assert . assert not null ( lfs ) ; }
string input = input file . get absolute path ( ) ; hash function hash function = hashing . sha1 ( ) ; hash code hash code = hash function . hash string ( input , charsets . utf _ 16 le ) ; return name + - + hash code . to string ( ) ; }
db representation after change = db representation . of ( create some data ( cluster ) ) ;
if ( _ to router = null ) { buf . append ( targetting ) ; buf . append ( _ to router . to base64 ( ) ) . append ( ) ; if ( _ to tunnel = null ) buf . append ( _ to tunnel . get tunnel id ( ) ) ; }
new dom . set end ( il . append ( new aload ( new dom . get index ( ) ) ) ) ;
for ( int i = number of entries - maximum weight ; i < number of entries ; i + + ) { cache . put ( i , integer . to string ( i ) ) ; } assert equals ( number of entries - maximum weight , evictions . get ( ) ) ; assert equals ( evictions . get ( ) , cache . stats ( ) . get evictions ( ) ) ;
assert equals ( { \ @ type \ : \ test subtypes sub d \ , \ d \ : 0 } , mapper . write value as string ( new sub d ( ) ) ) ;
return true ; default : add error ( property setter . can contain component returned + aggregation type ) ; return false ;
template . send body ( direct : start , < order > < type > my type < type > < user > func < user > < order > ) ; assert mock endpoints satisfied ( ) ;
for ( iterator < physics ghost object > it = current . iterator ( ) ; it . has next ( ) ; ) { physics ghost object physics object = it . next ( ) ; copy existing spatials if ( old objects . contains key ( physics object ) ) { spatial spat = old objects . get ( physics object ) ; ghosts . put ( physics object , spat ) ; old objects . remove ( physics object ) ; } else { if ( filter = = null | | filter . display object ( physics object ) ) { logger . log ( level . fine , create new debug ghost object ) ; create new spatial node node = new node ( physics object . to string ( ) ) ; node . add control ( new bullet ghost object debug control ( this , physics object ) ) ; ghosts . put ( physics object , node ) ; physics debug root node . attach child ( node ) ; } } }
assert format ( 1970 - 01 - 01 t00 : 00 : 00 . 005 z , 5 l ) ;
type = test to type ( dpt , new byte [ ] { ( byte ) 0x7 f , ( byte ) 0x ff } , decimal type . class ) ;
abstract message builder . merge from ( bytes ) . build partial ( ) ;
claims claims = create token ( user _ login , ten _ days _ ago ) ; claims . put ( last refresh time , four _ minutes _ ago ) ; when ( jwt serializer . decode ( jwt _ token ) ) . then return ( optional . of ( claims ) ) ; assert that ( under test . validate token ( request , response ) . is present ( ) ) . is true ( ) ;
if ( file type . is c ( ) | | capabilities _ . has all capabiliites ( ) ) return ;
procedure testing utility . wait procedure ( proc exec , proc id ) ;
if ( name . length ( ) = = 60 & & name . to lower case ( locale . us ) . ends with ( . b32 . i2p ) ) return lookup dest ( hash . create ( base32 . decode ( name . to lower case ( locale . us ) . substring ( 0 , 52 ) ) ) , max wait ) ;
return parent = null & & node util . is get ( parent ) ; }
for ( string hfile name : hfiles to add ) { log . trace ( adding hfile link + hfile name + to region = + region info . get encoded name ( ) + table = + table name ) ; restore store file ( family dir , region info , hfile name ) ; }
return new value animator ( ) . get duration ( ) ;
granule source source = structured reader . get granules ( coverage name , true ) ;
for ( int i = 0 ; i < cond index ; i + + ) { visit expression or statement ( expressions . get ( i ) ) ; } label continue label = controller . get compile stack ( ) . get continue label ( ) ; label break label = controller . get compile stack ( ) . get break label ( ) ; label cond = new label ( ) ; mv . visit label ( cond ) ;
file script file = new file ( test _ root _ dir , test script . cmd ) ; file utils . write string to file ( script file , @ echo % 1 + expected result ) ; shell decryption key provider provider = new shell decryption key provider ( ) ;
int colon index = host port . index of ( ' : ' ) ; if ( - 1 = colon index ) { endpoint . set hostname ( host port . substring ( 0 , colon index ) ) ; endpoint . set port ( integer . parse int ( host port . substring ( colon index + 1 ) ) ) ; } else { no host specified - leave the default host and set the port endpoint . set port ( integer . parse int ( host port . substring ( colon index + 1 ) ) ) ; } return endpoint ;
http servlet request . class . get method ( get content length long ) ; } catch ( no such method exception e ) {
return executor ( ) . new failed future ( new unsupported address type exception ( ) ) ; }
assert equals ( 1 , cache . size ( ) ) ; assert equals ( 0 , count index ( person . class , cache ) ) ; assert equals ( 0 , count index ( car . class , cache ) ) ; } } ) ; }
input stream topics = get class ( ) . get resource as stream ( trec topics . txt ) ;
stash size - - ; int last index = capacity + stash size ; if ( index < last index ) { key table [ index ] = key table [ last index ] ; value table [ index ] = value table [ last index ] ; } }
ldaptest utils . update group mapper config options ( mapper model , group mapper config . preserve _ group _ inheritance , false ) ; realm . update component ( mapper model ) ;
if ( auto shape type ) { if ( other = = null ) throw new illegal state exception ( must call begin ( shape type . + preferred + ) . ) ; else throw new illegal state exception ( must call begin ( shape type . + preferred + ) or begin ( shape type . + other + ) . ) ; }
user dto . set id ( null ) ; }
fast string buffer innermost = this ;
assert equals ( arrays . as list ( new many to one eager component ( entity2 , data component2 ) ) , get audit reader ( ) . find ( embeddable list entity2 . class , ele _ id1 , 2 ) . get component list ( ) ) ;
iterator < chat contact < ? > > chat participants = chat session . get participants ( ) ; while ( chat participants . has next ( ) ) chat contact list panel . add contact ( chat participants . next ( ) ) ;
pf = pivots . get ( 53 ) ; assert pivot ( place _ s , placeholder0 , 1 , pf ) ; assert range ( p1 , 0 , 100 , 1000 , 10 , pf . get facet ranges ( ) . get ( 0 ) ) ; assert range ( p2 , 0 , 200 , 1000 , 5 , pf . get facet ranges ( ) . get ( 1 ) ) ; rfc = pf . get facet ranges ( ) . get ( 0 ) . get counts ( ) ; assert equals ( 0 , rfc . get ( 0 ) . get value ( ) ) ;
dropped during poll . add ( conn ) ; connections [ i ] = new gsm connection ( phone . get context ( ) , dc , this , i ) ; if ( connections [ i ] . get call ( ) = = ringing call ) { new ringing = connections [ i ] ;
new conf . set boolean ( common configuration keys . ipc _ client _ ping _ key , false ) ; remote id = connection id . get connection id ( new inet socket address ( 0 ) , test rpc service . class , null , 0 , null , new conf ) ; assert equals ( 0 , remote id . get ping interval ( ) ) ; }
assert q ( req ( q , id : 3 ) , result [ @ num found = ' 1 ' ] ) ;
collections . reverse ( managed services ) ;
factory field . set ( null , null ) ;
in . read int ( ) ; int stream position ;
opt = name node . parse arguments ( new string [ ] { - upgrade } ) ;
properties . put ( osgi server constants . managed _ jetty _ server _ name , osgi server constants . managed _ jetty _ server _ default _ name ) ;
if ( handler instanceof idle state handler ) { break ; } }
if ( is flag ( flag , tmstartrscan ) & & is flag ( flag , tmnoflags ) ) throw new illegal argument exception ( tmnoflags this flag must be used when no other flags are specified . + received + flag ) ; return recovery iterator . has next ( ) ? recovery iterator . next ( ) : recovery manager . recovery iterator . nothing ;
path dir1 = new path ( user dir1 ) ; path file1 = new path ( dir1 , file1 ) ; fsdata output stream stm1 = test file creation . create file ( fs , file1 , 1 ) ; system . out . println ( test file creation delete parent : + created file + file1 ) ; test file creation . write file ( stm1 ) ; stm1 . hflush ( ) ; path dir2 = new path ( user dir2 ) ;
listenable future . add listener ( single call listener , direct executor ( ) ) ;
p ace themes _ . get ( ) ;
make graph call ( ) ; } } else if ( state = = session state . closed _ login _ failed & & login context = null ) { handle error ( new facebook authorization exception ( session was closed and was not closed normally ) , login context ) ; } }
base string = cdb ( ? : \ u00 c3 \ u006 e \ u0300 ) ;
count = tuple . get expressions ( ) . size ( ) ;
em . flush ( ) ; query q = em . create native query ( select * from item i where i . int val = : i val ) ; parameter p = new parameter ( ) { @ override public string get name ( ) { return i val ; } @ override public integer get position ( ) { return null ; } @ override public class get parameter type ( ) { return integer . class ; } } ; q . set parameter ( p , null ) ;
return non _ pk _ reference ; }
try { string resolved placeholder = system . get property ( location . get raw scheme specific part ( ) ) ; if ( resolved placeholder = = null ) { return false ; } location = new uri ( resolved placeholder ) ; scheme = location . get scheme ( ) ; } catch ( urisyntax exception e ) { return false ; }
short circuit replica info info = cache . fetch or create ( new extended block id ( 1 , test _ bp1 ) , new short circuit replica creator ( ) { @ override public short circuit replica info create short circuit replica info ( ) { assert . fail ( second replica went stale , despite 1 + hour staleness time . ) ; return null ; } } ) ; info . get replica ( ) . unref ( ) ;
tree map < byte [ ] , list < key value > > map = new tree map < byte [ ] , list < key value > > ( bytes . bytes _ comparator ) ;
if ( delete node ) { log . error ( the deletion of the closed node for the region + region . get encoded name ( ) + returned + delete node ) ; }
for ( int i = 0 ; i < 256 ; i + + ) { final atomic disposable reference counter counter = new atomic disposable reference counter ( ) ; incrementer . set counter ( counter ) ; decrementer . set counter ( counter ) ; counter . increment ( ) ;
return ( ( number ) ctxt . handle unexpected token ( _ value class , p ) ) . float value ( ) ;
pre registration initialization ( ) ;
out . write ( der value . tag _ sequence , tmp ) ; }
if ( visible ) frame . set visible ( true ) ; result = frame ; }
render name ( results ) ;
for ( int k = 0 ; k < retries _ before _ lock ; + + k ) { int mcsum = 0 ; for ( int i = 0 ; i < segments . length ; + + i ) { mcsum + = mc [ i ] = segments [ i ] . mod count ; if ( segments [ i ] . contains value ( value ) ) { return true ; } } boolean clean sweep = true ; if ( mcsum = 0 ) { for ( int i = 0 ; i < segments . length ; + + i ) { if ( mc [ i ] = segments [ i ] . mod count ) { clean sweep = false ; break ; } } } if ( clean sweep ) { return false ; } }
if ( control result . get state ( ) = = state . too _ many _ rows ) { test result = new query result ( state . invalid , null , null , null , null , immutable list . of ( ) ) ; return false ; }
list < integer > new events = seq ( window manager . expire _ events _ threshold + 101 , window manager . expire _ events _ threshold + 200 ) ;
batch = new sprite batch ( ) ;
checkpoint coordinator coord = graph . get checkpoint coordinator ( ) ; assert true ( coord = = null | | coord . is shutdown ( ) ) ; }
java . io . file file = new java . io . file ( filename ) ;
int version = data . get int ( ) ;
bitmap = bitmap . create bitmap ( bitmap , ( int ) ( math . abs ( left offset ) * m downscale factor ) , ( int ) ( math . abs ( top offset ) * m downscale factor ) , width , height ) ;
try { entity utils . consume ( response . get entity ( ) ) ; } catch ( throwable e ) {
return unmarshal ( ( ( org . w3c . dom . document ) result . get node ( ) ) , docx4j properties . get property ( docx4j . model . datastorage . binding traverser xslt . validation event continue , false ) ) ;
for ( int i = from pos ; i < value . length & & value [ i ] > = 0 ; i + + ) { if ( val > = bound ) { check for overflow if ( unsigned long div ( - 1 - value [ i ] , radix ) < val ) { return - 1 ; } } val = val * radix + value [ i ] ; } return val ;
if ( smsb = = null ) { log . e ( tag , dispatch message : message is null ) ; return intents . result _ sms _ generic _ error ; } string in ecm = system properties . get ( telephony properties . property _ inecm _ mode , false ) ;
assert true ( expected record got nothing , reader . next ( key , value ) ) ; assert equals ( wrong length for record value , 3 , value . get length ( ) ) ;
if ( m media player delegate = null ) { m media player delegate . release ( ) ; m media player delegate . video info . set progress ( 0 ) ; }
assert true ( first child . get object ( ) = second child . get object ( ) ) ;
try { list < backup restore callback > callbacks = geo server extensions . extensions ( backup restore callback . class ) ; for ( backup restore callback callback : callbacks ) { callback . on end request ( ) ; } } catch ( exception e ) { logger . log ( level . severe , could not unlock geo server catalog configuration , e ) ; }
if ( extension headers . get headers ( ) . size ( ) > 0 ) { response . get headers ( ) . add all ( extension headers . get headers ( ) ) ; } }
( ( lease set ) dsm . get entry ( ) ) . set received as reply ( ) ; if ( _ log . should log ( log . info ) ) _ log . info ( storing garlic ls down tunnel for : + dsm . get key ( ) + sent to : + _ client ) ; _ context . in net message pool ( ) . add ( dsm , null , null ) ; } else { if ( _ client = null ) {
test hystrix command < integer > attempt1 = get shared circuit breaker command ( key , execution isolation strategy . thread , abstract test hystrix command . fallback result . success , circuit breaker ) ; system . out . println ( command key ( from cmd ) : + attempt1 . command key . name ( ) ) ; attempt1 . execute ( ) ; thread . sleep ( 100 ) ; assert true ( attempt1 . is response from fallback ( ) ) ; assert false ( attempt1 . is circuit breaker open ( ) ) ; assert false ( attempt1 . is response short circuited ( ) ) ;
executor service . execute ( ( ) - > { guarded queue . put ( 20 ) ; } ) ;
fsdata output stream file1 = fs . create ( new path ( file1 ) ) ;
constraints . remove ( desc ) ; assert false ( desc . has coprocessor ( constraint processor . class . get name ( ) ) ) ; assert false ( constraints . has ( desc , all pass constraint . class ) ) ; }
boolean splittable = ( query instanceof boolean query ) ;
expression ex = parser . parse expression ( hello { 3 + 4 } world , default _ template _ parser _ context ) ; string s = ex . get value ( test scenario creator . get test evaluation context ( ) , string . class ) ; assert equals ( hello 7 world , s ) ; ex = parser . parse expression ( hello { 3 + 4 } wo { ' { ' } rld , default _ template _ parser _ context ) ;
if ( n = = 0 ) { nothing to do } else if ( m = = 1 ) { for ( j = 0 ; j < n ; j + + ) { if ( a . char at ( 0 ) = = b . char at ( j ) ) { sb . append ( a . char at ( 0 ) ) ; break ; } } step 2 } else { i = ( int ) math . floor ( ( ( double ) m ) 2 ) ; step 3 int [ ] l1 = alg b ( i , n , a . substring ( 0 , i ) , b ) ; int [ ] l2 = alg b ( m - i , n , reverse string ( a . substring ( i ) ) , reverse string ( b ) ) ; step 4 int k = find k ( l1 , l2 , n ) ; step 5 alg c ( sb , i , k , a . substring ( 0 , i ) , b . substring ( 0 , k ) ) ; alg c ( sb , m - i , n - k , a . substring ( i ) , b . substring ( k ) ) ; }
basic object input stream bois = new basic object input stream ( ) ; assert null ( test 1 : , bois . read object override ( ) ) ;
solr query response rsp = process commit ( ignore - commit - from - client - 403 , false ) ; assert not null ( sending a commit should have resulted in an exception in the response , rsp . get exception ( ) ) ; rsp = process commit ( ignore - commit - from - client - 200 , false ) ; exception should be null = rsp . get exception ( ) ; assert null ( sending a commit should not have resulted in an exception in the response : + should be null , should be null ) ; rsp = process commit ( ignore - optimize - only - from - client - 403 , true ) ; assert not null ( sending an optimize should have resulted in an exception in the response , rsp . get exception ( ) ) ;
multipart multipart = get multipart ( response ) ;
assert extern properties ( foo = { bar : null , ' baz ' : { foobar : null } } ; , bar , baz , foobar ) ;
if ( a = = double . class | | b = = double . class ) { return double . class ; } else if ( a = = float . class | | b = = float . class ) { return float . class ; } else if ( a = = long . class | | b = = long . class ) { return long . class ; } else { return int . class ; }
i min1 = i ;
string cert id = sip provider . get account id ( ) . get account property string ( protocol provider factory . client _ tls _ certificate ) ; if ( cert id = null ) {
args [ 0 ] = new deferred java object ( new hive decimal writable ( hive decimal . create ( - 1000 . 123456 ) ) ) ;
final string mname = jcode gen . to java id ( _ key . to string ( ) ) ; body sb . i ( ) . p ( java . util . arrays . fill ( preds , 0 ) ; ) . nl ( ) ; body sb . i ( ) . p ( double mean , sdev , prob ; ) . nl ( ) ;
subtest overlay ( client , alt _ overlay , alt _ overlay _ full _ length ) ;
list < metrics tag > tags = collections . empty list ( ) ; set < abstract metric > metrics = new hash set < abstract metric > ( ) ; metrics . add ( make metric ( foo1 , 1 ) ) ; metrics record record1 = new metrics record impl ( ms info . context , 1000000000000 l , tags , metrics ) ; metrics record record2 = new metrics record impl ( ms info . context , 1000000001000 l , tags , metrics ) ; sink . put metrics ( record1 ) ;
@ suppress warnings ( rawtypes ) class [ ] classes to mock = new class [ extra interfaces . length + 1 ] ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( invalid policy ) ) return null ; invalid policy exception e = ( invalid policy exception ) super . unmarshall ( node ) ;
package match = new string [ ] { , package name } ;
for ( orecord operation entry : tx entries ) { if ( entry . get record ( ) . get identity ( ) . is persistent ( ) & & entry . type = orecord operation . deleted ) total available records + + ; else if ( entry . type = = orecord operation . deleted ) total available records - - ; }
int n = on subscribe . max concurrent threads . get ( ) ;
if ( m down degrees = - 1 ) { degrees = get degrees from coords ( event x , event y , m doing move , is inner circle ) ; if ( degrees = - 1 ) { value = reselect selector ( degrees , is inner circle [ 0 ] , m doing move , false ) ; if ( get current item showing ( ) = = hour _ index & & m is24 hour mode ) { int am or pm = get is currently am or pm ( ) ; if ( am or pm = = am & & value = = 12 ) { value = 0 ; } else if ( am or pm = = pm & & value = 12 ) { value + = 12 ; } } set value for item ( get current item showing ( ) , value ) ; m listener . on value selected ( get current item showing ( ) , value , true ) ; } } m doing move = false ; return true ;
this . extensions = new array list < > ( ) ;
tuple incr dump = incremental load and verify ( db name , bootstrap dump . last repl id , repl db name ) ; verify if table not exist ( repl db name , unptned , meta store client mirror ) ; verify if table not exist ( repl db name , ptned _ tmp , meta store client mirror ) ; verify if table exist ( repl db name , unptned _ new , meta store client mirror ) ; verify if table exist ( repl db name , ptned , meta store client mirror ) ; verify if partition not exist ( repl db name , ptned , new array list < > ( arrays . as list ( 1 ) ) , meta store client mirror ) ; verify if partition not exist ( repl db name , ptned , new array list < > ( arrays . as list ( 2 ) ) , meta store client mirror ) ; verify if partition exist ( repl db name , ptned , new array list < > ( arrays . as list ( 20 ) ) , meta store client mirror ) ;
output size . set ( get build info recorder ( ) . get output size ( ) ) ; get build info recorder ( ) . add metadata ( build info . metadata key . output _ size , output size . get ( ) . to string ( ) ) ; if ( rule instanceof has post build steps ) { execute post build steps ( ( ( has post build steps ) rule ) . get post build steps ( build rule build context ) ) ; }
buffer . mark reader index ( ) ;
try { this . region = init hregion ( table name , method , conf , families ) ; } catch ( ioexception e ) { e . print stack trace ( ) ; fail ( got ioexception during init hregion , + e . get message ( ) ) ; }
int icon vertical position = ( canvas . size ( ) . y - texture . get height ( ) ) 2 ;
preconditions . check state ( batch . selected in use ) ; if ( is last group batch ) { return ; }
check point . await strict ( before - chunk , 30 , time unit . seconds ) ; topology manager . stop blocking all ( ) ; topology event future . get ( ) ;
twitter exception twitter exception = ( twitter exception ) throwable ;
if ( shd . get fill ( ) = null & & shd . get fill ( ) . equals ( auto ) ) { return compose css ( css _ name , + shd . get fill ( ) ) ; } else { return css _ null ; }
snapshot thread . sync ( ) ; test harness . close ( ) ;
string builder = new string builder ( ) ;
stream . close ( ) ;
boolean has exception = false ; try { dfstest util . create file ( dfs , new path ( quota dir21 , nqdir33 file2 ) , 2 * file len , replication , 0 ) ; } catch ( dsquota exceeded exception e ) { has exception = true ; } assert true ( has exception ) ;
return class name . replace ( ' . ' , ' ' ) + . class ;
stream record record = new stream record ( ) ;
assert equals ( 0 , scheduler . get number of localized assignments ( ) ) ; assert equals ( 0 , scheduler . get number of non localized assignments ( ) ) ; assert equals ( 15 , scheduler . get number of unconstrained assignments ( ) ) ; }
verify ( stor iosqlite ) . interceptors ( ) ;
long deadline millis = params . get timeout millis ( ) > 0 ? math . add exact ( system . current time millis ( ) , params . get timeout millis ( ) ) : 0 ; return new java subprocess ( builder . start ( ) , deadline millis ) ; }
assert . assert true ( batch . size = = 1 ) ; assert . assert true ( batch . selected [ 0 ] = = 0 ) ; batch = make string batch ( ) ; expr = new filter char scalar greater string group column ( new hive char ( new string ( red2 ) , 8 ) , 0 ) ; expr . evaluate ( batch ) ;
target federation target = target resolver . resolve ( new target spec ( specification , new federation options ( ) ) ) ;
cr = client . call procedure ( decode , 4 ) ; assert equals ( client response . success , cr . get status ( ) ) ; result = cr . get results ( ) [ 0 ] ; assert equals ( 1 , result . get row count ( ) ) ; assert true ( result . advance row ( ) ) ; assert equals ( volt db , result . get string ( 1 ) ) ;
if ( f dtdhandler = null & & f start dtdcalled ) { f dtdhandler . start dtd ( f entity scanner , null ) ; } if ( f dtdhandler = null ) { f dtdhandler . start external subset ( identifier , null ) ; } f entity manager . start external subset ( ) ; f entity store . start external subset ( ) ; f ext entity depth + + ; }
if ( head node = null ) { object graph . set head node ( head node ) ; } return object graph ;
shortcut encryption . keys keys = shortcut encryption . get keys ( this ) ;
double new current avg cluster latency = - 1 ; if ( total cluster call count > 0 ) { new current avg cluster latency = sum of cluster latencies total cluster call count ; } debug ( _ log , average cluster latency : , new current avg cluster latency ) ;
assert true ( can access ( manager , mil user , named tree a , access mode . read ) ) ;
for ( int line number = start line no ; line number < = end line no ; line number + + ) { final text block comment = cpp comments . get ( line number ) ; if ( comment = null & & comment . intersects ( start line no , start col no , end line no , end col no ) ) { has intersection = true ; break ; } } return has intersection ;
assert echo ( result , 02 - + collections . empty _ list . size ( ) ) ; }
zone offset offset = id _ cache . get ( offset id ) ;
assert true ( double . is na n ( ( double ) exec ( double x = 1 . 0 ; double y = 0 . 0 ; return x % y ; ) ) ) ;
for ( int i = listeners . length - 2 ; i > = 0 ; i - = 2 ) { if ( listeners [ i ] = = change listener . class ) { lazily create the event : if ( change event = = null ) change event = new change event ( this ) ; ( ( change listener ) listeners [ i + 1 ] ) . state changed ( change event ) ; } } }
assert . assert equals ( true , node labels . contains all ( copy . get node labels ( ) ) ) ;
if ( tleft . is simple ( ) | | tleft instanceof result tree type & & tright instanceof node set type ) { swap arguments ( ) ; }
method builder . add annotation ( new annotation metadata builder ( spring java type . primary ) ) ; method builder . add annotation ( new annotation metadata builder ( spring java type . bean ) ) ;
segment data manager . _ responses . add ( commit failed ) ; segment data manager . _ responses . add ( commit success ) ; final long lease time = 50000 l ;
while ( ( num bytes = bis . read ( buffer , length , 4096 ) ) > = 0 ) { length + = num bytes ;
if ( current scroll value = = 0 ) { view . set state ( state . overscrolling ) ; } view . set header scroll ( ( int ) ( scale factor * ( current scroll value + new scroll value ) ) ) ; } } else if ( new scroll value > ( scroll range + fuzzy threshold ) ) {
if ( enable default acceptor ) { executor . shutdown now ( ) ; }
parsable byte array . read unsigned long to long ( ) ; assert equals ( test _ data . length , parsable byte array . get position ( ) ) ;
of ( search node health ( green ) , search node health ( red ) ) ,
bundle data . get ( bundle ) . update ( stats ) ;
main handler . post ( new runnable ( ) { @ override public void run ( ) { add view to window ( image view ) ; glide app . with ( context ) . load ( gif drawable ) . listener ( wait for load ) . override ( target . size _ original ) . into ( image view ) ; } } ) ; wait for load . await ( ) ; gif drawable drawable from view = ( gif drawable ) image view . get drawable ( ) ;
services = service filter . apply ( services ) ;
stored event handler storing event handler = new stored event handler ( ) ; reporter . remove handler ( fail fast handler ) ; reporter . add handler ( storing event handler ) ; final artifact out = create tree artifact ( output ) ;
connectivity manager . unregister network callback ( ( connectivity manager . network callback ) null ) ;
set content handler ( null ) ;
int id = 0 ; while ( true ) {
zoom controller . get zoom controls ( ) . set visibility ( view . gone ) ; } else {
return negate ( ( non leaf expression node ) src ) ; }
rotate left ( grand parent ) ;
string region name = table . get region locations ( ) . first key ( ) . get encoded name ( ) ; hregion region = test _ util . get rsfor first region in table ( table name ) . get from online regions ( region name ) ; store store = region . get stores ( ) . values ( ) . iterator ( ) . next ( ) ; cache config cache conf = store . get cache config ( ) ; cache conf . set cache data on write ( true ) ; cache conf . set evict on close ( true ) ; block cache cache = cache conf . get block cache ( ) ;
string fmsg = xslmessages . create xpathmessage ( xpatherror resources . er _ getting _ unknown _ feature , new object [ ] { name , class _ name } ) ; throw new xpath factory configuration exception ( fmsg ) ;
return curr ;
read value before key ( records1st block + 10 ) ;
task = task service . create task query ( ) . or ( ) . task owner like ignore case ( % \ \ % % ) . process definition id ( undefined ) . single result ( ) ; assert not null ( task ) ; assert equals ( task1 . get id ( ) , task . get id ( ) ) ; task = task service . create task query ( ) . or ( ) . task owner like ignore case ( % \ \ _ % ) . process definition id ( undefined ) . single result ( ) ; assert not null ( task ) ; assert equals ( task2 . get id ( ) , task . get id ( ) ) ;
bcpgoutput stream buffered output = new bcpgoutput stream ( signature destination ) ;
cm content node . checkout ( ) ;
final configuration service cs = metadata . get metadata building options ( ) . get service registry ( ) . get service ( configuration service . class ) ; params . put ( available settings . prefer _ pooled _ values _ lo , cs . get setting ( available settings . prefer _ pooled _ values _ lo , standard converters . boolean , false ) ) ;
assert equals ( 0 , field1 . read ( ) ) ;
if ( boss group = null ) { boss group . shutdown gracefully ( ) ; boss group = null ; }
for ( udp endpoint p : socket endpoints . values ( ) ) { does it match the filter? if ( filter = null & & filter . apply ( p ) ) continue ; send the data p . send ( data ) ; } }
if ( testing util . get cache loader ( cache ) instanceof advanced cache expiration writer ) { assert equals ( v , event . get value ( ) ) ; assert not null ( event . get metadata ( ) ) ; }
if ( ( this obj instanceof xmlobject impl ) ) throw incompatible call error ( f ) ;
verify ( ctrl file ) . delete ( ) ;
final list < jcomponent > additional menus = new array list < jcomponent > ( ) ; final visual coverage action action = new visual coverage action ( graph frame ) ;
file sys . check path ( new path ( hdfs : + add . get host name ( ) . to upper case ( ) + : + add . get port ( ) ) ) ;
found book = found book . replace all ( amresh , saurabh ) ; string updated book = rest client . update entity ( session token , found book , book ) ; assert . assert not null ( updated book ) ; assert . assert true ( updated book . index of ( saurabh ) > 0 ) ;
c . gridwidth = 1 ; c . gridy = 2 ; c . gridx = 0 ; p entry . add ( new label ( use search words ) , c ) ; g all words = new checkbox group ( ) ; checkbox [ ] checkboxes = new checkbox [ 2 ] ;
for ( int i = 0 ; i < 8 ; i + + ) { value [ i ] = 0 ; }
tv command string = provider . get tvcommand ( item name , command . to string ( ) ) ;
if ( this . state = to state ) { system . out . println ( get name ( ) + enter state : + to state ) ; tcputils . log ( level . info , = = = = = = = = + get name ( ) + enter state : + to state + = = = = = = = = ) ; this . state = to state ; on pre state change ( to state ) ; on state change ( ) ; } }
operation = find cache operation ( method , target class ) ; if ( operation = null ) { return operation ; } }
esc set . replaceable array = false ; } break ; case reg ops . put _ static :
total data emitted in bytes + = tuple size in bytes ; }
if ( extension . char at ( 0 ) = = ' . ' ) { extension = extension . substring ( 1 ) ; } return extension ; }
admin operations protocol . refresh queue acls ( ) ; return 0 ; }
device = get first device ( providers , device class , false , false ) ; if ( device = null ) { return device ; } if ( device class = = receiver . class ) { try to get synthesizer device = get first device ( providers , device class , true , false ) ; if ( device = null ) { return device ; } } return null ;
try ( ar archive input stream stream = new ar archive input stream ( new file input stream ( filesystem . resolve ( output ) . to file ( ) ) ) ) { ar archive entry entry = stream . get next ar entry ( ) ; verify that the input names are relative paths from the outputs parent dir . assert that ( entry . get name ( ) , matchers . equal to ( output . get parent ( ) . relativize ( input ) . to string ( ) ) ) ; }
put all invokers ( new java data . invoker lookups ) ; if ( exclude classes ) { put all class definitions ( new java data . class lookups ) ; }
v ret = merger . merge ( new array list < v > ( ) , unflushed , this ) ;
index access . clear parents ( ) ;
if ( i < m text . length ( ) ) { if ( character utils . stay here ( i , different list ) ) { int alpha = ( int ) ( 255f char time * ( progress * duration - char time * i most count ) ) ; if ( alpha > 255 ) alpha = 255 ; if ( alpha < 0 ) alpha = 0 ; float size = m text size * 1f char time * ( progress * duration - char time * i most count ) ; if ( size > m text size ) size = m text size ; if ( size < 0 ) size = 0 ; m paint . set alpha ( alpha ) ; m paint . set text size ( size ) ; float width = m paint . measure text ( m text . char at ( i ) + ) ; canvas . draw text ( m text . char at ( i ) + , 0 , 1 , offset + ( gap list . get ( i ) - width ) 2 , start y , m paint ) ; } offset + = gap list . get ( i ) ; }
fetch trace = new string builder ( url : + url + ; status code : + code + ; bytes received : + content . length ) ;
final collection < string > dirty files = arrays . as list ( not - a - pom . txt ) ;
test plan follower ( true ) ;
trust manager [ ] trustmanagers = tmfactory . get trust managers ( ) ; for ( int i = 0 ; i < trustmanagers . length ; i + + ) { if ( trustmanagers [ i ] instanceof x509 trust manager ) { trustmanagers [ i ] = new custom x509 trust manager ( ( x509 trust manager ) trustmanagers [ i ] ) ; } } context . init ( new managers , trustmanagers , this . rand ) ; if ( log . is debug enabled ( ) ) { string [ ] d ciphers = context . get socket factory ( ) . get default cipher suites ( ) ; string [ ] s ciphers = context . get socket factory ( ) . get supported cipher suites ( ) ; int len = ( d ciphers . length > s ciphers . length ) ? d ciphers . length : s ciphers . length ; for ( int i = 0 ; i < len ; i + + ) { if ( i < d ciphers . length ) { log . debug ( default cipher : { } , d ciphers [ i ] ) ; } if ( i < s ciphers . length ) { log . debug ( supported cipher : { } , s ciphers [ i ] ) ; } } } return context ;
cluster event bus . post ( index set created event . create ( saved config ) ) ; log . debug ( successfully updated index set : { } , saved config ) ;
return immutable set . < e > of ( first ) ; }
ctx . send upstream ( e ) ; }
class path . add ( entry ) ; if ( configuration end ( ) ) { return class path ; }
store buffer as chunk ( this . first chunk buffer , 0 ) ;
while ( iter . has next ( ) ) { get the next command line token string token = ( string ) iter . next ( ) ; handle long option - - foo or - - foo = bar if ( token . starts with ( - - ) ) { int pos = token . index of ( ' = ' ) ; string opt = pos = = - 1 ? token : token . substring ( 0 , pos ) ; - - foo if ( options . has option ( opt ) ) { process non option token ( token , stop at non option ) ; } else { tokens . add ( opt ) ; if ( pos = - 1 ) { tokens . add ( token . substring ( pos + 1 ) ) ; } else { current option = options . get option ( opt ) ; } } } single hyphen else if ( - . equals ( token ) ) { tokens . add ( token ) ; } else if ( token . starts with ( - ) ) { if ( token . length ( ) = = 2 | | options . has option ( token ) ) { process option token ( token , stop at non option ) ; } requires bursting else { burst token ( token , stop at non option ) ; } } else { process non option token ( token , stop at non option ) ; } gobble ( iter ) ; } return ( string [ ] ) tokens . to array ( new string [ tokens . size ( ) ] ) ;
result = ( ipersistable ) the class . new instance ( ) ;
if ( state . get ( trigger _ state _ key ) = null ) { ( ( trigger policy ) trigger policy ) . restore state ( state . get ( trigger _ state _ key ) ) ; }
node list child nodes = element . get child nodes ( ) ; for ( int i = 0 ; i < child nodes . get length ( ) ; i + + ) { node node = child nodes . item ( i ) ; if ( node . get node type ( ) = node . element _ node ) { continue ; } element child element = ( element ) node ; string local name = child element . get local name ( ) ; string namespace uri = get namespace uri ( child element ) ; if ( common policy parser . namespace . equals ( namespace uri ) ) { throw new exception ( transfomations element is invalid ) ; } else if ( namespace . equals ( namespace uri ) ) { if ( provide _ devices _ element . equals ( local name ) ) { transfomations . set device permission ( device permission from element ( child element ) ) ; } else if ( provide _ services _ element . equals ( local name ) ) { transfomations . set service permission ( service permission from element ( child element ) ) ; } else if ( provide _ persons _ element . equals ( local name ) ) { transfomations . set person permission ( person permission from element ( child element ) ) ; } else { there are a lot of elements without good examples , so just put them in any elements as temporary solution . transfomations . get any ( ) . add ( child element ) ; } } else { any transfomations . get any ( ) . add ( child element ) ; } } return transfomations ;
storage dir . mkdir ( ) ;
for ( int i = 0 ; i < 10 ; i + + ) { mm1 . put ( ping - address , instance1 - + i ) ; }
table request = new jtable ( request model ) ; jmeter utils . apply hi dpi ( table request ) ; table request . set tool tip text ( jmeter utils . get res string ( textbox _ tooltip _ cell ) ) ; non - nls - 1 table request . add mouse listener ( new text box double click ( table request ) ) ; set first column preferred and max width ( table request ) ;
if ( database = null ) { return ; }
immutable list . builder < accumulo column handle > new column list = immutable list . builder ( ) ;
implementation class = resolve class ( default class name , target class , property name , false ) ; logger . info ( using { } as default implementation for { } , default class name , target class . get canonical name ( ) ) ; } }
fatals . push ( id ) ;
for ( entry < string , string > entry : query . get added prepared statements ( ) . entry set ( ) ) { string encoded key = url encode ( entry . get key ( ) ) ; string encoded value = url encode ( entry . get value ( ) ) ; response . header ( presto _ added _ prepare , encoded key + ' = ' + encoded value ) ; }
this . handler . handle message ( create with ( simp message type . message , joe , 123 , queue foo ) ) ;
assert job ( job queue , after re - insert , if job is still in the q , it should be returned , ids [ i ] , holders [ i ] ) ;
broadcast list activity fragment fragment = new broadcast list activity fragment ( ) ; bundle arguments = fragment utils . ensure arguments ( fragment ) ; arguments . put string ( extra _ user _ id _ or _ uid , user id or uid ) ; arguments . put parcelable ( extra _ user , user ) ; arguments . put string ( extra _ topic , topic ) ; return fragment ;
signal container request signal req = signal container request . new instance ( c id , command ) ; list < signal container request > reqs = new array list < > ( ) ; reqs . add ( signal req ) ; container manager . handle ( new cmgr signal containers event ( reqs ) ) ; final argument captor < container signal context > signal context captor = argument captor . for class ( container signal context . class ) ;
input stream is = bitstamp adapter test . class . get resource as stream ( marketdata example - trades - data . json ) ;
if ( query handle = null ) { wevtapi . instance . evt close ( query handle ) ; }
if ( catalog = = null ) { throw new illegal argument exception ( can ' t create catalog context with null catalog . ) ; } if ( settings = = null ) { throw new illegal argument exception ( cant ' t create catalog context with null cluster settings ) ; } this . catalog = catalog ;
for ( int i = 1 ; i < matches . length ( ) ; i + + ) { target . remove child ( matches . item ( i ) . child index ( ) ) ; }
current pos + = random int between ( 0 , 20 ) ; last end = end ; }
binder . bind ( commands _ , this ) ;
boolean is multiple = r ves . length > 1 ;
string cache value = exchange . get context ( ) . get type converter ( ) . convert to ( string . class , cache . get ( cache key ) . get object value ( ) ) ; string replaced token string = new string ( buffer ) . replace all ( replacement token , cache value ) ; log . trace ( replaced token string = { } , replaced token string ) ;
if ( is chunked ) { log . error ( transfer - encoding header set , the value is not supported : + transfer encoding header value ) ; } }
student oracle no sqldouble primitive student = new student oracle no sqldouble primitive ( ) ; student . set age ( ( short ) get random value ( short . class ) ) ; student . set id ( ( double ) get random value ( double . class ) ) ; student . set name ( ( string ) get random value ( string . class ) ) ; em . persist ( student ) ; em . close ( ) ; }
geo server resource loader resource loader = easy mock . create mock ( geo server resource loader . class ) ;
if ( f start container = = f end container ) return traverse same container ( how ) ;
mp . seek to ( 0 ) ; }
assert true ( inherits . get age ( ) = = 1 ) ; test bean inherits2 = ( test bean ) child . get bean ( inherited test bean ) ; assert true ( inherits2 = inherits ) ; }
rmapp attempt attempt = mock rm . wait for attempt scheduled ( app , rm ) ; system . out . println ( new app attempt launched + attempt . get app attempt id ( ) ) ;
if ( is platform ( aix ) ) { return ; } final management agent management agent = context . get management strategy ( ) . get management agent ( ) ;
new socket ( inet address . get local host ( ) , registry port ) . close ( ) ;
chroot fs . delete on exit ( chroot path ) ;
int str len = read len16 ( buffer ) ; string str = buffers . read string ( buffer , str len ) ;
file file = new file ( fname ) ; if ( file . exists ( ) ) file = new file ( target + fname ) ; if ( file . exists ( ) ) file = new file ( . . + fname ) ; if ( file . exists ( ) ) file = new file ( . . . . + fname ) ; if ( file . exists ( ) ) file = new file ( . . target + fname ) ; if ( file . exists ( ) ) file = null ; return file ;
color = f preference store . get boolean ( abstract text editor . preference _ color _ background _ system _ default ) ? null : create color ( f preference store , abstract text editor . preference _ color _ background , styled text . get display ( ) ) ; styled text . set background ( color ) ; if ( f background color = null ) f background color . dispose ( ) ;
if ( crs . get axis order ( crs ) = = axis order . north _ east ) { axis flip = true ; }
if ( end < start ) { if ( cx . get language version ( ) = context . version _ 1 _ 2 ) { double temp = start ; start = end ; end = temp ; } else {
if ( res info . get native name ( ) = = null & & res info . get name ( ) = null ) { res info . set native name ( res info . get name ( ) ) ; }
assert that ( layer . get default style ( ) . get name ( ) , equal to ( raster ) ) ; buffered image image = get as image ( wms reflect?layers = test : test123 & format = image png & width = 200 , image png ) ; file expected = new file ( src test resources test123 - simple - rgb . png ) ; image assert . assert equals ( expected , image , 1000 ) ; }
asm util . pop ( v , type ) ; continue ; } }
int shared groups = 0 ; for ( string group id : other . group ids ) { if ( group ids . add ( group id ) = = false ) { shared groups + + ; } } count = count + other . count - shared groups ; return this ;
if ( args . length = = 0 ) { system . out . println ( an example program must be given as the + first argument . ) ; print usage ( programs ) ; system . exit ( - 1 ) ; }
. set generated manifest ( resource apk . get primary resource ( ) . get manifest ( ) ) . set manifest ( rule context . get prerequisite artifact ( manifest , mode . target ) ) . set java package ( get java package ( rule context ) ) . set resource apk ( resource apk . get artifact ( ) ) ; } else {
for ( int i = 0 ; i < num threads ; i + + ) { all [ i ] . start ( ) ; }
indarray mask = nd4j . create ( new double [ ] [ ] { { 1 , 1 , 0 } , { 1 , 0 , 0 } , { 1 , 1 , 0 } , { 1 , 0 , 0 } , { 1 , 1 , 1 } } ) ; indarray labels = nd4j . create ( new double [ ] [ ] { { 1 , 1 , 1 } , { 0 , 0 , 0 } , { 1 , 1 , 1 } , { 0 , 1 , 1 } , { 1 , 0 , 1 } } ) ;
tkey key for value = get key ( value ) ;
if ( c = = ' ' | | c = = ' \ ' ' ) {
switch ( plugin . type ( ) ) { case source : case sink : case connector : return prune plugin name ( plugin , connector ) ; default : return prune plugin name ( plugin , plugin . type ( ) . simple name ( ) ) ; } }
this . left parent . set first child ( get handle next ( ) ) ;
for ( ; subtree . last index of ( ' . ' ) > = 0 ; i + + ) { subtree = subtree . substring ( 0 , subtree . last index of ( ' . ' ) ) ; } return i ; }
assert . assert equals ( 1 , loaded app0 . get app attempts ( ) . size ( ) ) ; application report app report = verify app report after rmrestart ( app0 , rm2 ) ; assert . assert equals ( app0 . get diagnostics ( ) . to string ( ) , app report . get diagnostics ( ) ) ; assert . assert equals ( tracking url , loaded app0 . get current app attempt ( ) . get original tracking url ( ) ) ; }
context context = ( context ) event . get source ( ) ; string host name = context . get parent ( ) . get name ( ) ; string context path = context . get path ( ) ; if ( . equals ( context path ) ) { context path = ; }
list . add ( generate value ( list type , 200 ) ) ; } } ) ; final atomic integer listener called count = new atomic integer ( 0 ) ;
tokens = dfs . add delegation tokens ( renewer , null ) ;
journal = new journal ( conf , test _ log _ dir , jid , startup option . regular , mock error reporter ) ;
database file = found . get ( ) . file ( ) . get absolute path ( ) ;
b . bind ( port ) . sync ( ) . channel ( ) . close future ( ) . sync ( ) ;
final byte [ ] rc _ magic = new byte [ ] { ( byte ) ' r ' , ( byte ) ' c ' , ( byte ) ' f ' } ;
assert equals ( null , multi . get type ( null ) ) ; }
if ( _ terminate = = true ) { create a new instance of run time exception final int einit = cpg . add methodref ( java . lang . runtime exception , < init > , ( ljava lang string ; ) v ) ; il . append ( new new ( cpg . add class ( java . lang . runtime exception ) ) ) ; il . append ( dup ) ; il . append ( new push ( cpg , termination forced by an + xsl : message instruction ) ) ; il . append ( new invokespecial ( einit ) ) ; il . append ( athrow ) ; }
return new singleton immutable set < e > ( elements . get ( 0 ) , hash code ) ;
dc . delete columns ( fam1 , col1 ) ; r . delete ( dc , null , true ) ; r . flushcache ( ) ; add content ( hri , bytes . to string ( fam1 ) , bytes . to string ( col1 ) , second row bytes , third row bytes ) ;
byte [ ] ni transaction id = headers . get text string ( pdu headers . transaction _ id ) ; if ( null = = ni transaction id ) { return false ; } break ;
try { state mgr = new processor state manager ( id , partitions , is standby , state directory , topology . store to changelog topic ( ) , changelog reader , eos enabled , log context ) ; } catch ( final ioexception e ) { throw new processor state exception ( string . format ( % s error while creating the state manager , log prefix ) , e ) ; }
long start = time utils . nano time ( ) ; for ( int j = 0 ; j < num _ mb ; j + + ) { sb . clear ( ) ; for ( int i = 0 ; i < len ; i + + ) sb . put ( shorts [ i ] ) ; } gdx . app . log ( buffer utils test , short buffer relative put : + ( time utils . nano time ( ) - start ) 1000000000 . 0f ) ;
generator1 . reset ( ) ;
if ( the index . get type ( ) = other index . get type ( ) ) { mismatched attrs . add ( index type ( hash vs tree ) ) ; }
line number info . u2start pc = new instruction offset ( line number info . u2start pc ) ; }
for ( string plugin setting key value : plugin settings opt list ) { string [ ] key value = plugin setting key value . split ( = , 2 ) ; if ( key value . length = 2 ) { throw new exception ( invalid setting : + plugin setting key value ) ; } plugin option values . put ( key value [ 0 ] , key value [ 1 ] ) ; } return plugin option values ;
minecraft forge . event _ bus . register ( this ) ; }
ret . put all ( mp ) ;
ctftn edn ftn = ( ctftn edn ) footnotes . get footnote ( ) . get ( pos ) ;
assert equals ( puts were replicated back , 2 , get count ( htable1 , put ) ) ;
if ( ( c = = ' ' ) | | ( c = = ' \ \ ' ) ) { buf . append ( ' \ \ ' ) ; }
filter = new dependent column filter ( families [ 0 ] , qualifier , true ) ; scan = new scan ( ) ; scan . set filter ( filter ) ; scan . set max versions ( integer . max _ value ) ; verify scan ( scan , 2 , 3 ) ;
final int child count = get child count ( ) ; for ( int i = 0 ; i < child count ; i + + ) { final view child = get child at ( i ) ; final layout params lp = ( layout params ) child . get layout params ( ) ; if ( lp . is decor ) { lp . width factor = 0 . f ; } } set current item internal ( new curr item , false , true ) ;
ticker . advance ( 1 , milliseconds ) ;
org . apache . hadoop . mapreduce . counter count2 = counter group . find counter ( unknown ) ;
fill ( in , buf , 6 ) ;
double learn rate = 0 . 1 ;
day of month = get day of month ( day of month string ) ;
{ string recent files label = j edit . get property ( options . general . recent files ) ; int recent files value = j edit . get integer property ( recent files ) ; spinner model model = new spinner number model ( recent files value , 0 , integer . max _ value , 1 ) ; recent files = new jspinner ( model ) ; add component ( recent files label , recent files ) ; }
assert null ( buffer . get next non blocked ( ) ) ; assert null ( buffer . get next non blocked ( ) ) ; buffer . cleanup ( ) ;
string documentation dir = properties util . get project properties ( ) . get ( project . documentation . dir ) ;
return property . ordinal ( ) ;
file logger module . unprepare ( ) ;
} , ( global , min ) - > { assert equals ( 0 , global . get doc count ( ) ) ; assert equals ( double . positive _ infinity , min . get value ( ) , 0 ) ; } ) ; }
list . add ( c . block . get block name ( ) + \ t + snap ) ;
if ( repositories . is empty ( ) & & subsystems . is empty ( ) ) { logger . log ( level . info , 0 dependencies were found on selected ' roo addon suite ' ) ; logger . log ( level . info , ) ; return ; }
if ( reader = = null ) { input stream stream = get class ( ) . get resource as stream ( template ) ; if ( stream = = null ) { stream = get class ( ) . get class loader ( ) . get resource as stream ( template ) ; } reader = stream = null ? new input stream reader ( stream ) : null ; }
assert equals ( \ hello world \ , json . to string ( utf - 8 ) ) ;
writer writer = new string writer ( ) ;
for ( i = 0 ; i < names length ; i + + ) { int gen type = m _ expanded name table . get expanded type id ( uris [ i ] , names [ i ] , types [ i ] , true ) ; if ( gen type > = 0 & & gen type < ex length ) { result [ gen type ] = ( short ) ( i + dtm . ntypes ) ; } } return result ;
if ( m _ evaluate thread = null ) { m _ evaluate thread . interrupt ( ) ; m _ evaluate thread . stop ( ) ; m _ evaluate thread = null ; m _ visual . set static ( ) ; }
decoder . destroy ( ) ;
fire tree structure changed ( this , path , null , ( object [ ] ) null ) ;
if ( existing xattrs = null ) { for ( xattr existing : existing xattrs ) { boolean already set = false ; for ( xattr set : to set ) { if ( set . equals ignore value ( existing ) ) { already set = true ; break ; } } if ( already set ) { x attrs . add ( existing ) ; if ( is user visible ( existing ) ) { user visible xattrs num + + ; } } } } if ( user visible xattrs num > fsd . get inode xattrs limit ( ) ) { throw new ioexception ( cannot add additional xattr to inode , + would exceed limit of + fsd . get inode xattrs limit ( ) ) ; }
if ( i = 0 ) { fold animation fold animation = new fold animation ( fold animation . fold animation mode . unfold _ down , m camera height , part90degree animation duration ) . with start offset ( next delay ) . with interpolator ( new decelerate interpolator ( ) ) ;
if ( counter . get count ( ) > 0 ) {
int interval end = analyzer result . tree size ; annotator context context = new annotator context ( interval end , analyzer result . size map ) ; assign interval labels ( predicate , interval . interval _ begin , interval end , false , context ) ; return new predicate tree annotations ( analyzer result . min feature , interval end , context . intervals , context . intervals with bounds , context . feature conjunctions ) ; }
final int depth = handlers . get oid depth ( h ) ; for ( enumeration < snmp mib sub request > rqs = handlers . get sub requests ( h ) ; rqs . has more elements ( ) ; ) {
while ( object . class . get name ( ) . equals ( base returned class or element . get name ( ) ) ) { property container prop container = new property container ( base returned class or element , x class processed , property accessor ) ; add elements of class ( base class elements , prop container , building context ) ; for ( property data element : base class elements ) { ordered base class elements . put ( element . get property name ( ) , element ) ; } base returned class or element = base returned class or element . get superclass ( ) ; } }
log . debug ( fs state after snapshot : ) ; util . get hbase cluster ( ) . get master ( ) . get master file system ( ) . log file system state ( log ) ; snapshot testing utils . confirm snapshot valid ( util , protobuf util . create hbase protos snapshot desc ( snapshots . get ( 0 ) ) , table _ name , test _ fam ) ; admin . delete snapshot ( snapshot ) ; snapshots = admin . list snapshots ( ) ; snapshot testing utils . assert no snapshots ( admin ) ; }
try { rw lock . write lock ( ) . lock ( ) ; controller paths = c paths ; parsed mtab = new mtab ; } finally { rw lock . write lock ( ) . unlock ( ) ; } }
for ( int i = 0 ; i < property span ; i + + ) { if ( property types [ i ] . is dirty ( get property value ( x , i ) , get property value ( y , i ) , session ) ) { return true ; } } return false ; }
base cfg = new marshalling configuration ( ) ;
dob . write utf ( protocol name ) ; data input buffer dib = new data input buffer ( ) ;
if ( n = = null ) { self . set peer state ( ( proposed leader = = self . get id ( ) ) ? server state . leading : learning state ( ) ) ; vote end vote = new vote ( proposed leader , proposed zxid , proposed epoch ) ; leave instance ( end vote ) ; return end vote ; }
m no activty this period container . set visibility ( view . gone ) ;
min time val = math . min ( min time val , time value ) ;
range set < long > timeline = tree range set . create ( ) ; for ( event pair pair : event pairs ) { if ( pair . is complete ( ) & & pair . get elapsed time ms ( ) > 0 ) { timeline . add ( range . open ( pair . get start time ( ) , pair . get end time ( ) ) ) ; } } for ( range < long > range : timeline . as ranges ( ) ) { total time + = range . upper endpoint ( ) - range . lower endpoint ( ) ; } return total time ;
try { string text = load text ( new file input stream ( file ) ) ; string name = as component name ( file ) ; matcher matcher = label _ pattern . matcher ( text ) ;
check access allowed ( httpclient , war b2 + ejbservlet ) ;
cache0 . put ( new magic key ( cache ( 1 ) , cache ( 2 ) ) , not - local ) ; cache0 . put ( new magic key ( cache ( 0 ) , cache ( 1 ) ) , local ) ; check point iterator cp = new check point ( ) ;
this . chars read + + ;
return hard concurrency limit ; }
updater . update material ( dependency material ) ; mockito . verify ( dependency material source dao , times ( 2 ) ) . get passed stages after ( any ( string . class ) , any ( dependency material . class ) , any ( pagination . class ) ) ;
if ( final cert ) { * check if ca cert * if ( ca cert ) throw new cert path validator exception ( cert is not a ca cert ) ; * if the certificate was not self - issued , verify that * remaining certs is greater than zero * if ( ( current state . remaining cacerts < = 0 ) & & x509 cert impl . is self issued ( cert ) ) { throw new cert path validator exception ( path len constraint violated , path too long , null , null , - 1 , pkixreason . path _ too _ long ) ; } * * check key usage extension ( only if ca cert and not final cert ) * key checker . verify cakey usage ( cert ) ; } else { * * if final cert , check that it satisfies specified target * constraints * if ( target cert constraints . match ( cert ) = = false ) { throw new cert path validator exception ( target certificate + constraints check failed ) ; } }
instructions . add ( reil helpers . create sub ( offset + 2 , target size , rotate mask , target size , 1 , target size , rotate mask less one ) ) ; instructions . add ( reil helpers . create bisz ( offset + 3 , target size , rotate mask less one , operand size . byte , rotate mask one ) ) ;
if ( ( double statistics . has minimum ( ) & & double . is na n ( double statistics . get minimum ( ) ) ) | | ( double statistics . has maximum ( ) & & double . is na n ( double statistics . get maximum ( ) ) ) | | ( double statistics . has sum ( ) & & double . is na n ( double statistics . get sum ( ) ) ) ) { return null ; } return new double statistics ( double statistics . has minimum ( ) ? double statistics . get minimum ( ) : null , double statistics . has maximum ( ) ? double statistics . get maximum ( ) : null ) ; }
change presence status for contact ( contact , get presence status ( ) ) ; return contact ;
end x2 = center x ; end y2 = dot bottom y ; control x1 = end x1 - ( ( 1 - adjusted fraction ) * dot radius ) ; control y1 = end y1 ; control x2 = end x1 - ( adjusted fraction * dot radius ) ; control y2 = end y2 ; unselected dot path . cubic to ( control x1 , control y1 , control x2 , control y2 , end x2 , end y2 ) ; }
start rms with customized client rmservice ( ) ; mock nm nm1 = new mock nm ( 127 . 0 . 0 . 1 : 1234 , 15120 , rm1 . get resource tracker service ( ) ) ; nm1 . register node ( ) ;
covering query q5 = new covering query ( arrays . as list ( tq1 , tq1 , tq2 ) , vs ) ; covering query q6 = new covering query ( arrays . as list ( tq1 , tq2 , tq2 ) , vs ) ; query utils . check unequal ( q5 , q6 ) ;
assert not null ( jaas file , jaas file ) ; string conf filename = system . get property ( environment . jaas _ conf _ key ) ; assert equals ( jaas file . get absolute path ( ) , conf filename ) ; }
swap ( p , max ) ;
current animation . end ( ) ;
job . set boolean ( mapreduce . fileoutputcommitter . marksuccessfuljobs , false ) ; job client . run job ( job ) ;
query q = em . create query ( no clause ) ; list < rdbms prime user > results = q . get result list ( ) ; assert . assert equals ( 1 , results . size ( ) ) ;
if ( has negative cycle ( ) ) { for ( int v = 0 ; v < g . v ( ) ; v + + ) { for ( directed edge e : g . adj ( v ) ) { int w = e . to ( ) ; for ( int i = 0 ; i < g . v ( ) ; i + + ) { if ( dist to [ i ] [ w ] > dist to [ i ] [ v ] + e . weight ( ) ) { system . err . println ( edge + e + is eligible ) ; return false ; } } } } } return true ;
create stream ( entry set ) . map to long ( to long ) . sorted ( ) . for each ordered ( list : : add ) ;
int n = compressed direct buf . remaining ( ) ; if ( n > 0 ) { n = math . min ( n , len ) ; ( ( byte buffer ) compressed direct buf ) . get ( b , off , n ) ; return n ; }
verify workspace ( new long [ ] [ ] [ ] { { { - 1 , - 1 , - 1 } , { ids [ 0 ] [ 1 ] [ 0 ] , ids [ 0 ] [ 1 ] [ 1 ] , ids [ 0 ] [ 1 ] [ 2 ] } , { ids [ 0 ] [ 2 ] [ 0 ] , ids [ 0 ] [ 2 ] [ 1 ] , ids [ 0 ] [ 2 ] [ 2 ] } , { ids [ 0 ] [ 3 ] [ 0 ] , ids [ 0 ] [ 3 ] [ 1 ] , ids [ 0 ] [ 3 ] [ 2 ] } , } , { { ids [ 0 ] [ 1 ] [ 3 ] } , } } ) ;
this . api = new forced user api ( this ) ;
assert same ( mode . byte , encoder . choose mode ( shift jisstring ( new byte [ ] { 0xe , 0x4 , 0x9 , 0x5 , 0x9 , 0x61 } ) ) ) ;
buf . append ( domain ) ; }
i + + ; }
set sqlvalue ( node , text , discrim ) ; }
pstmt = conn . prepare statement ( select id , account _ id , data _ center _ id from user _ statistics ) ;
object [ ] wrapped integer values = new object [ ] { integer values } ; set integer values . invoke ( test object , wrapped integer values ) ; method get integer values = integers getter . get method ( _ pinpoint _ get integer array ) ;
revoke from table ( test _ util , testgroup _ 1 _ name , table name , test _ family , q1 ) ;
int new value = result + 1 ;
ret . append ( string . format ( \ t | - pid ppid pgrpid sessid cmd _ name + user _ mode _ time ( millis ) system _ time ( millis ) vmem _ usage ( bytes ) + rssmem _ usage ( pages ) full _ cmd _ line % n ) ) ; for ( process info p : process tree . values ( ) ) { if ( p = null ) { ret . append ( string . format ( processtree _ dump _ format , p . get pid ( ) , p . get ppid ( ) , p . get pgrp id ( ) , p . get session id ( ) , p . get name ( ) , p . get utime ( ) , p . get stime ( ) , p . get vmem ( ) , p . get rssmem page ( ) , p . get cmd line ( procfs dir ) ) ) ; } } return ret . to string ( ) ;
if ( _ sources conn . is bootstrap enabled ( ) ) { _ log . error ( no scn found on relay while no bootstrap services provided : ) ; _ log . error ( bootstrap services = + _ sources conn . get bootstrap services ( ) + ; bootstrap registrations = + _ sources conn . get bootstrap registrations ( ) ) ; if ( _ is read latest scn on error enabled ) { read from latest scn on error _ log . error ( read latest scn window on scnnot found exception is enabled . will start reading from the lastest scn window ) ; cur state . get relay connection ( ) . enable read from latest scn ( true ) ; _ current state . set relay fell off ( false ) ; cur state . switch to stream response done ( ) ; } else { _ log . fatal ( got scnnot found exception but read latest scn window and bootstrap are disabled ) ; _ remote exception handler . handle exception ( new bootstrap database too old exception ( known remote error ) ) ; enqueue message = false ; } } else { _ log . info ( requested scn + cp . get window scn ( ) + not found on relay ; switching to bootstrap service ) ; cur state . switch to bootstrap ( cp ) ; unified client stats unified client stats = _ sources conn . get unified client stats ( ) ; if ( unified client stats = null ) { unified client stats . set bootstrapping state ( true ) ; } } return enqueue message ;
if ( outlinks = null & & outlinks . size ( ) > 0 ) { retval = outlinks . to array ( new outlink [ 0 ] ) ; } else { retval = new outlink [ 0 ] ; } return retval ;
state state = parent . capture state ( ) ;
s . create query ( select cast ( e . the lost number as float ) from my entity e ) . list ( ) ;
if ( presence . get status ( ) = null & & presence . get status ( ) . contains ( jabber status enum . on _ the _ phone ) ) return jabber status enum . get status ( jabber status enum . on _ the _ phone ) ; else if ( presence . get status ( ) = null & & presence . get status ( ) . contains ( jabber status enum . in _ a _ meeting ) ) return jabber status enum . get status ( jabber status enum . in _ a _ meeting ) ; else return jabber status enum . get status ( jabber status enum . away ) ;
string v = ( pretty print ) ? data . trim ( ) : data ;
view helper . set alpha ( m current dismiss data . view , math . max ( 0f , math . min ( 1f , 1f - 2f * math . abs ( delta x ) m view width ) ) ) ; return true ;
this . next ( ) ;
throwable previous = exchange . get property ( exchange . exception _ caught , throwable . class ) ;
final string relative file path = file name . substring ( file name . last index of ( ' ' ) + 2 ) ; final jar file jar file = jar connection . get jar file ( ) ; final zip entry zip entry = jar file . get entry ( relative file path ) ; final input stream input stream = jar file . get input stream ( zip entry ) ; return input stream = = null ;
value = convert label value ( value ) ;
override one method swapped oom = ( override one method ) xbf . get bean ( override one method swapped return values ) ; test bean tb = swapped oom . get prototype dependency ( ) ; assert equals ( david , tb . get name ( ) ) ; tb = swapped oom . protected override singleton ( ) ; assert equals ( jenny , tb . get name ( ) ) ; }
r = ri > 255 ? 255 : ( ri < 0 ? 0 : ri ) ;
for ( torrent file tf : _ torrent files ) { long length = tf . raffile . length ( ) ; if ( tf . raffile . exists ( ) & & length = = tf . length ) { if ( listener = null ) listener . storage allocated ( this , length ) ; resume = true ; xxx could dynamicly check } else if ( length = = 0 ) { changed = true ; synchronized ( tf ) { allocate file ( tf ) ; close as we go so we don ' t run out of file descriptors try { tf . close raf ( ) ; } catch ( ioexception ioe ) { } } } else { string msg = file ' + tf . name + ' exists , but has wrong length ( expected + tf . length + but found + length + ) - repairing corruption ; if ( listener = null ) listener . add message ( msg ) ; _ log . error ( msg ) ; changed = true ; resume = true ; _ probably complete = false ; to force rw synchronized ( tf ) { random access file raf = tf . check raf ( ) ; raf . set length ( tf . length ) ; try { tf . close raf ( ) ; } catch ( ioexception ioe ) { } } } }
ft info . get attributes ( ) . clear ( ) ; list < string > type names = arrays . as list ( data store . get type names ( ) ) ;
if ( strip file extension & & ( tmp1 . to lower case ( locale . english ) . ends with ( . war ) | | tmp1 . to lower case ( locale . english ) . ends with ( . xml ) ) ) { tmp1 = tmp1 . substring ( 0 , tmp1 . length ( ) - 4 ) ; } base name = tmp1 ; string tmp2 ;
final coordinate reference system wgs84 = crs . decode ( epsg : 4326 , true ) ; envelope env = new envelope ( 8 , 9 , 40 , 41 ) ; polygon roi = jts . to geometry ( env ) ; assert true ( roi . is rectangle ( ) ) ; roi . set srid ( 4326 ) ; roi . set user data ( wgs84 ) ;
htable descriptor htd = new htable descriptor ( table name ) ; htd . add family ( new hcolumn descriptor ( test ) ) ;
matcher = pattern _ field . matcher ( s ) ;
return procedure call ; }
sources [ 12 ] . add ( mock buffer ) ;
log . debug ( when closing { } stream for { } , uri , reason , e ) ;
session factory remote factory = second node environment ( ) . get session factory ( ) ; account dao dao0 = new account dao ( use jta , local factory ) ; account dao dao1 = new account dao ( use jta , remote factory ) ; integer id = new integer ( 1 ) ; dao0 . create account ( dao0 . get smith ( ) , id , new integer ( 5 ) , dual node test . local ) ;
if ( prof = null ) prof . app step ( app step . state manager update ) ;
bean desc = config . introspect for creation ( type ) ; } } if ( deser = = null ) { value instantiator inst = find value instantiator ( ctxt , bean desc ) ; if ( inst . can create using default ( ) ) {
if ( default elevation needed ) { dimension info di = new dimension info impl ( ) ; di . set enabled ( true ) ; di . set presentation ( dimension presentation . list ) ; di . set units ( epsg : 5030 ) ; di . set unit symbol ( m ) ; di . set attribute ( elevation dimension . get start attribute ( ) ) ; ci . get metadata ( ) . put ( resource info . elevation , di ) ; }
int index = working copy of image . last index of ( ' @ ' ) ;
head = next ;
query id backfill4 = create backfill ( query runner ) ;
list < struct > replica assignments structs = new array list < > ( args . replicas assignments . size ( ) ) ; for ( map . entry < integer , list < integer > > partition replica assignment : args . replicas assignments . entry set ( ) ) { struct replica assignment struct = single request struct . instance ( replica _ assignment _ key _ name ) ; replica assignment struct . set ( partition _ id , partition replica assignment . get key ( ) ) ; replica assignment struct . set ( replica _ assignment _ replicas _ key _ name , partition replica assignment . get value ( ) . to array ( ) ) ; replica assignments structs . add ( replica assignment struct ) ; } single request struct . set ( replica _ assignment _ key _ name , replica assignments structs . to array ( ) ) ;
if ( available streams . contains ( in _ dictionary ) ) { if ( available streams . contains ( row _ group _ dictionary ) ) { checkpoints . put ( new stream id ( column , row _ group _ dictionary ) , new byte array stream checkpoint ( compressed , positions list ) ) ; } checkpoints . put ( new stream id ( column , row _ group _ dictionary _ length ) , new row group dictionary length stream checkpoint ( compressed , positions list ) ) ; if ( available streams . contains ( data ) ) { checkpoints . put ( new stream id ( column , data ) , create long stream checkpoint ( encoding , compressed , positions list ) ) ; } checkpoints . put ( new stream id ( column , in _ dictionary ) , new boolean stream checkpoint ( compressed , positions list ) ) ; } else { if ( available streams . contains ( data ) ) { checkpoints . put ( new stream id ( column , data ) , create long stream checkpoint ( encoding , compressed , positions list ) ) ; } }
if ( sourcepath . get name ( ) . starts with ( part - r ) ) { continue ; }
authorization indexer tester . allow only group ( project , group ) ;
type check ( line _ joiner . join ( * * @ return { generator < string > } * , function * gen ( ) { , return ; , } , var * * generator < string > * x = gen ( ) ; ) ) ;
output stream bos = null ; try { bos = new output stream ( new java . io . file output stream ( filename ) , base64 . encode ) ; bos . write ( data to encode ) ;
pos = size - max size ;
while ( pool . get completed task count ( ) < 2 ) { threads . sleep ( 1 ) ; }
ensure transport on channel ( remote channel request , peer ) ;
artifact hello = create source artifact ( hello ) ; file system utils . create directory and parents ( hello . get path ( ) . get parent directory ( ) ) ; file system utils . write content as latin1 ( hello . get path ( ) , content1 ) ; artifact goodbye = create derived artifact ( goodbye ) ; button button = create action button ( sets . new hash set ( hello ) , sets . new hash set ( goodbye ) ) ; button . pressed = false ;
collection < string > files = cp . get file names ( ) ;
match function . join ( next build side record , probe record , collector ) ;
final default entitlement cancelled add on entitlement = ( default entitlement ) entitlement api . get entitlement for id ( add on entitlement . get id ( ) , call context ) ;
if ( build utils . is primitive ( fld . get type name ( ) ) ) { mv . visit field insn ( getstatic , build utils . get internal type ( build utils . box ( fld . get type name ( ) ) ) , type , type . get descriptor ( class . class ) ) ; mv . visit ldc insn ( type . get type ( build utils . get type descriptor ( build utils . box ( fld . get type name ( ) ) ) ) ) ; } else { mv . visit ldc insn ( type . get type ( type . get descriptor ( fld . get type ( ) ) ) ) ; } mv . visit var insn ( iload , 1 ) ; mv . visit method insn ( invokeinterface , type . get internal name ( trait field tms . class ) , don field , type . get method descriptor ( type . get type ( object . class ) , type . get type ( string . class ) , type . get type ( trait type . class ) , type . get type ( string . class ) , type . get type ( class . class ) , type . boolean _ type ) , true ) ; mv . visit var insn ( astore , j ) ; mv . visit var insn ( aload , 0 ) ;
owners . add ( receiver . < string > make ( object _ type ) ) ;
else if ( argument values = null & & cur arg index < argument values . size ( ) ) { return argument values . get ( cur arg index + + ) ; }
for ( int i = 0 ; i < m _ instances . attribute ( index ) . num values ( ) ; i + + ) { for ( int j = 0 ; j < m _ instances . num classes ( ) ; j + + ) { sum counts [ j ] + = counts [ i ] [ j ] ; } }
extract parameters ( bulls eye corners ) ;
events . clear ( ) ; generator . generate events ( 1 , 20 , 500 , 10 , events ) ; event size = 71 , can append . long cwp1 = reflector . get current write position ( ) . get position ( ) ;
side input handler . add side input value ( view1 , values in window ( immutable list . of ( ciao , buongiorno ) , new instant ( 0 ) , window ) ) ; assert . assert that ( side input handler . get ( view1 , window ) , contains ( ciao , buongiorno ) ) ;
case http _ acceptor :
m reorder alarm listener . on alarm ( m reorder alarm ) ; m on scroll hint alarm . cancel alarm ( ) ;
int partition = p . get partition ( c , hconstants . empty _ byte _ array , 1 ) ;
animation spatial animation = new animation ( name , duration ) ; spatial animation . set tracks ( new spatial track [ ] { spatial track } ) ; return spatial animation ;
flags | = native . epollrdhup ;
int index = rbcollation tables . get entry ( entry table , group chars , fwd ) ;
group node . get children ( ) . set all ( ( ( jfxlist view < ? > ) new node ) . get groupnode ( ) , drop icon ) ;
if ( current key hash offset = current position in data file ) { print error ( verbose , there seems to be a gap in the data file . + key hash + keys hash read + , offset from index file : + current key hash offset + , current position in data file : + current position in data file ) ; problems detected + + ; current position in data file = current key hash offset ; }
assert equals ( b , it . next ( ) ) ;
leaf queue a = stub leaf queue ( ( leaf queue ) queues . get ( b ) ) ;
builder . get parent id ( ) . if present ( parent id - > { record map . get ( parent id ) . add sub group ( resource group spec ) ; sub group ids to build . get ( parent id ) . remove ( id ) ; } ) ; } else {
for ( int i = 10 ; i < 20 ; i + + ) { index ( index name , doc , integer . to string ( i ) , foo , bar + i ) ; } refresh ( ) ; final string in progress snapshot = random alpha of length ( 8 ) . to lower case ( locale . root ) ;
assert with message ( option metadata tag + java tag + does not have a proto equivalent with the same value ) . that ( proto tag ) . is not null ( ) ;
slice _ from ( earli ) ; break ; case 10 :
for ( protocol provider service pp : get protocol providers ( ) ) { handle provider added ( pp ) ; } notification wiring activator . get media service ( ) . add recorder listener ( this ) ;
intent intent = new intent ( this , player service . class ) ; bind service ( intent , m connection , context . bind _ auto _ create ) ; }
prop names . remove ( jdom ) ;
list < field schema > cols = table meta . get cols ( ) ;
arrays . sort ( this . streams , segment comparator ) ; cur idx = 0 ;
float desired aspect = 0 . 0f ;
assert . assert equals ( 2 , rep queues . get all queues ( ) . size ( ) ) ; assert . assert null ( rep queues . get logs in queue ( 2 ) ) ; assert . assert null ( rep queues . get logs in queue ( 2 - sever2 ) ) ; replication admin . remove peer ( 1 ) ; rep queues . remove all queues ( ) ; zkw . close ( ) ; replication admin . close ( ) ; }
if ( config . get init parameter ( tunnel . timeout ) = null ) { connection timeout = integer . value of ( config . get init parameter ( tunnel . timeout ) ) ; }
switch ( state ) { case 0 : switch ( c ) { case ' \ r ' : state = 1 ; break ; case ' \ n ' : state = 2 ; break ; } break ; case 1 : switch ( c ) { case ' \ n ' : state = 2 ; break ; default : throw new illegal argument exception ( only ' \ \ n ' is allowed after ' \ \ r ' : + value ) ; } break ; case 2 : switch ( c ) { case ' \ t ' : case ' ' : state = 0 ; break ; default : throw new illegal argument exception ( only ' ' and ' \ \ t ' are allowed after ' \ \ n ' : + value ) ; } }
final management resource registration server = subsystem . register sub model ( new server definition ( register runtime only ) ) ; for ( path definition path : new path definition [ ] { path definition . journal _ instance , path definition . bindings _ instance , path definition . large _ messages _ instance , path definition . paging _ instance } ) { management resource registration path registry = server . register sub model ( path ) ; path definition . register resolve operation handler ( context , path registry ) ; }
conf . set int ( dfsconfig keys . dfs _ namenode _ edits _ dir _ minimum _ key , 2 ) ;
throw jpa logger . root _ logger . no punit name specified and multiple persistence units ( holder . get persistence units ( ) . size ( ) , unit ) ; } }
assert true ( fs . delete ( renamed path , true ) ) ; inode count - = 2 ; assert equals ( inode count , fsn . dir . get inode map size ( ) ) ;
type code real type = real type ( ) ;
keep specifications . add ( keep class specification ) ;
long label field = record . get label field ( ) ;
chunk material . set float ( daylight , backdrop provider . get daylight ( ) , true ) ; chunk material . set float ( time , world provider . get time ( ) . get days ( ) , true ) ;
port profile vo port profile obj ; port profile obj = _ port profile dao . find by name ( port prof name ) ; if ( port profile obj = null ) { s _ logger . info ( port profile with specified name : + port prof name + already exists ) ; throw new invalid parameter value exception ( port profile with specified name : + port prof name + already exists ) ; }
when ( queues . get ( 0 ) . get accessible node labels ( ) ) . then return ( immutable set . of ( x , y ) ) ;
for ( node allocation result node result : rebalance decision . get node decisions ( ) ) { if ( exclude nodes . contains ( node result . get node ( ) . get id ( ) ) ) { assert equals ( type . no , node result . get can allocate decision ( ) . type ( ) ) ; } }
card card = new gplay card custom source ( get activity ( ) ) ;
float inches = eighths ( 8 * 72 . 00f ) ; return inches 0 . 0394f ; }
try { element def . get parents ( ) . add ( parent group2 ) ; fail ( exception expected ) ; } catch ( final unsupported operation exception e ) { assert not null ( e ) ; }
if ( prior response = null ) { response = response . new builder ( ) . prior response ( prior response . new builder ( ) . body ( null ) . build ( ) ) . build ( ) ; } request follow up = follow up request ( response ) ; if ( follow up = = null ) { if ( for web socket ) { stream allocation . release ( ) ; } return response ; }
long new gs = b . get generation stamp ( ) + 1 ; b . set generation stamp ( new gs ) ; b . set num bytes ( b . get num bytes ( ) + 10 ) ; block info new block = new block info ( b , i node . get replication ( ) ) ; log . info ( updating block : + old block + to : + new block ) ;
if ( is rollback on commit failure ( ) ) { do rollback on commit exception ( status , ex ) ; } else { trigger after completion ( status , transaction synchronization . status _ unknown ) ; } throw ex ;
hot replicas . for each ( r - > collections . add ( r . get collection ( ) ) ) ;
work dir = new path ( get absolute test root path ( f sys ) , new path ( test ) ) ; f sys . set working directory ( work dir ) ; assert . assert equals ( work dir , f sys . get working directory ( ) ) ; path relative dir = new path ( existing dir1 ) ;
boolean seen white = tq . consume whitespace ( ) ; if ( tq . matches any ( combinators ) ) { combinator ( tq . consume ( ) ) ; } else if ( seen white ) { combinator ( ' ' ) ;
rm container = ( ( capacity scheduler ) scheduler ) . get application attempt ( container . get id ( ) . get application attempt id ( ) ) . get rmcontainer ( container . get id ( ) ) ; assert . assert null ( rm container ) ;
reg . register dependency ( disk _ file , java _ type _ object ) ;
get = new get ( rows [ 0 ] ) ; get . add column ( families [ 2 ] , qualifiers [ 2 ] ) ; result = ht . get ( get ) ; assert single result ( result , rows [ 0 ] , families [ 2 ] , qualifiers [ 2 ] , values [ 2 ] ) ;
record = proxy . read from client ( ) ; assert . assert equals ( tlsrecord . type . handshake , record . get type ( ) ) ; proxy . flush to server ( record ) ; assert . assert null ( renegotiation . get ( 5 , time unit . seconds ) ) ;
stream record record = new stream record ( ) ;
assert true ( the cores remaining + snapshot by core name , snapshot by core name . is empty ( ) ) ; assert true ( list collection snapshots ( solr client , collection name ) . is empty ( ) ) ;
m paint . set color ( am text color ) ;
tmp . tail . set next ( head ) ; head . set previous ( tmp . tail ) ; head = tmp . head ; return ;
try { extractor . _ apply ( entity ) ; fail ( exception expected ) ; } catch ( final illegal argument exception e ) { assert not null ( e ) ; }
if ( depth + 2 > length ) { throw new snmp status exception ( snmp status exception . no such instance ) ; }
if ( target = = null ) { return true ; }
boolean empty = true ;
if ( string utils . is empty ( item config . get region ( ) ) ) {
set property ( original property ) ;
if ( ( eq _ s _ b ( 1 , u ) ) ) { break lab13 ; } } while ( false ) ; cursor = limit - v _ 10 ;
http method params params = method . get params ( ) ;
for ( mention m : all predicted mentions . values ( ) ) { if ( m . speaker info = = null ) { for ( speaker info speaker info : speaker info map . values ( ) ) { if ( speaker info . has real speaker name ( ) ) { do loose match - assumes that there isn ' t that many speakers . . . . if ( rules . mention matches speaker ( m , speaker info , false ) ) { m . speaker info = speaker info ; break ; } } } } }
public static criteria where ( path key ) { return new criteria ( value node . create path node ( key ) ) ;
final model node operation = create describe operation ( ) ; final model node result = services b . execute operation ( operation ) ; assert . assert true ( the subsystem describe operation has to generate a list of operations to recreate the subsystem , result . has defined ( model description constants . failure _ description ) ) ; final list < model node > operations = result . get ( model description constants . result ) . as list ( ) ; services b . shutdown ( ) ; final kernel services services c = super . create kernel services builder ( additional init ) . set boot operations ( operations ) . build ( ) ;
signature = signature . get instance ( nonewith dsa ) ;
provider = key provider factory . get providers ( conf ) . get ( 0 ) ; assert array equals ( new byte [ ] { 2 } , provider . get current key ( key4 ) . get material ( ) ) ; assert array equals ( key3 , provider . get current key ( key3 ) . get material ( ) ) ; assert equals ( key3 @ 0 , provider . get current key ( key3 ) . get version name ( ) ) ; list < string > keys = provider . get keys ( ) ; assert true ( keys should have been returned . , keys . size ( ) = = 2 ) ;
url c . set request property ( user - agent , downloader . get user agent ( ) ) ;
final path file13 = new path ( dir1 , file - 13 ) ; assert true ( fs . hard link ( file10 , file13 ) ) ; verify dsquota setting ( dfs , root , 3 * disk size , 2 * disk size ) ; verify dsquota setting ( dfs , dir1 , 2 * disk size , 1 * disk size ) ; verify dsquota setting ( dfs , dir2 , 1 * disk size , 1 * disk size ) ;
em . get transaction ( ) . begin ( ) ; set owned entity2 = em . find ( set owned entity . class , 8 ) ; em . remove ( set owned entity2 ) ; em . get transaction ( ) . commit ( ) ; string set entity string set entity = new string set entity ( ) ; string set entity . get strings ( ) . add ( string 1 ) ; string set entity . get strings ( ) . add ( string 2 ) ;
slice _ from ( e ) ; break ; case 3 :
final list < ? extends certificate > actual certs ; if ( pkcs7 . equals ( encoding ) ) { actual certs = actual path . get certificates ( ) ; assert equals ( provider name , expected certs , actual certs ) ; } else { actual certs = path from list . get certificates ( ) ; } try { actual certs . remove ( 0 ) ; fail ( list of certificate should be immutable ) ; } catch ( unsupported operation exception expected ) { }
if ( user32 . instance . get icon info ( new hicon ( h image ) , icon info ) ) throw new exception ( invocation of user32 . get icon info ( ) failed : + kernel32 util . get last error message ( ) ) ;
m editor . set padding ( 10 , 10 , 10 , 10 ) ;
splice ( e new , e org . lnext ) ; splice ( e new sym , e dst ) ;
get http invoker request executor ( ) ;
replace node ( original expr , m node . without not ( ) ) ; } else {
hdfs . delete ( deleted y , true ) ;
rounding params . set corners radius ( 0 ) ; }
string insert = tb + . insert ;
if ( flusher . is failed ( ) ) { notify callback failure ( callback , new zip exception ( ) ) ; return ; } frame entry entry = new frame entry ( frame , callback , batch mode ) ;
double [ ] f values1 = new double [ m _ instances . num attributes ( ) ] ;
route selector = new route selector ( address , route database , null , event listener . none ) ;
for ( int k = left ; k < right ; run [ count ] = k ) { if ( a [ k ] < a [ k + 1 ] ) { ascending while ( + + k < = right & & a [ k - 1 ] < = a [ k ] ) ; } else if ( a [ k ] > a [ k + 1 ] ) { descending while ( + + k < = right & & a [ k - 1 ] > = a [ k ] ) ; for ( int lo = run [ count ] - 1 , hi = k ; + + lo < - - hi ; ) { float t = a [ lo ] ; a [ lo ] = a [ hi ] ; a [ hi ] = t ; } } else { equal for ( int m = max _ run _ length ; + + k < = right & & a [ k - 1 ] = = a [ k ] ; ) { if ( - - m = = 0 ) { sort ( a , left , right , true ) ; return ; } } } * * the array is not highly structured , * use quicksort instead of merge sort . * if ( + + count = = max _ run _ count ) { sort ( a , left , right , true ) ; return ; } }
source = rp . get source p ( ) ;
catch ( ioexception ex ) { stats recorder . record stats ( ex ) ; throw ex ; }
for ( recycler view . on scroll listener listener : m extra on scroll listener list ) { listener . on scrolled ( recycler view , dx , dy ) ; } int scroll y = quick return utils . get scroll y ( recycler view , m column count ) ;
if ( ( max term counts . length - num terms in field ) > 1024 ) { too much waste int [ ] new max term counts = new int [ num terms in field ] ; system . arraycopy ( max term counts , 0 , new max term counts , 0 , num terms in field ) ; max term counts = new max term counts ; } log . info ( un inverted multi - valued field + to string ( ) ) ;
clock . forward ( 70 , seconds ) ;
metadata = table metadata . builder ( ks , table ) . partitioner ( murmur3 partitioner . instance ) . add partition key column ( pk , int32 type . instance ) . add clustering column ( ck , int32 type . instance ) . add static column ( sc1 , int32 type . instance ) . add static column ( sc2 , int32 type . instance ) . add regular column ( v1 , int32 type . instance ) . build ( ) ; column filter = column filter . all ( metadata ) ; assert true ( column filter . fetch all regulars ) ;
list < string [ ] > lines = read lines ( resp . get content as string ( ) ) ; feature source fs1 = get feature source ( mock data . forests ) ;
start node = processed node . get next sibling ( ) ;
entity it extends = entity source by name map . get ( mapping document . qualify class name ( jaxb sub entity mapping . get extends ( ) ) ) ;
q . add ( tags , solr ) ;
sleep ( 150 ) ;
return get current time ( ) ;
if ( pq . size ( ) > m ) pq . del min ( ) ;
final string txt = lines [ slist line no - 1 ] . substring ( slist col no + 1 , rcurly col no ) ; if ( common utils . is blank ( txt ) ) { return value = true ; } }
for ( node n : string nodes to rename ) { string old name = n . get string ( ) ; property p = property map . get ( old name ) ; if ( p = null & & p . new name = null ) { check state ( old name . equals ( p . old name ) ) ; if ( p . new name . equals ( old name ) ) { n . set string ( p . new name ) ; compiler . report change to enclosing scope ( n ) ; } } }
int expected result = 0 ;
filler = new byte [ math . max ( filler . length , filler . length * 2 ) ] ;
log . debug ( default file system : + jt fs . get uri ( ) ) ;
list < class node > inner = new array list < class node > ( ) ;
event factory . recycle ( physics collision event ) ; }
final message msg2 = create message ( the hello ) ; extractor . run extractor ( msg2 ) ; assert that ( msg2 . has field ( target ) ) . is false ( ) ; }
while ( firehose = null & & ( gracefully stopped | | firehose drainable by closing ) & & firehose . has more ( ) ) { plumbers . add next row ( committer supplier , firehose , plumber , tuning config . is report parse exceptions ( ) , metrics ) ; } }
phrase = phrase . replace first ( ^ [ \ \ s + special _ chars + ] , ) ; phrase = phrase . replace first ( [ \ \ s + special _ chars + ] , ) ;
pointer index = event . find pointer index ( m active pointer id ) ; final float x = event . get x ( pointer index ) ; if ( math . abs ( x - m down motion x ) > m scaled touch slop ) { set pressed ( true ) ; invalidate ( ) ; on start tracking touch ( ) ; track touch event ( event ) ; attempt claim drag ( ) ; }
mem store size cf1 memstore size phase i = region . get store ( family1 ) . get mem store size ( ) ;
case success :
if ( data . length = = 0 ) { throw new illegal argument exception ( array is empty . ) ; } if ( data [ 0 ] . length = 2 ) { throw new illegal argument exception ( dimension is not 2 . ) ; }
exec utils . exit ( result ) ; } } catch ( exception e ) {
factoids = ( new score sorter filter ( ) ) . apply ( factoids ) ;
verify ( execution service , never ( ) ) . execute bulk request ( any ( ) , any ( ) , any ( ) ) ;
write packet ( avmedia _ type _ audio , audio _ pkt ) ; return true ;
client conf = new configuration ( conf ) ;
child = parent . create child injector ( ) ; ensure works ( child , foo impl . class ) ; }
super . add view ( child , index , params ) ;
return get normalized hash ( key ) segment size ;
build slave events query query0 = new build slave events query ( ) ;
final indexed < string > dim values = index selector . get dimension values ( dimension ) ; if ( dim values = = null | | dim values . size ( ) = = 0 ) { return predicate . apply ( null ) ? 1 . : 0 . ; }
if ( me command msg . length ( ) > 0 ) processed message = me command msg ; }
un box ( i ) ;
assert to string ( cat . name = ?1 or cust . name . first name = ?2 or kitten . name = ?1 , cat . name . eq ( kitty ) . or ( cust . name . first name . eq ( hans ) ) . or ( kitten . name . eq ( kitty ) ) ) ; }
@ suppress warnings ( unchecked ) model view < ? > [ ] array = new model view < ? > [ bindings . size ( ) ] ; int i = 0 ; for ( model binding binding : bindings ) { model node internal element = binding . get node ( ) ; model view < ? > view = element . as immutable ( binding . get predicate ( ) . get type ( ) , descriptor ) ; array [ i + + ] = view ; } @ suppress warnings ( unchecked ) list < model view < ? > > views = arrays . as list ( array ) ; return views ;
war . add as resource ( web jpatest case . class . get package ( ) , persistence . xml , meta - inf persistence . xml ) ; return war ; }
val . set value ( abc ) . set exists ( true ) ; filter . set value ( true ) . set exists ( true ) ; assert equals ( abc , func . get string ( ) ) ; assert true ( func . exists ( ) ) ; val . set value ( def ) . set exists ( true ) ; filter . set value ( false ) . set exists ( true ) ; func . get string ( ) ; assert false ( func . exists ( ) ) ; val . set value ( 123 ) . set exists ( true ) ; filter . set value ( true ) . set exists ( true ) ; assert equals ( 123 , func . get string ( ) ) ; assert true ( func . exists ( ) ) ; val . set value ( 456 ) . set exists ( true ) ; filter . set value ( false ) . set exists ( true ) ; func . get string ( ) ;
beacon parsed beacon = parser . from scan data ( bytes , - 59 , null ) ; assert equals ( parsed beacon should contain a valid data on index 0 , now , parsed beacon . get data fields ( ) . get ( 0 ) ) ;
limiter . set ( 100 , time unit . seconds ) ;
return bookmark ; }
resource url provider url provider = get resource url provider ( ) ;
out . write byte ( no _ entry _ value ) ; }
aggregation group by operator aggregation group by operator = get operator for query ( query ) ; intermediate results block results block = ( intermediate results block ) aggregation group by operator . next block ( ) ; queries test utils . test inner segment execution statistics ( aggregation group by operator . get execution statistics ( ) , 100000 l , 0 l , 700000 l , 100000 l ) ; queries test utils . test inner segment aggregation group by result ( results block . get aggregation group by result ( ) , w \ t3818 \ t369 , 1 l , 1095214422 l , 1547156787 , 528554902 , 52058876 l , 1 l ) ;
if ( service url = null ) { builder . set root url ( service url ) ; } return builder . build ( ) ;
response = interceptor . submit application ( request ) ; assert . assert not null ( response ) ;
start repl producers ( ) ;
session s = open session ( ) ; s . begin transaction ( ) ; application application = new application ( ) ;
mod tinfo = new table info ( table name ) ; tables info . put ( table name , mod tinfo ) ; try { table descriptor htd = fstable descriptors . get table descriptor from fs ( fs , hbase root , table name ) ; mod tinfo . htds . add ( htd ) ; } catch ( ioexception ioe ) { if ( orphan table dirs . contains key ( table name ) ) { log . warn ( unable to read . tableinfo from + hbase root , ioe ) ;
{ error msg . missing _ xslt _ target _ err , no s ' ' ha trobat la destinaci \ u00f3 ' ' { 0 } ' ' del full d ' ' estils . } ,
big integer edge102 = bidirectional edge count . multiply ( vertex count . subtract ( two ) ) . subtract ( triplet111d count ) . subtract ( triplet111u count ) . subtract ( triplet201 count . multiply ( two ) ) . subtract ( triangle120d count ) . subtract ( triangle120u count ) . subtract ( triangle120c count ) . subtract ( triangle210 count . multiply ( two ) ) . subtract ( triangle300 count . multiply ( three ) ) ; big integer edge012 = unidirectional edge count . multiply ( vertex count . subtract ( two ) ) . subtract ( triplet021d count . multiply ( two ) ) . subtract ( triplet021u count . multiply ( two ) ) . subtract ( triplet021c count . multiply ( two ) ) . subtract ( triplet111d count ) . subtract ( triplet111u count ) . subtract ( triangle030t count . multiply ( three ) ) . subtract ( triangle030c count . multiply ( three ) ) . subtract ( triangle120d count . multiply ( two ) ) . subtract ( triangle120u count . multiply ( two ) ) . subtract ( triangle120c count . multiply ( two ) ) . subtract ( triangle210 count ) ;
codepage = little endian . get ushort ( src , o ) ;
separators = ( ) < > @ , ; : \ \ \ [ ] ? = { } \ t ; }
int payload = a . return states [ i ] ;
instance = runtime service . create process instance query ( ) . variable value not equals ignore case ( upper , uiop ) . single result ( ) ;
throw new org . apache . axis2 . databinding . adbexception ( reservation id cannot be null ) ;
parse user current user = new parse user ( ) ; current user . set object id ( test ) ; cached current user controller current user controller = mock ( cached current user controller . class ) ; when ( current user controller . set if needed async ( any ( parse user . class ) ) ) . then return ( task . < void > for result ( null ) ) ; parse core plugins . get instance ( ) . register current user controller ( current user controller ) ; parse user user = new parse user ( ) ; parse user . pin current user if needed async ( user ) ;
} } if ( null = = part data ) { log ( decode part data error ) ; return null ; } part . set data ( part data ) ; } }
worker virtual port virtual _ port = new worker virtual port ( conf , supervisor id , topology id , port , mq context , taskids ) ; shutdownable virtual _ port _ shutdown = virtual _ port . launch ( ) ; topology context system topology = system context . make ( null ) ;
boolean visited [ ] = new boolean [ 10 ] ;
if ( schema manager = null ) { schema manager . drop schema ( ) ; }
check lp . set changed after nested scroll ( handled ) ; } } } }
if ( debug ) { long l = dis . read long ( ) ; if ( debug ) { system . out . println ( index + : long [ + l + ] ) ; } } else { dis . skip ( 8 ) ; }
for ( entry < node port , list < integer > > entry : new slot assigned . entry set ( ) ) { list < integer > tasks = slot assigned . get ( entry . get key ( ) ) ; list < integer > lst = entry . get value ( ) ; if ( tasks = = null | | tasks . size ( ) = lst . size ( ) | | lst . contains all ( tasks ) ) { brand new slots . add all ( lst ) ; } } return brand new slots ; }
assert that ( junc . to file ( ) . exists ( ) ) . is false ( ) ;
for ( register arg use arg : new array list < register arg > ( inst arg . get svar ( ) . get use list ( ) ) ) { register arg dup = result arg . duplicate ( ) ; insn node parent insn = use arg . get parent insn ( ) ; parent insn . replace arg ( use arg , dup ) ; dup . set parent insn ( parent insn ) ; result arg . get svar ( ) . use ( dup ) ; }
if ( call record = = null ) return ;
if ( expr1 . get type info ( ) . equals ( expr2 . get type info ( ) ) ) { expr1 = get column expr ( expr1 ) ; expr2 = get column expr ( expr2 ) ; } expr node desc [ ] extracted = expr node desc utils . extract compare pair ( expr1 , expr2 ) ;
sink . replicate entries ( entries , cell util . create cell scanner ( edit . get cells ( ) . iterator ( ) ) , replication cluster id , base namespace dir , hfile archive dir ) ;
dump store . dump hex ( record , buffer , 2 , 4 ) ;
regionating strategy regionating strategy = null ; string stratname = ( string ) map content . get request ( ) . get format options ( ) . get ( regionate by ) ; if ( ( auto ) . equals ( stratname ) ) { catalog catalog = wms . get geo server ( ) . get catalog ( ) ; name name = layer . get feature source ( ) . get name ( ) ; stratname = catalog . get feature type by name ( name ) . get metadata ( ) . get ( kml . regionate strategy , string . class ) ; if ( stratname = = null | | . equals ( stratname ) ) { stratname = best _ guess ; logger . log ( level . fine , no default regionating strategy has been configured in + name + ; using automatic best - guess strategy . ) ; } } filter regionating filter = filter . include ;
collections . sort ( spans , new comparator < call tree node > ( ) { @ override public int compare ( call tree node source , call tree node target ) { return ( int ) ( source . get value ( ) . get start time ( ) - target . get value ( ) . get start time ( ) ) ; } } ) ;
if ( install context . get writeable library paths ( ) . length ( ) = = 0 ) { global display _ . show message ( message dialog . info , check for updates , all packages are up to date . ) ; }
else { abstract attribute attribute = ( abstract attribute ) key obj . get attribute ( field name ) ; string column name = attribute . get jpacolumn name ( ) ; is present = build where clause ( builder , is present , translator , condition , value , use in clause , attribute , column name , false ) ; }
assert equals ( array4 . size ( ) , adds . size ( ) ) ; assert false ( array4 . is empty ( ) ) ; array4 . clear ( ) ; assert true ( array4 . is empty ( ) ) ; assert equals ( array4 . size ( ) , 0 ) ;
token cursor cursor = code model . get token cursor ( ) ;
assert xpath evaluates to ( 1 , count ( csw : get records response ) , dom ) ;
object anti alias = g2 . get rendering hint ( rendering hints . key _ antialiasing ) ; g2 . set rendering hint ( rendering hints . key _ antialiasing , rendering hints . value _ antialias _ off ) ;
file data = new file ( root , data ) ; file cite = new file ( data , mock data . cite _ prefix ) ; file buildings = new file ( cite , buildings . properties ) ; file model model = new file model ( new model < string > ( ) , root ) ;
inflate gens ( sis , arrays . as list ( dir . list all ( ) ) , info stream . get default ( ) ) ; assert equals ( 3 , sis . info ( 0 ) . get next del gen ( ) ) ; dir . close ( ) ; }
long seconds = read seven byte long ( bytes , bin sort offset ) ^ seven _ byte _ long _ sign _ flip ; int nanos = bytes to int ( bytes , bin sort offset + 7 ) ; timestamp tz . set ( seconds , nanos , time zone ) ; timestamp tzempty = false ; bytes empty = true ; }
float mid fold = m is horizontal ? ( anchor point m fold draw width ) : anchor point m fold draw height ; m src [ 0 ] = 0 ;
purchase record record1 = new purchase record ( ) ;
if ( generic udafevaluators = null ) { generic udafevaluators . put ( entry . get key ( ) , generic udafevaluator ) ; } }
assert true ( extract result ( test harness2 ) . is empty ( ) ) ; test harness2 . process watermark ( 20 l ) ;
config lite config = new config ( ) ; lite config . set lite member ( true ) ; hazelcast instance i3 = factory . new hazelcast instance ( lite config ) ; map config map config on lite member = i3 . get config ( ) . get map config ( map name ) ; assert equals ( test config utils . non _ default _ backup _ count , map config on lite member . get backup count ( ) ) ; }
image view . set scale type ( image view . scale type . fit _ xy ) ; } else
int last entry = entries . size ( ) - 1 ;
validate compress ( reader configuration ) ;
if ( ( s . length ( ) - position ) < . n . length ( ) ) { throw bad timestamp string ( s ) ; }
assert false ( user principal was ' test ' , but it should be null here . + the container seemed to have remembered it from the previous request . , response . contains ( web username : test ) ) ;
clip view on the right ( bound , w , right ) ;
utils . delete all tables ( ) ;
overview . put client property ( overview . animate scroll to , boolean . true ) ;
if ( percent < 0 ) percent = 0 ; else if ( percent > 100 ) percent = 100 ; _ context . get service ( ) . http nfc lease progress ( _ mor , percent ) ; }
return from . compare to ( other to ) < = 0 & & to . compare to ( other from ) > = 0 ; }
schemas . add ( schema ) ;
assert normalize ( sin ( 1 . 0 ) , is literal ( 0 . 8414709848078965 , data types . double ) ) ; assert normalize ( sin ( cast ( 2 . 0 as float ) ) , is literal ( 0 . 9092974268256817 , data types . double ) ) ; assert normalize ( sin ( 3 ) , is literal ( 0 . 1411200080598672 , data types . double ) ) ; assert normalize ( sin ( cast ( 4 as integer ) ) , is literal ( - 0 . 7568024953079282 , data types . double ) ) ; assert normalize ( sin ( cast ( 5 as short ) ) , is literal ( - 0 . 9589242746631385 , data types . double ) ) ;
hregion info hri dupe = create region ( conf , tbl . get table descriptor ( ) , bytes . to bytes ( b ) , bytes . to bytes ( b ) ) ; test _ util . get hbase cluster ( ) . get master ( ) . assign region ( hri dupe ) ; test _ util . get hbase cluster ( ) . get master ( ) . get assignment manager ( ) . wait for assignment ( hri dupe ) ; hbase fsck hbck = do fsck ( conf , false ) ;
verify allowed ( new access test action ( ) { @ override public object run ( ) throws exception { access _ controller . pre truncate table ( observer context impl . create and prepare ( cp _ env ) , test _ table . get table name ( ) ) ; return null ; } } , superuser , user _ admin , user _ rw , user _ ro , user _ owner , user _ create , user _ qual , user _ none ) ;
f current element . uri = f element qname . uri ; if ( f element qname . prefix = = null & & f element qname . uri = null ) { f element qname . prefix = xmlsymbols . empty _ string ;
final string [ ] field values = new string [ sorted fields . size ( ) ] ;
immutable set < build target > alias targets = buck config . get build targets for alias ( pattern ) ;
long data set index header value = actual . get in ( ) . get header ( exchange . dataset _ index , long . class ) ;
config . set property ( group property . query _ result _ size _ limit . get name ( ) , 1 ) ; hazelcast instance hz = create hazelcast instance ( config ) ; map = hz . get map ( trial ) ; }
b [ offset + + ] = enc _ separator ; system . arraycopy ( md5 hash bytes , 0 , b , offset , md5 _ hex _ length ) ; offset + = md5 _ hex _ length ; b [ offset + + ] = enc _ separator ; }
float crease = math . abs ( ( ( number ) edge . get field value ( crease ) ) . float value ( ) ) ;
boolean get all pinned tracks = false ;
main . set config admin pid ( stuff ) ;
spinner spinner = ( spinner ) find view by id ( r . id . spinner ) ;
session init packet id = jingle . get stanza id ( ) ; send stanza ( jingle ) ;
last ex = ex ; } }
assert not same ( b mem . get segment memory ( ) , exists1 mem . get segment memory ( ) ) ;
if ( destination type . is array ( ) ) { array converter < t > array converter = new array converter ( this , destination type . get component type ( ) ) ; return ( t ) array converter . convert ( value ) ; }
file classes jar = new file ( new file ( exploder dir , jars ) , classes . jar ) ;
( ( dynamic realm ) realm ) . create object ( schema . get class name ( ) ) ;
write text file ( readme . txt , welcome to my addon , folder ) ;
id = buffer . read byte ( ) & 0x ff | ( buffer . read byte ( ) & 0x ff ) < < 8 | ( buffer . read byte ( ) & 0x ff ) < < 16 ;
j = j - 1 ;
string value = ( string ) lambda info . get implementation method ( ) . invoke ( null , 1 l ) ; assert that ( value , is ( 1 ) ) ;
cache . get and replace ( random string ( ) , random string ( ) ) ;
cli . send line ( jms - topic remove - - profile = + profile name + - - topic - address = test jms topic ) ;
catch ( exception e ) { logger . debug ( could not retrieve metadata version . exception : + e ) ; } return null ; }
node next call = ir . expr result ( ir . call ( ir . getprop ( ir . name ( temp var name ) , ir . string ( next ) ) ) ) ;
int [ ] indices = new int [ vals . length ] ; for ( int i = 0 ; i < indexed . size ( ) ; + + i ) { final int expected = vals [ i ] ; final int actual = indexed . get ( i ) ; assert . assert equals ( expected , actual ) ; indices [ i ] = i ; }
if ( string utils . is blank ( upstream dependency ) | | metadata identification utils . is valid ( upstream dependency ) ) { return ; }
- - count ;
assert equals ( new key value ( bytes . to bytes ( rk ) , bytes . to bytes ( fam ) , null , 1 , ( byte [ ] ) null ) , new key value ( bytes . to bytes ( rk ) , bytes . to bytes ( fam ) , hconstants . empty _ byte _ array , 1 , ( byte [ ] ) null ) ) ;
assert that ( kv . of ( new int [ ] { 1 , 2 } , 3 ) , not ( equal to ( kv . of ( new int [ ] { 1 , 37 } , 3 ) ) ) ) ;
throw new illegal seek position exception ( timeline , seek position . window index , seek position . window position us ) ;
m paint = new paint ( ) ;
end = parse end of line ( header part , non ws ) ;
bucket id split left = new bucket id ( split dist bits , bucket . get id ( ) ) ;
if ( simulation start time > 0 ) { process ( item ) ; total simulation time = system . current time millis ( ) - get simulation start time ( ) ; }
log . alternate service role ( service role . get name ( ) , binding . get service role ( ) . get name ( ) ) ;
this . factor filter list . put ( filter . get factor name ( ) , filter ) ; logger . debug ( string . format ( factor filter added for ' % s ' . , filter . get factor name ( ) ) ) ; }
string uri = page info . get uri ( prefix ) ; if ( uri = = null ) { if ( page info . is error on undeclared namespace ( ) ) { err . jsp error ( start , jsp . error . undeclared _ namespace , prefix ) ; } else { reader . reset ( start ) ; remember the prefix for later error checking page info . put non custom tag prefix ( prefix , reader . mark ( ) ) ; return false ; } } tag library info tag lib info = page info . get taglib ( uri ) ; tag info tag info = tag lib info . get tag ( short tag name ) ;
await = action interrupted . await ( 3 , time unit . seconds ) ;
if ( r _ step _ 6 ( ) ) { break lab15 ; } } while ( false ) ; cursor = limit - v _ 16 ; cursor = limit _ backward ; do , line 243 v _ 18 = cursor ; lab18 : do {
message digest digest = null ; try { digest = message digest . get instance ( sha - 256 ) ; digest . update ( pub _ key . get encoded ( ) ) ; return util . byte array to hex string ( digest . digest ( ) , 0 , 16 ) ; } catch ( no such algorithm exception e ) { return e . to string ( ) ; } }
jmx server = server ;
final saxparser factory factory = saxparser factory . new instance ( ) ; try { factory . set feature ( constants . namespace _ feature , true ) ; } catch ( exception e ) { factory . set namespace aware ( true ) ; } _ parser = factory . new saxparser ( ) ; _ reader = _ parser . get xmlreader ( ) ; }
out . write ( long . to string ( used ) + + long . to string ( timer . now ( ) ) ) ;
public void test full bootstrap two sources ( ) {
scanner report . issue report issue = scanner report . issue . new builder ( ) . set msg ( the message ) . set rule repository ( rule key . repository ( ) ) . set rule key ( rule key . rule ( ) ) . set severity ( constants . severity . blocker ) . build ( ) ; report reader . put issues ( file _ ref , as list ( report issue ) ) ; file source repository . add line ( file _ ref , line1 ) ; under test . visit any ( file ) ;
config config = new config ( props ) ; run data = new perf run data ( config ) ; task sequence tasks = new task sequence ( run data , test bzip2 , null , false ) ; tasks . add task ( new create index task ( run data ) ) ; for ( int i = 0 ; i < num adds ; i + + ) { tasks . add task ( new add doc task ( run data ) ) ; } tasks . add task ( new close index task ( run data ) ) ; try { tasks . do logic ( ) ; } finally { tasks . close ( ) ; }
return arrange fr ( container , g2 , constraint ) ;
parent . remove ( 0 ) ; alert node grand parent = parent . get parent ( ) ; this . remove node from parent ( parent ) ; this . node changed ( grand parent ) ; return ;
http2 stream stream = connection . local ( ) . create stream ( stream id - 2 , true ) ; stream . close ( ) ; final ticker ticker = new ticker ( ) { @ override public long read ( ) { return nano time ; } } ;
object mapper mapper = new object mapper ( ) ; coinbase orders orders = mapper . read value ( is , coinbase orders . class ) ; list < coinbase order > order list = orders . get orders ( ) ;
assert equals ( 1024 , scheduler . get scheduler app ( att id1 ) . get current reservation ( ) . get memory size ( ) ) ;
list . add ( create remove operation ( subsystem ) ) ;
return fbx null attribute . class ; } else if ( subclass name . equals ( limb node ) ) {
parse task utils . wait ( controller . request password reset async ( session token ) ) ; }
file current dir = cluster . get journal current dir ( jnid , jid ) ;
byte [ ] bdata = data . get bytes ( device . get char set ( ) ) ; final cipher cipher = cipher . get instance ( aes ecb no padding ) ; cipher . init ( cipher . encrypt _ mode , new secret key spec ( device . get crypt key priv ( ) , aes ) ) ; logger . debug ( create padding . . ) ; int bsize = cipher . get block size ( ) ; logger . debug ( add padding and encrypt aes . . ) ; final byte [ ] encrypted data = cipher . do final ( add zero padding ( bdata , bsize , device . get char set ( ) ) ) ; logger . debug ( encrypt b64 . . ) ; try { encrypted data b64 = base64 . encode base64 ( encrypted data ) ; } catch ( exception e ) { logger . error ( base64encoding not possible : { } , e . get message ( ) ) ; } return encrypted data b64 ;
document dom = context . get type converter ( ) . convert to ( document . class , events ) ; assert not null ( dom ) ; node list list = dom . get elements by tag name ( backlog tracer event message ) ;
item path . set length ( 0 ) ;
assert true ( timeout should occur faster than + taken , taken < 4500 ) ;
dispatch through descriptor = true ;
instructions . add ( reil helpers . create and ( base offset + + , dw , integer operand1 . get value ( ) , dw , string . value of ( 0x1 fl ) , dw , sh ) ) ; instructions . add ( reil helpers . create sub ( base offset + + , dw , sh , dw , string . value of ( 32 l ) , dw , sh2 ) ) ;
set < string > copy flat ids = new tree set < string > ( arrays . as list ( copy flat results . get identifiers ( ) ) ) ;
if ( discard last block & & discard done ( pending file , src ) ) { have client retry lease recovery . return false ; }
list locators = arrays . as list ( gml . get instance ( ) . create schema locator ( ) ) ;
master key data second master key data = app token mgr . create new master key ( ) ; amrmtoken secret manager state state2 = amrmtoken secret manager state . new instance ( first master key data . get master key ( ) , second master key data . get master key ( ) ) ; rm context . get state store ( ) . store or update amrmtoken secret manager ( state2 , true ) ;
for ( cached item block : multi blocks ) { cache . cache block ( block . cache key , block ) ; expected cache size + = block . cache block heap size ( ) ; assert equals ( cache . get block ( block . cache key , true , false ) , block ) ; }
rpc [ ] rpcs = new rpc [ ] { new rpc ( transport ) , new rpc ( transport ) , new rpc ( transport ) } ;
time field spec = new time field spec ( new time granularity spec ( data type . long , time unit . hours , date ) ) ;
standalone server factory list . remove ( active zkserver index ) ; client port list . remove ( active zkserver index ) ; zoo keeper servers . remove ( active zkserver index ) ; log . info ( kill the current active zk servers in the cluster + on client port : + client port ) ; if ( standalone server factory list . is empty ( ) ) { there is no backup servers ; return - 1 ; }
load and verify ( repl db name , curr dump . dump location , incr dump . last repl id ) ;
if ( state = = removed & & first removed = = - 1 ) first removed = index ; index - = probe ; if ( index < 0 ) { index + = length ; } state = _ states [ index ] ;
long string pos = begin pos + string pool header . get strings start ( ) - string pool header . get header size ( ) ; buffer . position ( ( int ) string pos ) ; string pool entry [ ] entries = new string pool entry [ offsets . length ] ; for ( int i = 0 ; i < offsets . length ; i + + ) { entries [ i ] = new string pool entry ( i , string pos + offsets [ i ] ) ; } string last str = null ;
if ( bytedata = null ) { return bytedata ; }
hawt dbaggregation repository repo = new hawt dbaggregation repository ( repo1 , target data hawtdb . dat ) ;
delete tags for site ( site id ) ; if ( tags = null ) { for ( tag tag : tags ) { add tag ( tag ) ; } }
assert same ( collection , snapshot ) ;
test same ( line _ joiner . join ( class c { , constructor ( ) { , this . a = 1 ; , } , } , var obj = new c ( ) , ( { x : { a } } = { x : obj } ) ; ) ) ;
if ( null = cache service loader . get service ( ) ) { add operation handler ( named operation . class , new named operation handler ( ) ) ; add operation handler ( add named operation . class , new add named operation handler ( ) ) ; add operation handler ( get all named operations . class , new get all named operations handler ( ) ) ; add operation handler ( delete named operation . class , new delete named operation handler ( ) ) ; }
server server = new server ( ) ; singleton configurator . set instance ( server ) ; server config listener . set pojo clazz ( server . class ) ; tomcat tomcat = get tomcat instance ( ) ;
info . set diiinitiate ( false ) ; } else {
m cursor row = 0 ;
string sql = cast ( cast ( 1 - 2 as unsigned ) as signed ) ; my sqlexpr parser parser = new my sqlexpr parser ( new my sqllexer ( sql ) ) ; expression expr = parser . expression ( ) ; string output = output2 my sql ( expr , sql ) ; assert . assert equals ( cast ( cast ( 1 - 2 as unsigned ) as signed ) , output ) ; sql = position ( ' a ' in \ abc \ ) ;
bytes in last second + = current window . bytes transferred ;
system . out . println ( something ) ;
pn = nf . create call or new ( token . new , member expr ( false ) ) ; if ( match token ( token . lp ) ) { decompiler . add token ( token . lp ) ;
assert . assert equals ( 3 , repo . get ( ) . evaluators ( route - 2 ) . count ( ) ) ;
double from lat = to radians ( from . latitude ) ; double from lng = to radians ( from . longitude ) ; double to lat = to radians ( to . latitude ) ; double to lng = to radians ( to . longitude ) ; double cos from lat = cos ( from lat ) ; double cos to lat = cos ( to lat ) ;
this . operation set presence1 = ( operation set presence ) supported operation sets1 . get ( operation set presence . class . get name ( ) ) ;
fail ( message + : not found + path + in + path . get parent ( ) ) ;
rp1 = get default retry policy ( true , 10000 , 2 ) ; rp2 = get default retry policy ( true , 10000 , 2 ) ; rp3 = get default retry policy ( true , 10000 , 2 ) ; verify retry policy equivalence ( new retry policy [ ] { rp1 , rp2 , rp3 } ) ;
center panel . add ( get bottom panel ( ) , border layout . south ) ;
tree generator . safely set block ( view , pos x + ( int ) position . x + 1 , pos y + ( int ) position . y , pos z + ( int ) position . z , bark ) ;
animation spatial animation = new animation ( name , duration ) ; spatial animation . set tracks ( new spatial track [ ] { spatial track } ) ; return spatial animation ;
case 1 : portable activation idl server proxy install { this . install ( ) ; out = rh . create reply ( ) ; break ; }
m keyboard state = keyboard _ state _ capslock ;
controller . set retain view mode ( retain view mode . retain _ detach ) ;
conf = hbase configuration . create ( original conf ) ;
editor . set sketch location ( new point ( left , top ) ) ;
if ( res . is successful ( ) ) { transaction sample result . set successful ( false ) ; no failing samples + + ; }
settings . set property ( sonar . leak . period , 2008 - 11 - 30 ) ; under test . execute ( ) ;
log . info ( skipped line of size + new size + at pos + ( pos - new size ) ) ; }
assert equals ( 2 , test helpers . filter native registers ( interpreter . get defined registers ( ) ) . size ( ) ) ;
while ( path . starts with ( . . ) ) { path = path . substring ( 3 ) ; }
assert equals ( 0 , purge ( , app id , persistence policies . application , registry admin service . purge policy . skip on children ) ) ; assert path exists ( app path ) ; assert path exists ( dns1path ) ;
bitmap . recycle ( ) ;
realm dc0 = get admin client for started node in dc ( 0 ) . realms ( ) . realm ( realm _ name ) . to representation ( ) ; assert . assert equals ( cool realm , realm dc0 . get display name ( ) ) ; assert . assert false ( realm dc0 . is registration allowed ( ) ) ; atomic integer i = new atomic integer ( 0 ) ;
final string model name = 6029760550880411648 ; assert jq ( managed model store . rest _ end _ point , models [ 0 ] name = = ' + model name + ' ) ; assert jq ( managed feature store . rest _ end _ point + + feature store . default _ feature _ store _ name , features [ 0 ] name = = ' title ' ) ; assert jq ( managed feature store . rest _ end _ point + + feature store . default _ feature _ store _ name , features [ 1 ] name = = ' description ' ) ;
t . set t1 ( 4 ) ;
assert equals ( 0 , ksession . fire all rules ( ) ) ;
fabric . with ( this , new crashlytics ( ) ) ;
return i record . field type ( field name ) ; }
shell . run ( new file ( src main org codehaus groovy tools doc generator . groovy ) , args ) ;
if ( engine = = null ) { engine = new activity monitor engine ( entity manager factory , get transaction template ( ) , get process rules ( ) ) ; }
m notification manager . notify ( my _ notification _ id , notification builder . build ( ) ) ;
synchronized ( this ) { global string list = ( list < string > ) header . get ( strings ) ; global string map = new hash map < > ( global string list . size ( ) ) ; for ( int i = 0 ; i < global string list . size ( ) ; i + + ) { global string map . put ( global string list . get ( i ) , i + 1 ) ; } } }
if ( result = = null ) { result = other ; }
light = new ambient light ( ) ;
ar = ( async result ) msg . obj ;
return new dbrecord reader < t > ( split , input class , conf , create connection ( ) , get dbconf ( ) , conditions , field names , table name ) ;
for ( int i = to inc + 1 ; i < result . length ; i + + ) { if ( i > = fuzzy key meta . length | | fuzzy key meta [ i ] = = 0 * non - fixed * ) { result [ i ] = order . min ( ) ; } } }
anchor info . m layout from end = m current pending saved state . get boolean ( anchor layout from end ) ; if ( anchor info . m layout from end ) { anchor info . m coordinate = m orientation helper . get end after padding ( ) - m current pending saved state . get int ( anchor offset ) ; } else { anchor info . m coordinate = m orientation helper . get start after padding ( ) + m current pending saved state . get int ( anchor offset ) ; } return true ;
get physical plan helper ( ) . get topology context ( ) . invoke hook bolt ack ( tuple , latency ) ; bolt metrics . acked tuple ( tuple . get source stream id ( ) , tuple . get source component ( ) , latency . to nanos ( ) ) ; }
m zoom buttons controller . set zoom in enabled ( can zoom in ) ; m zoom buttons controller . set zoom out enabled ( can zoom out ) ; }
assert equals ( filter test 2 , , tagutils . filter ( ) ) ;
action event action event = new action event ( sub tree . get ( sub tree . get array ( ) [ sub tree . size ( ) - 1 ] ) , id , merging ? action names . sub _ tree _ merged : action names . sub _ tree _ loaded ) ; action router . get instance ( ) . action performed ( action event ) ;
string = test util . random unicode string ( random ( ) ) ; } else {
throw new parser configuration exception ( se . get message ( ) ) ;
if ( entry . is directory ( ) | | name . starts with ( meta - inf ) ) { continue ; }
int expected result = 0 ;
app . add preemption ( container , get clock ( ) . get time ( ) ) ;
if ( old request count = = this . request count . get ( ) ) { stop ( stopped ; only catalog regions remaining online ) ; break ; } old request count = this . request count . get ( ) ; } else {
rebalance ( ) ;
if ( operation . equals ( op _ create _ write ) ) { log . info ( deleting data directory ) ; temp fs . delete ( new path ( base dir , data _ dir _ name ) , true ) ; }
if ( _ max header list size > 0 & & _ header list size > _ max header list size ) { log . warn ( header list size too large { } > { } for { } , _ header list size , _ max header list size ) ; if ( log . is debug enabled ( ) ) log . debug ( metadata = { } , metadata ) ; } if ( log . is debug enabled ( ) ) log . debug ( string . format ( ctx tbl [ % x ] encoded % d octets , _ context . hash code ( ) , buffer . position ( ) - pos ) ) ;
return restaurant ; }
if ( event . get action ( ) = = action . left _ click _ block & & placed . get type ( ) = = material . fire ) { if ( events . fire and test cancel ( new break block event ( event , create ( event . get player ( ) ) , placed ) ) ) { event . set use interacted block ( result . deny ) ; break ; } } if ( event . is cancelled ( ) ) { play deny effect ( event . get player ( ) , clicked . get location ( ) . add ( 0 . 5 , 1 , 0 . 5 ) ) ; }
versioned < byte [ ] > v2 = new versioned < byte [ ] > ( value , vc1 ) ;
connection . add request property ( secure shuffle utils . http _ header _ url _ hash , enc hash ) ;
input processor . set metric group ( get environment ( ) . get metric group ( ) . get iometric group ( ) ) ;
f string buffer . append ( ' ' ) ;
default value configurations configs = config model . get object ( ) ;
for ( groovy constructor doc constructor : constructors ) { parameters for ( groovy parameter groovy parameter : constructor . parameters ( ) ) { simple groovy parameter param = ( simple groovy parameter ) groovy parameter ; string param type name = param . type name ( ) ; if ( visible classes . contains key ( param type name ) ) { param . set type ( ( groovy type ) visible classes . get ( param type name ) ) ; } else { groovy class doc doc = resolve class ( root doc , param type name ) ; if ( doc = null ) param . set type ( doc ) ; } process annotation refs ( root doc , param . annotations ( ) ) ; } process annotation refs ( root doc , constructor . annotations ( ) ) ; } for ( groovy field doc field : fields ) { simple groovy field doc mutable field = ( simple groovy field doc ) field ; groovy type field type = field . type ( ) ; string type name = field type . type name ( ) ; if ( visible classes . contains key ( type name ) ) { mutable field . set type ( ( groovy type ) visible classes . get ( type name ) ) ; } else { groovy class doc doc = resolve class ( root doc , type name ) ; if ( doc = null ) mutable field . set type ( doc ) ; } process annotation refs ( root doc , field . annotations ( ) ) ; }
intent sharing intent = new intent ( android . content . intent . action _ send ) ; sharing intent . add flags ( intent . flag _ activity _ clear _ when _ task _ reset ) ; sharing intent . set type ( image * ) ;
display matrix . set ( base matrix ) ; display matrix . post concat ( supp matrix ) ; return display matrix ; }
if ( _ pending ) {
execution = runtime service . create execution query ( ) . variable value greater than or equal ( date var , next month . get time ( ) ) . single result ( ) ; assert not null ( execution ) ; assert equals ( process instance3 . get id ( ) , execution . get id ( ) ) ; execution = runtime service . create execution query ( ) . variable value greater than or equal ( date var , next year . get time ( ) ) . single result ( ) ; assert not null ( execution ) ; assert equals ( process instance3 . get id ( ) , execution . get id ( ) ) ; assert equals ( 3 , runtime service . create execution query ( ) . variable value greater than or equal ( date var , one year ago . get time ( ) ) . count ( ) ) ;
found uri = true ; uri = buf . to string ( ) ; buf . set length ( 0 ) ; in curly = false ; } else {
byte [ ] ret = new byte [ k 2 ] ; assert . assert equals ( k 2 , is . read ( ret , 0 , k 2 ) ) ; is . close ( ) ; assert . assert false ( m file system . exists ( uri ) ) ;
this . dialect = new dialect = = null ? sqldialect . default : new dialect ; return this ; }
camel . start route ( foo ) ; assert equals ( true , camel . get route status ( foo ) . is started ( ) ) ;
dfstest util . append file ( get dfs ( ) , bar , blocksize ) ; current file len + = blocksize ; quota = foo node . get directory with quota feature ( ) . get space consumed ( ) ;
default addr = net utils . create socket addr ( original conf . get ( dfs . http . address ) ) ; default name = default addr . get host name ( ) + : + default addr . get port ( ) ; registration = zk . get primary avatar address ( default name , new stat ( ) , false ) ; output stream . println ( primary node http address : + registration ) ; for ( avatar an avatar : avatar . avatars ) { output stream . println ( an avatar + entries : ) ; for ( zookeeper key key : zookeeper key . values ( ) ) { string key in zookeeper = get znode name ( conf , service name , an avatar , key ) ; output stream . println ( key in zookeeper + : + zk . get primary avatar address ( key in zookeeper , new stat ( ) , false ) ) ; } }
tfr = parse _ test _ file ( . smalldata airlines allyears2k _ headers . zip ) ;
jtype input type = generation util . ref ( type ) ; jmethod write method = parcelable class . method ( jmod . public | jmod . static , void . type , write _ method ) ; jblock write method body = write method . body ( ) ; jvar write input var = write method . param ( input type , variable namer . generate name ( input type ) ) ; jvar parcel param = write method . param ( parcel type , variable namer . generate name ( parcel type ) ) ; jvar flags param = write method . param ( int . class , variable namer . generate name ( flags ) ) ; jvar identity param = write method . param ( code model . ref ( identity collection . class ) , variable namer . generate name ( identity map ) ) ; jvar identity key = write method body . decl ( code model . int , variable namer . generate name ( identity ) , identity param . invoke ( get key ) . arg ( write input var ) ) ; jconditional contains value conditional = write method body . _ if ( identity key . ne ( jexpr . lit ( - 1 ) ) ) ;
store parameters ( clazz , method ) ;
sql = select a from r1 where c in + ( select max ( c ) from r2 group by e having min ( a ) > ? ) ;
boolean ret = scheduler main . run scheduler ( ) ;
long clone = puzzle | shape . bitmap ;
muc . grant membership ( get bare jid ( 1 ) ) ; thread . sleep ( 300 ) ;
map < string , string > params = collections . singleton map ( pretty , true ) ;
final hmaster master = test _ util . get mini hbase cluster ( ) . get master ( ) ; quota snapshot store < table name > table store = master . get quota observer chore ( ) . get table snapshot store ( ) ; space quota snapshot snapshot = table store . get current state ( tn ) ; assert false ( quota should not be in violation , snapshot . get quota status ( ) . is in violation ( ) ) ; }
p stmt = connection . prepare statement ( insert into application _ key ( public _ key , private _ key , passphrase ) values ( ? , ? , ? ) ) ; p stmt . set string ( 1 , public key ) ; p stmt . set string ( 2 , encryption util . encrypt ( private key ) ) ; p stmt . set string ( 3 , encryption util . encrypt ( passphrase ) ) ; p stmt . execute ( ) ; dbutils . close stmt ( p stmt ) ; system . out . println ( key box generated global public key : ) ;
assert measures count for qualifier ( trk , measures on trk ) ; assert measures count for qualifier ( brc , measures on brc ) ; assert measures count for qualifier ( dir , measures on dir ) ; assert measures count for qualifier ( fil , measures on fil ) ;
return ; } else if ( stage = = block construction stage . pipeline _ close
assert false ( include a . class . is assignable from ( include b . class ) ) ;
results [ 0 ] . advance row ( ) ; map < string , string > column targets = new hash map < string , string > ( ) ; column targets . put ( hostname , results [ 0 ] . get string ( hostname ) ) ; validate row seen at all hosts ( results [ 0 ] , column targets , false ) ; assert equals ( hosts , results [ 0 ] . get row count ( ) ) ;
new customizable trace interceptor ( ) . set exit message ( ) ;
start ts = system . nano time ( ) ;
pixel store state pss = new pixel store state ( ) ;
pi hash offsets [ 0 ] = 0 ;
throw new voldemort exception ( the plan in server state + info + is not the same as the process passed + steal info ) ; } else if ( acquire rebalancing permit ( steal info . get donor id ( ) ) ) {
return slow equals ( hash , test hash ) ;
else { return false ; }
( ( message view holder ) holder ) . is last position ( position = = get item count ( ) - 1 ) ;
scan = new scan ( startrow , stoprow ) ; scan . add family ( hconstants . catalog _ family ) ; s = r . get scanner ( scan ) ;
rj = jc . submit job ( job ) ;
string [ ] terms = tpv . get terms ( ) ;
indarray l1 = null ; if ( index syn0 vec map . contains key ( vocab . element at index ( current word index ) ) ) { l1 = index syn0 vec map . get ( vocab . element at index ( current word index ) ) ; } else { l1 = get random syn0 vec ( vector length , ( long ) current word index ) ; }
register cell ( primary , primary , primary ) ; register cell ( secondary , primary , primary ) ; register cell ( secondary , secondary , secondary ) ; test data helper . override buckconfig ( primary , immutable map . of ( build , immutable map . of ( metadata _ storage , sqlite ) ) ) ;
cond = expr ( false ) ;
key value [ ] expected kvs4 = { } ; long expected rows = this . num rows ; long expected keys = 1 ; scan s = new scan ( ) ;
while ( iterator . has next ( ) ) { string t = iterator . next ( ) ; the value is the double - dash if ( - - . equals ( t ) ) { eat the rest = true ; } the value is a single dash else if ( - . equals ( t ) ) { if ( stop at non option ) { eat the rest = true ; } else { cmd . add arg ( t ) ; } } the value is an option else if ( t . starts with ( - ) ) { if ( stop at non option & & get options ( ) . has option ( t ) ) { eat the rest = true ; cmd . add arg ( t ) ; } else { process option ( t , iterator ) ; } } the value is an argument else { cmd . add arg ( t ) ; if ( stop at non option ) { eat the rest = true ; } } eat the remaining tokens if ( eat the rest ) { while ( iterator . has next ( ) ) { string str = iterator . next ( ) ; ensure only one double - dash is added if ( - - . equals ( str ) ) { cmd . add arg ( str ) ; } } } } process properties ( properties ) ;
for ( hazelcast instance instance : instances ) { ilock lock = instance . get lock ( key ) ; assert true ( lock . is locked ( ) ) ; }
sorted = file . create temp file ( sorted _ strings , txt ) ; string [ ] command = { bin bash , - c , export lc _ all = \ c \ & & cat \ + input . get absolute path ( ) + \ | sort > \ + sorted . get absolute path ( ) + \ } ;
fsdata output stream stm = file sys . create ( name ) ;
send window update ( 0 , ( 1 < < 31 ) - 1 ) ; handle go away response ( 1 , http2 error . flow _ control _ error ) ; }
assert queue state ( buffer , first , 11 , 3 ) ;
set content cache ( true ) ; }
linked list < pending data > send list = new linked list < pending data > ( ) ;
client rep . set full scope allowed ( false ) ;
push message ( data , true , wait for ack ) ; exception = null ; } catch ( ioexception xx ) { exception = xx ; close socket ( ) ; } } } finally {
test registration gateway test gateway = new test registration gateway ( new retrying registration test . test registration success ( connection id ) ) ; testing rpc service rpc service = new testing rpc service ( ) ; try { rpc service . register gateway ( test rpc connection endpoint address , test gateway ) ; test rpc connection connection = new test rpc connection ( test rpc connection endpoint address , leader id , rpc service . get executor ( ) , rpc service ) ; connection . start ( ) ; wait for connection established thread . sleep ( retrying registration test . test retrying registration . max _ timeout ) ; validate correct invocation and result assert true ( connection . is connected ( ) ) ; assert equals ( test rpc connection endpoint address , connection . get target address ( ) ) ; assert equals ( leader id , connection . get target leader id ( ) ) ; assert equals ( test gateway , connection . get target gateway ( ) ) ; assert equals ( connection id , connection . get connection id ( ) ) ; } finally { test gateway . stop ( ) ; rpc service . stop service ( ) ; }
simple byte cache . release ( data ) ; found = 1 ; } else {
assert equals ( 1 , query ( ) . any embedded ( user . addresses , address ) . on ( address . street . eq ( aakatu1 ) ) . fetch count ( ) ) ;
final string description override = intent . get string extra ( extra _ description _ text _ override ) ;
index writer config iwc = new index writer config ( analyzer ) ; iwc . set merge policy ( new log merge policy ( ) ) ; index writer iwriter = new index writer ( directory , iwc ) ; document doc = new document ( ) ; doc . add ( new sorted doc values field ( dv , new bytes ref ( foo ) ) ) ; doc . add ( new sorted doc values field ( dv , new bytes ref ( bar ) ) ) ; expect throws ( illegal argument exception . class , ( ) - > { iwriter . add document ( doc ) ; } ) ; iwriter . commit ( ) ;
assert equals ( 0 , events . size ( ) ) ; thread . sleep ( wait for seconds * 1000 + 2000 ) ;
if ( precision > 0 ) { return precision ; } int bit length = this . bit length ;
final striped data streamer current = get current streamer ( ) ;
file result parent = create and register temp file ( result ) ; result dir = result parent . to uri ( ) . to string ( ) ; result path = new file ( result parent , file . txt ) . get absolute path ( ) ; }
if ( input blocking state . get service ( ) = = null | | input blocking state . get service ( ) . equals ( entitlement service . entitlement _ service _ name ) ) { throw new entitlement api exception ( error code . sub _ blocking _ state _ invalid _ arg , need to specify a valid service name ) ; } if ( input blocking state . get state name ( ) = = null | | input blocking state . get state name ( ) . equals ( default entitlement api . ent _ state _ cancelled ) | | input blocking state . get state name ( ) . equals ( default entitlement api . ent _ state _ blocked ) | | input blocking state . get state name ( ) . equals ( default entitlement api . ent _ state _ clear ) ) { throw new entitlement api exception ( error code . sub _ blocking _ state _ invalid _ arg , need to specify a valid state name ) ; }
scan = new scan ( ) ; scan . add family ( families [ 4 ] ) ; result = get single scan result ( ht , scan ) ; assert null result ( result ) ;
xsltattribute def select attr def dot = new xsltattribute def ( null , select , xsltattribute def . t _ expr , false , xsltattribute def . error , . ) ;
unimplemented sequence ( b ) ;
class node . get fields ( ) . remove ( stored node ) ; } property node property node = new property node ( field node , modifiers , null , null ) ; configure ast ( property node , field def ) ; class node . add property ( property node ) ; } else {
if ( this . app view . plugin manager = null ) { this . app view . plugin manager . on reset ( ) ; }
if ( r = = null ) { throw new null pointer exception ( runnable can ' t be null ) ; } final chained ref hard ref = new chained ref ( m lock , r ) ; m runnables . insert after ( hard ref ) ; return hard ref . wrapper ; }
joystick . get pov yaxis ( ) . assign axis ( camera input . flycam _ rise , camera input . flycam _ lower ) ;
log . info ( index = + index ) ; index . print verbose string ( log , level . debug ) ; check success ( index , 200 , 500 , 200 ) ; check success ( index , 200 , 500 , 200 ) ; check success ( index , 300 , 2100 , 300 ) ; assert equals ( head check , 0 , index . get head ( ) ) ; assert equals ( tail check , 0 , index . get tail ( ) ) ;
class < ? > rt = am . get raw type ( ) ;
container container1 = create mock container ( user , 1 ) ; string localizer id1 = container1 . get container id ( ) . to string ( ) ; rls . get private localizers ( ) . put ( localizer id1 , rls . new localizer runner ( new localizer context ( user , container1 . get container id ( ) , null ) , localizer id1 ) ) ;
in = new object input stream ( bais ) ;
int rbytes = actual readable bytes ( ) ; channel buffer payload buffer = null ; long will have read byte count = frame payload bytes read + rbytes ;
scale drawable scale drawable = ( scale drawable ) ( ( layer drawable ) m seek bar . get progress drawable ( ) ) . find drawable by layer id ( r . id . progress ) ; gradient drawable gradient drawable = ( gradient drawable ) scale drawable . get drawable ( ) ; gradient drawable . set colors ( new int [ ] { black white color , black white color , black white color } ) ; m is favorite = favorite song . get instance ( get context ( ) ) . is favorite ( music player . get current audio id ( ) ) ;
assert equals ( - 30000 , get feature at ( url , 36 , 31 , sf : watertemp ) , eps ) ;
for ( resource web inf jar : context . get meta data ( ) . get ordered web inf jars ( ) ) { for ( map . entry < servlet container initializer , resource > entry : sci resource map . entry set ( ) ) { if ( web inf jar . equals ( entry . get value ( ) ) ) non excluded initializers . add ( entry . get key ( ) ) ; } }
return method . invoke ( ejb , invocation . get arguments ( ) ) ;
string [ ] edits dirs = cluster . get configuration ( 0 ) . get trimmed strings ( dfsconfig keys . dfs _ namenode _ name _ dir _ key ) ; shut down mini cluster ( ) ; configuration conf = get conf ( ) ; conf . set ( dfsconfig keys . dfs _ namenode _ edits _ dir _ required _ key , edits dirs [ 0 ] ) ; conf . set int ( dfsconfig keys . dfs _ namenode _ edits _ dir _ minimum _ key , 0 ) ; conf . set int ( dfsconfig keys . dfs _ namenode _ checked _ volumes _ minimum _ key , 0 ) ; set up mini cluster ( conf , true ) ; assert true ( do an edit ( ) ) ;
if ( f dtdhandler = null & & f start dtdcalled ) { f dtdhandler . start dtd ( f entity scanner , null ) ; } if ( f dtdhandler = null ) { f dtdhandler . start external subset ( identifier , null ) ; } f entity manager . start external subset ( ) ; f entity store . start external subset ( ) ; f ext entity depth + + ; }
int [ ] run = new int [ max _ run _ count + 1 ] ; int count = 0 ; run [ 0 ] = left ;
set value ( e , new tombstone ( zero , tombstone update . get timestamp ( ) ) ) ; }
for ( node comment : comments ) { xml element . get xml ( ) . remove child ( comment ) ; xml element . get xml ( ) . insert before ( comment , first child ) ; }
pn = nf . create expr statement no return ( pn , base lineno ) ;
file mapping prev = null ; file mapping current = mapped files ; while ( current = null ) { if ( current . paged file = = file ) { if ( prev = = null ) { mapped files = current . next ; } else { prev . next = current . next ; } page cache tracer . unmapped file ( current . file ) ; flush and close without fail ( file ) ; break ; } prev = current ; current = current . next ; }
for ( flow element flow element : flow elements ) { sequence flow are also flow elements , but are only parsed once every activity is found if ( flow element instanceof sequence flow ) { sequence flow to parse . add ( ( sequence flow ) flow element ) ; } else if ( flow element instanceof boundary event ) { boundary events to parse . add ( ( boundary event ) flow element ) ; } else if ( flow element instanceof event ) { deffered flow elements to parse . add ( flow element ) ; } else { bpmn parser handlers . parse element ( this , flow element ) ; } }
display metrics metrics = view . get context ( ) . get resources ( ) . get display metrics ( ) ;
assert not equals ( record identifier < > reader key , left , rk right ) ;
volt queue sql ( insert order line , 5 l , 7 l , 3 l , 1 l , 5 l , 3 l , timestamp , 45 l , 152 . 15 , blah blah blah ) ;
new async http request ( client , http context , uri request , content type , response handler , context ) . run ( ) ;
view . set background color ( color manager . get instance ( ) . get navigation drawer background color ( ) ) ; try { ( ( text view ) view . find view by id ( r . id . version ) ) . set text ( get activity ( ) . get package manager ( ) . get package info ( get activity ( ) . get package name ( ) , 0 ) . version name ) ; } catch ( package manager . name not found exception e ) { log manager . exception ( this , e ) ; } view drawer header = view . find view by id ( r . id . drawer _ header ) ;
assert equals ( 1 , type . get parameters ( ) . size ( ) ) ; type extends t = ( type extends ) type . get parameters ( ) . get ( 0 ) ; assert equals ( t , t . get var name ( ) ) ; assert equals ( 1 , t . get parameters ( ) . size ( ) ) ; }
set fill viewport ( true ) ; set over scroll mode ( over _ scroll _ never ) ; final display metrics dm = get resources ( ) . get display metrics ( ) ;
left input adapter node . do insert segment memory ( wm , true , lia mem , memory . get segment memory ( ) , peer , node . get left tuple source ( ) . is stream mode ( ) ) ;
return ( ( property mapping ) lhs persister ) . to columns ( column qualifier , property name ) ;
if ( bottoml1 > topl1 | | bottoml2 > topl2 ) { return 0 ; } int d = find _ middle _ snake ( bottoml1 , topl1 , bottoml2 , topl2 , v , snake ) ;
string user name = get user name ( ) ;
assert that ( messages . size ( ) , is ( 1 ) ) ;
tp . next position ( ) ; bytes ref payload = tp . get payload ( ) ; assert equals ( wrong payload length . , 1 , payload . length ) ; assert equals ( payload . bytes [ payload . offset ] , payload data [ num terms ] ) ; tp . next doc ( ) ; tp . next position ( ) ;
collections . shuffle ( handlers ) ;
x509 certificate c = get certificate ( f , cert _ rsa ) ;
hash map < string , object > vars = new hash map < string , object > ( ) ; vars . put ( boolean var , true ) ; process instance process instance1 = runtime service . start process instance by key ( one task process , vars ) ; vars = new hash map < string , object > ( ) ; vars . put ( boolean var , false ) ; process instance process instance2 = runtime service . start process instance by key ( one task process , vars ) ;
engine . searcher search result = engine . acquire searcher ( test ) ; matcher assert . assert that ( search result , engine searcher total hits matcher . engine searcher total hits ( 1 ) ) ; matcher assert . assert that ( search result , engine searcher total hits matcher . engine searcher total hits ( long point . new exact query ( _ seq _ no , 2 ) , 1 ) ) ; search result . close ( ) ; }
integer a = new integer ( 4 ) ;
is temp session = false ; session = original session ; try { if ( is jta ) { ( ( session ) temp session ) . get transaction ( ) . commit ( ) ; } ( ( session ) temp session ) . close ( ) ; } catch ( exception e ) { log . warn ( unable to close temporary session used to load lazy collection associated to no session ) ; }
emit to ganglia hosts ( ) ; }
pivot x = side padding + dip4 ;
itest bean adrian2 = ( itest bean ) bf . get bean ( adrian ) ;
if ( value = = null ) { provider . default serialize null ( jgen ) ; return ; }
test same ( function f ( a ) { var b = 1 ; a = 2 ; var c ; } ) ; }
log . info ( collection + collection + does not exist . ) ;
pb params . set revocation enabled ( true ) ;
string table alias = get lhs ( ) . get from element ( ) . get table alias ( ) ;
byte [ ] [ ] components = inode directory . get path components ( src ) ; write lock ( ) ;
call clients ( 100 , 0 . 5 , clients , clock , time interval , false , false ) ;
if ( first run ) { this . query . set start time ( system . current time millis ( ) ) ; } else { this . query . set start time ( system . current time millis ( ) - get delay ( ) ) ; }
for ( int i = 0 ; ( i + 1 ) < languages . length ; i + = 2 ) { try { string lang = new string ( languages , i , 2 , iso - 8859 - 1 ) ; for ( int j = 0 ; j < locales . length ; j + + ) { if ( locales [ j ] = null & & locales [ j ] . length ( ) > = 2 & & locales [ j ] . substring ( 0 , 2 ) . equals ( lang ) ) { return lang ; } } if ( best match = null ) break ; } catch ( java . io . unsupported encoding exception e ) { log ( failed to parse sim language records ) ; } }
attribute mining att = data dictionary . attribute ( name ) ;
if ( jpeg . is non standard icc ( cs ) ) { icc profile = ( ( icc _ color space ) cs ) . get profile ( ) ; } } else { int transform = jpeg . transform for type ( dest type , false ) ; if ( transform = jpeg . adobe _ impossible ) { write adobe = true ; new adobe transform = transform ; } }
if ( desktop . is desktop ( ) ) { if ( session info . get multi session ( ) ) commands _ . new session ( ) . set menu label ( new session . . . ) ; else commands _ . new session ( ) . remove ( ) ; }
error ( xmlmessages . create xmlmessage ( xmlerror resources . er _ method _ not _ supported , null ) ) ; not yet supported ) ; return null ;
url url = new url ( http : + address . get host address ( ) + : + http port ) ; url . open connection ( ) . connect ( ) ;
if ( m _ source system id . size ( ) = m _ size ) { string msg = coding error in source location : + m _ size + = + m _ source system id . size ( ) ; system . err . println ( msg ) ; throw new runtime exception ( msg ) ; } }
payload . put ( header name , s ) ; } } } finally {
int total expected split bundles = bundles . get bundles ( ) . size ( ) + number split bundles - 1 ;
replace string = dbutils . get quoted identifier ( data source , replace string ) ;
consumer < string , string > consumer2 = new pulsar kafka consumer < > ( props ) ; consumer2 . subscribe ( arrays . as list ( topic ) ) ; consumer records < string , string > records = consumer2 . poll ( 100 ) ; assert equals ( records . count ( ) , 0 ) ; consumer2 . close ( ) ; }
m default event color = color . parse color ( 9fc6e7 ) ;
assert equals ( out1 . get length ( ) , out2 . get length ( ) ) ;
if ( powers of two > 0 ) { if ( bits to shift + scale factor < = 62 ) { fits in long? return value of ( ( result < < bits to shift ) * new sign ) ; } else { return value of ( result * new sign ) . shift left ( ( int ) bits to shift ) ; } } else { return value of ( result * new sign ) ; }
producer template template = context . create producer template ( ) ;
m tile provider = entry . provider ; m tile overlay = m map . add tile overlay ( tile overlay ) ; }
if ( first edge = null ) { smallest alias = first edge . out ? first edge . edge . out . alias : first edge . edge . in . alias ; } else { smallest alias = pattern . alias to node . values ( ) . iterator ( ) . next ( ) . alias ; } execution plan . root alias = smallest alias ; iterable < oidentifiable > all candidates = match context . candidates . get ( smallest alias ) ; if ( all candidates = = null ) { oselect statement select = build select statement ( alias classes . get ( smallest alias ) , alias filters . get ( smallest alias ) ) ; all candidates = ( iterable ) get database ( ) . query ( new osqlsynch query < object > ( select . to string ( ) ) ) ; }
index second = index base + 1 ;
bug54716 server = new bug54716 ( ) ; singleton configurator . set instance ( server ) ; server config listener . set pojo clazz ( bug54716 . class ) ; tomcat tomcat = get tomcat instance ( ) ;
jmx server = server ;
headers . put ( camel box . listener , null ) ; final java . io . output stream result = request body and headers ( direct : downloadpreviousfileversion , null , headers ) ;
input file . read ( file offset , size ) . then ( file part - > { if ( is completed ) { return ; } if ( log ) { log . d ( tag , block + block index + read ) ; } if ( is write to dest provider ) { if ( output file . write ( file offset , file part . get contents ( ) , 0 , file part . get part length ( ) ) ) { if ( log ) { log . w ( tag , write + block index + error ) ; } report error ( ) ; return ; } } crc32 . update ( file part . get contents ( ) , 0 , file part . get part length ( ) ) ; if ( log ) { log . d ( tag , starting block upload + block index ) ; } upload count + + ; upload part ( block index , file part . get contents ( ) , 0 ) ; check queue ( ) ; } ) . failure ( e - > { if ( is completed ) { return ; } if ( log ) { log . w ( tag , block + block index + read failure ) ; } report error ( ) ; } ) ;
sb . append ( < td > ) ;
tuple working to return = new tuple ( new hash map < > ( ) ) ; tuple working for evaluators = new tuple ( new hash map < > ( ) ) ;
untested nodes = new array list < address > ( builder . get members ( ) ) ;
out buf [ out ptr + + ] = c ;
if ( alt > unsettled nodes . get priority ( candidate ) & & visited . contains ( candidate ) ) { unsettled nodes . relax priority ( candidate , alt ) ; previous . put ( candidate , u ) ; }
case ' t ' : { csi } { top } { left } { bottom } { right } { attributes } t
try { r . get length ( ) ; } catch ( processing exception e ) { return ; } fail ( ) ; }
list < runnable > pending = executor . shutdown now ( ) ; assert true ( pending . is empty ( ) ) ; assert true ( executor . is shutdown ( ) ) ; assert true ( executor . is terminated ( ) ) ;
return ( sign * 0 . 0d ) ;
ilbc _ common . bwexpand ( weightdenum , pos , lp , ilbc _ constants . lpc _ chirp _ weightdenum , lp _ length ) ;
put p = new put ( rows _ one [ 2 ] ) ; p . add ( families [ 0 ] , qualifiers _ one [ 2 ] , values [ 1 ] ) ; this . region . put ( p ) ;
if ( table name builder . is table resource ( table name ) ) { continue ; }
conf . set boolean ( mrjob config . job _ ubertask _ enable , false ) ;
final int size = array . get length ( value ) ;
app context . set remoting server ( remoting server ) ; app context . set job logger ( new smart job logger ( app context ) ) ; job queue factory factory = service loader . load ( job queue factory . class , config ) ;
if ( result state = = service state . state _ emergency _ only | | result state = = service state . state _ power _ off ) { result state = service state ; }
throw new org . apache . axis2 . databinding . adbexception ( status cannot be null ) ;
if ( validate part ( parts . get ( last index ) , true ) ) { return false ; } for ( int i = 0 ; i < last index ; i + + ) { string part = parts . get ( i ) ; if ( validate part ( part , false ) ) { return false ; } }
text buffer . replace ( prev line end , offset + length - prev line end , ) ; non - nls - 1 return ;
view child = m list . get child at ( i ) ;
cluster settings . apply settings ( settings . builder ( ) . put ( jobs log service . stats _ jobs _ log _ size _ setting . get key ( ) , 0 ) . put ( jobs log service . stats _ jobs _ log _ expiration _ setting . get key ( ) , 0s ) . put ( jobs log service . stats _ operations _ log _ size _ setting . get key ( ) , 0 ) . put ( jobs log service . stats _ operations _ log _ expiration _ setting . get key ( ) , 0s ) . build ( ) ) ; assert that ( stats . jobs log sink , matchers . instance of ( noop log sink . class ) ) ; assert that ( stats . operations log sink , matchers . instance of ( noop log sink . class ) ) ; assert that ( stats . is enabled ( ) , is ( true ) ) ; cluster settings . apply settings ( settings . builder ( ) . put ( jobs log service . stats _ jobs _ log _ size _ setting . get key ( ) , 200 ) . put ( jobs log service . stats _ operations _ log _ size _ setting . get key ( ) , 200 ) . put ( jobs log service . stats _ enabled _ setting . get key ( ) , true ) . build ( ) ) ;
if ( auth entity . is requisite ( ) ) { break ; } } }
field field = text view . class . get declared field ( m cursor drawable res ) ; field . set accessible ( true ) ; int drawable res id = field . get int ( this ) ;
for ( node < k , v > n = find first ( ) ; n = null ; n = n . next ) { v v = n . get valid value ( ) ; if ( v = null ) { s . write object ( n . key ) ; s . write object ( v ) ; } }
split ( hri , server , region count ) ;
if ( log . is debug enabled ( ) ) { log . debug ( ping from + task attempt id . to string ( ) ) ; } return feedback ; }
register function ( distance , new sqlfunction template ( standard basic types . double , ?1 . stdistance ( ?2 ) ) ) ;
assert invalid ( select * from % s where token ( key ) > token ( int ( 3030343330393233 ) ) limit 1 ) ;
stub factory = null ; } } else if ( stub adapter . is stub class ( clz ) ) {
int pending frames = pending bytes bytes per frame ; if ( pending frames > 0 ) { long time us = wav header . get time us ( input . get position ( ) - pending bytes ) ; int size = pending frames * bytes per frame ; pending bytes - = size ; track output . sample metadata ( time us , c . buffer _ flag _ key _ frame , size , pending bytes , null ) ; } return bytes appended = = result _ end _ of _ input ? result _ end _ of _ input : result _ continue ;
final recovery environment bean recovery environment bean = recovery property manager . get recovery environment bean ( ) ; final socket binding recovery binding = recovery binding injector . get value ( ) ; recovery environment bean . set recovery inet address ( recovery binding . get socket address ( ) . get address ( ) ) ; recovery environment bean . set recovery port ( recovery binding . get socket address ( ) . get port ( ) ) ; final socket binding status binding = status binding injector . get value ( ) ; recovery environment bean . set transaction status manager inet address ( status binding . get socket address ( ) . get address ( ) ) ; recovery environment bean . set transaction status manager port ( status binding . get socket address ( ) . get port ( ) ) ; recovery environment bean . set recovery listener ( recovery listener ) ; if ( recovery listener ) { managed binding binding = managed binding . factory . create simple managed binding ( recovery binding ) ; binding manager . get value ( ) . get named registry ( ) . register binding ( binding ) ; }
m player . reset ( ) ;
v doc a _ version = v doc a _ db1 . get version ( ) ;
map < string , integer > key val = new hash map < > ( 100 ) ;
if ( bytes . length < min _ number _ of _ bytes | | bytes . length > max _ number _ of _ bytes ) { throw new illegal argument exception ( string . format ( invalid hash code length : % d bytes , bytes . length ) ) ; } return from bytes no copy ( bytes . clone ( ) ) ; }
owner document . removed node ( this , replace ) ; check normalization after remove ( old previous sibling ) ; return old internal ;
this . configs . add ( 0 , new immutable conf wrapper ( conf ) ) ; return this ;
return get matcher ( path . substring ( 0 , idx ) ) . matches ( ) ; }
assert . assert true ( sigs . contains ( hash code ( ) i ) ) ; assert . assert true ( sigs . contains ( to string ( ) ljava lang string ; ) ) ;
field values field = null ;
log . debug ( sending group coordinator request to broker { } , node ) ;
try { method [ ] ms = a . get class ( ) . get methods ( ) ; method found = null ; for ( method m : ms ) { if ( m . get name ( ) . equals ( generate ) ) { found = m ; todo cache break ; } } found . set accessible ( true ) ; byte [ ] bs = ( byte [ ] ) found . invoke ( a , b ) ; proxy . load new version ( versionsuffix , bs ) ; proxy . run static initializer ( ) ; } catch ( throwable t ) { t . print stack trace ( ) ; }
final data source ds = get mandatory bean ( data source . class , data source ) ; jdbc = new jdbc template ( ds ) ; }
run statement on driver ( insert into + tbl name + values ( 1 , ' foo ' ) , ( 2 , ' bar ' ) , ( 3 , ' baz ' ) ) ;
while ( current file = null & & current file . exists ( ) ) { current file = current file . get parent file ( ) ; }
object [ ] working = new object [ ilength ] ; for ( int i = 0 ; i = ilength ; + + i ) { working [ i ] = get elem ( cx , this obj , i ) ; } heapsort ( cx , scope , working , ilength , compare , cmp buf ) ;
autocomplete candidate c = new autocomplete candidate ( generic completion types . field , v , v . length ) ; autocomplete candidate l = c ; while ( l . has children ( ) ) l = l . get childrens ( ) . get ( 0 ) ; class < ? > cl = get class ( curtype ) ; if ( cl = = null ) {
break ; case 2 : break ; case 3 : break ; } switch ( i ) { case 1 : break ;
if ( should refresh on rr ) { reload ( ) ; return true ; } else { should refresh on rr = true ; navigation application . instance . run on main thread ( new runnable ( ) { @ override public void run ( ) { should refresh on rr = false ; } } , 500 ) ; }
annotation descriptor annotation = new annotation descriptor ( annotation type ) ; copy string attribute ( annotation , subelement , name , false ) ; copy string attribute ( annotation , subelement , catalog , false ) ; if ( string helper . is not empty ( defaults . get catalog ( ) ) & & string helper . is empty ( ( string ) annotation . value of ( catalog ) ) ) { annotation . set value ( catalog , defaults . get catalog ( ) ) ; } copy string attribute ( annotation , subelement , schema , false ) ; if ( string helper . is not empty ( defaults . get schema ( ) ) & & string helper . is empty ( ( string ) annotation . value of ( schema ) ) ) { annotation . set value ( schema , defaults . get schema ( ) ) ; } build unique constraints ( annotation , subelement ) ; build index ( annotation , subelement ) ; annotation . set value ( join columns , get join columns ( subelement , false ) ) ; annotation . set value ( inverse join columns , get join columns ( subelement , true ) ) ; return annotation factory . create ( annotation ) ;
assert xpath evaluates to ( true false , wcs : capabilities ows : operations metadata + ows : operation [ @ name = \ get coverage \ ] ows : parameter ows : allowed values , dom ) ;
object old aahint = g2d . get rendering hint ( rendering hints . key _ antialiasing ) ;
gridview . set on item click listener ( new on item click listener ( ) { public void on item click ( adapter view < ? > parent , view v , int position , long id ) {
compiler . report ( t . make error ( n , hidden _ interface _ property , property name , interface type . get top most defining type ( property name ) . to string ( ) ) ) ;
key event key event = new key event ( key event . action _ down , key code ) ; intent intent = new intent ( intent . action _ media _ button ) ; intent . put extra ( intent . extra _ key _ event , key event ) ; try { m client intent . send ( get context ( ) , 0 , intent ) ; } catch ( canceled exception e ) { log . e ( tag , error sending intent for media button down : + e ) ; e . print stack trace ( ) ; } key event = new key event ( key event . action _ up , key code ) ; intent = new intent ( intent . action _ media _ button ) ; intent . put extra ( intent . extra _ key _ event , key event ) ; try { m client intent . send ( get context ( ) , 0 , intent ) ; } catch ( canceled exception e ) { log . e ( tag , error sending intent for media button up : + e ) ; e . print stack trace ( ) ; }
m . set tags ( new tree set < > ( ) ) ;
assert true ( equals builder . reflection equals ( to1 , teso , test transients ) ) ;
http message message = get base msg ( ) ;
create index no close ( do full merge , index1 , writer ) ;
switch ( state ) { case background _ disabled : paint background disabled ( g ) ; break ; case background _ enabled : paint background enabled ( g ) ; break ; }
conf . set long ( dfsconfig keys . federation _ store _ connection _ test _ ms , time unit . hours . to millis ( 1 ) ) ;
istream . read _ string ( ) ; value . reason = istream . read _ string ( ) ; return value ; }
bytes bytes multi hash map . result hash map result = new bytes bytes multi hash map . result ( ) ;
zoo keeper utility factory . close ( cleanup ) ;
do return ( new long ( 1 * 1024 * 1024 ) ) . when ( runtime ) . max memory ( ) ; insert blocks ( 0 , false ) ; for ( block b : map . get blocks ( ) ) { fail ( there should be no blocks in the map ) ; }
for ( int i = 0 ; i < num _ threads ; i + + ) { threads [ i ] = new ioperformance ( immediate flush , len ) ; }
attr = points . get attribution ( ) ; attr . set href ( http : example . com points provider ) ; get catalog ( ) . save ( points ) ; doc = get as dom ( wms?service = wms & request = get capabilities & version = 1 . 3 . 0 , true ) ;
dom = get as dom ( oseo search?count = 1 & start index = 3 ) ; assert has link ( dom , self , 3 , 1 ) ; assert has link ( dom , first , 1 , 1 ) ; assert has link ( dom , previous , 2 , 1 ) ; assert has link ( dom , last , 3 , 1 ) ; assert that ( dom , not ( has xpath ( at : feed at : link [ @ rel = ' next ' ] ) ) ) ; assert that ( dom , has xpath ( count ( at : feed at : entry ) , equal to ( 1 ) ) ) ; assert that ( dom , has xpath ( at : feed at : entry [ 1 ] at : title , equal to ( landsat8 ) ) ) ; }
ensure stack trace contains expected method ( expected . get cause ( ) . get stack trace ( ) , open ) ; }
layer group . set workspace ( workspace ) ;
controller = null ;
fold ( x = new reg exp ( \ \ ) , x = reg exp ( \ \ ) ) ;
info . set exists ( false ) ; return info ; }
array list values = new array list ( ) ; cookie [ ] cookies = ( ( http servlet request ) page context . get request ( ) ) . get cookies ( ) ; if ( cookies = = null ) { cookies = new cookie [ 0 ] ; }
final set < string > key set result = wrapper . key set ( ) ; verify ( map ) . key set ( ) ; assert same ( key set , key set result ) ;
8 , 8 , 9 , nll , 9 , \ 1 , 000 \ , nine , 1 . 10 , 1 . 11 , + current time + , point ( 9 9 ) , \ polygon ( ( 0 0 , 9 0 , 0 9 , 0 0 ) ) \ , 10 , 10 , 10 , 10 101 010 , second , 2 . 20 , 2 . 22 + current time + , point ( 10 10 ) , \ polygon ( ( 0 0 , 10 0 , 0 10 , 0 0 ) ) \ , 12 , n ull , 12 , 12121212 , twelveth , 12 . 12 , 12 . 12 } ; int invalid line cnt = 4 ; int valid line cnt = 7 ; test _ interface ( my options , my data , invalid line cnt , valid line cnt ) ; }
appender = new dbus event appender ( events , dbus buf , null ) ; appender . run ( ) ; log . info ( head : + parser . to string ( dbus buf . get head ( ) ) + , tail : + parser . to string ( dbus buf . get tail ( ) ) ) ; log . info ( num buffers : + dbus buf . get buffer ( ) . length ) ; log . info ( buffer : + arrays . to string ( dbus buf . get buffer ( ) ) ) ; head pos = dbus buf . get head ( ) ;
v = u ;
assert docs skipping equals ( info , left reader , left terms enum . doc freq ( ) , left docs = left terms enum . postings ( left docs , postings enum . none ) , right docs = right terms enum . postings ( right docs , postings enum . none ) , false ) ;
term query q1 = new term query ( new term ( hist , dummy ) ) ;
return scope = = null ? null : scope . get qualified slot ( name ) ;
receiver status listener . wait for event ( 14000 ) ;
test proc with valid json ( updated _ 1 row , client , update set field proc , id . veggies , - 9 , 5 ) ;
assert equals ( 2 , runtime service . create execution query ( ) . count ( ) ) ;
if ( available view x < 0 ) { available view x = 0 ; } float pager movement x ;
update fields ( ) ;
for ( int i = 0 ; i < 512 ; i + + ) { if ( i % 10 = = 0 ) system . out . println ( i ) ; ab . put a1 ( data ) ; }
float c = math utils . clamp ( settings . toi baugarte * ( separation + settings . linear slop ) , - settings . max linear correction , 0 . 0f ) ;
assert equals ( 5 , list1 . size ( ) ) ; assert equals ( 2 l , list1 . get ( 2 ) . long value ( ) ) ; assert equals ( 3 l , list1 . get ( 3 ) . long value ( ) ) ; assert equals ( 4 l , list1 . get ( 4 ) . long value ( ) ) ;
progress bar bar = new progress bar ( parent engine . get view ( ) . get context ( ) ) ; linear layout . layout params bar layout params = new linear layout . layout params ( layout params . wrap _ content , layout params . wrap _ content ) ; bar layout params . gravity = gravity . center ; bar . set layout params ( bar layout params ) ; layout . add view ( bar ) ; m video progress view = layout ; }
rest cache manager . get cache ( cache2 , media type . text _ plain ) ; rest cache manager . get cache ( cache2 , media type . from string ( text plain ; charset = utf - 8 ) ) ; rest cache manager . get cache ( cache2 , media type . from string ( text plain ; charset = shift - jis ) ) ; assert equals ( known caches . key set ( ) . size ( ) , 4 ) ;
student couch dbdouble primitive student max = new student couch dbdouble primitive ( ) ;
verify service properties ( d2 utils . get symlink name for master ( cluster name ) , d2 utils . add master to base name ( service1 ) , + service1 , null ) ;
doc . add ( new text field ( field , wizard oz the the the the the the , field . store . no ) ) ;
cli ( stop - deployment - group , test _ group ) ; await deployment group status ( default client ( ) , test _ group , deployment group status . state . failed ) ;
field field = dummy txn manager . class . get declared field ( lock mgr ) ;
if ( expression def . get order ( ) = = order . desc ) { return p . size ( ) ; }
p . put ( android . icu . library . version , icu . get icu version ( ) ) ; p . put ( android . icu . unicode . version , icu . get unicode version ( ) ) ; p . put ( android . icu . cldr . version , icu . get cldr version ( ) ) ; parse property assignments ( p , special properties ( ) ) ; parse property assignments ( p , robovm special properties ( ) ) ;
list < string > project keys = int stream . range ( 0 , worker count + 2 ) . map to obj ( i - > prj + i ) . collect ( to list ( ) ) ; for ( string project key : project keys ) { sonar scanner sonar runner = sonar scanner . create ( it utils . project dir ( shared xoo - sample ) ) . set properties ( sonar . project key , project key ) ; orchestrator . execute build ( sonar runner , false ) ; } list < ws ce . task > tasks list = wait for ws call status ( this : : get tasks all tasks , ( tasks ) - > verify in progress task count ( tasks , worker count ) ) ;
if ( f current entity . position = = f current entity . count ) { load ( 0 , true , true ) ; }
safe clear locator ( ) ;
final int color = math . abs ( key . hash code ( ) ) % num _ of _ tile _ colors ;
return m snapshots . get snapshot ( i ) . get key ( ) . hash code ( ) ;
methods . add ( get index method ( folder name , declared by metadata id ) ) ;
boolean is page menu ; boolean is overview menu ; boolean is tablet empty mode menu ; boolean is overview = m activity . is in overview mode ( ) ;
return new ingest rule response ( acknowledged ) ; } } ) ; }
int test max bulk length = default max bulk length 10 ;
if ( this . is stopped ) { fragment manager fragment manager = get support fragment manager ( ) ; while ( fragment manager . get back stack entry count ( ) > 1 ) { fragment manager . pop back stack immediate ( ) ; } fragment manager . pop back stack ( ) ; }
create property group ( mongodb , new string [ ] { source , database , username , password } ) ; create property group ( sampler , new string [ ] { script } ) ;
thread t = new thread ( new runnable ( ) { public void run ( ) { for ( iconnection listener listener : connection listeners ) { listener . notify disconnected ( con ) ; } connection listeners . clear ( ) ; } } , thread id ) ;
string props = test \ n second = 2 \ n third item : a short phrase ; test prop . load ( new string reader ( props ) ) ;
return new unsafe heap swapped byte buf ( this ) ;
int nb segments = ( radial samples ) * 3 ; short buffer idx buf = buffer utils . create short buffer ( 2 * nb segments ) ;
assert analyzes to ( a , خورده شده بوده باشد , new string [ ] { خورده } ) ;
if ( looper . my looper ( ) = = null ) { was looper null = true ; looper . prepare ( ) ; } handler = new handler ( ) ;
elem template match template = transformer . get matched template ( ) ; transformer . apply template to node ( this , match template , source node ) ; }
if ( old value = = null ) { system . clear property ( hadoop . home . dir ) ; } else { system . set property ( hadoop . home . dir , old value ) ; } try {
final map storm _ conf = config . read storm config ( src main resources master _ defaults . yaml ) ; storm _ conf . put ( backtype . storm . config . storm _ zookeeper _ port , zk server . port ( ) ) ; storm _ conf _ file = test conf . create config file ( storm _ conf ) ; confirm nothing is running ( storm _ conf ) ; storm amrmclient mock client = mock ( storm amrmclient . class ) ; server = new master server ( storm _ conf , mock client ) ;
for ( widget w : this ) { if ( w instanceof chunk output frame ) { chunk output frame frame = ( chunk output frame ) w ; frame . run after render ( after render _ ) ; } else if ( w instanceof fixed ratio widget ) { fixed ratio widget fixed ratio widget = ( fixed ratio widget ) w ; widget inner widget = fixed ratio widget . get widget ( ) ; if ( inner widget instanceof chunk output frame ) { chunk output frame frame = ( chunk output frame ) inner widget ; frame . run after render ( after render _ ) ; } } else if ( w instanceof editor theme listener ) { ( ( editor theme listener ) w ) . on editor theme changed ( colors ) ; } }
if ( is wait for completion ( ) ) { while ( done . get ( ) & & stopped ) { if ( step execution . is terminate only ( ) ) { log . info ( cancelling job tasklet ) ; stopped = true ; stop jobs ( job listener ) ; wait for stopping to properly occur while ( done . get ( ) ) { synchronized ( done ) { done . wait ( ) ; } } } else { wait a bit more then the internal hadoop threads thread . sleep ( 5500 ) ; } } } return repeat status . finished ;
sm = scheduling policy . parse ( fair ) ;
bitmap factory . options o = new bitmap factory . options ( ) ;
final count down latch cdl = new count down latch ( 1 ) ;
handover . wakeup producer ( ) ; synchronized ( consumer reassignment lock ) { if ( consumer = null ) { consumer . wakeup ( ) ; } else {
if ( total docs > index writer . get actual max docs ( ) ) { throw new corrupt index exception ( too many documents : an index cannot exceed + index writer . get actual max docs ( ) + but readers have total max doc = + total docs , input ) ; } return infos ;
if ( text . length ( ) = = 0 ) { return ; } writer . write ( ) ;
if ( _ socket _ . is input shutdown ( ) ) { return false ; }
builder = new wcsrequest builder panel ( request builder , new get coverage request ( ) ) ;
desired method = method signature bean . class . get method ( overloaded , new class [ ] { string . class , bean factory . class } ) ;
return unit . convert from ( val , suffix = null ? byte suffixes . get ( suffix ) : unit ) ; } else if ( fraction matcher . matches ( ) ) { throw new number format exception ( fractional values are not supported . input was : + fraction matcher . group ( 1 ) ) ; } else { throw new number format exception ( failed to parse byte string : + str ) ; } } catch ( number format exception e ) {
parse config config again = current config controller . get from disk ( ) ;
node meta data . format . write ( meta data , paths ) ; return meta data ; }
completable future < multiple jobs details > job details future = leader gateway . request job details ( true , true , timeout ) ; job details future . when complete async ( ( multiple jobs details job details , throwable throwable ) - > { if ( throwable = null ) { log . debug ( fetching of job details failed . , throwable ) ; } else { array list < string > active jobs = new array list < > ( ) ; for ( job details job : job details . get running ( ) ) { active jobs . add ( job . get job id ( ) . to string ( ) ) ; } for ( job details job : job details . get finished ( ) ) { active jobs . add ( job . get job id ( ) . to string ( ) ) ; } metrics . retain jobs ( active jobs ) ; } } , executor ) ;
scriptable object . define property ( scope , name , function , scriptable object . permanent ) ;
y + = fm . get height ( ) ;
assert that ( modifier . is final ( robo data field . get modifiers ( ) ) ) . is true ( ) ;
map < string , string > aliases = new hash map < string , string > ( ) ; map < string , string > implementations = new hash map < string , string > ( ) ; for ( entry < object , object > entry : provider . entry set ( ) ) { object k = entry . get key ( ) ; object v = entry . get value ( ) ; assert equals ( string . class , k . get class ( ) ) ; assert equals ( string . class , v . get class ( ) ) ; string key = ( string ) k ; string value = ( string ) v ;
set < string > keys to delete = sets . difference ( local set of keys , all keys ) ;
throw new hibernate exception ( illegal attempt to associate a managed entity with two open persistence contexts . + entity entry ) ;
if ( file system . exists ( current attempt ) ) { id = get next id to try ( initial , id ) ; current attempt = new path ( initial . to string ( ) + . + id ) ; } else { throw ex ; }
system . arraycopy ( plclpc , 0 , this . prev lpc , 0 , ilbc _ constants . lpc _ filterorder + 1 ) ;
min bound = next min bound ; max bound = next max bound ; }
case down : case floor : return ( integer . size - 1 ) - integer . number of leading zeros ( x ) ; case up :
string servlet path = ( string ) get attribute ( request dispatcher . include _ servlet _ path ) ;
out . put ( ( byte ) 0x38 ) . put ( ( byte ) 0x39 ) . put ( ( byte ) 0x61 ) ;
callback . expect ( tree . get first child ( ) , tree ) ; t . traverse with scope ( tree . get first child ( ) , top scope ) ; callback . assert entered ( ) ;
if ( m state = = state . normal ) { m launcher . get drag layer ( ) . set background alpha ( progress = = 1 ? 0 : progress * 0 . 8f ) ; } if ( m launcher . get hotseat ( ) = null ) { m launcher . get hotseat ( ) . set translation x ( translation x ) ; }
int new size = size - ( to index - from index ) ;
resource client . update ( resource ) ;
launch intent ( intent ) ; return true ; }
assert that ( build nodes . get length ( ) , equal to ( 2 ) ) ; assert that ( build nodes . item ( 0 ) . get node value ( ) , equal to ( root gid ) ) ; assert that ( build nodes . item ( 1 ) . get node value ( ) , equal to ( root gid ) ) ; }
return old index = = index?recid : null ;
return m _ result listener . is result required ( this , new key ) ; }
slice _ from ( ente ) ;
instance endpoint endpoint2 = new instance endpoint ( ) ; endpoint2 . set name ( elasticsearch ) ; endpoint2 . set virtual ipaddress ( inet address . get loopback address ( ) ) ; endpoint2 . set port ( 9401 ) ; instance2 . set instance endpoints ( new singleton array list ( endpoint2 ) ) ; deployment . set role instances ( new array list < > ( arrays . as list ( instance1 , instance2 ) ) ) ;
session . get transaction ( ) . begin ( ) ; object result = session . create query ( from jpa test entity where text = : text ) . set parameter ( text , unique _ text _ 2 ) . get single result ( ) ; session . get transaction ( ) . commit ( ) ;
instructions . add ( reil helpers . create bsh ( base offset + 5 , operand size . byte , helpers . auxiliary _ flag , operand size . byte , 12 , operand size . word , shifted af ) ) ;
big integer mod val = this ; if ( signum < 0 | | ( this . compare magnitude ( m ) > = 0 ) ) mod val = this . mod ( m ) ; if ( mod val . equals ( one ) ) return one ;
fsdata output stream os2 = fs . create ( file2 , replication ) ; os2 . write ( new byte [ 1 ] ) ; os2 . hflush ( ) ; int expected file2 reserved = block _ size - 1 ; check reserved space ( expected file2 reserved ) ;
storage helper . save sd card info ( get application context ( ) , tree uri ) ;
int final offset = correct offset ( scanner . yychar ( ) + scanner . yylength ( ) ) ; offset att . set offset ( final offset , final offset ) ;
return execute . xml ;
final class ownerclass = get ownerclass ( owner , class level ) ;
section . check warning headers ( empty list ( ) ) ;
m paint . set style ( paint . style . fill _ and _ stroke ) ;
string [ ] libraries table cols = { library _ name , library _ tag , song _ id } ; string [ ] libraries table col types = { text , text , text } ; string create libraries table = build create statement ( libraries _ table , libraries table cols , libraries table col types ) ;
assert . assert true ( resource handlers . get ( 0 ) = = handler ) ; }
if ( rhs . get kind ( ) = sql kind . literal ) { return null ; }
uristatus status = m file system . get status ( file path ) ;
int tag = constant . get tag ( ) ; if ( tag = = class constants . constant _ long | | tag = = class constants . constant _ double ) { new constant pool [ new length + + ] = null ; } previous comparable constant = comparable constant ;
assert equals ( ufodog , test realm2 . where ( dog . class ) . find first ( ) . get name ( ) ) ; test realm2 . close ( ) ;
begin shape ( quads ) ;
pair . set left ( column . substring ( 1 , column . length ( ) - 1 ) ) ;
drop keys2 ( ) ;
xs . add default implementation ( grid geometry2 d . class , grid geometry . class ) ; xs . add default implementation ( default geographic crs . class , coordinate reference system . class ) ;
from ( quartz2 : my group my timer name?fire now = true & trigger . repeat interval = 2000 & trigger . repeat count = 2 ) . to ( log : quartz ) . to ( mock : result ) ;
mapper . disable ( json generator . feature . auto _ close _ json _ content ) ;
assert equals ( 0 , test . get years ( ) ) ; ( 4 + ( 3 * 7 ) + ( 2 * 30 ) + 365 ) = = 450 assert equals ( 0 , test . get months ( ) ) ; assert equals ( 0 , test . get weeks ( ) ) ; assert equals ( 0 , test . get days ( ) ) ; assert equals ( ( 450 * 24 ) + 5 , test . get hours ( ) ) ; assert equals ( 6 , test . get minutes ( ) ) ; assert equals ( 7 , test . get seconds ( ) ) ; assert equals ( 8 , test . get millis ( ) ) ; }
executor executor = executors . new cached thread pool ( ) ; server bootstrap sb = new server bootstrap ( new nio server socket channel factory ( executor , executor ) ) ;
digest . reset ( ) ;
htable t = new htable ( conf , bytes . to bytes ( table ) ) ; result scanner s = t . get scanner ( new scan ( ) ) ; s . close ( ) ; t . close ( ) ; scanner . close ( ) ;
final string action = intent . get action ( ) ;
if ( domain match ( host , cookie domain ) ) { return false ; }
for ( final object o : collection ) { if ( oquery operator equals . equals ( i left , o ) ) return false ; }
if ( inside parenthesis = = 0 ) throw new oserialization exception ( found invalid + embedded _ end + character at position + i + of text + new string ( i source ) + . ensure it is opened and closed correctly . ) ;
builder . put ( cmd line settings ) ; validate known settings ( builder ) ;
assert not null ( data map . load ( id ) ) ;
default button model button model = ( default button model ) model ;
while ( cluster . get data nodes ( ) . get ( 0 ) . is datanode fully started ( ) ) { thread . sleep ( 50 ) ; } assert equals ( dn generated a new uuid despite disk1 having it intact , original uuid , cluster . get data nodes ( ) . get ( 0 ) . get datanode uuid ( ) ) ; } finally {
m job storage . remove ( request ) ;
assert contains ( client . endpoint . count = 0 ) ;
list < parameter < ? > > parameters = collections . < parameter < ? > > singleton list ( param ) ; return argument builder . build args ( new object [ 0 ] , get mock resource method ( parameters ) , mock resource context , template ) ; }
expected entries = math . max ( expected entries , 2 ) ;
try { unregister mbeans ( non cache components ) ; need to unregister = false ; } catch ( exception e ) { log . problems unregistering mbeans ( e ) ; }
final string permission type = ( string ) view . get tag ( r . id . permission _ type ) ;
case tileset _ player1 _ base _ id + 4 : obj = new player base left ( 0 , team . team1 ) ; break ; case tileset _ player1 _ base _ id + 5 : obj = new player base left ( 1 , team . team1 ) ; break ; case tileset _ player1 _ base _ id + 12 : obj = new player base left ( 2 , team . team1 ) ; break ; case tileset _ player1 _ base _ id + 13 : obj = new player base left ( 3 , team . team1 ) ; break ; case tileset _ player1 _ base _ id + 20 : obj = new player base left ( 4 , team . team1 ) ; break ; case tileset _ player1 _ base _ id + 21 : obj = new player base left ( 5 , team . team1 ) ; break ;
get test data ( ) . add default raster layer ( system test data . tasmania _ bm , get catalog ( ) ) ;
add injections ( context , descriptor , node , jndi name , type util . from name ( type ) ) ;
sms helper . set max attachment size setting ( m context , ( string ) new value ) ; break ; case delay _ duration : try { int duration = integer . parse int ( ( string ) new value ) ; if ( duration < 1 | | duration > 30 ) throw new exception ( duration out of bounds ) ; } catch ( exception e ) { toast . make text ( m context , r . string . delayed _ duration _ bounds _ error , toast . length _ short ) . show ( ) ; } break ;
available line count - - ;
string snapshot name = snapshot ; byte [ ] snapshot name bytes = bytes . to bytes ( snapshot name ) ; admin . snapshot ( snapshot name bytes , table _ name ) ; log . info ( after snapshot file - system state ) ;
final path bar2 = new path ( sdir2 , bar ) ;
int offset num = 0 ; for ( string s : split text ) { float offset = text paint . measure text ( s ) 2 ; canvas . draw text ( s , this . get width ( ) 2 - offset , this . get height ( ) 2 + ( text size * ( offset num ) ) - ( ( split text . length - 1 ) * ( text size 2 ) ) , text paint ) ; offset num + + ; } }
fold ( x = [ foo ( ) , 0 ] . length , x = [ foo ( ) , 0 ] . length ) ;
instructions . add ( reil helpers . create bsh ( base offset + + , dw , target register , wd , - 31 , bt , helpers . cr0 _ less _ then ) ) ;
if ( text . ends with ( l ) | | text . ends with ( l ) ) { text = text . substring ( 0 , text . length ( ) - 1 ) ; }
if ( zkutil . check exists ( region server . get zoo keeper ( ) , node ) = - 1 ) { thread . sleep ( 100 ) ; }
if ( ( table . get effective table style ( ) . get tbl pr ( ) = null ) & & ( table . get effective table style ( ) . get tbl pr ( ) . get bidi visual ( ) = null ) & & ( table . get effective table style ( ) . get tbl pr ( ) . get bidi visual ( ) . is val ( ) ) ) { html css helper . append style ( table root , property . compose css ( direction , rtl ) ) ; }
image holder . apply to or set invisible ( get icon ( ) , view holder . profile icon , drawer image loader . tags . profile _ drawer _ item . name ( ) ) ;
map . put ( path , foo bar?verbose = true ) ; map . put ( disconnect , true ) ; uri = catalog . as endpoint uri ( netty4 - http , map , true ) ; assert equals ( netty4 - http : https : localhost : 8080 foo bar?verbose = true & disconnect = true , uri ) ; }
if ( last column takes rest & & field id = = fields . length - 1 ) { field byte end = struct byte end ; }
input stream is = kraken trade json test . class . get resource as stream ( trading example - addorder - response - data . json ) ;
check water temp value ( request , 14 . 89799975766800344 ) ; }
int length = absolute directories . length < relative directories . length ? absolute directories . length : relative directories . length ;
if ( ( width = - 1 ) & & ( height = - 1 ) ) { writer . set use custom dimensions ( true ) ; writer . set custom width ( width ) ; writer . set custom height ( height ) ; } writer . to output ( ) ;
int size = local servers . size ( ) ;
( ( frame layout . layout params ) get layout params ( ) ) . gravity | = gravity . center _ horizontal ;
call event call created event = ( call event ) call1 listener . collected events . get ( 0 ) ; assert equals ( call event . get event id ( ) , call event . call _ initiated , call created event . get event id ( ) ) ; assert same ( call event . get source ( ) , call at p1 , call created event . get source ( ) ) ;
decoder . reset ( ) ;
assert . assert equals ( no app master log found , 1 , num app masters ) ;
when ( explain work . get analyzer ( ) ) . then return ( mock ( base semantic analyzer . class ) ) ; return explain work ; }
exchange out = template . send ( endpoint , exchange ) ;
throw new null pointer exception ( item = = null ) ;
curator framework zk temp = mk zk ( ) ; string root path = string . value of ( conf . get ( config . storm _ zookeeper _ root ) ) ; client zookeeper . mkdirs ( zk temp , root path , acls ) ; zk temp . close ( ) ; active = new atomic boolean ( true ) ;
output stack [ output stack top + + ] = type ;
mv . visit label ( break label ) ; controller . get compile stack ( ) . pop ( ) ;
istream . seek ( offset ) ;
int current = get selected pos ( str . to string ( ) ) ;
object helper . not null ( configuration . get nodes ( ) , zoo keeper nodes ) ; retry policy retry policy = configuration . get retry policy ( ) ;
if ( serialized instanceof double & & ( ( double ) serialized ) . is na n ( ) ) { serialized = null ; } serialized = parameters . non null field validator ( ) . validate ( parameters . path ( ) , serialized ) ; return completed future ( new execution result impl ( serialized , null ) ) ;
return assign multiple enabled & & ( max assign per heartbeat = = - 1 | | assigned containers < max assign per heartbeat ) ;
doc = new document ( ) ; doc . add ( new string field ( id , doc1 , store . no ) ) ; doc . add ( new string field ( ndv , mock - value , store . no ) ) ; writer . add document ( doc ) ; writer . commit ( ) ;
do execute ( true , false , args ) ;
integer node id to get store xmlfrom = node id ; if ( node id < 0 ) { collection < node > nodes = admin client . get admin client cluster ( ) . get nodes ( ) ; if ( nodes . is empty ( ) ) { throw new voldemort exception ( no nodes in this cluster ) ; } else { node id to get store xmlfrom = nodes . iterator ( ) . next ( ) . get id ( ) ; } } versioned < string > stores xml = admin client . metadata mgmt ops . get remote metadata ( node id to get store xmlfrom , metadata store . stores _ key ) ;
spatial sky = sky factory . create sky ( asset manager , textures sky bright fullskies blue clear03 . dds , false ) ; sky . set cull hint ( spatial . cull hint . never ) ; root node . attach child ( sky ) ; fpp = new filter post processor ( asset manager ) ;
if ( ref . get size ( ) = null ) { set size ( ref . get size ( ) ) ; }
config . set expected to crash ( true ) ; boolean success = config . compile ( builder ) ;
check xpath count ( result , md : domains md : dimension domain [ ows : identifier = ' elevation ' ] , 1 ) ;
template . send body ( url , message one ) ; template . send body ( url , message two ) ; final service support consumer = ( service support ) context . get route ( foo ) . get consumer ( ) ;
return bitcoinium ticker ;
store manager = new ttlkcvsmanager ( store manager ) ;
if ( queue . size ( ) > 0 ) { pull top ( ) ; } else { current = null ; } if ( current = = null ) { throw new no such element exception ( ) ; } return current ;
results . put ( node name , response . get payload ( ) ) ;
store = get managed model store ( ) ;
s = new scanner ( 23 . 45 \ u0666 23 . 456 ) ; s . use locale ( locale . chinese ) ; try { s . next int ( 10 ) ; fail ( ) ; } catch ( input mismatch exception expected ) { } s . use locale ( locale . germany ) ;
code . put12 ( opcodes . multianewarray , i . index ) . put byte ( dims ) ;
_ rs . _ pinfs = pinfs ;
if ( prefix . starts with ( xml _ prefix ) ) { return false ; } stack stack ;
docker linux container runtime runtime = new docker linux container runtime ( mock executor , mock cgroups handler ) ;
if ( e < concise set utils . min _ allowed _ set _ bit | | e > concise set utils . max _ allowed _ integer ) { throw new index out of bounds exception ( string . value of ( e ) ) ; }
solid = geo area factory . make geo area ( planet model . sphere , 0 . 0 , 0 . 0 , - 1 . 1 , 1 . 1 , - 1 . 1 , 1 . 1 ) ;
chunk chunk = chunk util . create chunk ( reader ) ;
my repeatable [ ] array = clazz . get annotations by type ( my repeatable . class ) ;
sql type descriptor sql type descriptor = new integer type descriptor ( ) { @ override public boolean can be remapped ( ) { return false ; } } ;
this . segment . inc scanner count ( ) ;
max resolution = resolutions [ resolutions . length - 1 ] ;
short pow2w b = ( short ) ( 1 < < width ) ; big integer pow2w bi = big integer . value of ( pow2w b ) ; int i = 0 ;
{ string [ ] parameters = { - flip6 , string . value of ( new job id ( ) ) } ; stop options options = cli frontend parser . parse stop command ( parameters ) ; assert true ( options . get command line ( ) . has option ( flip6 default cli . flip _ 6 . get opt ( ) ) ) ; }
return ; } else { throw assertion error ; } }
int expires = 0 ; if ( resp . has expires header ( ) ) { expires = resp . get expires header ( ) . get delta seconds ( ) ; } else if ( resp . has contact header ( ) ) { vector contacts = resp . get contacts ( ) . get headers ( ) ; for ( int i = 0 ; i < contacts . size ( ) ; i + + ) { int exp _ i = ( new contact header ( ( header ) contacts . element at ( i ) ) ) . get expires ( ) ; if ( exp _ i > 0 & & ( expires = = 0 | | exp _ i < expires ) ) expires = exp _ i ; } } if ( expires > 0 & & expires < renew _ time ) renew _ time = expires ; print log ( registration success : + result , log level . high ) ;
solr query response rsp = make request ( handler , req ( ) ) ;
random random = new random ( 0 ) ;
namespace info ns info = get nsnamenode ( namespace id ) . version request ( ) ;
ukv . remove ( envkey ) ; env . poppush ( 4 , res , null ) ; }
client . head now ( other - uri , response - > { system . out . println ( received response with status code + response . status code ( ) ) ; } ) ; }
collections . swap ( to schedule , insert place , i ) ;
perform sized right extended long failure test ( new byte [ ] { } ) ;
instructions . add ( reil helpers . create or ( base offset + + , bt , or var1 , bt , or var2 , bt , helpers . get crbit ( i ) ) ) ; }
string param string = params . get param string ( ) . trim ( ) ;
previous record content = loaded . get result ( ) . buffer ; previous record version = loaded . get result ( ) . version ; previous record = orient . instance ( ) . get record factory manager ( ) . new instance ( loaded . get result ( ) . record type ) ; orecord internal . fill ( previous record , rid , previous record version , loaded . get result ( ) . get buffer ( ) , false ) ; }
curs . to first content token ( ) ;
else if ( shape . get map value type ( ) = null ) { string map val shape = shape . get map value type ( ) . get shape ( ) ; if ( shape substitutions . contains key ( map val shape ) ) { throw new illegal state exception ( shape substitution customization found for shape + map val shape + , but this shape is the value for a map shape . ) ; } }
ra = ref . get ( lifo ) ; if ( ra = null & & ra . get content ( ) = null ) { ikds . set default lifo ( boolean . value of ( ra . get content ( ) . to string ( ) ) . boolean value ( ) ) ; } ra = ref . get ( max idle per key ) ; if ( ra = null & & ra . get content ( ) = null ) { ikds . set default max idle ( integer . parse int ( ra . get content ( ) . to string ( ) ) ) ; } ra = ref . get ( max total per key ) ; if ( ra = null & & ra . get content ( ) = null ) { ikds . set default max total ( integer . parse int ( ra . get content ( ) . to string ( ) ) ) ; } ra = ref . get ( max wait millis ) ;
logger . debug ( executing http method : { } , uri : { } , request . get request line ( ) . get method ( ) , request . get request line ( ) . get uri ( ) ) ;
files . create directories ( metrics dir , dir _ attrs ) ; } catch ( ioexception e ) { logger . error ( failed to create directory { } : { } , metrics dir , e . get message ( ) ) ; return ; } }
if ( is valid join order ( table aliases ) ) { if ( m _ has large number of table joins ) return false ; throw new planning error exception ( the specified join order is invalid for the given query ) ; }
put pipeline request put request = new put pipeline request ( id , new bytes array ( { \ processors \ : [ ] } ) , xcontent type . json ) ; cluster state previous cluster state = cluster state ; cluster state = store . inner put ( put request , cluster state ) ; store . inner update pipelines ( previous cluster state , cluster state ) ; pipeline = store . get ( id ) ; assert that ( pipeline , not null value ( ) ) ; assert that ( pipeline . get id ( ) , equal to ( id ) ) ; assert that ( pipeline . get description ( ) , null value ( ) ) ; assert that ( pipeline . get processors ( ) . size ( ) , equal to ( 0 ) ) ;
q . set parameter ( amount , new monetory amount ( new big decimal ( 76 ) , currency . get instance ( usd ) ) ) ; assert equals ( 0 , q . list ( ) . size ( ) ) ; final query q timestamp = s . create query ( from transaction where timestamp = : timestamp ) ;
assert false ( p . is bucket finished ( new bucket id ( 32 , 1 < < 3 ) ) ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( hosted zone not empty ) ) return null ; hosted zone not empty exception e = ( hosted zone not empty exception ) super . unmarshall ( node ) ;
inet socket address listen addr = client rpc server . get listener address ( ) ; client rpc address = new inet socket address ( rpc addr . get host name ( ) , listen addr . get port ( ) ) ; nn . set rpc server address ( conf , client rpc address ) ; minimum data node version = conf . get ( dfsconfig keys . dfs _ namenode _ min _ supported _ datanode _ version _ key , dfsconfig keys . dfs _ namenode _ min _ supported _ datanode _ version _ default ) ;
object rel obj = get relation ( relation id ) ; string result ;
pinfo . update process info ( m . group ( 2 ) , integer . parse int ( m . group ( 3 ) ) , integer . parse int ( m . group ( 4 ) ) , integer . parse int ( m . group ( 5 ) ) , long . parse long ( m . group ( 7 ) ) , long . parse long ( m . group ( 8 ) ) , long . parse long ( m . group ( 10 ) ) , long . parse long ( m . group ( 11 ) ) ) ;
m resource = 0 ; } }
int balancer period = get configuration ( ) . get int ( hbase . balancer . period , 300000 ) ; balancer cutoff time = balancer period 2 ;
if ( offset + writable utils . decode vint size ( bytes [ offset ] ) > end ) { throw new eofexception ( ) ; }
from ( direct : start ) . load balance ( ) . weighted ( true , 2 , 3 ) . to ( mock : x , mock : y , mock : z ) ;
header . set other button drawable ( r . drawable . ic _ action _ add ) ; } else {
new thread ( new runnable ( ) { @ override public void run ( ) { realm realm = realm . get instance ( config ) ; assert equals ( 3 , realm . get global instance count ( config ) ) ; realm . close ( ) ; assert equals ( 2 , realm . get global instance count ( config ) ) ; bg done . count down ( ) ; } } ) . start ( ) ; test helper . await or fail ( bg done ) ;
add file ( connection , aaa , aaa \ n ) ; connection . add ( add params . create ( singleton list ( . ) ) ) ; add file ( connection , aaa , bbb \ n ) ; }
mock http servlet response resp = get as servlet response ( wfs?request = get feature & version = 1 . 0 . 0 & type name = sf : primitive geo feature & output format = excel ) ;
handler . finalize snapshot phase ( cp1 ) ; assert snapshot complete checkpoint ( handler , cp1 , 0 , three _ sources [ 0 ] ) ; assert . assert true ( cp1 . is snap shot source completed ( ) ) ; cp1 . set bootstrap target scn ( 110 l ) ;
if ( m item = null ) { ( ( text view ) root view . find view by id ( r . id . item _ detail ) ) . set text ( m item . content ) ; } return root view ;
byte [ ] oid = root poa . activate _ object ( new binding iterator impl ( rest ) ) ;
: new priority blocking queue < e > ( 11 , comparator ) ; }
for ( string ls : locale utils . get available locales ( ) ) { string [ ] lang array = ls . split ( _ ) ; if ( lang array . length = = 1 ) { if ( systloc . get language ( ) . equals ( lang array [ 0 ] ) ) { userloc = systloc ; break ; } } if ( lang array . length = = 2 ) { if ( systloc . get language ( ) . equals ( lang array [ 0 ] ) & & systloc . get country ( ) . equals ( lang array [ 1 ] ) ) { userloc = systloc ; break ; } } if ( lang array . length = = 3 ) { if ( systloc . get language ( ) . equals ( lang array [ 0 ] ) & & systloc . get country ( ) . equals ( lang array [ 1 ] ) & & systloc . get variant ( ) . equals ( lang array [ 2 ] ) ) { userloc = systloc ; break ; } } } if ( userloc = = null ) { second , try partial language match for ( string ls : locale utils . get available locales ( ) ) { string [ ] lang array = ls . split ( _ ) ; if ( systloc . get language ( ) . equals ( lang array [ 0 ] ) ) { userloc = create locale ( lang array ) ; break ; } } }
path in file = new path ( out dir , reduce - out ) ; long writable num inside = new long writable ( ) ; long writable num outside = new long writable ( ) ; sequence file . reader reader = new sequence file . reader ( fs , in file , job conf ) ; try { reader . next ( num inside , num outside ) ; } finally { reader . close ( ) ; }
object stream field [ ] fields = new class desc . get load fields ( ) ;
string id = cloud search utils . get id ( url ) ;
device . install files ( files type , install paths ) ; }
test context test context3a = test context test utils . build test context ( class hierarchy context hierarchy level3a test case . class , context cache ) ; test context3a . get application context ( ) ; assert context cache statistics ( context cache , level 3 , a , 3 , 0 , 3 ) ; assert parent context count ( 2 ) ;
for ( int i = 0 ; i < freq . length ; i + + ) { z top nw [ i ] = p3d . z ( top nw [ i ] ) ; z top ne [ i ] = p3d . z ( top ne [ i ] ) ; z top sw [ i ] = p3d . z ( top sw [ i ] ) ; z top se [ i ] = p3d . z ( top se [ i ] ) ; z bottom nw [ i ] = p3d . z ( bottom nw [ i ] ) ; z bottom ne [ i ] = p3d . z ( bottom ne [ i ] ) ; z bottom sw [ i ] = p3d . z ( bottom sw [ i ] ) ; z bottom se [ i ] = p3d . z ( bottom se [ i ] ) ; }
else if ( 21000 . equals ( sql state ) ) { return new bad sql grammar exception ( hive query , , new sqlexception ( cause , sql state ) ) ; }
elfunction mapper . map ( page nodes ) ;
define symbol ( token . function , false , name ) ;
last errors holder . do handle ( create log message ( log message1 ) ) ;
handler . send message ( handler . obtain message ( dispatcher . hunter _ decode _ failed , hunter ) ) ; } else {
dtmiterator result = ( dtmiterator ) m _ free stack . remove ( m _ free stack . size ( ) - 1 ) ; return result ;
map . get ( i ) ; }
if ( p = null ) { bean = sub deser . deserialize ( p , ctxt , bean ) ; }
assert true ( second async fallback command . get execution events ( ) . contains ( hystrix event type . failure ) ) ; assert true ( third async fallback command . get execution events ( ) . contains ( hystrix event type . failure ) ) ;
configuration . set uri ( parameters . get ( uri ) = = null ? this . uri : ( string ) parameters . get ( uri ) ) ;
set to ( email address . create from ( msg . get recipients ( message . recipient type . to ) ) ) ;
on complete runnable . run ( ) ;
if ( last reduce key col name = null ) { rs dist udafparam name = utilities . reduce field . key . name ( ) + . + last reduce key col name + : + num distinct udfs + . + semantic analyzer . get column internal name ( j ) ; } distinct udafparam = new expr node column desc ( rs dist udafparam col info . get type ( ) , rs dist udafparam name , rs dist udafparam col info . get tab alias ( ) , rs dist udafparam col info . get is virtual col ( ) ) ;
stash size - - ;
mailbox index = ( int ) data [ 0 ] & 0xff ;
file size = url connection . get content length ( ) ;
return dtmfilter . show _ text | dtmfilter . show _ cdata _ section ; case op codes . nodetype _ pi : return dtmfilter . show _ processing _ instruction ; case op codes . nodetype _ node :
int found constraint error = 0 ;
string base64 encoded public key = iab util . key ;
fsimage . roll edit log ( ) ;
global component registry component registry = cache . get cache manager ( ) . get global component registry ( ) ;
do action ( action . increase , auto tune factor , progress ) ;
get mock endpoint ( mock : result ) . expected message count ( 0 ) ; template . send body and header ( direct : start , hi world , id , 1 ) ;
return s _ name ; }
if ( audio sync enabled . is selected ( ) ) { codec config . extra trans . put ( audio - sync , ) ; } return codec config ;
create forwarding method return ( mv , caster , return type , sam method type , impl method , instantiated method type ) ; mv . visit maxs ( - 1 , - 1 ) ; mv . visit end ( ) ; }
map < string , state heartbeat > allocated = null ;
this . cache flusher = new mem store flusher ( conf , this ) ;
short type = ( short ) ( gotslot [ 0 ] & 0x ffff ) ;
return super . dispatch touch event ( ev ) ;
assert true ( geo area . overlaps = = rect . get relationship ( path ) ) ;
ec level = error correction level . value of ( ld string ) ;
assert translated lines ( translation , @ property ( copy , null _ resettable ) nsstring * test5 ; , @ property ( copy , null _ unspecified ) nsstring * test6 ; ) ;
while ( iter . has next ( ) ) { visitor iterator . bucket progress bp = iter . get next ( ) ; assert true ( buckets . contains ( bp . get superbucket ( ) ) ) ; buckets . remove ( bp . get superbucket ( ) ) ; } assert true ( buckets . is empty ( ) ) ;
assert false ( current thread ( ) . interrupted ( ) ) ; try { cache . get ( new object ( ) ) ; fail ( ) ; } catch ( execution exception expected ) { assert same ( e , expected . get cause ( ) ) ; } assert true ( current thread ( ) . interrupted ( ) ) ;
return max size 1024 ;
assert that ( doc . root doc ( ) . get fields ( point ) , not null value ( ) ) ;
set first line ( actual first line ) ;
query . set fields ( * , score , features : [ fv ] ) ;
create task ( task1 , new date ( now . get time ( ) + ( 2 * 24 l * 60 l * 60 l * 1000 l ) ) ) ; 2
assert equals ( result set . get string ( key _ field ) , insert key ) ; for ( int i = 0 ; i < 3 ; i + + ) { assert equals ( result set . get string ( field _ prefix + i ) , insert map . get ( field _ prefix + i ) . to string ( ) ) ; }
assert translated lines ( translation , pragma push _ macro ( \ include _ all _ some path test \ ) , ifdef restrict _ some path test , define include _ all _ some path test 0 , else , define include _ all _ some path test 1 , endif , undef restrict _ some path test ) ;
final file status file = fs . get file status ( file path ) ;
assert true ( inherits . get age ( ) = = 1 ) ; }
configuration . put ( instance _ name _ key , uuid . random uuid ( ) . to string ( ) ) ;
int old value = 111 ; set value ( node engine1 , partition id , old value ) ; long [ ] initial replica versions = get default replica versions ( node engine1 . get node ( ) , partition id ) ;
thread . sleep ( time unit . seconds . to millis ( 3 ) ) ; int total running count = 0 ; for ( dummy job job : running jobs ) { total running count + = job . get on run cnt ( ) ; } matcher assert . assert that ( only max consumer count jobs should start , total running count , equal to ( max consumer count ) ) ;
environment . lifecycle ( ) . manage ( data source ) ;
args = new string [ ] { - non interactive } ;
expect fail not assignable ( parser , ctx , ( iii - - ) + + ) ;
datagram socket the socket = new datagram socket ( ( socket address ) null ) ; try { inet address bad address = inet address . get by address ( support _ configuration . non local address bytes ) ; the socket . bind ( new inet socket address ( bad address , support _ port manager . get next port for udp ( ) ) ) ; fail ( no exception when binding to bad address ) ; } catch ( socket exception expected ) { } the socket . close ( ) ; }
write _ long ( 0 ) ;
key manager factory key manager factory = key manager factory . get instance ( key manager factory . get default algorithm ( ) ) ;
assert xpath evaluates to ( 0 , count ( ows : exception report ) , dom ) ;
m adapter items . remove ( next section . section break item ) ;
server configuration server conf = new server configuration ( ) ;
case 0xf0 :
ajax button button = new ajax button ( add identifier ) { private static final long serial version uid = 1 l ; @ override protected void on submit ( ajax request target target , form < ? > form ) { list < layer identifier info > list = identifiers . get model object ( ) ; layer identifier info new identifier = new layer identifier ( ) ; list . add ( new identifier ) ; identifiers . set model object ( list ) ; update links visibility ( ) ; target . add ( layer identifier list editor . this ) ; } } ;
string s = aced0005737200216a6176612e7574696c2e547265654d617024417363656e646 + 96e675375624d61700cab946d1f0fab1c020000787200216a6176612e7574696c2 + e547265654d6170244e6176696761626c655375624d617026617d4eacdd5933020 + 0075a000966726f6d53746172745a000b6869496e636c75736976655a000b6c6f4 + 96e636c75736976655a0005746f456e644c000268697400124c6a6176612f6c616 + e672f4f626a6563743b4c00026c6f71007e00024c00016d7400134c6a6176612f7 + 574696c2f547265654d61703b7870000001007400016374000161737200116a617 + 6612e7574696c2e547265654d61700cc1f63e2d256ae60300014c000a636f6d706 + 17261746f727400164c6a6176612f7574696c2f436f6d70617261746f723b78707 + 372002a6a6176612e6c616e672e537472696e672443617365496e73656e7369746 + 97665436f6d70617261746f7277035c7d5c50e5ce0200007870770400000004710 + 07e000671007e00067400016271007e000c71007e000571007e000574000164710 + 07e000d78 ;
m showing expanded caption = false ;
m layout mode = layout _ move _ selection ;
s = new scanner ( 23 ' 456 23 ' 456 ) ;
set chunk value ( f node value , null , echunk , eindex ) ;
delayed transport . reprocess ( picker ) ; verify ( picker ) . pick subchannel ( args ) ;
if ( acquired permit ) { topic load semaphore . release ( ) ; } create pending load topic ( ) ; return null ; } ) ; } catch ( runtime exception re ) {
es search . add sort ( append sort suffix if needed ( field _ rule _ key ) , sort order . asc ) ;
check unsorted ( unsorted map , related action , result ) ;
execute ( insert into % s json ? , { \ k \ : 0 , \ listmap \ : { \ [ 0 , 1 , 2 ] \ : true , \ [ 3 , 4 , 5 ] \ : false } } ) ;
return srgb < = 0 . 04045f ? srgb 12 . 92f : ( float ) math . pow ( ( srgb + 0 . 055f ) 1 . 055f , 2 . 4f ) ;
assert . assert equals ( 0 , encoder . get hpack context ( ) . size ( ) ) ; }
for ( string valid id : time zone . get available ids ( ) ) { assert true ( valid id + not found in list of known ids , time zone utils . known _ timezone _ ids . contains ( valid id ) ) ; final time zone expected = time zone . get time zone ( valid id ) ; final time zone actual = time zone utils . get time zone ( valid id ) ; assert same rules ( valid id , expected , actual ) ; ids tested . add ( valid id ) ; } assert equals ( time zone . get available ids vs time zone utils . known _ timezone _ ids , time zone utils . known _ timezone _ ids . size ( ) , ids tested . size ( ) ) ;
entry = entry . replace all ( \ \ s , ) ;
vec o2 j ( pose . position ( ) , hmd relative eye positions [ eye ] ) ;
batch answer = answer ;
if ( namespaces . length % 2 = 0 ) { throw new runtime exception ( invalid number of namespaces provided . ) ; }
if ( ( namespace quota < = 0 & & namespace quota = fsconstants . quota _ dont _ set & & namespace quota = fsconstants . quota _ reset ) | | ( diskspace quota < = 0 & & diskspace quota = fsconstants . quota _ dont _ set & & diskspace quota = fsconstants . quota _ reset ) ) { throw new illegal argument exception ( invalid values for quota : + namespace quota + and + diskspace quota ) ; } try { namenode . set quota ( src , namespace quota , diskspace quota ) ; } catch ( remote exception re ) { throw re . unwrap remote exception ( access control exception . class , file not found exception . class , nsquota exceeded exception . class , dsquota exceeded exception . class ) ; }
assert no errors ( do fsck ( conf , false ) ) ; }
if ( 0 = = named params . size ( ) ) { throw new ioexception ( string . format ( locale . root , invalid expression % s - at least one named parameter expected . eg . ' q = * : * ' , expression ) ) ; } modifiable solr params m params = new modifiable solr params ( ) ;
output obj inspector = udtf output oi ;
fast byte array output stream out = new fast byte array output stream ( ) ; out . write ( b ) ; write the byte we read when testing for end of stream copy ( in , out ) ; byte [ ] result = new byte [ bytes . length + out . size ( ) ] ; system . arraycopy ( bytes , 0 , result , 0 , bytes . length ) ; out . write to ( result , bytes . length ) ; return result ; }
restart ( ) ; wait procedure ( proc id ) ; procedure testing utility . assert proc not yet completed ( proc executor , proc id ) ; assert false ( proc executor . is running ( ) ) ;
m tab max width = m requested tab max width > 0 ? m requested tab max width : spec width - dp to px ( tab _ min _ width _ margin ) ;
java type t = mapper . construct type ( optional . class ) ; assert not null ( t ) ; assert equals ( optional . class , t . get raw class ( ) ) ; assert true ( t . is reference type ( ) ) ; }
for ( int arc idx = 0 ; arc idx < node . num arcs ; arc idx + + ) { final builder . arc < t > arc = node . arcs [ arc idx ] ; system . out . println ( label = + arc . label + target = + ( ( builder . compiled node ) arc . target ) . address + h = + h + output = + fst . outputs . output to string ( arc . output ) + is final? = + arc . is final ) ; h = prime * h + arc . label ; h = prime * h + ( ( builder . compiled node ) arc . target ) . address ; h = prime * h + arc . output . hash code ( ) ; h = prime * h + arc . next final output . hash code ( ) ; if ( arc . is final ) { h + = 17 ; } }
if ( index = 2 ) { text view badge text view = ( text view ) layout inflater . from ( context ) . inflate ( r . layout . simple _ count _ badge _ layout , null ) ; badge text view . set text ( + ( index + 1 ) ) ; badge pager title view . set badge view ( badge text view ) ; } else { image view badge image view = ( image view ) layout inflater . from ( context ) . inflate ( r . layout . simple _ red _ dot _ badge _ layout , null ) ; badge pager title view . set badge view ( badge image view ) ; }
nzb = 0 ;
final scope scope = chunk . get scope ( ) ;
int required bits = 64 - long . number of trailing zeros ( value ) ; if ( required bits = = 0 ) { required bits = 1 ; }
work duration = work duration . create from long ( 100 l , hours _ in _ day ) ;
list < type > param types = arrays . < type > as list ( org _ robovm _ apple _ foundation _ nsobject . get type ( ) , org _ robovm _ objc _ selector . get type ( ) ) ;
if ( cl = null & & cl = this ) try { return cl . load class ( name ) ; } catch ( class not found exception e ) { throw new class not found exception ( designated loader could not find class : + e ) ; }
for ( bundle installed bundle : all installed bundles ) { if ( installed bundle . get symbolic name ( ) . equals ( bundle . get symbolic name ( ) ) ) { return true ; } } return false ;
con . unwrap ( ivolt dbconnection . class ) . save statistics ( stats , config . statsfile ) ; con . close ( ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( authorization error ) ) return null ; authorization error exception e = ( authorization error exception ) super . unmarshall ( node ) ;
for ( handlers handlers : handler map . values ( ) ) { for ( handler holder holder : handlers . list ) { holder . get handler ( ) . unregister ( ) ; } }
return token . substring ( token . index of ( ' ) ) ;
if ( _ max header list size > 0 & & _ header list size > _ max header list size ) { log . warn ( header list size too large { } > { } for { } , _ header list size , _ max header list size ) ; if ( log . is debug enabled ( ) ) log . debug ( metadata = { } , metadata ) ; } if ( log . is debug enabled ( ) ) log . debug ( string . format ( ctx tbl [ % x ] encoded % d octets , _ context . hash code ( ) , buffer . position ( ) - pos ) ) ;
try { prop . clear property ( name ) ; prop . save ( ) ; } catch ( exception ex ) { log . error ( ex . to string ( ) , ex ) ; }
my proxy sender another sender = ac . get bean ( my another proxy sender , my proxy sender . class ) ; spring camel context context = ac . get beans of type ( spring camel context . class ) . values ( ) . iterator ( ) . next ( ) ; mock endpoint result = resolve mandatory endpoint ( context , mock : result , mock endpoint . class ) ; result . expected bodies received ( hello my friends ) ; another sender . greeting ( hello my friends ) ; result . assert is satisfied ( ) ; result . reset ( ) ;
consumer . update beginning offsets ( end offsets ) ;
set timeout ( 2 ) ; set execution delay ( 0 ) ; set encode delay ( 3 , 0 ) ; document dom = get as dom ( wfs?request = get feature & typenames = cdf : fifteen & version = 2 . 0 . 0 & service = wfs ) ;
assert equals ( mux rest response . get status ( ) , 200 , multiplexer should return 200 ) ;
max results for suggest = ( int ) max results for suggest param value ;
int num nodes = m nodes . size ( ) ;
optional nanos = r . next int ( ( int ) milliseconds _ per _ second ) * ( int ) nanoseconds _ per _ millissecond ;
assert true ( fs . rename ( path foo baz , path foo bar ) ) ;
if ( state decl . state type ( ) . is subtype of ( type descriptor . of ( set state . class ) ) ) { throw new unsupported operation exception ( string . format ( % s does not currently support % s , dataflow runner . class . get simple name ( ) , set state . class . get simple name ( ) ) ) ; }
when ( write handle . remaining ( ) ) . then return ( 5 , new integer [ ] { 4 , 3 , 2 , 1 , 0 } ) ; final byte array output stream byte array output stream = setup mock write handle to output stream ( write handle ) ;
set cycle duration ( duration . seconds ( 0 . 4 ) ) ;
query . builder ( ) . table ( test _ table ) . table ( null ) ;
dfsclient dfsclient = get dfsclient ( ) ; return dfsclient . get namenode ( ) . get block locations ( filepath . to string ( ) , 0 , size kb * 1024 ) . get located blocks ( ) ; }
vertex vertices [ ] = new vertex [ vertex _ count ] ;
equivalence set . put ( right expr , eq set1 ) ;
val . set exists ( false ) ; casted . stream objects ( value - > { assert true ( there should be no values to stream , false ) ; } ) ;
text view tv app name = ( text view ) find view by id ( r . id . tv app ) ;
make thread safe ( logger mock , true ) ; for ( method method : logger factory methods ) { settings . stub method ( method , logger mock ) ; }
db field position = integer . value of ( db field position str ) + 3 ;
load reporter load reporter = new sample load reporter ( app like . get application ( ) ) ;
@ suppress warnings ( { unchecked } ) class < ? extends module > module class = ( class < ? extends module > ) class . for name ( module class name ) ; this . module = module class . new instance ( ) ; } catch ( exception e ) {
r . close ( ) ;
try { final properties properties = new properties ( ) ; properties . set property ( checkstyle . header . file , new file ( config java . header ) . get canonical path ( ) ) ; final properties expander expander = new properties expander ( properties ) ; final configuration config = configuration loader . load configuration ( new input source ( new string reader ( code ) ) , expander , false ) ; final checker checker = new checker ( ) ; try { final class loader module class loader = checker . class . get class loader ( ) ; checker . set module class loader ( module class loader ) ; checker . configure ( config ) ; } finally { checker . destroy ( ) ; } } catch ( checkstyle exception ex ) { throw new checkstyle exception ( file name + has invalid checkstyle xml ( + ex . get message ( ) + ) : + unserialized source , ex ) ; }
set button . add action listener ( new action listener ( ) { public void action performed ( action event e ) { jpopup menu popup = get choose class popup menu ( ) ;
return m tab . get tab model selector ( ) . get model ( m tab . is incognito ( ) ) ;
request . get http response ( ) . set content type ( application xml ) ;
return s chars to gsm tables [ 0 ] . get ( ' ' , ' ' ) ; }
string lang = parse . get data ( ) . get parse meta ( ) . get ( metadata . language ) ;
for ( iclass file class file : class files ) { if ( class file . get element name ( ) . contains ( ) ) { filtered . add ( class file ) ; } } object [ ] non packages = concatenate ( filtered . to array ( ) , fragment . get non java resources ( ) ) ; if ( result . is empty ( ) ) return non packages ; collections . add all ( result , non packages ) ; return result . to array ( ) ;
return check merged segment ( test dir , merged segment ) ;
kraken depth depth = kraken market data service . get kraken depth ( currency pair . btc _ eur , long . max _ value ) ;
rm . get rmcontext ( ) . get dispatcher ( ) . get event handler ( ) . handle ( new rmapp event ( application . get application id ( ) , rmapp event type . attempt _ killed ) ) ;
use table name globally = use table name new ;
} } ) ; assert true ( encoder . offer ( http chunk . last _ chunk ) ) ; assert true ( encoder . finish ( ) ) ; assert not null ( encoder . poll ( ) ) ; assert null ( encoder . poll ( ) ) ; }
string [ ] temp nsarray = new string [ new size ] ;
regex . append ( . * ) ;
assert that ( go config service . has pipeline named ( pipeline config . name ( ) ) , is ( true ) ) ; assert that ( go config service . pipeline config named ( pipeline config . name ( ) ) , is ( pipeline config ) ) ;
state manager . stop queue ( q1 ) ; assert . assert equals ( queue state . stopped , cs . get queue ( q1 ) . get state ( ) ) ; assert . assert equals ( queue state . stopped , cs . get queue ( q3 ) . get state ( ) ) ; assert . assert true ( state manager . can delete ( q1 ) ) ; assert . assert true ( state manager . can delete ( q2 ) ) ; assert . assert true ( state manager . can delete ( q3 ) ) ;
final output stream out = new buffered output stream ( new output stream ( ) { byte [ ] buf = new byte [ 1 ] ; @ override public void write ( int b ) throws ioexception { buf [ 0 ] = ( byte ) b ; write ( buf , 0 , 1 ) ; } @ override public void write ( byte [ ] b , int off , int len ) throws ioexception { final string content = new string ( b , off , len ) ; swing utilities . invoke later ( new runnable ( ) { public void run ( ) { w . add text ( content ) ; } } ) ; } } , 100 ) ; system . set out ( new print stream ( out ) ) ;
info . set bitrate ( compute bitrate ( info . get track length ( ) , raf . length ( ) ) ) ;
assert . assert true ( node prioritizer . is preferred node to be reloacted ( nodes , b , parent ) ) ;
q timestamp . set parameter ( timestamp , new composite date time ( 2013 , 8 , 23 , 14 , 35 , 0 ) ) ; assert equals ( 0 , q timestamp . list ( ) . size ( ) ) ;
fast result . fast reset ( ) ; return true ; }
cache . put ( hostname , new address cache entry ( value , expiry nanos ) ) ;
field info fi ;
solr config sc = new solr config ( new solr resource loader ( test _ path ( ) . resolve ( collection1 ) ) , solrconfig - defaults . xml , null ) ;
response = mvc . perform ( get ( uri ) . header ( if _ none _ match , response . get header ( etag ) ) ) . and expect ( status ( ) . is not modified ( ) ) . and expect ( header ( ) . string ( etag , is ( not null value ( ) ) ) ) . and expect ( header ( ) . string ( last _ modified , is ( not null value ( ) ) ) ) . and do ( document ( if - none - match ) ) . and return ( ) . get response ( ) ;
expected exception . expect ( invalid column name exception . class ) ;
time . add ( calendar . second , http _ cache _ seconds ) ; response . set header ( expires , date formatter . format ( time . get time ( ) ) ) ; response . set header ( cache _ control , private , max - age = + http _ cache _ seconds ) ; response . set header ( last _ modified , date formatter . format ( new date ( file to cache . last modified ( ) ) ) ) ; }
for ( int i = 1 ; i < = num _ broker _ tags ; i + + ) { string broker tag = broker _ tag _ prefix + i ; send delete request ( _ controller request urlbuilder . for broker tenant delete ( broker tag ) ) ; assert . assert equals ( _ helix admin . get instances in cluster with tag ( _ helix cluster name , controller tenant name builder . get broker tenant name for tenant ( broker tag ) ) . size ( ) , 0 ) ; assert . assert equals ( _ helix admin . get instances in cluster with tag ( _ helix cluster name , common constants . helix . untagged _ broker _ instance ) . size ( ) , num _ instances - ( num _ broker _ tags - i ) * num _ brokers _ per _ tag ) ; }
d . put ( table header . content margins , new insets uiresource ( 0 , 0 , 0 , 0 ) ) ;
source = new source ( ) . set url ( stopurl ) . set user ( user ) . set password ( password ) . set locale ( locale . get default ( ) ) . set time zone ( time zone . get default ( ) ) ;
if ( ( b is deg _ a ^ b is deg _ b ) = false ) { p tri infos [ t ] . flag | = quad _ one _ degen _ tri ; p tri infos [ t + 1 ] . flag | = quad _ one _ degen _ tri ; }
group tree x = new group tree ( ) ; for ( int i = 0 ; i < 101 ; i + + ) { x . add ( new tdigest . group ( i 2 ) ) ; } assert null ( x . floor ( new tdigest . group ( - 30 ) ) ) ; }
for ( ; ; ) system . out . println ( receive ( ) ) ; } } ) ; final actor < object , void > m = spawn actor ( new basic actor < object , void > ( mailbox config ) { @ override protected void do run ( ) throws suspend execution , interrupted exception { link ( a . ref ( ) ) ; receive ( message selector . select ( ) . of type ( string . class ) ) ;
if ( body content = null ) { tag utils . get instance ( ) . write previous ( page context , body content . get string ( ) ) ; body content . clear body ( ) ; } return ( skip _ body ) ;
m blurred background layout params . set margins ( 0 , action bar height , 0 , 0 ) ;
try { stack trace element [ ] class names = thread . current thread ( ) . get stack trace ( ) ; for ( int j = 0 ; j < class names . length ; j + + ) { if ( class . for name ( class names [ j ] . get class name ( ) ) = = loader . class ) { return class . for name ( class names [ i + j ] . get class name ( ) ) ; } } } catch ( class not found exception e ) { logger . error ( no definition for the class found : + e . get message ( ) ) ; }
fp . add ( f . create relationship to ( c , my rel types . r1 ) ) ;
class < ? > [ ] interfaces = type . get interfaces ( ) ; add interfaces ( interfaces , dependency ) ; type = type . get superclass ( ) ; } while ( type = null ) ; return dependency ; }
java class cache . clear ( ) ; }
assert equals ( 0 , result . get jsonarray ( features ) . size ( ) ) ; result = ( jsonobject ) get as json ( disable request ) ;
assert jq ( req ( qf , text _ sw title , def type , edismax , q , wifi , sow , true ) , response num found = = 1 , response docs [ 0 ] id = = ' 72 ' ) ;
final int expected = memo . apply ( 1 , 2 , 3 , 4 ) ;
if ( fetch set & & link list . size ( ) > 0 ) { fetch = link list . get ( 0 ) ; fetch set = true ; }
l2 cache . cache block ( cache key , buf , in memory , true ) ; }
int ix = - 1 ;
f viewer . set input ( root vmc ) ;
assert equals ( 2 , realm . where ( null types . class ) . not equal to ( null types . field _ integer _ null , 1 ) . count ( ) ) ; assert equals ( 2 , realm . where ( null types . class ) . not equal to ( null types . field _ integer _ null , ( integer ) null ) . count ( ) ) ;
node . set aggregated containers utilization ( nm . get aggregated containers utilization ( ) ) ;
power mockito . when ( shell utils . curl package ( topology _ uri , topology _ dest , is _ verbose , false ) ) . then return ( true ) ;
when ( mock . concrete method ( frame = thread . current thread ( ) . get stack trace ( ) [ 1 ] . to string ( ) ) ) . then return ( ) ;
display metrics metrics = view . get context ( ) . get resources ( ) . get display metrics ( ) ;
baos = new java . io . byte array output stream ( ) ; b64os = new base64 . output stream ( baos , encode | options ) ; gzos = new java . util . zip . gzipoutput stream ( b64os ) ; gzos . write ( source , off , len ) ;
discovery nodes discovery nodes = discovery nodes . builder ( ) . add ( node a . discovery node ) . local node id ( node a . discovery node . get id ( ) ) . master node id ( node a . discovery node . get id ( ) ) . build ( ) ;
comment thread snippet comment thread snippet = new comment thread snippet ( ) ;
tokens = dfs . add delegation tokens ( renewer , null ) ;
paint list l1 = new paint list ( ) ;
if ( write cdata brackets & & m _ cdata tag open ) { m _ writer . write ( cdata _ delimiter _ open ) ; m _ cdata tag open = true ; }
logger . log ( level . info , - restoring : + restore file version ) ; restore file system action restore action = new restore file system action ( config , assembler , restore file version , options . get relative target path ( ) ) ;
if ( content . get ( default entry . get key ( ) ) instanceof map & & default entry . get value ( ) instanceof map ) { merge defaults ( ( map < string , object > ) content . get ( default entry . get key ( ) ) , ( map < string , object > ) default entry . get value ( ) ) ; } else if ( content . get ( default entry . get key ( ) ) instanceof list & & default entry . get value ( ) instanceof list ) { list default list = ( list ) default entry . get value ( ) ; list content list = ( list ) content . get ( default entry . get key ( ) ) ; list merged list = new array list ( ) ; if ( all list values are maps of one ( default list ) & & all list values are maps of one ( content list ) ) {
if ( key serializer instanceof string serializer ) { return ( string ) key ; } else { byte [ ] key bytes = key serializer . serialize ( topic , key ) ; return base64 . get encoder ( ) . encode to string ( key bytes ) ; }
rot . mul to out unsafe ( xfq , n1s [ i ] , n ) ; transform . mul to out unsafe ( xf , v1s [ i ] , v1 ) ;
sim predicate = p ; return sim score ;
http client params . set redirecting ( params , false ) ;
timer entry . duration = timer entry . duration + now - timer entry . clock started or resumed ;
reader . close ( ) ; w . add document ( new document ( ) ) ; w . force merge ( 1 ) ; reader = w . get reader ( ) ; searcher = new index searcher ( reader ) ; searcher . set query cache ( null ) ; weight = searcher . create normalized weight ( query , false ) ; scorer = weight . scorer ( searcher . get index reader ( ) . leaves ( ) . get ( 0 ) ) ; assert false ( doc id set iterator . all ( 1 ) . get class ( ) . equals ( scorer . iterator ( ) . get class ( ) ) ) ; reader . close ( ) ;
for ( queue acl acl : queue acl . values ( ) ) { access type access type = scheduler utils . to access type ( acl ) ; if ( acls . get ( access type ) = = null ) { access control list default acl = queue name . equals ( root ) ? everybody _ acl : nobody _ acl ; acls . put ( access type , default acl ) ; } } queue acls . put ( queue name , acls ) ;
listener . got extension ( peer , id , bs ) ;
security manager security = system . get security manager ( ) ; try { if ( security = null ) { final int last dot = class name . last index of ( . ) ; string package name = class name ; if ( last dot = - 1 ) package name = class name . substring ( 0 , last dot ) ; security . check package access ( package name ) ; } } catch ( security exception e ) { throw e ; } class provider class ;
java archive jar = shrink wrap . create ( java archive . class , jar _ name ) ;
assert equals ( cos . get byte count ( ) , content _ length _ value ) ; }
object obj = stack [ stack top ] ; if ( obj = = dbl _ mrk ) obj = script runtime . wrap number ( s dbl [ stack top ] ) ; stack [ stack top ] = script runtime . special ref ( obj , string reg , cx ) ; continue loop ; } case token . ref _ member : {
for ( file f : target files ) { if ( f . delete ( ) ) { logger . warn ( cannot remove file { } from deleted directory . , f . get absolute path ( ) ) ; } }
assert true ( baos . size ( ) < initial buffer size ) ;
context . add routes ( new route builder ( ) { @ override public void configure ( ) throws exception { from ( direct : bar ) . route id ( bar ) . recipient list ( header ( bar ) ) ; } } ) ;
int current count = n . get projected count ( recursion level ) ; if ( current count > 0 ) { fptree node temp = n . get parent ( ) ; while ( temp = tree ) {
assert equals ( tracker is not lost upon host decommissioning , 1 , jt . get cluster status ( false ) . get task trackers ( ) ) ;
candidates - - ;
if ( params . contains key ( jndi name ) ) { return false ; } return true ; }
mailbox index = ( int ) data [ 0 ] & 0xff ;
test expression ( test2 , mosaic _ test2 , expression , file names ) ;
empty request = empty . get default instance ( ) ;
double cpu cost = 0 . 0 ; for ( int i = 0 ; i < cardinalities . size ( ) ; i + + ) { cpu cost + = cardinalities . get ( i ) * cpu cost ; } return cpu cost ; }
serialization test . verify self ( map , comparator ) ;
table config table config = new table config . builder ( common constants . helix . table type . offline ) . set table name ( table _ name ) . set num replicas ( 3 ) . set broker tenant ( broker _ tenant _ name ) . set server tenant ( server _ tenant _ name ) . build ( ) ;
pattern analyzer a = new pattern analyzer ( pattern . compile ( , ) , false , null ) ;
if ( octet > 255 | | ( ip part . starts with ( 0 ) & & ip part . length ( ) > 1 ) ) { throw new number format exception ( ) ; } return ( byte ) octet ;
assert equals ( bkdl _ readahead _ batchsize _ default , dyn conf . get read ahead batch size ( ) ) ;
try { execution = runtime service . create execution query ( ) . variable value not equals ignore case ( upper , null ) . single result ( ) ; fail ( exception expected ) ; } catch ( activiti illegal argument exception ae ) { assert equals ( value is null , ae . get message ( ) ) ; }
assert pixel ( panel . legend image , 10 , 10 , color . red ) ;
verify ( mock transport factory ) . new client transport ( same ( bad address ) , any ( string . class ) , any ( string . class ) , any ( proxy parameters . class ) ) ; verify ( mock transport factory , times ( 0 ) ) . new client transport ( same ( good address ) , any ( string . class ) , any ( string . class ) , any ( proxy parameters . class ) ) ; mock client transport info bad transport info = transports . poll ( ) ;
node meta data . format . write ( meta data , paths ) ; return meta data ; }
progress = 2 . 0f 3 + ( ( ( float ) ( now - start time ) ) run time ) 3 . 0f ;
store < byte array , byte [ ] , byte [ ] > store = get store ( 0 , test store name ) ;
assert parse error ( 1 : 22 : expected identifier . found ' } ' , optional group < a : 1 } ) ;
super method type = method types . iterator ( ) . next ( ) ;
this . primitive value = choose value ( ) ;
assert equals ( module - 1 . dex . jar , data [ 0 ] ) ; assert true ( string . format ( unexpected class : % s , data [ 2 ] ) , file to class name . values ( ) . contains ( data [ 2 ] ) ) ; }
if ( nr > 0 | | should estimate stats ) { return nr ; }
children = array utils . remove ( dbnnode . class , children , child resource ) ;
cp . role call ( 0 ) ;
if ( sub generator lists . is empty ( ) ) { return null ; } final long global watermark = get watermark ( ) ;
if ( rx = = 0 | | ry = = 0 ) { p . line to ( x , y ) ; return ; } if ( x = = last x & & y = = last y ) { return ; nothing to draw }
this . signature value element = xmlutils . get next element ( signed info elem . get next sibling ( ) ) ;
if ( ( key . interest ops ( ) & selection key . op _ write ) = = 0 ) key . interest ops ( selection key . op _ write ) ;
cached class varg = pt [ param minus1 ] ; class clazz = varg . get the class ( ) . get component type ( ) ; if ( size = = pt . length & & ( varg . is assignable from ( arguments [ param minus1 ] ) | | test component assignable ( clazz , arguments [ param minus1 ] ) ) ) { return true ; }
sb . delete ( 0 , sb . length ( ) ) ;
slice big array . set ( 0 , wrapped buffer ( second bytes , 11 , 1200 ) ) ;
mockito . when ( cnxn params . get connector ( ) ) . then return ( connector ) ;
x = virtual bounds . x + virtual bounds . width - width - border distance ;
byte array output stream baos = new byte array output stream ( ) ; data output out = new data output stream ( baos ) ; for ( file status fs : tests ) { fs . write ( out ) ; } log . info ( creating byte array input stream object ) ; data input in = new data input stream ( new byte array input stream ( baos . to byte array ( ) ) ) ; log . info ( testing if read objects are equal to written ones ) ;
uid = shexec1 . get output ( ) . replace all ( \ n , ) ; } catch ( exception e ) {
callback capture . get value ( ) . on complete ( 42 ) ; assert requests total ( thrift , 1 ) ;
services = new array list < > ( ) ;
if ( ignored = null & & ignored . contains ( key elem ) ) continue ; key serializer = _ key serializer ; } final object value elem = entry . get value ( ) ;
for ( int i = 0 ; i < vals . length ; + + i ) vals [ i ] = x [ rnd . next int ( 2 ) ] ;
for ( iterator < version > v = accepted . iterator ( ) ; v . has next ( ) ; ) { version version = ( version ) v . next ( ) ; if ( provided . contains ( version ) ) { v . remove ( ) ; } }
assert u ( adoc ( sdoc ( id , 8 , field to update , immutable map . of ( inc , - 555 ) ) ) ) ;
if ( contains ( value , index + 3 , 2 , oo , er , en , uy , ed , em ) ) {
horizontal panel col list panel = new horizontal panel ( ) ;
. with scroll keepalive ( 5m )
assert quantiles map ( expected , quantiles . scale ( 10 ) . indexes ( 0 , 10 , 5 , 1 , 8 , 1 ) . compute ( sixteen _ squares _ doubles ) ) ; }
list < integer > entity ids = new array list < integer > ( ) ;
if ( cache = null & & object type = null ) { find all arguments marked with @ cachable key final map < integer , object > key pieces = new linked hash map < integer , object > ( ) ; final annotation [ ] [ ] annotations = get annotations ( method ) ; for ( int i = 0 ; i < annotations . length ; i + + ) { for ( int j = 0 ; j < annotations [ i ] . length ; j + + ) { final annotation annotation = annotations [ i ] [ j ] ; if ( cachable key . class . equals ( annotation . annotation type ( ) ) ) { cachable key position starts at 1 key pieces . put ( ( ( cachable key ) annotation ) . value ( ) - 1 , args [ i ] ) ; break ; } } } build the cache key final string cache key = build cache key ( key pieces ) ; final internal tenant context internal tenant context = ( internal tenant context ) iterables . find ( immutable list . copy of ( args ) , new predicate < object > ( ) { @ override public boolean apply ( final object input ) { return input instanceof internal tenant context ; } } , null ) ; final cache loader argument cache loader argument = new cache loader argument ( object type , args , internal tenant context , handle ) ; return cache . get ( cache key , cache loader argument ) ; } else { return invoke raw ( method , args ) ; }
assert equals ( 1 , session factory ( ) . get statistics ( ) . get update timestamps cache hit count ( ) ) ; testing jta platform impl . instance . get transaction manager ( ) . resume ( tx1 ) ;
under test . refresh state ( ) ;
annotations . add ( get join column annotation ( references . iterator ( ) . next ( ) , referenced column , field type ) ) ; } else {
security util . remove ( servlet ) ;
instances = runtime service . create process instance query ( ) . variable value equals ( true ) . list ( ) ; assert not null ( instances ) ; assert equals ( 1 , instances . size ( ) ) ; assert equals ( process instance1 . get id ( ) , instances . get ( 0 ) . get id ( ) ) ;
pn = compile ( select * from c where abs ( b ) = 1 and abs ( e ) > ? ; ) ; check scan uses index ( pn , z _ full _ idx _ a ) ; }
with terminal sized ( 3 , 3 ) . enter string ( \ 033 [ 2 * x abcdefghi \ 033 [ 1 ; 1 ; 2 ; 2 ; 1 r ) . assert lines are ( abc , def , ghi ) ; assert effect attributes set ( effect line ( b , b , 0 ) , effect line ( b , b , 0 ) , effect line ( 0 , 0 , 0 ) ) ; }
sslengine result unwrap ;
this . m axis dependency = axis dependency . left ; this . m yoffset = 0f ; }
if ( ( t1 . get exception ( ) = null & & t1 . get exception ( ) instanceof activiti optimistic locking exception ) | | ( t2 . get exception ( ) = null & & t2 . get exception ( ) instanceof activiti optimistic locking exception ) ) { optimistic locking exception happened once = true ; break ; } boolean process instance ended = runtime service . create process instance query ( ) . process instance id ( process instance . get id ( ) ) . count ( ) = = 0 ;
list < string > tool arg list = new array list < string > ( ) ;
typed value color value = new typed value ( ) ;
if ( node . get cmd type ( ) = = command . type . motion ) {
return new thread ( ) ; indent : 20 exp : 20
if ( out instanceof send definition ) { send definition send = ( send definition ) out ; list < processor definition < ? > > children = send . get outputs ( ) ; do find type ( children , type , found , + + current , max deep ) ; }
validate table of longs ( cl , sql , new long [ ] [ ] { { 3 } , { 4 } , { 2 } } ) ; }
object value = null ; if ( jjt get num children ( ) > 0 ) { simple node initializer = ( simple node ) jjt get child ( 0 ) ; * if we have type info and the child is an array initializer pass it along . . . else use the default eval style . ( this allows array initializer to handle the problem . . . allowing for future enhancements in loosening types there ) . * if ( ( type node = null ) & & initializer instanceof bsharray initializer ) value = ( ( bsharray initializer ) initializer ) . eval ( type node . get base type ( ) , type node . get array dims ( ) , callstack , interpreter ) ; else value = initializer . eval ( callstack , interpreter ) ; }
list < person > persons = entity manager . create query ( select p + from person p + where p . id > : id , person . class ) . set parameter ( id , 0 l ) . set hint ( query hints . hint _ cacheable , true ) . set hint ( query hints . hint _ cache _ region , query . cache . person ) . set hint ( javax . persistence . cache . store mode , cache store mode . refresh ) . get result list ( ) ;
delete index response delete index response = client ( ) . admin ( ) . indices ( ) . prepare delete ( test ) . execute ( ) . action get ( ) ; assert that ( delete index response . is acknowledged ( ) , equal to ( true ) ) ; cluster state = client ( ) . admin ( ) . cluster ( ) . prepare state ( ) . get ( ) . get state ( ) ;
( ( ldapsecurity service config ) config ) . set user filter ( ( given name = { 1 } ) ) ;
case after : {
try { managed conn . release connection ( ) ; } catch ( ioexception ignored ) { this . log . debug ( ioexception releasing connection , ignored ) ; } managed conn = null ; }
if ( regex _ flag = null & & regex _ flag . equals ( i ) ) { return pattern . compile ( regex , pattern . case _ insensitive ) ; } else { return pattern . compile ( regex ) ; }
seed [ frame _ length ] = ois . read int ( ) ; seed [ frame _ length + 1 ] = ois . read int ( ) ; seed [ frame _ length + 14 ] = ois . read int ( ) ; seed [ frame _ length + 15 ] = ois . read int ( ) ; }
if ( is focusable ( ) ) return false ;
assert true ( consumed messages . size ( ) > = remaining messages ) ;
for ( int i = 0 ; i < field count ; i + + ) { fields [ i ] . finish ( ) ; }
char ch = character . for digit ( ( b > > 4 ) & 0x f , 16 ) ;
if ( clazz . get name ( ) . starts with ( java ) ) {
reader . close ( ) ; directory . close ( ) ; directory = new directory ( ) ;
tester . get or create ( mid key ) . add dependency ( changed key ) . set computed value ( concatenate ) ;
channel channel = conn . _ channel ; socket address client addr = channel . get local address ( ) ; channel server channel = _ dummy server . get child channel ( client addr ) ; channel pipeline server pipeline = server channel . get pipeline ( ) ;
metrics . add all ( output row signature . get row order ( ) ) ;
if ( super type . is generic ( ) ) { return null ; } return bindings . types as array ( ) ; }
final string explicit hbm xmls = ( string ) configuration values . remove ( available settings . hbxml _ files ) ;
ldapstorage provider ldap provider = ldaptest utils . get ldap provider ( session , ldap model ) ; component model role mapper model = ldaptest utils . get subcomponent by name ( app realm , ldap model , realm roles mapper ) ; role ldapstorage mapper role mapper = ldaptest utils . get role mapper ( role mapper model , ldap provider , app realm ) ; ldapobject john ldap = ldap provider . load ldapuser by username ( app realm , johnrolemapper ) ; role mapper . add role mapping in ldap ( realm role1 , john ldap ) ; role mapper . add role mapping in ldap ( realm role2 , john ldap ) ;
case latin _ capital _ letter _ i :
byte [ ] digest = ( ( regular file state value ) file value . real file state value ( ) ) . get digest ( ) ;
if ( cidr mask > 128 ) { throw new unknown host exception ( invalid mask length used : + cidr mask ) ; } return new cidr6 ( ( inet6 address ) base address , cidr mask ) ; }
m _ hsql = hsqlinterface . load hsqldb ( parameterization info . get param state manager ( ) ) ;
merging report . get action recorder ( ) . record attribute action ( this , actions . action type . added , get owner element ( ) . get attribute operation type ( get name ( ) ) ) ; }
throw failure ;
write deleted ( this . ll [ 0 ] - 1 + start2 ) ;
return - 1 ; } case op _ nothing : case op _ goto :
manifold . local normal . normalize ( ) ; manifold . local point . set ( v2 ) ; manifold . points [ 0 ] . local point . set ( circlep ) ; manifold . points [ 0 ] . id . zero ( ) ; } else {
} else if ( notification . get type ( ) . equals ( payment ) & & notification . get direction ( ) . equals ( passthrough ) ) {
class < ? > super class = non match class . get superclass ( ) ;
final list < r > sorted reps = new topological sort < r > ( ) . sort ( vertices . values ( ) ) ;
http response . set status ( 400 ) ;
hook = hookwin proc ( hwnd ping ) ;
assert true ( added file unexpectedly deleted , fs . exists ( racy file ) ) ; assert true ( parent directory deleted unexpectedly , fs . exists ( parent ) ) ; assert false ( original file unexpectedly retained , fs . exists ( file ) ) ; mockito . verify ( spy , mockito . times ( 1 ) ) . is file deletable ( mockito . any ( path . class ) ) ; }
renderer . draw text run ( canvas , x , y , cx , 1 , blank , 0 , 1 , true , default style , cx , 0 , 1 , 1 , cursor mode ) ;
string queue = event . get job queue name ( ) ;
try { new regex validator ( ) ; fail ( single zero length - expected illegal argument exception ) ; } catch ( illegal argument exception e ) { assert equals ( single zero length , regular expression [ 0 ] is missing , e . get message ( ) ) ; }
foster elements . add ( element ) ; } } else {
if ( oc = = null ) { l4j . trace ( close called . no row processed by map . ) ; }
vm . inputs . params from activity ( discovery params . builder ( ) . build ( ) ) ;
float pair proximity = source . get parameters ( ) . get proximity ( distance + source . get parameters ( ) . get proximity limit ( ) ) ; unweighted proximity + = pair proximity ; float connectedness = source . get query ( ) . get terms ( ) [ i ] . get connectedness ( ) ; proximity + = pow ( pair proximity , connectedness 0 . 1 ) * max ( 0 . 1 , connectedness ) ; pairs + + ; }
if ( this . writer = null ) { closing before the first flip , collect the memory in the writer this . writer . close ( ) ; for ( int i = this . num memory segments in writer ; i > 0 ; i - - ) { segments . add ( this . writer . get next returned block ( ) ) ; } this . writer . close and delete ( ) ; this . writer = null ; }
verify ( mock callback , times ( 1 ) ) . on dismissed ( snackbar , expected event ) ; verify no more interactions ( mock callback ) ;
assert is not in l1 ( cache , key ) ; }
char [ ] buf = text . to char array ( ) ; buf [ i - - ] = ' ' ; for ( ; i > = 0 ; i - - ) if ( is white space except space ( buf [ i ] ) ) buf [ i ] = ' ' ; return new string ( buf ) ; }
new handler ( ) . post ( new runnable ( ) { @ override public void run ( ) { on dismiss ( ) ; } } ) ; } else {
list < loaded manifest info > loaded library documents = load libraries ( selectors , merging report builder ) ;
pair < inet socket address , process > pair = network utils . establish sshtunnel if needed ( address , tunnel config , network utils . tunnel type . port _ forward ) ; ret . add ( pair ) ; }
return error copying update : + ioe ; } finally {
try { raw mapper . get ( srcs , build type . label _ list ) ; fail ( expected srcs lookup to fail since the returned type is a selector list and not a list ) ; } catch ( illegal argument exception e ) { assert that ( e ) . has cause that ( ) . has message that ( ) . contains ( selector list cannot be cast to java . util . list ) ; }
com . linkedin . pinot . client . result set pinot first group by result set = pinot result set group . get result set ( 0 ) ;
cmap legend builder . set label font ( legend utils . get label font ( request ) ) ; cmap legend builder . set label font color ( legend utils . get label font color ( request ) ) ;
parser plugin = get configuration ( ) . get plugin factory ( ) . create parser plugin ( ) ; cst = parser plugin . parse cst ( this , reader ) ;
batblock bat = create bat ( offset , true ) ; bat . set value at ( 0 , poifsconstants . fat _ sector _ block ) ; _ bat _ blocks . add ( bat ) ;
table descriptor htd = table descriptor builder . new builder ( table name . value of ( table ) ) . add column family ( column family descriptor builder . of ( bytes . to bytes ( new string ( family ) . to upper case ( locale . root ) ) ) ) . build ( ) ; try { run test ( test name , htd , bloom type . none , true , split _ keys , h file ranges , false , false ) ; assert true ( loading into table with non - existent family should have failed , false ) ; } catch ( exception e ) { assert true ( ioexception expected , e instanceof ioexception ) ; further check whether the exception message is correct string err msg = e . get message ( ) ; assert true ( incorrect exception message , expected message : [ + expected _ msg _ for _ non _ existing _ family + ] , current message : [ + err msg + ] , err msg . contains ( expected _ msg _ for _ non _ existing _ family ) ) ; }
item height = font metrics . get height ( ) + 3 ;
if ( destination host . get status ( ) = com . cloud . host . status . up | | destination host . get resource state ( ) = resource state . enabled ) { throw new invalid parameter value exception ( cannot migrate vm , destination host is not in correct state , has status : + destination host . get status ( ) + , state : + destination host . get resource state ( ) ) ; }
assert false ( raid fs . exists ( src path ) ) ;
realm results < person > results = realm . where ( person . class ) . between ( age , 1 , 99 ) notice implicit and operation . begins with ( name , j ) . find all ( ) ; status + = \ n number of people aged between 1 and 99 who ' s name start with ' j ' : + results . size ( ) ; realm . close ( ) ; return status ; }
handled = b . on dependent view changed ( this , check child , child ) ; break ; } if ( type = = event _ nested _ scroll ) {
assert collection is unmodifiable ( multimap . entries ( ) , maps . immutable entry ( sample key , sample value ) ) ;
clazz = object . class ;
replab0 : while ( true ) { v _ 1 = cursor ; lab1 : do {
conf . set int ( hbase . hstore . compaction . min , 10 ) ;
assert equals ( 2 l , task service . create task query ( ) . count ( ) ) ; task list = task service . create task query ( ) . order by task name ( ) . desc ( ) . list ( ) ; assert equals ( first task , task list . get ( 0 ) . get name ( ) ) ; assert equals ( escalation task 2 , task list . get ( 1 ) . get name ( ) ) ;
for ( int i = 0 ; i < num ; i + + ) { sb . append ( ' \ n ' ) ; } need newlines = 0 ; need space = false ; }
assert null ( the one result atts . get ( sn ) ) ; }
command cmd = new command ( count , node . get action id ( ) , node . get action ( ) , node . get cmd type ( ) , node . get flags ( ) ) ;
info . set bitrate ( vorbis identification header . get nominal bitrate ( ) 1000 ) ; info . set variable bit rate ( false ) ; }
int add queue size = add queue . size ( ) ;
byte modifiers = cursor . get byte ( ) ;
pair mode = false ;
implicit params str map . put if absent ( conf , implicit params str ) ; implicit params map . put if absent ( conf , implicit params ) ; this . implicit _ params = implicit params ;
final download impl download = new download impl ( description , transfer progress , listener chain , null , state listener , get object request , file , object metadata , is download parallel ) ; long total bytes to download = last byte - starting byte + 1 ;
system . out . print ( disabling table + htd . get name as string ( ) + ) ; admin . disable table async ( htd . get name ( ) ) ; long start = system . current time millis ( ) ;
list variant . add ( new variant ddn path ( ) ) ;
key manager factory key manager factory = key manager factory . get instance ( key manager factory . get default algorithm ( ) ) ;
assert . assert true ( temp mode . cached = = neighbors join . get input2 ( ) . get temp mode ( ) ) ; job graph generator jgg = new job graph generator ( ) ;
long num buffs = max total event buffer size _ max buffer size ;
return ( ( conjunction ) predicate ) . get operands ( ) . stream ( ) . map to double ( child - > find min feature ( child , is negated , context ) ) . sum ( ) ;
append child ( xml ) ; return this ;
object = new parse object ( test object ) ; assert false ( matches ( logic , query , object ) ) ; }
flush . set ( false ) ; } }
string group name = propose group name ( ) ; add group ( group name , reg in group ) ; group name = propose group name ( ) ; add group ( group name , reg in group ) ; group name = propose group name ( ) ; add group ( group name , reg in group ) ;
byte buffer . position ( 0 ) . limit ( 0 ) ;
assert . assert true ( latch . await ( 5 * sleep , time unit . milliseconds ) ) ; }
await ( ) . at most ( 1 , time unit . seconds ) . until asserted ( ( ) - > { set < string > suspended = ( set < string > ) mbean server . invoke ( on , get suspended breakpoint node ids , null , null ) ; assert not null ( suspended ) ; assert equals ( 1 , suspended . size ( ) ) ; assert equals ( cheese , suspended . iterator ( ) . next ( ) ) ; } ) ;
parse user current user = new parse user ( ) ; current user . set object id ( test ) ; cached current user controller current user controller = mock ( cached current user controller . class ) ; when ( current user controller . set if needed async ( any ( parse user . class ) ) ) . then return ( task . < void > for result ( null ) ) ; parse core plugins . get instance ( ) . register current user controller ( current user controller ) ; parse user user = new parse user ( ) ;
verify split point scenario ( 0 , false , 2 . 1f , 4 , 4 , 4 ) ; 8 4 is less than 2 . 1f
final map < integer , collection < tuple match > > expected matches map = right outer join tuples ( collect tuple data ( input1 ) , collect tuple data ( input2 ) ) ; final tuple match removing join matcher = new tuple match removing join ( expected matches map ) ;
if ( local logv ) log . v ( tag , r . id + : resuming ) ;
assert equals ( 0 , multi . get index ( ns1 : foo ) ) ; assert equals ( 1 , multi . get index ( ns1 : bar ) ) ; assert equals ( 2 , multi . get index ( ns2 : answer ) ) ; assert equals ( 4 , multi . get index ( gabba : hey ) ) ;
sql = select v _ p1 . v _ cnt from v _ p1 join v _ r4 on v _ p1 . v _ g2 = v _ p1 . v _ cnt + order by v _ p1 . v _ cnt ; ; sql = sql . replace ( v _ p1 , tb ) ; vt = client . call procedure ( @ ad hoc , sql ) . get results ( ) [ 0 ] ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( target group not found ) ) return null ; target group not found exception e = ( target group not found exception ) super . unmarshall ( node ) ; return e ; }
assert false ( cursor1 . is active ( ) ) ;
if ( 3 = = ( i % 4 ) ) { null byte cur + + ; }
get ksession ( ) . get entry point ( in _ age ) . insert ( - 100 ) ; get ksession ( ) . fire all rules ( ) ; check first data field of type status ( age , true , false , null , - 100 ) ;
out attrs . input type = input type . type _ class _ phone ;
if ( micro edition & & stack map frame list . is empty ( ) ) { convert the initial variable values to types . verification type [ ] initial variables = corresponding verification types ( program class , program method , code attribute , partial evaluator . at _ method _ entry , partial evaluator . get variables before ( 0 ) ) ; special case : the < init > method . if ( method . get name ( program class ) . equals ( class constants . method _ name _ init ) ) { initial variables [ 0 ] = verification type factory . create uninitialized this type ( ) ; } compress stack map frames ( initial variables , stack map frame list ) ; }
@ suppress warnings ( { optional get without is present , constant conditions } ) operation type definition query op = operation types . stream ( ) . filter ( op - > query . equals ( op . get name ( ) ) ) . find first ( ) . get ( ) ; optional < operation type definition > mutation op = operation types . stream ( ) . filter ( op - > mutation . equals ( op . get name ( ) ) ) . find first ( ) ; optional < operation type definition > subscription op = operation types . stream ( ) . filter ( op - > subscription . equals ( op . get name ( ) ) ) . find first ( ) ; query = build operation ( build ctx , query op ) ;
if ( filter = null ) { filter . return code code = filter . filter key value ( kv ) ; system . out . println ( filter returned : + code ) ; if its not an accept type , then skip this kv if ( ( code . equals ( filter . return code . include ) | | code . equals ( filter . return code . include _ and _ next _ col ) ) ) { if ( log . is debug enabled ( ) ) { system . out . println ( skipping key : + kv + from filter decision : + code ) ; } return null ; } }
if ( null = e . get cause ( ) & & e . get cause ( ) instanceof solr exception ) { solr exception inner = ( solr exception ) e . get cause ( ) ; throw inner ; } throw new solr exception ( solr exception . error code . server _ error , error instantiating + msg + , + class name + failed to instantiate + cast . get name ( ) , e ) ; }
provider [ ] secure random providers = security . get providers ( secure random . sha1 prng ) ; if ( ( secure random providers = = null ) | | ( secure random providers . length < 1 ) | | ( linux prngsecure random provider . class . equals ( secure random providers [ 0 ] . get class ( ) ) ) ) { security . insert provider at ( new linux prngsecure random provider ( ) , 1 ) ; }
string obj name = clean string ( o . get name ( ) ) ; string group = is in room ? current room name : group name ;
int w3 = local name index | prefix index < < 16 ;
controller . add flow controlled ( stream , data a ) ; data a . assert not written ( ) ; controller . increment window size ( stream , 100 ) ; data a . assert not written ( ) ; assert writability changed ( 0 , false ) ;
( ( entity model dao base ) entity model dao ) . set record id ( target record id ) ;
assert equals ( block size delta = = 0 & & correct answer = = 1 , is valid block range ( block range , offset , length ) ) ;
if ( request . get headers ( ) . contains key ( http headers . accept _ encoding ) ) { request . get headers ( ) . add ( http headers . accept _ encoding , gzip _ encoding ) ; } if ( request . get entity ( ) = null ) { object request encoding = request . get headers ( ) . get first ( http headers . content _ encoding ) ; if ( gzip _ encoding . equals ( request encoding ) ) { request . set adapter ( new gzip adapter ( request . get adapter ( ) ) ) ; } else if ( is compression enabled ( ) ) { request . get headers ( ) . add ( http headers . content _ encoding , gzip _ encoding ) ; request . set adapter ( new gzip adapter ( request . get adapter ( ) ) ) ; } }
return true ; ?? }
make key ( new byte [ us . length ( ) ] ) ;
configuration conf = test _ util . get configuration ( ) ;
p . set current value ( result ) ; final json deserializer < object > value des = _ value deserializer ;
context ejb [ ] ejbs = naming resources . find ejbs ( ) ;
if ( this . no _ entry _ value = ( byte ) 0 ) { arrays . fill ( _ values , this . no _ entry _ value ) ; } set up ( ( int ) math . ceil ( default _ capacity _ load factor ) ) ;
em1 . get transaction ( ) . begin ( ) ; object p1 = prepare data ( 11 , 10 ) ; em1 . persist ( p1 ) ;
handler . push elem template element ( elem ) ;
visit composite definition ( ( non encapsulated entity identifier definition ) identifier definition ) ;
session . get transaction ( ) . begin ( ) ; zoo zoo1 = new zoo ( ) ; zoo1 . set name ( null ) ; zoo zoo2 = new zoo ( ) ; zoo2 . set name ( warsaw zoo ) ; session . persist ( zoo1 ) ; session . persist ( zoo2 ) ; session . get transaction ( ) . commit ( ) ; session . get transaction ( ) . begin ( ) ;
assert doc with vals is first ( num docs expected , sum ( 32 , field ( + fieldname + , max ) ) desc ) ; assert doc with vals is last ( num docs expected , sum ( 32 , field ( + fieldname + , max ) ) asc ) ; assert doc with vals is first ( num docs expected , sum ( 32 , field ( + fieldname + , min ) ) asc ) ;
string expected definition = < fieldtype name = \ tdatedv \ class = \ + date class + \ + precision step = \ 6 \ doc values = \ true \ multi valued = \ true \ > ;
persistent subscription sub = topic2 . get subscription ( success sub name ) ; consumer cons = sub . get dispatcher ( ) . get consumers ( ) . get ( 0 ) ; sub . remove consumer ( cons ) ;
final int slot size = component type . is primitive ( ) ? sizeof primitive type ( component type ) : objref _ size ; return object _ shell _ size + int _ field _ size + objref _ size + length * slot size ;
view holder = ( toggle item view holder ) custom shadow of ( adapter ) . get view holder ( 0 ) ; view holder1 = ( toggle item view holder ) custom shadow of ( adapter ) . get view holder ( 1 ) ; view holder2 = ( toggle item view holder ) custom shadow of ( adapter ) . get view holder ( 2 ) ; }
assert not equals ( foo1 , bar ) ;
dao . get rules ( ) . for each ( r - > { if ( r . equals ( orig ) ) { r . set root ( rule . get root ( ) ) ; r . set global group rule ( rule . is global group rule ( ) ) ; r . set layer ( rule . get layer ( ) ) ; r . set access mode ( rule . get access mode ( ) ) ; r . get roles ( ) . clear ( ) ; r . get roles ( ) . add all ( rule . get roles ( ) ) ; } } ) ;
if ( dsmr port = = null | | dsmr port . is open ( ) ) { logger . debug ( creating dsmr port : { } , port ) ; dsmr port = new dsmrport ( port , new p1 telegram parser ( new obismsg factory ( dsmr meters ) ) , dsmr _ update _ interval 2 , dsmr _ update _ interval * 2 , fixed port settings ) ; }
final short required replication = get expected replica num ( block ) ; number replicas num replicas = count nodes ( block ) ; final int pending num = pending reconstruction . get num replicas ( block ) ; if ( has enough effective replicas ( block , num replicas , pending num , required replication ) ) { needed reconstruction . remove ( block , priority ) ; rw . reset targets ( ) ; block log . debug ( block * removing { } from needed replications as + it has enough replicas , block ) ; return false ; } datanode storage info [ ] targets = rw . get targets ( ) ;
this . java sscert = cf . generate certificate ( new byte array input stream ( self signed cert . get bytes ( ) ) ) ;
if ( its in function flag & & its data . its needs activation ) index = script or fn . get index for name node ( node ) ;
lb capabilities . put ( capability . load balancing supported ips , additional ) ; lb stickiness method method ;
left = raw x + label margin ;
complete snapshot ( this . snapshot dir , this . working dir , this . fs ) ;
conf . set long ( jhadmin config . mr _ history _ max _ age _ ms , 10 * 1000 ) ;
case xk _ kanji : return keyboard . key _ kanji ;
final java type mock last used type = mock ( java type . class ) ; when ( mock last used . get java type ( ) ) . then return ( mock last used type ) ;
for ( string key : undeploy ) { app app = _ deployed . remove ( key ) ; if ( app = null ) { _ _ log . info ( undeploy { } , key ) ; _ deployment manager . remove app ( app ) ; } }
string live nodes info = ( string ) ( mbs . get attribute ( mxbean name , live nodes ) ) ;
boolean splittable = ( query instanceof boolean query ) ;
rule key appendable dep appendable = sink - > { } ;
if ( max image size = = integer . max _ value & & quality = = 100 ) { return path ; } if ( selected max size > max image size ) { selected max size = max image size ; }
if ( w . broadcaster = null ) { w . broadcaster = broadcaster factory . lookup ( w . broadcaster . get id ( ) , true ) ; } }
if ( string at ( ( m _ current + 1 ) , 3 , lia , lio , lie , ) & & is vowel ( m _ current - 1 ) ) { metaph add exact approx ( l , gl , l , kl ) ; m _ current + = 2 ; return true ; } return false ;
fs . set permission ( path , new fs permission ( ( short ) 0704 ) ) ;
m account header = m account header container . find view by id ( r . id . material _ drawer _ account _ header ) ;
fis = hdfs . open ( file1snap1 ) ;
db client . properties dao ( ) . save property ( db session , new property dto ( ) . set key ( sonar . jira . project . key ) . set value ( sonar ) . set resource id ( project . get id ( ) ) ) ; db client . properties dao ( ) . save property ( db session , new property dto ( ) . set key ( sonar . jira . login . secured ) . set value ( john ) . set resource id ( project . get id ( ) ) ) ; component dto module = component testing . new module dto ( project ) ;
public void test parse settings evaporator1 ( ) throws stiebel heat pump exception { list < request > result = requests . search in ( configuration , new matcher < request > ( ) { @ override public boolean matches ( request r ) { return r . get name ( ) = = settings evaporator1 ; } } ) ; byte [ ] response = new byte [ ] { ( byte ) 0x01 , ( byte ) 0x00 , ( byte ) 0x0e , ( byte ) 0x03 , ( byte ) 0x00 , ( byte ) 0x96 , ( byte ) 0x00 , ( byte ) 0x0a , ( byte ) 0x00 , ( byte ) 0x96 , ( byte ) 0x00 , ( byte ) 0x64 , ( byte ) 0x10 , ( byte ) 0x10 , ( byte ) 0x60 , ( byte ) 0x10 , ( byte ) 0x03 } ;
this . session id = uuid . random uuid ( ) . to string ( ) ;
cache . put for external read ( key , value2 ) ; assert no locks ( cache ) ; assert equals ( value , cache . get ( key ) ) ; }
finally { util . close ( bais ) ;
gl3 . gl gen vertex arrays ( int buf16 ) ;
chk preview after building _ . set text ( preview book after building ) ;
if ( published info . class . equals ( clazz ) ) { filter layer filter = predicates . and ( predicates . is instance of ( layer info . class ) , filter ) ; filter layer group filter = predicates . is instance of ( layer group info . class ) ; return predicates . or ( layer filter , layer group filter ) ; } else { return filter ; }
configuration . set srs syntax ( wfs . get gml ( ) . get ( wfsinfo . version . v _ 11 ) . get srs name style ( ) . to srs syntax ( ) ) ;
kernel32 util . close handle ( h ) ; }
return new term query ( new term ( textgrams _ field _ name , token ) ) ;
if ( f referenced instanceof itype ) { final itype type = ( itype ) f referenced ; adjust member visibility ( type , new sub progress monitor ( monitor , 1 ) ) ; }
ln = ln . substring ( 1 , ln . length ( ) - 1 ) ; if ( ln . equals ( node name ) ) { throw new ioexception ( node depends on itself . ) ; }
quality query parser qq parser = new simple qqparser ( field set . to array ( new string [ 0 ] ) , body ) ;
response . put ( active , true ) ; always true if token exists and not expired return response ; }
am . get region states ( ) . is region in state ( hri , state . closed ) ;
system . out . println ( = = = = closing the connection on b ) ;
assert invalid cast ( cast ( unchecked _ to _ json ( ' { \ a \ : 1 , \ b \ : 2 , \ a \ : 3 } ' ) as row ( a bigint , b bigint ) ) , cannot cast to row ( a bigint , b bigint ) . duplicate field : a \ n { \ a \ : 1 , \ b \ : 2 , \ a \ : 3 } ) ;
generate output stats = writer . write segment ( write size , os ) ;
enumeration enumeration = ( enumeration ) access controller . do privileged ( new privileged action ( ) { public java . lang . object run ( ) { return system . get properties ( ) . property names ( ) ; } } ) ; return make iterator ( enumeration ) ;
if ( getter . get annotation ( column . class ) = = null ) { return accessible ( getter ) ; } } catch ( no such method exception ignore ) { } try { method getter = type . get method ( is + m . substring ( 3 ) ) ;
request request = new request . builder ( ) . url ( server . url ( ) ) . header ( cache - control , max - stale ) . build ( ) ; response response = client . new call ( request ) . execute ( ) ; assert equals ( a , response . body ( ) . string ( ) ) ; assert equals ( 110 http urlconnection \ response is stale \ , response . header ( warning ) ) ; }
int range size = max - min + 1 ;
for ( person owner : car1 _ 2 . get owners ( ) ) { for ( car owned car : owner . get cars ( ) ) { owned car . get registration number ( ) ; } } for ( person owner : car2 _ 2 . get owners ( ) ) { for ( car owned car : owner . get cars ( ) ) { owned car . get registration number ( ) ; } } car1 = ( car ) get session ( ) . get ( car . class , id _ car1 ) ;
store definitions mapper mapper = new store definitions mapper ( ) ; string store def str = mapper . write store ( store def ) ; versioned < string > versioned value str = new versioned < string > ( store def str ) ; this . store definitions storage engine . put ( store def . get name ( ) , versioned value str , null ) ;
int scroll bar x ;
assert false ( target remote cache . contains key ( 5 ) ) ;
- - i ; return i ; }
assert equals ( 1024 , scheduler . get scheduler app ( att id1 ) . get current reservation ( ) . get memory size ( ) ) ;
if ( sdk _ int > = 21 ) { activity manager . task description task description = new activity manager . task description ( amaze , ( ( bitmap drawable ) get resources ( ) . get drawable ( r . mipmap . ic _ launcher ) ) . get bitmap ( ) , get color preference ( ) . get color ( color usage . get primary ( main activity . current tab ) ) ) ; set task description ( task description ) ; } if ( shared pref . get boolean ( key _ preference _ bookmarks _ added , false ) ) { utils handler . add common bookmarks ( ) ; shared pref . edit ( ) . put boolean ( key _ preference _ bookmarks _ added , true ) . commit ( ) ; }
int num bar series = 0 ; int current series order = 0 ; int num values = 0 ; boolean is current series ; sorted set < double > x vals = new tree set < double > ( ) ; for ( series inspected series : graph view . get series ( ) ) { if ( inspected series instanceof bar graph series ) { is current series = ( inspected series = = this ) ; if ( is current series ) { current series order = num bar series ; } num bar series + + ; calculate the number of slots for bars based on the minimum distance between x coordinates in the series . this is divided into the range to find the placement and width of bar slots ( sections of the x axis for each bar or set of bars ) todo : move this somewhere more general and cache it , so we don ' t recalculate it for each series iterator < e > cur values = inspected series . get values ( min x , max x ) ; if ( cur values . has next ( ) ) { x vals . add ( cur values . next ( ) . get x ( ) ) ; if ( is current series ) { num values + + ; } while ( cur values . has next ( ) ) { x vals . add ( cur values . next ( ) . get x ( ) ) ; if ( is current series ) { num values + + ; } } } } } if ( num values = = 0 ) { return ; }
if ( round env . processing over ( ) ) { post round ( round env ) ; report missing elements ( deferred elements , elements deferred by steps . values ( ) ) ; return false ; } process ( valid elements ( deferred elements , round env ) ) ;
if ( server = null ) { server . stop ( ) ; server = null ; }
if ( password bytes = null ) { java . util . arrays . fill ( password bytes , ( byte ) 0 ) ; }
activity . finish ( ) ; } } ) ; dialog . show ( ) ; }
adapter = asmclass node adapter . get ( plugin context , class loader , com navercorp pinpoint profiler instrument mock base class , true ) ; try { adapter . get declared methods ( ) ; fail ( can ' t throw illegal state exception ) ; } catch ( exception ignored ) { } try { adapter . get declared method ( base , ( ) ) ; fail ( can ' t throw illegal state exception ) ; } catch ( exception ignored ) { }
make thread safe ( logger mock , true ) ; for ( method method : logger factory methods ) { settings . stub method ( method , logger mock ) ; }
int idx separator = spec . index of ( , , idx closed ) ;
if ( null = m on last item visible listener ) { m last item visible = ( total item count > 0 ) & & ( first visible item + visible item count > = total item count - 1 ) ; }
dimension default value setting default value setting = new dimension default value setting ( ) ; default value setting . set strategy type ( strategy . maximum ) ; setup feature custom dimension ( scanning _ angle _ dimension , scanning angle , default value setting ) ; feature type info time elevation custom = get catalog ( ) . get feature type by name ( time _ elevation _ custom . get local part ( ) ) ;
assert true ( advapi32 . instance . set thread token ( null , ph token duplicate . get value ( ) ) ) ;
m _ cached added classes . clear ( ) ;
assert equals ( metric prefix + bt . index . fs block read cnt , schema metrics . get block metric name ( block category . index , false , block metric type . read _ count ) ) ; assert equals ( metric prefix + bt . data . compaction block read cache hit cnt , schema metrics . get block metric name ( block category . data , true , block metric type . cache _ hit ) ) ;
assert that ( cursor a . copy to ( 1 , cursor b , 0 , page size ) , is ( page size - 1 ) ) ;
data . write _ value ( cdr out ) ; return cdr out . to byte array ( ) ; }
if ( last nanos . compare and set ( original last nanos , new last nanos ) ) { break ; } } else {
element block . append null ( ) ;
list iterator it = header list . list iterator ( ) ; while ( it . has next ( ) ) { header param temp = ( header param ) it . next ( ) ; if ( header . equals ignore case ( temp . get name ( ) ) ) { return temp . get value ( ) ; } } return null ;
assert equals ( region11 , region21 ) ;
web root = webroot3 ;
ticker . advance ( ttl * 2 3 , milliseconds ) ;
if ( line . ends with ( ) ) = = false ) { throw new illegal argument exception ( invalid method definition : expected a closing parenthesis [ + line + ] ) ; }
block and location [ ] locations = stat . get block locations ( ) ; assert equals ( 2 , locations . length ) ; assert equals ( block _ len , locations [ 0 ] . get length ( ) ) ; assert equals ( 0 l , locations [ 0 ] . get offset ( ) ) ; string [ ] host names = locations [ 0 ] . get names ( ) ; assert equals ( 3 , host names . length ) ; for ( string host name : host names ) { assert true ( hostname is + host name , host name . starts with ( 127 . 0 . 0 . 1 : ) ) ; } assert equals ( file _ len - block _ len , locations [ 1 ] . get length ( ) ) ; assert equals ( block _ len , locations [ 1 ] . get offset ( ) ) ; fs . delete ( file1 , true ) ;
this . opp container context . set container id generator ( new opportunistic container allocator . container id generator ( ) { @ override public long generate container id ( ) { return this . container id counter . decrement and get ( ) ; } } ) ;
final intent intent = new intent ( context , widget service . class ) ; intent . put extra ( app widget manager . extra _ appwidget _ id , app widget id ) ; intent . put extra ( small _ widget , small widget ) ; intent . set data ( uri . parse ( intent . to uri ( intent . uri _ intent _ scheme ) ) ) ; remote views . set remote adapter ( r . id . conversation _ list , intent ) ; remote views . set text view text ( r . id . widget _ label , context . get string ( r . string . title _ conversation _ list ) ) ;
return first term ( seed ) + i ;
default resources ( ) . add ( config name ) ; } catch ( ioexception ex ) {
client . create table like ( null , table name , clone table , true , false , null ) ; list < string > tables = client . list table names by pattern ( null , table * ) ; assert true ( tables . size ( ) = = 2 ) ; client . close ( ) ; }
protocol protocol = new protocol factory ( nutch configuration . create ( ) ) . get protocol ( url string ) ; content = protocol . get protocol output ( new text ( url string ) , new crawl datum ( ) ) . get content ( ) ; protocol = null ; }
assert true ( entry set . contains ( entry1 ) ) ;
final list < long > r2 store file sizes = arrays . as list ( 1024 l * 1024 l ) ;
split index = found + 2 ;
assert true ( command . is executed in thread ( ) ) ; assert not null ( command . get execution exception ( ) ) ; assert equals ( 0 , command . metrics . get current concurrent execution count ( ) ) ;
msg = the message key ' + msg key + ' is not in the message class ' + m _ resource bundle name + ' ; } }
put = new put ( row , timestamp2 , null ) ; put . add ( contents , contents , value2 ) ; table . put ( put ) ;
m attr = headers . get ( current cells . size ( ) ) . attr ;
case rs _ zk _ region _ closed : case rs _ zk _ region _ failed _ open : return executor type . master _ close _ region ; case rs _ zk _ region _ opened :
log . warn ( [ { } ] got exception while trying to retrieve ledger , name , e ) ; } }
progress estimator estimator = new progress estimator ( storage path , get buck event bus ( ) ) ;
assert equals ( dummy _ fs _ uri , file system . get default uri ( conf ) . to string ( ) ) ;
assert that ( provider , same instance ( injector . get instance ( postoffice provider . class ) ) ) ; assert that ( provider , same instance ( injector . get instance ( postoffice provider . class ) ) ) ; postoffice postoffice = provider . get ( ) ;
throw new illegal argument exception ( not a valid attribute string value : + val + , improper usage of backslash ) ; } } } else { builder . append ( chars [ i ] ) ; snarf unescaped char } }
for ( character ch : marks . key set ( ) ) { mark mark = marks . get ( ch ) ; if ( logger . is debug enabled ( ) ) logger . debug ( mark = + mark ) ;
label2 : indent : 2 exp : 4 , 8 warn system . identity hash code ( toplevel ) ; indent : 8 exp : 8
has existing imports = false ;
do { index - = probe ; if ( index < 0 ) { index + = length ; } state = states [ index ] ; } while ( state = = full & & set [ index ] = key ) ; }
split attachments expression . set extract attachments ( true ) ; producer producer = endpoint . create producer ( ) ;
results . add ( success , new simple ordered map < > ( ) ) ;
int dot _ count = 0 , index = 0 ; while ( ( index = ia4 . index of ( ' . ' , index ) ) = - 1 ) { dot _ count + + ; index + + ; } if ( dot _ count = 3 ) return null ;
_ min text size = typed value . apply dimension ( typed value . complex _ unit _ sp , 12 , get resources ( ) . get display metrics ( ) ) ;
personnel uni mto1 int p2 = ( personnel uni mto1 int ) dao . find person ( personnel uni mto1 int . class , 12346 ) ; assert person2 ( p2 ) ; }
boolean secondary index = server = = null ? false : server . get configuration ( ) . get boolean ( hbase . use . secondary . index , false ) ;
assert equals ( curr us . get symbol ( ) , , curr us . get symbol ( ) ) ; locale . set default ( new locale ( en , ie ) ) ;
assert read test data ( test _ format _ 1 , 1 , 7 ) ;
configuration conf2 = new configuration ( config ) ; conf2 . set ( dfs . name . dir , new file ( hdfs dir , name2 ) . get path ( ) ) ; name node . format ( conf2 ) ; boolean started = can start name node ( conf2 ) ; assert false ( started ) ; should fail
this . extensions = new array list < > ( ) ;
if ( annotations & & dann = 0 ) { annotation visitor dv = mv . visit annotation default ( ) ; read annotation value ( dann , c , null , dv ) ; if ( dv = null ) { dv . visit end ( ) ; } }
test custom json name message with custom json name = test custom json name . new builder ( ) . set value ( 12345 ) . build ( ) ;
m range selector helper = new range selector helper ( fast item adapter ) . with saved instance state ( saved instance state ) . with action mode helper ( m action mode helper ) ;
db session [ ] db sessions = collector . to array ( new db session [ 0 ] ) ;
iterator . remove ( ) ;
body builder . append formal line ( % s ( result . size ( ) ) . as ( \ check ' find all ' returns a not empty list of entries \ ) , get name of java type ( assert _ that ) ) ;
if ( chunk states [ 0 ] . pos enum . next ( ) ) { doc id = doc id set iterator . no _ more _ docs ; return doc id ; } final int doc = chunk states [ 0 ] . pos enum . doc ( ) ;
if ( context . get verbosity ( ) . should use verbosity flag if available ( ) ) { builder . add ( - verbose ) ; }
assert true ( page . user group palette . is enabled ( ) ) ; tester . assert component ( form : roles : palette : recorder , recorder . class ) ; tester . debug component trees ( ) ; add new role ( role _ new ) ; tester . assert rendered page ( edit user page . class ) ; assign role ( role _ new ) ;
reader reader = resources . get resource as reader ( org apache ibatis submitted lazyload _ proxyfactory _ comparison mybatis - config - + get configuration ( ) + . xml ) ; sql session factory = new sql session factory builder ( ) . build ( reader ) ; reader . close ( ) ;
if ( render progress < = start _ left _ duration _ offset ) { float start left offset progress = render progress start _ left _ duration _ offset ; compute left ball move offsets ( decelerate _ interpolator . get interpolation ( start left offset progress ) ) ; return ; }
if ( s . info . process name = = owner . package name ) { out error [ 0 ] = heavy - weight applications can not have services in main process ; return null ; } }
injector . get instance ( open offer manager . class ) . shut down ( ( ) - > { injector . get instance ( p2 pservice . class ) . shut down ( ( ) - > { injector . get instance ( wallets setup . class ) . shut down complete . add listener ( ( ov , o , n ) - > { bisq app module . close ( injector ) ; log . debug ( graceful shutdown completed ) ; result handler . handle result ( ) ; } ) ; injector . get instance ( wallets setup . class ) . shut down ( ) ; injector . get instance ( btc wallet service . class ) . shut down ( ) ; injector . get instance ( bsq wallet service . class ) . shut down ( ) ; } ) ; } ) ;
sp checker ( client , spinsert on partition table , has previous batch , try catch contains1 batch , - 1 , has following batch , following batch has exception , expected ) ;
to attr grp . replace attribute use ( existing attr use , one attr use ) ; } } }
return raw store . get function ( db name , func name ) ; }
if ( boolean . logical xor ( has conj , has cc ) ) { return optional . empty ( ) ; }
next value id = star tree index node interf . all ; add node to search queue ( search queue , node . get child for dimension value ( next value id ) , remaining predicate columns , remaining group by columns ) ; } }
int median idx = select ( split attrib , m _ instlist , node . m _ start , node . m _ end , ( node . m _ end - node . m _ start ) 2 + 1 ) ; utils . select ( array , indices , node . m _ start , node . m _ end , ( node . m _ end - node . m _ start ) 2 + 1 ) ; ( int ) ( node . m _ num instances 2 d + 0 . 5 d ) ; instance pivot ;
width and height panel . add ( new html ( & nbsp ; & nbsp ; ) ) ;
map < object identity , acl > result map = new hash map < object identity , acl > ( ) ; for ( acl input acl : acls . values ( ) ) { assert . is instance of ( acl impl . class , input acl , map should have contained an acl impl ) ; assert . is instance of ( long . class , ( ( acl impl ) input acl ) . get id ( ) , acl . get id ( ) must be long ) ; acl result = convert ( acls , ( long ) ( ( acl impl ) input acl ) . get id ( ) ) ; result map . put ( result . get object identity ( ) , result ) ; } return result map ;
if ( current . has layer ( ) & & current . get layer ( ) instanceof frozen layer ) break ; if ( current . is output vertex ( ) ) {
map < string , object > props and features = new hash map < string , object > ( ) ;
page test ( new file ( test dir , rel . html ) , http : foo . com , http : creativecommons . org licenses by - nc 2 . 0 , rel , null ) ;
exchange . set exception ( new camel exchange exception ( error occurred during aggregation , exchange , e ) ) ; callback . done ( true ) ;
collection cert store parameters cp = new collection cert store parameters ( certificates ) ;
else { throw new illegal state exception ( cannot omit key ( ) clause on a non - updatable table ) ; } }
line = line + , \ \ ;
m has fast scroll touch settled = false ; m has fast scroll touch settled at least once = false ; m current fast scroll section = null ; m target fast scroll section = null ; m target fast scroll position = - 1 ; update tracked views fast scroll focus state ( ) ;
publisher . publish authentication success ( mock ( authentication . class ) ) ;
double sqrtm2 = double . value of ( math . sqrt ( - 2 . 0 ) ) ; double sqrtm3 = double . value of ( math . sqrt ( - 3 . 0 ) ) ; assert equals ( sqrtm2 , sqrtm3 ) ; }
query builder max erev qb = root query builder . new sub query builder ( id data . get audit entity name ( ) , alias2 ) ; max erev qb . add projection ( max , alias2 , revision property path , false ) ;
geo server info global = get geo server ( ) . get global ( ) ; global . get settings ( ) . set proxy base url ( http : www . geoserver . org : 1234 gs ) ; get geo server ( ) . save ( global ) ; document dom = get as dom ( wms? layers = sf : indexed & styles = & format = application openlayers & service = wms & version = 1 . 1 . 1 + & request = get map & srs = epsg : 4326 & bbox = 100 , 78 , 104 , 80 & width = 300 & height = 150 ) ;
infix expression ie = ( infix expression ) expression ; if ( infix expression . operator . plus . equals ( ie . get operator ( ) ) ) { string val1 = get literal value ( clazz , block , ie . get left operand ( ) ) ; string val2 = get literal value ( clazz , block , ie . get right operand ( ) ) ;
result . put ( key , value ) ; }
get menu inflater ( ) . inflate ( r . menu . share _ menu , menu ) ;
if ( name = = null ) { string fmsg = xslmessages . create xpathmessage ( xpatherror resources . er _ feature _ name _ null , new object [ ] { class _ name , new boolean ( value ) } ) ; throw new null pointer exception ( fmsg ) ; }
cursor . next ( ) ; }
return this . key range . lower endpoint ( ) . compare to ( other . key range . lower endpoint ( ) ) ;
params = get parameters ( ) ;
try { get executor ( ) . execute ( this ) ; } catch ( rejected execution exception e ) { if ( get connector ( ) . is running ( ) ) log . warn ( e ) ; else log . ignore ( e ) ; get end point ( ) . close ( ) ; }
v12 . add edge ( parent , v13 ) ; fail ( ) ; } catch ( schema violation exception e ) {
this ( code , name , 4 ) ; }
long uptime millis = system clock . uptime millis ( ) ; move gestures ( current time , uptime millis ) ; send pointer sync ( gesture . generate up event ( pressed gestures , uptime millis + 1 ) ) ;
full = new double ( ( ( high & 0x7fffffff ) < < 32 ) + ( 0x80000000 < < 32 ) ) ; }
parser = ( parser < message lite > ) method . invoke ( null ) ; } catch ( invocation target exception e ) {
return bitmap . create bitmap ( src , 0 , 0 , src . get width ( ) , src . get height ( ) , bitmap matrix , false ) ;
assert that ( result3 . get facets ( ) . get all ( ) ) . has size ( 2 ) ;
for ( int i = 0 ; i < paths . length ; i + + ) { tree path path = paths [ i ] ; tree path temp = null ; while ( are siblings selected ( path ) ) { temp = path ; if ( path . get parent path ( ) = = null ) { break ; } path = path . get parent path ( ) ; } if ( temp = null ) { if ( temp . get parent path ( ) = null ) { add selection path ( temp . get parent path ( ) ) ; } else { if ( is selection empty ( ) ) { remove selection paths ( get selection paths ( ) ) ; } super . add selection paths ( new tree path [ ] { temp } ) ; } } else { super . add selection paths ( new tree path [ ] { path } ) ; } }
list < historic task instance > list = history service . create historic task instance query ( ) . process instance business key like ignore case ( % \ \ % % ) . order by historic task instance start time ( ) . asc ( ) . list ( ) ; assert equals ( 2 , list . size ( ) ) ; list < string > task ids = new array list < string > ( 2 ) ; task ids . add ( list . get ( 0 ) . get id ( ) ) ; task ids . add ( list . get ( 1 ) . get id ( ) ) ; assert true ( task ids . contains ( task1 . get id ( ) ) ) ; assert true ( task ids . contains ( task2 . get id ( ) ) ) ; list = history service . create historic task instance query ( ) . process instance business key like ignore case ( % \ \ _ % ) . order by historic task instance start time ( ) . asc ( ) . list ( ) ; assert equals ( 2 , list . size ( ) ) ;
for ( int i = 0 ; i < 10 ; i + + ) { add doc ( writer ) ; } check invariants ( writer ) ; writer . close ( ) ;
curs . to first content token ( ) ;
assert that ( manager . supports ( method invocation . class ) ) . is true ( ) ;
if ( to = = order . none ) { return false ; }
if ( e . get cause ( ) instanceof hystrix runtime exception ) { return ( hystrix runtime exception ) e . get cause ( ) ; }
assert equals ( number of stores on server 1 is wrong . , num keys , server1 . get cache manager ( clustered ) . get cache ( memcached cache ) . get stores ( ) ) ;
bootstrap method index map [ index ] = - 1 ;
server1 . start ( ) ;
return super . do start tag ( ) ;
local storage folder . set writable ( false ) ;
byte [ ] data = row id factory . serialize row id ( value , field , output ) ;
test same ( line _ joiner . join ( class c { , constructor ( ) { , this . a = 1 ; , } , } , ( { a : x } = new c ( ) ) ; ) ) ;
return date left . compare to ( ( date ) o2 ) ; }
store = create and start store ( ) ;
for ( path type type : new path type [ ] { path type . listvalue , path type . mapvalue , path type . mapvalue _ constant } ) { add ( type , { 0 } . get ( { 1 } ) ) ; }
if ( rtex . get cause ( ) = null ) { throw new compiler exception ( cannot instantiate optimizer post pass : + rtex . get message ( ) , rtex . get cause ( ) ) ; } else { throw rtex ; }
task . set claim time ( null ) ;
boolean root access = can access ( user , root ) ; list < filter > exceptions = new array list < > ( ) ;
assert false ( aop utils . is aop proxy ( bean ) ) ;
configuration mock = mockito . spy ( conf ) ; mockito . when ( mock . get property ( user . name ) ) . then return ( hadoop _ user ) ; mockito . when ( mock . getenv ( file _ name ) ) . then return ( hello ) ; out = new buffered writer ( new file writer ( config ) ) ;
assert equals ( 0x ffff0000 , style . get font color ( ) ) ; assert equals ( serif , style . get font family ( ) ) ; assert equals ( 0x ffff0000 , style . get background color ( ) ) ; assert equals ( ttml style . style _ bold _ italic , style . get style ( ) ) ; assert true ( style . is linethrough ( ) ) ; }
update referenced classes ( local variable type info . referenced classes ) ; }
while ( op queue . is empty ( ) ) { node node = op queue . poll ( ) ; if ( node output = null & & get dispatched list ( ) . contains ( node ) ) { node output . put ( node , ret map . get ( node ) ) ; } } }
tree set < version > accepted = new tree set < version > ( ) ;
if ( f delegate updating ) result . merge ( add delegates ( ) ) ; add declaration update ( ) ;
dest . position ( start pos ) ; int new lim = dest . limit ( ) ; if ( new lim > start lim ) { throw new assertion error ( after codec , buffer [ + start pos + , + start lim + ) became [ + dest . position ( ) + , + new lim + ) ) ; } }
counter c = h . get core container ( ) . get metric manager ( ) . counter ( null , solr . jvm , foo ) ;
cr = client . call procedure ( @ ad hoc , select dept , count ( wage ) , sum ( distinct wage ) , sum ( wage ) , + count ( distinct wage ) + 5 , sum ( wage ) ( count ( wage ) + 1 ) from + tb + group by dept order by dept desc ; ) ;
display metrics metrics = new display metrics ( ) ;
return y conditions ;
compiled plan best plan = assembler . get best cost plan ( parsed stmt ) ;
string tokenizer st = new string tokenizer ( text ) ; while ( st . has more tokens ( ) ) { output < token , 1 > pairs output . collect ( new text ( st . next token ( ) ) , new long writable ( 1 ) ) ; } }
success = create block output stream ( nodes , storage types , storage ids , 0 l , false ) ; if ( success ) { block . set current block ( null ) ; final datanode info bad node = nodes [ get error state ( ) . get bad node index ( ) ] ; log . warn ( excluding datanode + bad node ) ; excluded nodes . put ( bad node , bad node ) ; throw new ioexception ( unable to create new block . + this ) ; }
process instance pi = runtime service . start process instance by key ( intermediate timer event example ) ;
m child height cache . add ( position , child height ) ; return child height ;
if ( get journal edit servlet . check storage info or send error ( storage , request , response ) ) { return ; } long start tx id = servlet util . parse long param ( request , start _ txid _ param ) ;
usage marker . mark as used ( enum constant element value ) ; mark constant ( clazz , enum constant element value . u2element name index ) ;
match ( tracking , line hash and message key : : new ) ; return tracking ;
for ( int i = listeners . length - 2 ; i > = 0 ; i - = 2 ) { if ( listeners [ i ] = = cell editor listener . class ) { ( ( cell editor listener ) listeners [ i + 1 ] ) . editing canceled ( new change event ( this ) ) ; } }
compact equals ( sf create ( 7 , 6 , 5 , 4 , 3 , 2 , 1 ) , 5 , 4 , 3 , 2 , 1 ) ; compact equals ( sf create ( 50 , 10 , 10 , 10 , 10 ) , 10 , 10 , 10 , 10 ) ; compact equals ( sf create ( 10 , 10 , 10 , 10 , 50 ) , 10 , 10 , 10 , 10 ) ; compact equals ( sf create ( 251 , 253 , 251 , max size - 1 ) , 251 , 253 , 251 ) ; compact equals ( sf create ( max size - 1 , max size - 1 , max size - 1 ) * empty * ) ;
final view header view = menu . get header view ( ) ; if ( header view = null ) { menu ' s client has given a custom header view , use it builder . set custom title ( header view ) ; } else { otherwise use the ( text ) title and icon builder . set icon ( menu . get header icon ( ) ) . set title ( menu . get header title ( ) ) ; }
array list < hybrid file parcelable > base files = new array list < > ( ) ;
if ( arrays . equals ( hregion info . get table name ( info . get region name ( ) ) , this . table name ) ) { return bypass ; }
get opts ( ) . load ( ) ;
pos and direction p = new pos and direction ( ) ;
cell . set price ( 2899 . 88 ) ; cell . set in stock ( ' n ' ) ; assert true ( cell . save ( ) ) ; cellphone updated cell = get cell phone ( cell . get id ( ) ) ; assert equals ( 2899 . 88 , updated cell . get price ( ) ) ; assert true ( ' n ' = = updated cell . get in stock ( ) ) ; }
evaluate ( new long ( 3 ) , 3 l , long . class ) ; }
int transports created = 0 ; int backoff1 consulted = 0 ; int backoff2 consulted = 0 ; int backoff reset = 0 ;
return value . equals ( float . na n ) | | value . equals ( double . na n ) ; }
widget pres widget = app presenter . as widget ( ) ; main panel . add ( pres widget ) ; main panel . set widget left right ( pres widget , 0 , unit . px , 0 , unit . px ) ; main panel . set widget top bottom ( pres widget , 0 , unit . px , 0 , unit . px ) ; }
final object [ ] database snapshot = get database snapshot ( session , persister , id ) ;
synchronized ( this ) { for ( entry < integer , client affinity stats > e : m _ client affinity stats . entry set ( ) ) { retval . put ( e . get key ( ) , ( client affinity stats ) e . get value ( ) . clone ( ) ) ; } } return retval ; }
stats publisher stats publisher = utilities . get stats publisher ( jc ) ; stats collection context sc = new stats collection context ( jc ) ; sc . set stats tmp dir ( conf . get tmp stats dir ( ) ) ; if ( stats publisher . connect ( sc ) ) { just return , stats gathering should not block the main query . if ( log . is info enabled ( ) ) { log . info ( stats publishing error : cannot connect to database . ) ; } if ( is stats reliable ) { throw new hive exception ( error msg . statspublisher _ connection _ error . get error coded msg ( ) ) ; } return ; } map < string , string > stats to publish = new hash map < string , string > ( ) ;
for ( field packet field : detail fields ) { buffer = field . write ( buffer , c , true ) ; }
put p = new put ( b1 ) ;
double min score = double . positive _ infinity ;
scan = new scan ( ) ; scan . add column ( families [ 2 ] , qualifiers [ 2 ] ) ; result = get single scan result ( ht , scan ) ; assert single result ( result , rows [ 0 ] , families [ 2 ] , qualifiers [ 2 ] , values [ 2 ] ) ;
if ( bytes since last delete old files > 0 ) { delete old files ( ) ; } }
if ( cache span . is cached ) { obtain a new span with updated last access timestamp . simple cache span new cache span = index . get ( key ) . touch ( cache span ) ; notify span touched ( cache span , new cache span ) ; return new cache span ; }
buffer . get ( first , 3 , size of pages ( 10 ) ) . cancel ( true ) ;
files . create parent dirs ( file for path ) ; if ( path . ends with ( ) & & file for path . create new file ( ) ) { files . write ( ( this is the file ' + path parts [ path parts . length - 1 ] + ' . ) . get bytes ( ) , file for path ) ; paths to add . add ( path . substring ( 1 ) ) ; } }
em . get transaction ( ) . begin ( ) ; re1 = em . find ( referenced entity . class , re _ id1 ) ; child ing entity cie = new child ing entity ( c _ id , y , 1l ) ;
build embedded value ( embeddable key obj , meta model , temp builder , ( singular attribute ) sub attribute ) ; } else {
if ( ( ( jfxtext area ) get skinnable ( ) ) . is disable animation ( ) ) { error container . resize ( w , compute error height ( compute error width ( w ) ) ) ; }
clients = create tracker client ( 100 , clock , degrader config ) ; config = degrader load balancer strategy config . create http config from map ( my map ) ; degrader load balancer strategy v2 _ 1 strategy v2 = new degrader load balancer strategy v2 _ 1 ( config , degrader load balancer test , null ) ; strategy = new degrader load balancer strategy adapter ( strategy v2 ) ; test degrader load balancer simulator ( strategy , clock , time interval , clients , qps , degrader config ) ; }
timer = new timer ( ) ; wakeup count = 0 ;
banner ( transition 4 - > 2 . should stop secret manager . ) ; nn . get rpc server ( ) . transition to standby ( req _ info ) ; assert true ( nn . is standby state ( ) ) ; assert false ( nn . is in safe mode ( ) ) ; assert false ( is dtrunning ( nn ) ) ; banner ( transition 2 - > 4 . should start secret manager ) ;
execute ( select title , description from novels where match ( title _ desc _ fulltext , ' fish ' ) ) ;
for ( int i = 0 ; i < = 3 ; i + + ) { string ip segment = groups [ i ] ; if ( ip segment = = null | | ip segment . length ( ) = = 0 ) { return false ; } int i ip segment = 0 ; try { i ip segment = integer . parse int ( ip segment ) ; } catch ( number format exception e ) { return false ; } if ( i ip segment > 255 ) { return false ; } if ( ip segment . length ( ) > 1 & & ip segment . starts with ( 0 ) ) { return false ; } } return true ;
if ( ( position . get field attribute ( ) = = date format field | | ( position . get field attribute ( ) = = null & & position . get field ( ) = = index ) ) & & position . get end index ( ) = = 0 ) { position . set begin index ( begin position ) ; position . set end index ( buffer . length ( ) ) ; }
part = get binary part ( jcr session , node mapper , docx node , ctm , resolved part uri ) ;
replica . new nrtpoint ( primary version2 , 0 , primary . tcp port ) ; wait for version and hits ( replica , primary version2 , 20 ) ;
return tag . is empty ( ) ? 1 : 0 ;
assert equals ( 0 , ids . next id ( ) ) ;
check update remote control display _ sync af rcs ( rc _ info _ all ) ; } } } }
db connector . create ( test ) ;
byte [ ] [ ] data = { bytes . to bytes ( value1 ) , bytes . to bytes ( value2 ) } ;
throwable cause = e . get cause ( ) ;
this . mode = type inference mode . nti _ only ; test error ( line _ joiner . join ( * * @ constructor * function foo ( ) { } , * * @ type { foo } * foo . prototype = new foo ( ) ; , * * @ const * foo . prop = 1 ; , foo . prop = 2 ; ) , const _ property _ reassigned _ value ) ; }
return ( eval _ body _ tag ) ;
workspace . get config ( ) . get commands ( ) . remove ( 1 ) ;
p . set user property ( build . compiler , ext javac ) ;
string input separator = sep = = null ? \ t : sep ; string input = ignore1 \ n + ignore2 \ n + ignore3 \ n + col1 + input separator + col2 + input separator + col3 \ n + sub1 + input separator + sub2 + input separator + sub3 \ n + skip1 \ n + data1 + input separator + data2 + input separator + data3 ; try { prepare options ( sep , - 1 , 1 , 3 , 2 , false , false ) ; parse one file ( sut , new string reader ( input ) ) ; } catch ( exception e ) { assert . fail ( exception during file parse , e ) ; } assert . assert equals ( project . column model . columns . size ( ) , 3 ) ;
this . loader . load entities ( this . chunk info . world , this . nbt . get compound tag ( level ) , this . chunk ) ; minecraft forge . event _ bus . post ( new chunk data event . load ( this . chunk , this . nbt ) ) ; don ' t call chunk data event . load async
float pair proximity = source . get parameters ( ) . get proximity ( distance + source . get parameters ( ) . get proximity limit ( ) ) ; unweighted proximity + = pair proximity ; float connectedness = source . get query ( ) . get terms ( ) [ i ] . get connectedness ( ) ; proximity + = pow ( pair proximity , connectedness 0 . 1 ) * max ( 0 . 1 , connectedness ) ; pairs + + ; }
calls . remove ( call . id ) ;
supervisor id = indexer . submit supervisor ( spec ) ; log . info ( submitted supervisor ) ;
set < resource > resources = new hash set < > ( ) ; for ( packing plan . instance plan instance plan : container plan . get instances ( ) ) { resources . add ( instance plan . get resource ( ) ) ; } assert . assert equals ( 1 , resources . size ( ) ) ; assert . assert equals ( instance default resources . get ram ( ) , resources . iterator ( ) . next ( ) . get ram ( ) ) ; }
gui activator . get contact list ( ) . start selected contact chat ( ) ;
assert . assert equals ( reduce _ limit , mock scheduler . last any ask reduce ) ;
return 8afde66ea51d865689083ba6bb779fac ;
string original qname = fn name . get original qualified name ( ) ; return original qname . ends with ( . same ) & & original qname . contains ( equality ) ;
int expected rows = nmap input format . get num map tasks ( conf ) * rowspersplit ;
mutable list multimap < string , integer > multi map = new fast list multimap < string , integer > ( ) ;
package manager pm = instrumentation registry . get context ( ) . get package manager ( ) ; resolve info resolve info = pm . resolve activity ( intent , package manager . match _ default _ only ) ; return resolve info . activity info . package name ; }
typed array arr = obtain styled attributes ( val . data , new int [ ] { com . avast . android . dialogs . r . attr . is light theme } ) ;
restore db task . set pending ( get context ( ) , false ) ; } }
put headers ( response , content , 0 ) ;
if ( needs sync data ( ) ) { synchronize data ( ) ; }
if ( port > 0 ) { this . port = port ; }
if ( log . is debug enabled ( ) ) { log . debug ( creating event driven polling consumer with queue size : { } block when full : { } block timeout : { } , new object [ ] { get polling consumer queue size ( ) , is polling consumer block when full ( ) , get polling consumer block timeout ( ) } ) ; } event driven polling consumer consumer = new event driven polling consumer ( this , get polling consumer queue size ( ) ) ; consumer . set block when full ( is polling consumer block when full ( ) ) ; consumer . set block timeout ( get polling consumer block timeout ( ) ) ; return consumer ;
current pos + = random int between ( 0 , 20 ) ; last end = end ; }
string value = properties . get property ( option ) ;
if ( advertised socket address . get port ( ) = = 0 ) { int bolt port = connector port register . get local address ( bolt ) . get port ( ) ; advertised socket address = new advertised socket address ( advertised socket address . get hostname ( ) , bolt port ) ; } if ( advertised socket address . get hostname ( ) . equals ( localhost ) ) {
while ( in queue . is empty ( ) ) { message msg = in queue . poll ( ) ; if ( msg instanceof checkpoint manager . initiate stateful checkpoint ) { persist state ( ( ( checkpoint manager . initiate stateful checkpoint ) msg ) . get checkpoint id ( ) ) ; } if ( msg instanceof heron tuples . heron tuple set ) { heron tuples . heron tuple set tuples = ( heron tuples . heron tuple set ) msg ; handle the tuples if ( tuples . has control ( ) ) { throw new runtime exception ( bolt cannot get acks fails from other components ) ; } topology api . stream id stream = tuples . get data ( ) . get stream ( ) ; for ( heron tuples . heron data tuple data tuple : tuples . get data ( ) . get tuples list ( ) ) { handle data tuple ( data tuple , stream , tuples . get src task id ( ) ) ; } to avoid spending too much time if ( system . nano time ( ) - start of cycle - instance execute batch time . to nanos ( ) > 0 ) { break ; } to avoid emitting too much data if ( collector . get total data emitted in bytes ( ) - total data emitted in bytes before cycle > instance execute batch size . as bytes ( ) ) { break ; } } }
check ( value matcher . looking at ( ) , bad key in js object literal ) ;
check value ( key , value ) ; }
if ( order by . is empty ( ) & & for count row ) { append ( order _ by ) ; boolean first = true ; for ( final order specifier < ? > os : order by ) { if ( first ) { append ( comma ) ; } handle ( os . get target ( ) ) ; append ( os . get order ( ) = = order . asc ? asc : desc ) ; if ( os . get null handling ( ) = = order specifier . null handling . nulls first ) { append ( nulls first ) ; } else if ( os . get null handling ( ) = = order specifier . null handling . nulls last ) { append ( nulls last ) ; } first = false ; } }
cache = new lruauthentication cache impl ( 5 , 0 , 4 ) ;
verify ( listener , never ( ) ) . on added job graph ( any ( job id . class ) ) ;
if ( data = null ) { log . trace ( % s : received get _ mbrs _ rsp from % s : % s , local _ addr , msg . src ( ) , data ) ; handle discovery response ( data , msg . src ( ) ) ; } return null ;
start app shortcut or info activity ( v ) ; }
check throws runtime exception ( new callable < object > ( ) { public object call ( ) throws exception { write . write ( 42 ) ; return null ; } } ) ;
dashboard workspace . enter name workspace ( max _ workspace _ name + a ) ;
return vert src0 ;
assert translated lines ( translation , void test _ foo with int _ ( test * self , jint i ) { , java _ test _ foo _ _ i ( & j2 obj c _ jnienv , self , i ) ; , } ) ;
m player . start ( ) ;
byte [ ] ary = _ bb . array ( ) ;
assert true ( state . assigned partitions ( ) . is empty ( ) ) ; state . subscribe from pattern ( new hash set < > ( collections . singleton list ( topic ) ) ) ;
for ( int i = 0 ; i < ip length ; i + + ) { permitted subnet address [ i ] = ( byte ) ( constraint [ i ] & subnet mask [ i ] ) ; ip subnet address [ i ] = ( byte ) ( ip [ i ] & subnet mask [ i ] ) ; } return arrays . are equal ( permitted subnet address , ip subnet address ) ;
l = random ( ) . next int ( model . index size ) ; u = math . max ( model . index size - 1 , l + random ( ) . next int ( math . max ( model . index size 10 , 2 ) ) ) ; for ( fixed bit set set : sets ) { int end = math . min ( u + 1 , set . length ( ) ) ; set . clear ( l , end ) ; }
if ( body content type = null ) { this . parsed response = object path . create from xcontent ( body content type . x content ( ) , new bytes array ( bytes ) ) ; }
first routing = test shard routing . new shard routing ( test , 0 , node1 , null , true , shard routing state . started ) ;
if ( ( idx new = match nodes ( next , max node , idx ) ) = - 1 ) { return idx new ; } } return - 1 ; case op _ reluctantstar : do {
return in . remaining ( ) ;
final string json = apos to quotes ( { ' values ' : [ null ] } ) ;
return curr ;
g . set color ( fill ) ;
final map < string , shape model > java shapes = new hash map < string , shape model > ( ) ; for ( map . entry < string , operation > entry : get service model ( ) . get operations ( ) . entry set ( ) ) { operation operation = entry . get value ( ) ; list < error map > operation errors = operation . get errors ( ) ; if ( operation errors = null ) { for ( error map error : operation errors ) { string error shape name = error . get shape ( ) ; string java class name = get naming strategy ( ) . get exception name ( error shape name ) ; shape model exception shape model = generate shape model ( java class name , error shape name ) ; exception shape model . set type ( shape type . exception . get value ( ) ) ; exception shape model . set error code ( get error code ( error shape name ) ) ; if ( exception shape model . get documentation ( ) = = null ) { exception shape model . set documentation ( error . get documentation ( ) ) ; } java shapes . put ( java class name , exception shape model ) ; } } }
if ( value = = null ) { remove attribute ( name ) ; return ; }
file hadoop conf dir = new file ( new file ( home dir , conf ) , hadoop - conf ) ; if ( hadoop conf dir . mkdirs ( ) ) { throw new ioexception ( ) ; } string fs default name = nn conf . get ( common configuration keys public . fs _ default _ name _ key ) ;
m caret animator = object animator . of float ( m caret drawable , caret progress , 0 ) ;
canvas . draw line ( node region . min x ( ) , node region . min y ( ) , node region . max x ( ) , node region . min y ( ) , color . white ) ;
throw new volt abort exception ( the transfer from card pan + from _ pan + rejected for insufficient balance ) ;
if ( res . length = initial count ) { log . warn ( we lost some rows on the master cluster ) ; we don ' t really expect the other cluster to have more rows initial count = res . length ; } int last count = 0 ;
property value = get account key from configuration ( account name , session configuration ) ;
if ( visit this class ) { accept ( class visitor ) ; }
if ( ( event instanceof amstarted event ) ) { handler . handle ( new job history event ( job id , event ) ) ; }
assert false ( create process with logon w should have returned false because the username was bogus . , result ) ;
update parent chain ( successor , node , - successor . length , - 1 ) ;
assert equals ( 85 , config . get property ( perm gen threshold option . property _ name ) ) ;
disk lru cache cache2 = disk lru cache . open ( cache dir , app version , 2 , integer . max _ value ) ;
final int n selectors = send mtfvalues1 ( n groups , alpha size ) ;
try { uri = urldecoder . decode ( uri , utf - 8 ) ; } catch ( unsupported encoding exception e ) { throw new error ( e ) ; } if ( uri . is empty ( ) | | uri . char at ( 0 ) = ' ' ) { return null ; }
m _ nextsib . set element at ( dtm . null , attr index ) ;
for ( relation info info : entity metadata . get relation infos ( ) . values ( ) ) { if ( info . cardinality = = cardinality . one _ to _ one ) { this . property id generator = entity metadata . get current indentifier field ( ) . get field name ( ) ; annotation metadata builder identify info = new annotation metadata builder ( json _ identity _ info ) ; identify info . add class attribute ( generator , object _ id _ generators _ property _ generator ) ; identify info . add string attribute ( property , this . property id generator . get symbol name ( ) ) ; ensure governor is annotated ( identify info ) ; break ; } }
if ( constant value . equals ( attr name ) ) { int item = read unsigned short ( u + 8 ) ; value = item = = 0 ? null : read const ( item , c ) ; } else if ( signatures & & signature . equals ( attr name ) ) { signature = read utf8 ( u + 8 , c ) ; } else if ( deprecated . equals ( attr name ) ) { access | = opcodes . acc _ deprecated ; } else if ( synthetic . equals ( attr name ) ) { access | = opcodes . acc _ synthetic | class writer . acc _ synthetic _ attribute ; } else if ( annotations & & runtime visible annotations . equals ( attr name ) ) { anns = u + 8 ; } else if ( annotations & & runtime visible type annotations . equals ( attr name ) ) { tanns = u + 8 ; } else if ( annotations & & runtime invisible annotations . equals ( attr name ) ) { ianns = u + 8 ; } else if ( annotations & & runtime invisible type annotations . equals ( attr name ) ) { itanns = u + 8 ; } else { attribute attr = read attribute ( context . attrs , attr name , u + 8 , read int ( u + 4 ) , c , - 1 , null ) ; if ( attr = null ) { attr . next = attributes ; attributes = attr ; } }
node start node = graph . get node ( start ) ; node end node = graph . get node ( x ) ; assert paths ( finder . find all paths ( start node , end node ) , start , a , b , c , x , start , a , b , c , d , e , x ) ;
if ( system . getenv ( gae _ long _ app _ id ) = null ) { return platform . appengine _ flexible ; } try { if the current environment is null , we ' re not inside app engine . boolean is inside appengine = class . for name ( com . google . apphosting . api . api proxy ) . get method ( get current environment ) . invoke ( null ) = null ; return is inside appengine ? platform . appengine _ standard : platform . standard ; } catch ( class not found exception e ) { if api proxy doesn ' t exist , we ' re not on app engine at all . return platform . standard ; } catch ( invocation target exception e ) { if api proxy throws an exception , we ' re not in a proper app engine environment . return platform . standard ; } catch ( illegal access exception e ) { if the method isn ' t accessible , we ' re not on a supported version of app engine ; return platform . standard ; } catch ( no such method exception e ) { if the method doesn ' t exist , we ' re not on a supported version of app engine ; return platform . standard ; }
components . add ( model ) ; } } else {
body builder . append formal line ( return % s ; , path variable ) ; method metadata builder method builder = new method metadata builder ( get id ( ) , modifier . public , method name , entity type , parameter types , parameter names , body builder ) ;
batch parts . add ( olingo2 batch change request . resource path ( test _ resource ) . operation ( operation . delete ) . build ( ) ) ;
string sql = select borders . name , num points ( borders . region ) from borders + where borders . pk < 100 and num interior ring ( borders . region ) = 0 + order by borders . pk ;
for ( int i = 0 ; i < message count ; + + i ) { log . debug ( triggering message { } , i ) ; object response = source . request body and header ( generate message ( i ) , camel mllp message control id , string . format ( % 05d , i ) ) ; log . debug ( response { } \ n { } , i , response ) ; } assert mock endpoints satisfied ( 15 , time unit . seconds ) ;
replace ( fragment , parent fragment . get child fragment manager ( ) , null ) ;
final int current = m action view . get display options ( ) ; final boolean home as up = ( current & display _ home _ as _ up ) = 0 ; if ( home as up ) { m display home as up set = true ; } action bar policy abp = action bar policy . get ( m context ) ;
assert equals ( ram dir . size in bytes ( ) , ram dir . get recomputed size in bytes ( ) ) ;
this . canon = canonicalizer . get instance ( canonicalizer . algo _ id _ c14 n _ physical ) ; } else { this . canon = canonicalizer . get instance ( canon alg ) ; } } catch ( invalid canonicalizer exception ice ) {
thrown . expect ( illegal state exception . class ) ; client cache manager . get cache ( any - cache ) ; }
logger . info ( cancel all pending tasks ( due to upgrade ) ) ;
string [ ] fields from command = string utils . split ( fields , , ) ;
timer _ logger . logp ( level . finer , timer . class . get name ( ) , remove all notifications , removing all timer notifications ) ; timer table . clear ( ) ;
ddl error test ( malformed numeric constant , create procedure sel hex as select tinyval from blah where x ' 0000000000000000 ff ' < tinyval ; ) ;
else if ( ми . equals ( right word ) & & pattern . compile ( ( . * [ ^ 1 ] | ^ ) [ 78 ] ) . matcher ( left word ) . matches ( ) ) { new analyzed tokens . add ( new analyzed token ( word , ipostag . noun . get text ( ) + : p : v _ rod : & numr : bad , left word ) ) ; new analyzed tokens . add ( new analyzed token ( word , ipostag . noun . get text ( ) + : p : v _ dav : & numr : bad , left word ) ) ; new analyzed tokens . add ( new analyzed token ( word , ipostag . noun . get text ( ) + : p : v _ mis : & numr : bad , left word ) ) ; }
return decode test data ( new byte array input stream ( binary data ) ) ; }
configuration conf = new configuration ( config ) ;
try { file region . custom shuffle transfer ( target , count + 1 ) ; assert . fail ( expected a illegal argument exception ) ; } catch ( illegal argument exception ie ) { log . info ( expected - illegal argument is passed . ) ; } catch ( exception e ) { assert . fail ( expected a illegal argument exception ) ; }
object obj1 = new object ( ) ; object obj2 = new object ( ) ;
file ideal file = new file ( system . get property ( java . io . tmpdir ) + libgdx + system . get property ( user . name ) + + dir name , file name ) ;
final byte [ ] new data = concat ( first chunk . get bytes ( ) , second chunk . get bytes ( ) ) ; new chunk = new memory chunk ( new address , new data ) ;
if ( m source uri = = null ) { throw new builder exception ( source must be set ) ; }
class < ? > builder = bean desc . find pojobuilder ( ) ;
heap = null ; } else {
test ( expected host , expected port , expected db , expected schema , expected repo id , expected user , expected password ) ; }
if ( topo conf . contains key ( windowing configs . topology _ bolts _ sliding _ interval _ count ) ) { sliding interval count = new count ( ( ( number ) topo conf . get ( windowing configs . topology _ bolts _ sliding _ interval _ count ) ) . int value ( ) ) ; } else if ( topo conf . contains key ( windowing configs . topology _ bolts _ sliding _ interval _ duration _ ms ) ) { sliding interval duration ms = ( long ) topo conf . get ( windowing configs . topology _ bolts _ sliding _ interval _ duration _ ms ) ; } else { default is a sliding window of count 1 sliding interval count = new count ( 1 ) ; }
file config file = new file ( app dir , config . file _ config ) ; config to . save ( config file ) ;
else if ( is item pass ( pass ) ) { setup for collecting optional entity info . . . entity collection entities = null ; if ( info = null ) { entities = info . get owner ( ) . get entity collection ( ) ; } draw secondary pass ( g2 , plot , dataset , pass , series , item , domain axis , data area , range axis , crosshair state , entities ) ; }
process instance process instance = runtime service . start process instance by key ( async task ) ;
split keys = new byte [ ] [ ] { new byte [ ] { 1 , 1 , 1 } , new byte [ ] { 2 , 2 , 2 } , new byte [ ] { 3 , 3 , 3 } , new byte [ ] { 2 , 2 , 2 } } ;
attribute value value = convert ( get boolean set , collections . singleton ( true ) ) ; assert . assert equals ( 1 , value . get l ( ) . size ( ) ) ;
response user info response = user info client util . execute user info request _ get method ( jaxrs client , access token response . get access token ( ) ) ;
try { if ( style count = = 0 & & info = null & & info instanceof layer info ) { style info style info = ( ( layer info ) info ) . get default style ( ) ; if ( style info = null ) { visit ( style info . get style ( ) ) ; } } } catch ( ioexception e ) { throw new unchecked ioexception ( e ) ; } finally { clean up state style count = 0 ; }
return new chained aggregator declarer ( this , new global agg scheme ( ) ) . aggregate ( input fields , agg , function fields ) . chain end ( ) . partition persist ( spec , function fields , new combiner agg state updater ( agg ) , function fields ) ;
service builder . install ( ) ;
channel section list response channel section list response = youtube . channel sections ( ) . list ( snippet ) . set id ( channel section id ) . set ( hl , language ) . execute ( ) ;
assert . assert equals ( 1 , env . get messages in the system ( ) ) ;
boolean valid method = true ;
number value = dataset . get value ( row , column ) ;
body builder . append formal line ( if ( search condition . has value ( ) ) { ) ;
if ( graphevent . get type ( ) = = graph event . pre _ event ) { count the started event sequences sequence counter + + ; } else if ( graphevent . get type ( ) = = graph event . post _ event ) { finish the counting of an event sequence sequence counter - - ; if all event sequences finished , we can fire the event . if ( sequence counter = = 0 ) { update selection state ( ( graph2 d ) graphevent . get graph ( ) ) ; this flag makes sure to fire the event for single selection events in on graph2 dselection event fire flag = true ; } }
foster elements . add ( element ) ; } } else {
boolean m skip next move event = prev . get pointer count ( ) = curr . get pointer count ( ) ; m focus delta external = m skip next move event ? focus _ delta _ zero : new point f ( m curr focus internal . x - m prev focus internal . x , m curr focus internal . y - m prev focus internal . y ) ;
atomic reference < metadata > trailers capture = new atomic reference < metadata > ( ) ; atomic reference < metadata > headers capture = new atomic reference < metadata > ( ) ; stub = metadata utils . capture metadata ( stub , headers capture , trailers capture ) ; list < integer > response sizes = arrays . as list ( 50 , 100 , 150 , 200 ) ;
parent . completed container ( cluster resource , application , node , rm container , null , event , this , sort queues ) ;
if ( document . get ( dtc . get start ( ) , dtc . get end ( ) - dtc . get start ( ) ) . trim ( ) . length ( ) = = 0 ) return true ;
throw new exception ( can ' t recover from previous error ( s ) ) ;
return get camel context ( ) . get shutdown route ( ) ;
if ( usage > threshold ) { int excluded = this . excluded ; log . info ( top - n hash is flushing rows ) ; flush internal ( ) ; if ( excluded = = 0 ) { log . info ( top - n hash has been disabled ) ; is enabled = false ; return forward ; hash is ineffective , disable . } }
populate view ( view , model , position ) ;
partition cache lock . read lock ( ) . lock ( ) ;
tmp map . put ( e . get key ( ) , unflushed . put ( e . get key ( ) , e . get value ( ) ) ) ; } } }
if ( cat proc . get singlepartition ( ) | | ( cat proc . get partitionparameter ( ) = 0 ) | | cat proc . get systemproc ( ) ) { return new client response impl ( client response impl . graceful _ failure , new volt table [ 0 ] , invalid procedure for all - partition execution . + targeted procedure must be partitioned , must be partitioned on the first parameter , + and must not be a system procedure . , task . client handle ) ; }
region = hregion . open hregion ( region , null ) ;
clean ( compact id2 compact info map . get ( queue entry . get key ( ) ) ) ; } else {
if ( conversation . is muted ( ) ) { items . add ( options menu item . unsilence ) ; } else { items . add ( options menu item . silence ) ; }
assert xpath evaluates to ( buildings , layer * [ 1 ] , dom ) ;
@ suppress warnings ( serial ) map < string , object > service group1 = new hash map < string , object > ( ) { { put ( type , cluster variants list ) ; put ( cluster list , arrays . as list ( new string [ ] { z cluster1 } ) ) ; } } ;
provider = new wmtslayer provider ( ) ; provider . set store id ( store id ) ; if ( provider . size ( ) < = 0 ) { error ( new param resource model ( store empty , this , store . get name ( ) , store . get workspace ( ) . get name ( ) ) . get string ( ) ) ; }
event = factory . create exchange sent event ( exchange , endpoint , time taken ) ;
jsp config jsp config = ( jsp config ) _ web app . get servlet context ( ) . get jsp config descriptor ( ) ;
render manager . preload scene ( dummy geom ) ; } catch ( renderer exception e ) {
bs = new bit set ( 10 ) ; try { bs . flip ( - 1 , 3 ) ; fail ( ) ; } catch ( index out of bounds exception expected ) { } try { bs . flip ( 2 , - 1 ) ; fail ( ) ; } catch ( index out of bounds exception expected ) { } try { bs . flip ( 4 , 2 ) ; fail ( ) ; } catch ( index out of bounds exception expected ) { }
response list < status > res = twitter1 . get user list statuses ( 2031945 , paging ) ; int actual = res . size ( ) ;
byte [ ] bytes = section data . data ; section data . reset ( math . min ( max _ section _ length , math . max ( total section length , bytes . length * 2 ) ) ) ; system . arraycopy ( bytes , 0 , section data . data , 0 , section _ header _ length ) ; } } } else {
gossiper . instance . inject application state ( joininghost , application state . tokens , value factory . tokens ( tokens ) ) ; ss . on change ( joininghost , application state . status , value factory . bootstrapping ( tokens ) ) ; ss . remove node ( joining id . to string ( ) ) ; }
tester . set content servlet ( default servlet . class ) ; try { tester . start ( ) ; assert is response not gzip compressed ( tester , get , file . txt , filesize , http status . ok _ 200 ) ; } finally { tester . stop ( ) ; }
layer group = sc . get layer group by name ( topp , eo states layer group ) ;
try { node field . set ( this , null ) ; children . clear ( ) ; } catch ( illegal access exception e ) { throw new runtime exception ( e ) ; } return value ;
attribute wrapper wrapper = wrap ( entity metadata , entity ) ;
string file name = null ; if ( model . is path as directory ( ) ) {
add successor ( stack size , dflt ) ;
node name = ejbmanagement util . get node name ( ) ;
pipeline . add last ( chunked writer , new chunked write handler ( ) ) ; pipeline . add last ( handler , new http upload client handler ( ) ) ;
insert instructions ( offset , replace , before , old instruction , pop opcodes ) ;
string input _ text = hello world hello all hi world ;
collection . update many ( not ( eq ( zip , null ) ) , set ( zip , null ) , print modified count ) ; system . out . println ( ) ;
pulsar client pulsar client = pulsar client . create ( http : localhost : 8080 ) ;
boolean as eff = line . has option ( as eff ) ; boolean as sequence file = line . has option ( as sequence file ) ; dump nodes ( new path ( web graph db ) , type , top n , new path ( output ) , as eff , name type , aggr type , as sequence file ) ;
this . pending response received millis = clock . current time millis ( ) ; this . backups acks expected = expected backups ;
result = services a . execute operation ( remove container op ) ;
while ( true ) { container status status = nm client . get container status ( container . get id ( ) , container . get node id ( ) ) ; if ( status . get state ( ) = = container state . running ) { break ; } sleep ( 100 ) ; } } } catch ( yarn exception e ) {
try { service reference < ? > [ ] references = context . get all service references ( project operations . class . get name ( ) , null ) ; for ( service reference < ? > ref : references ) { return ( project operations ) context . get service ( ref ) ; } return null ; } catch ( invalid syntax exception e ) { logger . warning ( cannot load project operations on application module feature . ) ; return null ; }
environment edge manager . inject edge ( null ) ;
project operations . add dependency ( path . get module ( ) , new dependency ( javax . validation , validation - api , null ) ) ;
rest manager . get rest manager ( solr request info . get request info ( ) ) . attach managed resources ( rest manager . schema _ base _ path , router ) ; log . info ( create inbound root complete for schema ) ;
add seconds to current time ( process engine , 180 l ) ; try { wait for all jobs being executed ( process engine , 500 l ) ; assert . fail ( ) ; } catch ( activiti exception e ) {
path manifest file = folder . new file ( actual _ manfiest . mf ) ; try ( output stream os = files . new output stream ( manifest file ) ) { from user . write ( os ) ; } path tmp = folder . new folder ( ) ;
return new env type pair ( in env , required type ) ;
bucket = username buckets . get ( 1 ) ;
return a . length ( ) - b . length ( ) ;
if ( tab _ alias = null ) { col info . set tab alias ( tab _ alias . to lower case ( ) ) ; }
int interval = this . monitoring interval . get ( ) ;
int previous position = m first position - 1 ; fill up ( previous position , get next child ups bottom ( previous position ) ) ;
request request = client . new request ( http : localhost : + port + context path + servlet mapping . substring ( 1 ) + ?action = old - create ) ;
jpa test entity te = new jpa test entity ( ) ; dao . persist ( te ) ;
meta tags . set refresh ( true ) ; } catch ( exception e ) { ; } url refresh url = null ; if ( meta tags . get refresh ( ) & & idx = - 1 ) { set the url idx = content . to lower case ( ) . index of ( url = ) ; if ( idx = = - 1 ) { assume a mis - formatted entry with just the
fc . rename ( new path ( new dir dir foo ) , new path ( file : dir foo bar ) ) ;
if ( url instanceof string [ ] ) { if ( log . is debug enabled ( ) ) log . debug ( > > > resolution of array of urls requested ) ; string [ ] urls = ( string [ ] ) url ; context rootctx = new java root urlcontext ( env ) ; object object = null ; naming exception e = null ; for ( int i = 0 ; ( i < urls . length ) & & ( object = = null ) ; i + + ) { try { object = rootctx . lookup ( urls [ i ] ) ; } catch ( naming exception x ) { e = x ; } } if ( object = = null ) throw e ; else return object ; } if ( log . is debug enabled ( ) ) log . debug ( > > > no idea what to do , so return a new root context anyway ) ;
builder . set segment ( segment builder . build ( ) . to byte string ( ) ) ; }
public object invoke ( evaluation context ctx , @ suppress warnings ( rawtypes ) class [ ] param types , object [ ] param values ) throws elexception { target t = get target ( ctx ) ;
json object json ; try { json = ( json object ) jsoner . deserialize ( connector json ) ; } catch ( deserialization exception e ) { throw new runtime exception ( error parsing camel - connector . json file due + e . get message ( ) , e ) ; } this . connector name = json . get string ( name ) ; this . base scheme = json . get string ( base scheme ) ; this . base java type = json . get string ( base java type ) ; this . scheduler = json . get string ( scheduler ) ; string type = json . get string ( input data type ) ; if ( type = null ) { this . input data type = new data type ( type ) ; }
tester . assert number of nodes with flavor ( content nodes , large - variant - variant , 3 ) ;
path meta file path = new path ( matrix path , model files constent . model meta file name ) ; file system fs = meta file path . get file system ( conf ) ; fsdata input stream input = fs . open ( meta file path ) ;
if ( disallowed characters = null ) { for ( int index = 0 ; index < disallowed characters . length ; index + + ) { if ( disallowed characters [ index ] = = character ) { return false ; } } }
throw new ioexception ( invalid or corrupt contents : file in tar with long filename but empty filename found ) ;
int branch count = instruction offsets . instruction offset count ( ) ;
boolean . write boolean ( block builder , i % 2 = = 0 ) ;
if ( source screen = = target screen ) { m stack tabs [ i ] . set scroll offset ( target ) ; continue ; } float step = source + ( target - source ) * relative progress ; float step screen = math . min ( screen max , scroll to screen ( step + m scroll target ) ) ;
for ( int i = text . length ( ) - 1 ; i > = 0 ; i - - ) { if ( ( text . char at ( i ) = = ' * ' | | text . char at ( i ) = = ' ? ' ) & & unescaped char sequence . was escaped ( text , i ) ) { return true ; } } return false ;
solr cores . close ( ) ;
in order iterative ( root , list ) ; return list ; }
for ( socket dn sock : dn sockets ) { cache . put ( dn sock ) ; } assert equals ( nn socket evicted , null , cache . get ( nn addr ) ) ; assert true ( evicted socket closed , nn sock . is closed ( ) ) ;
packages . add ( sun ) ; packages . add ( java ) ; packages . add ( javax ) ; break ; } jre packages = packages . to array ( new string [ packages . size ( ) ] ) ; }
timeout executor . send stop signal ( ) ; thread pool . shutdown now ( ) ; return true ; }
wordprocessing mlpackage wml package = ( ( wordprocessing mlpackage ) this . get package ( ) ) ; list < section wrapper > sections = wml package . get document model ( ) . get sections ( ) ;
index descriptor existing index1 = index descriptor factory . for label ( label id1 , key1 ) ;
int a = 0 ; < - a tab
for ( enum and scorer sub : subs ) { if ( sub = null ) { cost + = sub . pos enum . cost ( ) ; subs on doc [ num subs on doc + + ] = sub ; } } this . cost = cost ; }
_ echo servers . get ( 1 ) . mark down ( ) ; _ echo servers . get ( 1 ) . stop server ( ) ; since we are running echo server in the same vm , this is not a real shutdown msg = generate message ( _ zk uri string ) ; assert equals ( _ cli . send request ( _ client , cluster - 1 , service - 1 _ 1 , msg ) , get expected response ( 0 , msg , _ echo servers . get ( 0 ) . get response postfix string with port ( ) ) ) ; assert equals ( _ cli . send request ( _ client , cluster - 1 , service - 1 _ 2 , msg ) , get expected response ( 0 , msg , _ echo servers . get ( 0 ) . get response postfix string with port ( ) ) ) ; assert equals ( _ cli . send request ( _ client , cluster - 2 , service - 2 _ 2 , msg ) , get expected response ( 0 , msg , _ echo servers . get ( 2 ) . get response postfix string with port ( ) ) ) ;
cntr . x ( ( int ) math . rint ( cntr x ) ) ;
if ( serve ) { do service ( servlet request , servlet response ) ; }
keep specifications . add ( keep class specification ) ;
byte [ ] cell block = new byte [ size ] ;
delete . set config set name ( config set ) ; verify exception ( solr client , delete , requested delete of immutable config set ) ; solr client . close ( ) ;
verify ( state backend test source . operator state backend ) . close ( ) ; verify ( state backend test source . keyed state backend ) . close ( ) ; assert equals ( execution state . finished , task . get execution state ( ) ) ;
for ( int i = 1 ; i < n - 1 ; + + i ) { rhs [ i ] = 4 * knots [ i ] . x + 2 * knots [ i + 1 ] . x ; }
server socket channel ssc = server socket channel . open ( ) ;
assert true ( all node managers did not connect to the rm within the + allotted 5 - second timeout , yarn cluster . wait for node managers to connect ( 5000 l ) ) ; node reports = yarn client . get node reports ( node state . running ) ; assert equals ( not all node managers were reported running , node count , node reports . size ( ) ) ; priority = priority . new instance ( 1 ) ;
message edit text . set on key listener ( ( view , keycode , key event ) - > { if ( messenger ( ) . is send by enter enabled ( ) ) { if ( key event . get action ( ) = = key event . action _ down & & keycode = = key event . keycode _ enter ) { on send button pressed ( ) ; return true ; } } return false ; } ) ;
sb . append ( < ) ;
string [ ] resource types = { user _ vm , public _ ip , volume , snapshot , template } ; for ( long account id : accounts ) { for ( string resource type : resource types ) { pstmt = conn . prepare statement ( select * from resource _ count where type = ? and account _ id = ? ) ; pstmt . set string ( 1 , resource type ) ; pstmt . set long ( 2 , account id ) ; rs = pstmt . execute query ( ) ; if ( rs . next ( ) ) { s _ logger . debug ( inserting resource _ count record of type + resource type + for account id = + account id ) ; pstmt = conn . prepare statement ( insert into resource _ count ( account _ id , domain _ id , type , count ) values ( ? , null , ? , 0 ) ) ; pstmt . set long ( 1 , account id ) ; pstmt . set string ( 2 , resource type ) ; pstmt . execute update ( ) ; } rs . close ( ) ; } pstmt . close ( ) ; }
oresult set results = db . query ( select * from index : person . composite where key = ' name : luke age : [ 5 to 6 ] ' ) ;
final find request < album entry > search req = _ album entry builders . find by search ( ) . album id param ( album id ) . build ( ) ; final response future < collection response < album entry > > response future = _ rest client . send request ( search req ) ; final response < collection response < album entry > > response = response future . get response ( ) ; final list < album entry > entries = new array list < album entry > ( response . get entity ( ) . get elements ( ) ) ; entries . add ( new album entry ( ) . set album id ( - 1 ) . set photo id ( 9999 ) ) ;
add left widget ( commands _ . clear plots ( ) . create toolbar button ( ) ) ;
units [ id ] = ( units [ id ] & 0x ff ) | ( ( id ^ unused offset ) & 0x ff ) ;
region coprocessor environment env = ( region coprocessor environment ) get environment ( ) ;
animate view ( holder , position ) ; }
final int child count = get child count ( ) ; for ( int i = 0 ; i < child count ; i + + ) { final view child = get child at ( i ) ; final layout params lp = ( layout params ) child . get layout params ( ) ; if ( lp . is decor ) { lp . width factor = 0 . f ; } } set current item internal ( new curr item , false , true ) ;
assert equals ( true , properties . circuit breaker force closed ( ) . get ( ) ) ;
list < row > expected results = arrays . as list ( group by query runner test helper . create expected row ( 2011 - 04 - 01 , ql , 0 l , qf , 0 . 0 , count , 2 l ) , group by query runner test helper . create expected row ( 2011 - 04 - 01 , ql , 170000 l , qf , 170000 . 0 , count , 2 l ) ) ; iterable < row > results = group by query runner test helper . run query ( factory , runner , query ) ;
result = new instances ( input format . relation name ( ) , atts , 0 ) ;
if ( acceptable url pattern . matcher ( str ) . matches ( ) ) { return value ; }
to front ( ) ; }
assert not null ( get adapter ( observable . class ) ) ;
for ( map . entry < integer , string > entry : label enumeration . entry set ( ) ) { output . append int ( entry . get key ( ) ) ; byte [ ] bytes = entry . get value ( ) . get bytes ( utf _ 8 ) ; output . append int ( bytes . length ) ; output . append bytes ( bytes ) ; } return output . slice ( ) . get bytes ( ) ; }
list < material revision > revision list = changeset service . revisions between ( foo - bar , first pipeline . get counter ( ) , bisect pipeline . get counter ( ) , new username ( new case insensitive string ( loser ) ) , result , true , true ) ;
assert equals ( http : a b c g , new url ( base , http : g ) . to string ( ) ) ;
final job id job id4 = create job ( test job name + _ 4 , test job version , busybox , idle _ command ) ;
system bar tint manager tint manager = new system bar tint manager ( this ) ;
factory . build transition for ( flag2 setter ) ) . add equality group (
execute ( insert into t ( id , name , female ) ( select id , name , female from characters ) + on duplicate key update female = values ( female ) ) ; assert that ( response . row count ( ) , is ( 4 l ) ) ; refresh ( ) ; execute ( select female , count ( * ) from t group by female order by female ) ;
jsonarray properties = info . get jsonarray ( property ) ;
task service . add comment ( null , process instance id , hello world ) ;
if ( ssl host configs . get ( get default sslhost config name ( ) ) = = null ) { throw new illegal argument exception ( sm . get string ( endpoint . no ssl host config , get default sslhost config name ( ) , get name ( ) ) ) ; } }
matching build rules = targets command . get matching nodes ( target graph , optional . of ( immutable set . of ( paths . get ( foo foo . m ) ) ) , optional . empty ( ) , optional . empty ( ) , false , buck ) ;
admin permission management permissions = admin permissions . management ( session , realm ) ; group model group = keycloak model utils . find group by path ( realm , top ) ; user model group member = session . users ( ) . add user ( realm , group member ) ; group member . join group ( group ) ; group member . set enabled ( true ) ; user model group manager = session . users ( ) . add user ( realm , group manager ) ; group manager . grant role ( query groups role ) ; group manager . grant role ( query users role ) ; group manager . set enabled ( true ) ; group manager . grant role ( mapper role ) ; session . user credential manager ( ) . update credential ( realm , group manager , user credential model . password ( password ) ) ; user model group manager no mapper = session . users ( ) . add user ( realm , no mapper group manager ) ; group manager no mapper . set enabled ( true ) ;
if ( ( eq _ s _ b ( 1 , u ) ) ) { break lab13 ; } } while ( false ) ; cursor = limit - v _ 10 ;
final uri locator factory locator factory = new simple uri locator factory ( ) . add locator ( wro test utils . create resource mocking locator ( ) ) ; final resource pre processor failing pre processor = new resource pre processor ( ) { public void process ( final resource resource , final reader reader , final writer writer ) throws ioexception { throw new ioexception ( boom ) ; } } ;
assert true ( raid fs . exists ( src path ) ) ;
do sort ( a , left , less - 2 ) ;
partition chunk < string > chunk0 = new numbered shard spec ( 0 , 2 ) . create chunk ( 0 ) ;
branched store bs = beans ( cluster . get master ( ) ) . get branched store bean ( ) ;
path path = meta . get file status ( ) . get path ( ) . get parent ( ) ;
builder . set lazy init ( true ) ; }
throw new runtime exception ( incorrect number of args . ) ;
if ( voldemort config . is slop purge job enabled ( ) ) { logger . info ( initializing slop purge job ) ; slop purge job job = new slop purge job ( store repository , metadata , scan permit wrapper , voldemort config . get slop purge job max keys scanned per sec ( ) ) ; jmx utils . register mbean ( job , jmx utils . create object name ( job . get class ( ) ) ) ; store repository . register slop purge job ( job ) ; }
if ( type . is assignable from ( object id . class ) & & ( value instanceof object id | | value instanceof string ) ) { return new object id ( value . to string ( ) ) ; }
permissions . add ( manifest . permission . access _ fine _ location ) ;
if ( is on custom content ( ) & & m drag controller . is dragging ( ) ) {
val call = async http client call . builder ( ) . http client ( http client ) . request ( request ) . on request start ( e - > num started . increment and get ( ) ) . on request failure ( t - > num failed . increment and get ( ) ) . on request success ( r - > num ok . increment and get ( ) ) . request customizer ( rb - > num request customizer . increment and get ( ) ) . execute timeout millis ( 1000 ) . build ( ) ;
if ( in mem sorter . has space for another record ( ) ) { logger . error ( unable to grow the pointer array ) ; throw e ; } return ;
cv . visit label ( default label ) ;
class specifications . remove ( index ) ; return true ;
final file status src status = get file link status ( src ) ; if ( src status = = null ) { throw new file not found exception ( rename source + src + not found . ) ; } boolean overwrite = false ;
type env entry env = get entry type env ( ) ;
final lruquery cache query cache = new lruquery cache ( 1 , 10000 , context - > true , float . positive _ infinity ) ; final index searcher searcher = new searcher ( reader ) ; searcher . set query cache ( query cache ) ; searcher . set query caching policy ( query caching policy . always _ cache ) ; bad query query = new bad query ( ) ; searcher . count ( query ) ; query . i [ 0 ] + = 1 ; change the hash code
system . out . println ( flushing cache ) ;
assert equals ( 2 , session factory ( ) . get statistics ( ) . get update timestamps cache hit count ( ) ) ; testing jta platform impl . instance . get transaction manager ( ) . resume ( tx4 ) ;
ioutils . close while handling exception ( index in , this ) ; } }
if ( row elements > 0 ) { while ( row elements = m num columns ) { add swatch to row ( row , create blank space ( ) , row number ) ; row elements + + ; } add view ( row ) ; } }
meeting . get properties ( ) . add ( tz . get time zone id ( ) ) ;
alert level characteristic . set value ( new byte [ ] { mi band2 service . alert _ level _ none } ) ; gatt . write characteristic ( alert level characteristic ) ; return false ;
expect throws ( ioexception . class , ( ) - > { check read bytes ( input , 50 , pos ) ; } ) ; input . seek ( pos ) ;
props . put ( org . quartz . thread pool . class , org . quartz . simpl . simple thread pool ) ; props . put ( org . quartz . thread pool . thread count , 10 ) ; final string sql scripts dir = get sql scripts dir ( ) ;
if ( draw xinside & & draw yinside ) { draw value ( c , formatter , value , entry , 0 , x , y , data set . get value text color ( j ) ) ; if ( j < data . get entry count ( ) & & entry . get label ( ) = null ) { draw entry label ( c , entry . get label ( ) , x , y + line height ) ; } } else if ( draw xinside ) { if ( j < data . get entry count ( ) & & entry . get label ( ) = null ) { draw entry label ( c , entry . get label ( ) , x , y + line height 2f ) ; } } else if ( draw yinside ) { draw value ( c , formatter , value , entry , 0 , x , y + line height 2f , data set . get value text color ( j ) ) ; }
byte array output stream stream = new byte array output stream ( ) ;
repository connection exception rce = new repository connection exception ( no geo gig repository found with name or id : + name ) ;
if ( spdy headers frame . is last ( ) ) { half close stream ( stream id , false , promise ) ; } } else if ( msg instanceof spdy window update frame ) {
part . set data uri ( res ) ; return res ;
integer order = get order ( metadata ) ; if ( order = null ) { bean def . set attribute ( order _ attribute , order ) ; } return true ;
initializations [ initialization count + + ] = var ; }
int length = buffer . length ;
log . warn ( encountered initialized collection in batch fetch queue , this should not happen . ) ;
try ( final kafka producer < byte [ ] , byte [ ] > kafka producer = kafka server . new producer ( ) ) { for ( producer record < byte [ ] , byte [ ] > record : records ) { kafka producer . send ( record ) . get ( ) ; } } final kafka index task task = create task ( null , new kafka ioconfig ( sequence0 , new kafka partitions ( topic , immutable map . of ( 0 , 200 l ) ) , new kafka partitions ( topic , immutable map . of ( 0 , 500 l ) ) , kafka server . consumer properties ( ) , true , false , null , null , false ) , true ) ;
if ( host . get type ( ) = = host . type . routing ) { final list < vminstance vo > vms = _ vm dao . list by host id ( host id ) ; if ( vms . size ( ) = = 0 ) { return true ; } list < host vo > hosts = list all up and enabled hosts ( host . type . routing , host . get cluster id ( ) , host . get pod id ( ) , host . get data center id ( ) ) ; for ( final vminstance vo vm : vms ) { if ( hosts = = null | | hosts . is empty ( ) | | answer . get migrate ( ) ) { for the last host in this cluster , stop all the vms _ ha mgr . schedule stop ( vm , host id , work type . force stop ) ; } else { _ ha mgr . schedule migration ( vm ) ; } } } return true ;
fail ( expected a timeout ) ;
if ( module commands = null & & module commands . contains ( command . get class ( ) ) ) output . write byte ( 1 ) ; else output . write byte ( 0 ) ; output . write short ( command . get command id ( ) ) ;
memstore . delete ( key value test util . create ( r , f , q , 100 , v ) ) ; t = memstore . time of oldest edit ( ) ; assert true ( t = = 1234 ) ; t = run snapshot ( memstore ) ;
if ( headers . contains key ( hazelcast constants . object _ id ) ) { headers . remove ( hazelcast constants . object _ id ) ; } if ( headers . contains key ( hazelcast constants . operation ) ) { headers . remove ( hazelcast constants . operation ) ; }
for ( int i = 0 ; i < n * n ; i + + ) { memset ( out matrix , 0 , n * n ) out matrix [ i ] = 0 ; } for ( int i = 0 ; i < n ; i + + ) { out matrix [ i * n + i ] = 1 ; }
do { ancestor = _ parent ( ancestor ) ; } while ( candidate < ancestor ) ;
if ( writer . is enabled ( serialization feature . indent _ output ) ) { g . use default pretty printer ( ) ; } java type root type = null ; if ( ( generic type = null ) & & ( value = null ) ) {
operator chain . flush outputs ( ) ;
data . add ( new string [ ] { 6 . 13 . 1 , c020 c120 c220 c320 c420 c520 c620 c720 c820 c920 ca20 cb20 cc20 cd20 ce20 cf2 + 0 d020 d120 d220 d320 d420 d520 d620 d720 d820 d920 da20 db20 dc20 dd20 de20 } ) ; data . add ( new string [ ] { 6 . 13 . 2 , e020 e120 e220 e320 e420 e520 e620 e720 e820 e920 ea20 eb20 ec20 ed20 ee20 } ) ; data . add ( new string [ ] { 6 . 13 . 3 , f020 f120 f220 f320 f420 f520 f620 } ) ; data . add ( new string [ ] { 6 . 13 . 4 , f820 f920 fa20 } ) ; data . add ( new string [ ] { 6 . 13 . 5 , fc20 } ) ;
info . set bitrate ( vorbis identification header . get nominal bitrate ( ) 1000 ) ;
conf . set int ( hbase . hstore . compaction . min , 3 ) ; conf . set int ( hbase . hstore . compaction threshold , 5 ) ;
rack ring info info = policy . racks map . get ( network topology . default _ rack ) ; assert null ( info ) ; hash map < node , node > empty map = new hash map < node , node > ( ) ;
working full tuple = null ; working full hash = null ; workng hash set idx = 0 ; }
create new file ( path _ to _ files , new _ file _ name , test menu commands constants . project . new . file , ) ; check default text in code mirror editor for file ( default _ text _ for _ new _ file _ name , new _ file _ name ) ; editor . close file by name with saving ( new _ file _ name ) ;
a [ left ] = a [ less - 1 ] ; a [ less - 1 ] = pivot1 ; a [ right ] = a [ great + 1 ] ; a [ great + 1 ] = pivot2 ;
fields = str time . split ( : ) ; retval . set ( calendar . hour _ of _ day , integer . parse int ( fields [ 0 ] ) ) ; retval . set ( calendar . minute , integer . parse int ( fields [ 1 ] ) ) ; retval . set ( calendar . second , integer . parse int ( fields [ 2 ] ) ) ; return retval ; }
new node cl ( c , ( - ip 127 . 0 . 0 . 1 - port + ports [ i ] + - flatfile + flat ) . split ( ) ) . start ( ) ; }
final int size = ( 16 + 1 + 1 + 1 ) * 4 ; assert equals ( size , img . get height ( ) ) ; assert equals ( size , img . get width ( ) ) ; buffered image expected = image io . read ( kmltest . class . get resource ( circle - red - 16 - x4 . png ) ) ;
for ( int i = 0 ; i < 3 ; i + + ) { now . add and get ( 25 * 1000 ) ; pubsub client . advance ( ) ; assert false ( reader . advance ( ) ) ; }
try { attrs . set attributes ( null ) ; fail ( null pointer exception expected ) ; } catch ( null pointer exception e ) { expected , but must be empty now assert equals ( 0 , attrs . get length ( ) ) ; }
list < application > all applications = atlas hacks . activity thread _ m all applications . get ( activity thread ) ; for ( int i = 0 ; i < all applications . size ( ) ; i + + ) { if ( all applications . get ( i ) = = m raw application ) {
solr plugin utils . set min should match ( q , 100 % , false ) ; assert equals ( 3 , q . build ( ) . get minimum number should match ( ) ) ;
assert that ( stats . get cgroup ( ) . get memory control group ( ) , not null value ( ) ) ; assert that ( stats . get cgroup ( ) . get memory limit in bytes ( ) , not null value ( ) ) ; assert that ( new big integer ( stats . get cgroup ( ) . get memory limit in bytes ( ) ) , greater than ( big integer . zero ) ) ; assert that ( stats . get cgroup ( ) . get memory usage in bytes ( ) , not null value ( ) ) ; assert that ( new big integer ( stats . get cgroup ( ) . get memory usage in bytes ( ) ) , greater than ( big integer . zero ) ) ; } } else {
synchronized ( this ) { if ( is cleaning ) { return ; } is cleaning = true ; }
branch unit . set trace branch targets ( trace value ) ; if ( debug ) { if ( branch unit . was called ( ) ) { system . out . println ( is branching to + branch targets ) ; } if ( branch target values [ instruction offset ] = null ) { system . out . println ( has up till now been branching to + branch target values [ instruction offset ] ) ; } system . out . println ( vars : + variables ) ; system . out . println ( stack : + stack ) ; }
last slash index = 1 ; } default path = default path . substring ( 0 , last slash index ) ; }
create function add2bigint from method org . voltdb _ testfuncs . user defined test functions . add2 bigint ; ,
long start time = new date ( ) . get time ( ) ; while ( uploaded file . exists ( ) & & ( new date ( ) . get time ( ) - start time ) < 120000 ) { thread . sleep ( 1000 ) ; } assert true ( uploaded file . exists ( ) ) ; cleaner . set expiration delay ( 300000 ) ; }
cert path path = certificate factory . generate cert path ( get cert list ( false , false ) ) ; cert path validator cert path validator = cert path validator . get instance ( pkix ) ;
i _ p v = limit ; i _ p1 = limit ; i _ p2 = limit ;
string safe chars = \ 0 \ u0100 \ u d800 \ u dc00 \ u ffff ;
if ( conf . get write type ( ) = acid utils . operation . not _ acid & & conf . is mm table ( ) ) { return true ; } for ( boolean b : stats from rw ) { if ( b ) { return false ; } } return true ;
q = em . create named query ( name ) ; assert equals ( lock mode . optimistic , q . unwrap ( org . hibernate . query . class ) . get lock options ( ) . get lock mode ( ) ) ; assert equals ( lock mode type . optimistic , q . get lock mode ( ) ) ; em . get transaction ( ) . commit ( ) ;
byte array = new byte array ( new byte [ ] { 0x00 , 0x00 , 0x00 , 0x00 , 0x31 } ) ;
return task . output frame ( null , null , new string [ ] [ ] { vec domain } ) . vec ( 0 ) ;
fs . delete ( in dir , true ) ;
jar entry entry = new jar entry ( name ) ;
return super . check property ( property id ) ;
fs . set permission ( dir , permission ) ; return result ;
identifier ident = ( identifier ) e . get function ( ) ; assert that ( ident . get name ( ) ) . is equal to ( f ) ; assert that ( e . get arguments ( ) ) . has size ( 3 ) ; assert that ( e . get num positional arguments ( ) ) . is equal to ( 3 ) ; integer literal arg0 = ( integer literal ) e . get arguments ( ) . get ( 0 ) . get value ( ) ; assert that ( ( int ) arg0 . get value ( ) ) . is equal to ( 1 ) ; argument . passed arg1 = e . get arguments ( ) . get ( 1 ) ; identifier arg1val = ( ( identifier ) arg1 . get value ( ) ) ;
if ( _ socket _ . is input shutdown ( ) ) { return false ; }
thread thread id [ ] = new thread [ num _ threads ] ;
m ptr frame layout . set keep header when refresh ( true ) ;
set string ( key , string . value of ( value ) ) ;
assert false ( m bottom navigation . get menu ( ) . find item ( r . id . destination _ people ) . is checked ( ) ) ;
schema = create table t0 ( id bigint not null , name varchar ( 32 ) not null , age integer , primary key ( id ) ) ; \ n + partition table t0 on column id ; \ n + create unique index user _ index2 on t0 ( id ) ; ; check valid unique and assume unique ( schema , null , msg pr ) ;
assert false ( connection . peer settings . get enable push ( true ) ) ;
string answer = result . get answer ( ) ;
final list < boolean > timeout _ flag = new array list < boolean > ( 1 ) ;
for ( i = 0 ; i < r ; i + + ) st [ i ] = + ( char ) i ; st [ i + + ] = ; ( unused ) lookahead for eof int codeword = binary std in . read int ( w ) ;
wrapper proxetta builder builder = proxetta . builder ( calc . get class ( ) ) ; class calc2 class = builder . define ( ) ;
for ( chunk checksum chunk checksum : multi chunk . get chunks ( ) ) { chunk multi chunk cache . put ( chunk checksum , multi chunk . get id ( ) ) ; }
assert . assert equals ( 1 , task . get metrics ( ) . processed ( ) ) ; assert . assert equals ( 2 , task . get metrics ( ) . thrown away ( ) ) ; assert . assert equals ( 0 , task . get metrics ( ) . unparseable ( ) ) ;
always mobilize = shared prefs . get boolean ( mobilized _ browser , false ) & & shared prefs . get boolean ( mobilize _ on _ data _ only , true ) ; mobilize on data = shared prefs . get boolean ( mobilized _ browser , false ) & & shared prefs . get boolean ( mobilize _ on _ data _ only , true ) ; if ( ui extras ) { floating compose = false ; }
while ( idx < len & & pattern . char at ( idx ) = = ' | ' ) { idx + + ; branch = branch ( flags ) ; set next of end ( ret , branch ) ; }
assert . assert equals ( 5 , f . vec ( 2 ) . at8 ( 3 ) ) ; assert . assert equals ( 5 , f . vec ( 2 ) . na cnt ( ) ) ; assert . assert equals ( e , string . value of ( f . vec ( 3 ) . at str ( new buffered string ( ) , 3 ) ) ) ; assert . assert equals ( 5 , f . vec ( 3 ) . na cnt ( ) ) ; } finally {
no _ entry _ key = in . read float ( ) ;
prefix row tests ( new filter ) ;
get conf ( ) . set ( hbase . client . registry . impl , simple registry . class . get name ( ) ) ;
element section elem = tr . get parent element ( ) ;
int w = get line width ( long line ) ;
assert true ( test harness . get output ( ) . size ( ) > = 3 ) ; test harness . close ( ) ;
for ( int i = 0 ; i < delay ; i + = 1000 ) { if we see schema , we can proceed to the next check directly if ( schema . instance . get version ( ) . equals ( schema constants . empty version ) ) { logger . debug ( got schema : { } , schema . instance . get version ( ) ) ; break ; } uninterruptibles . sleep uninterruptibly ( 1 , time unit . seconds ) ; }
final kie session ksession = new kie helper ( property specific option . always ) . add content ( drl , resource type . drl ) . build ( ) . new kie session ( ) ; final list < string > list = new array list < string > ( ) ; ksession . set global ( list , list ) ; final person mario = new person ( mario , 40 ) ;
get as dom ( request ) ;
assert equals ( iva , iva . copy ( ) ) ;
handler . send empty message delayed ( message _ long _ click , 600 ) ;
writer . write ( 0 ) ; return debug item offset ;
if ( m hide am pm ) { m is touching am or pm = m am pm circles view . get is touching am or pm ( event x , event y ) ; } else { m is touching am or pm = - 1 ; }
return expression builder . exchange property expression ( remainder ) ;
save ( saved data ) ;
bitmap . compress ( bitmap . compress format . jpeg , 90 , new file output stream ( environment . get external storage directory ( ) + resulthooked . jpg ) ) ;
if ( v . is long clickable ( ) ) { on long click ( v ) ; } return ;
if ( previous = null ) { task vertices . put ( id , previous ) ; throw new illegal argument exception ( the job graph already contains a vertex with that id . ) ; } }
m editor . set padding ( 10 , 10 , 10 , 10 ) ;
list < ? extends variable tree > parameter tree = method tree . get parameters ( ) ; tree param type = parameter tree . get ( parameter tree . size ( ) - 1 ) . get type ( ) ; char sequence param type source = state . get source for node ( param type ) ; if ( param type source = = null ) { no fix if we don ' t have tree end positions . return describe match ( method tree ) ; } description . builder description builder = build description ( method tree ) ;
ai = new attributes impl ( multi ) ; assert equals ( 5 , ai . get length ( ) ) ;
content response response = client . get ( http : localhost : + port + context path + servlet mapping . substring ( 1 ) + ?action = create ) ;
final byte [ ] header = value buffer . read prefixed bytes ( ) ; agent stat header decoder header decoder = new bit counting header decoder ( header ) ; encoding strategy < integer > id encoding strategy = unsigned integer encoding strategy . get from code ( header decoder . get code ( ) ) ; encoding strategy < short > service type encoding strategy = unsigned short encoding strategy . get from code ( header decoder . get code ( ) ) ; encoding strategy < string > database name encoding strategy = string encoding strategy . get from code ( header decoder . get code ( ) ) ; encoding strategy < string > url encoding strategy = string encoding strategy . get from code ( header decoder . get code ( ) ) ; encoding strategy < integer > active connection size strategy = unsigned integer encoding strategy . get from code ( header decoder . get code ( ) ) ; encoding strategy < integer > max connection size strategy = unsigned integer encoding strategy . get from code ( header decoder . get code ( ) ) ; list < integer > ids = this . codec . decode values ( value buffer , id encoding strategy , num values ) ;
stack . peek ( ) . add child ( expr ) ;
string builder output = new string builder ( ) ;
if ( orb . transport debug flag ) { dprint ( . run : ignoring , t ) ; } } }
deploy wars ( app base , filtered app paths ) ;
account dao . remove email ( new account email model dao ( email ) , internal call context ) ;
if ( working ) { log . debug ( not adding history because of noop ) ; return ; } jmeter tree node root = ( jmeter tree node ) tree model . get root ( ) ;
mean + = ( value - mean ) ( index + 1 ) ;
try { thread . sleep ( 5 ) ; } catch ( exception e ) {
context . set object source ( utils . attach node ( context , ria node ) ) ;
sslengine result unwrap ;
configuration . set property ( hibernate . generate _ statistics , true ) ;
m _ executor pool . execute ( new task ) ;
return math . round ( current allocation * total cores ) + cores requested < = total cores ;
add mapper ( common collection mapper data , element component data , index component data ) ;
reset ( unmarshaller ) ; marshaller . set process external entities ( true ) ; marshaller . set support dtd ( true ) ; marshaller . unmarshal ( new saxsource ( new input source ( 1 ) ) ) ;
int temp length = length - 1 ; while ( text . char at ( temp length ) = ' ' ) { temp length - - ; if ( temp length < = 0 ) return length ; if we count all the way back to 0 then this line cannot be broken , just return the original break length } return temp length + 1 ; return the nicer break length which doesn ' t split a word up }
array list < rec record new > recs read = new array list < rec record new > ( ) ; for ( i = 0 ; i < recs write . size ( ) ; i + + ) { rec record new s2 rec = new rec record new ( ) ; s2 rec . deserialize ( in ) ; recs read . add ( s2 rec ) ; } istream . close ( ) ; tmpfile . delete ( ) ; tmp rtifile . delete ( ) ;
writer . dup ( ) ; def , def
boolean selected = pos = = m selected position ;
string base symbol = model . get currency pair code ( ) . substring ( 0 , 3 ) ; string counter symbol = model . get currency pair code ( ) . substring ( 3 , 6 ) ; currency pair currency pair = new currency pair ( base symbol , counter symbol ) ;
if ( interfaces . contains key ( interface type . get name ( ) ) ) { interfaces . put ( interface type . get name ( ) , interface type ) ; } } ) ) ; interfaces . values ( ) . for each ( builder : : with interface ) ; }
scanner . reseek ( rows _ three [ 1 ] ) ;
throw new conversion exception ( missing classpathentry @ path ) ; }
process builder process builder = new process builder ( ) . command ( command ) . directory ( root path . to file ( ) ) . redirect error stream ( true ) . inherit io ( ) ; process process = process builder . start ( ) ; log . info ( starting type script tests . . . ) ;
vminstance vo system vm = _ vm instance dao . find by id types ( id , virtual machine . type . console proxy , virtual machine . type . secondary storage vm ) ; if ( system vm = = null ) { invalid parameter value exception ex = new invalid parameter value exception ( unable to find a system vm with specified vm id ) ; ex . add proxy object ( system vm , id , vm id ) ; throw ex ; } try { if ( system vm . get type ( ) = = virtual machine . type . console proxy ) { return stop console proxy ( system vm , cmd . is forced ( ) ) ; } else if ( system vm . get type ( ) = = virtual machine . type . secondary storage vm ) { return stop secondary storage vm ( system vm , cmd . is forced ( ) ) ; } return null ; } catch ( operation timedout exception e ) { throw new cloud runtime exception ( unable to stop + system vm , e ) ; }
string raw path = get raw path ( request ) ; headers . put ( exchange . http _ method , request . get method ( ) ) ; headers . put ( exchange . http _ query , request . get query string ( ) ) ; headers . put ( exchange . http _ url , request . get request url ( ) . to string ( ) ) ; headers . put ( exchange . http _ uri , request . get request uri ( ) ) ; headers . put ( exchange . http _ path , raw path ) ;
p = pattern . compile ( [ \ \ u1234 - \ \ u2345 ] _ + [ a - z ] - + [ \ u0001 - \ \ x11 ] ) ; m = p . matcher ( \ u2000 _ q - \ u0007 ) ; assert true ( m . matches ( ) ) ; m = p . matcher ( \ u1234 _ z - \ u0001 ) ; assert true ( m . matches ( ) ) ; m = p . matcher ( r _ p - q ) ; assert false ( m . matches ( ) ) ; m = p . matcher ( \ u2345 _ _ _ _ _ d - - - - - \ n ) ; assert true ( m . matches ( ) ) ;
if ( ( flags & skip _ debug ) = = 0 & & ( source file = null | | source debug = null ) ) { class visitor . visit source ( source file , source debug ) ; }
string reply = context . get type converter ( ) . convert to ( string . class , payload . get body ( ) . get ( 0 ) ) ; assert not null ( reply ) ; assert true ( reply . contains ( < person id > 123 < person id ) ) ; assert true ( reply . contains ( < ssn > 456 < ssn ) ) ;
eg . get termination future ( ) . get ( 2000 , time unit . milliseconds ) ;
final value injection service < pool config > new default pool config service = new value injection service < pool config > ( ) ;
double x1 = dataset . get xvalue ( series , item ) ; double y1 = dataset . get yvalue ( series , item ) ; double x = x1 ; double y = double . is na n ( y1 ) ? get range base ( ) : y1 ; double trans x1 = domain axis . value to java2 d ( x , data area , plot . get domain axis edge ( ) ) ; double trans y1 = range axis . value to java2 d ( y , data area , plot . get range axis edge ( ) ) ;
case reg ops . get _ static :
if ( lr = = null ) { return false ; }
prefix = null ; default prefix
return extensions . get critical extensions ( ) ;
string drl1 = package org . drools . compiler . integrationtests \ n + import + message . class . get canonical name ( ) + \ n + global java . util . list list \ n + rule r1 when \ n + m : message ( message = = \ hello world \ ) \ n + then \ n + list . add ( \ ok \ ) ; \ n + end \ n ; string drl2 = package org . drools . compiler . integrationtests \ n + import + message . class . get canonical name ( ) + \ n + global java . util . list list \ n + rule r2 when \ n + m : message ( message = = \ hi universe \ ) \ n + then \ n + list . add ( \ ko \ ) ; \ n + end \ n ;
int num of services to stop = service list . size ( ) ;
threw = false ;
validate cluster properties ( stores , cluster - 3 ) ;
for ( final edge edge : edges ) { final boolean expected result = edge . is directed ( ) ; final pair < key , key > keys = converter . get keys from edge ( edge ) ; assert equals ( failed for edge : + edge . to string ( ) , expected result , filter . accept ( keys . get first ( ) , value ) ) ; if ( null = keys . get second ( ) ) { self edges are not added the other way round assert equals ( failed for edge : + edge . to string ( ) , expected result , filter . accept ( keys . get second ( ) , value ) ) ; } } }
record property name ( proto prop . get first child ( ) . get last child ( ) ) ; return true ;
extension ext = extensions . get extension by oid ( oid ) ; return ( ext = = null ) ? null : ext . get raw extn value ( ) ; }
throw kit . init cause ( new illegal state exception ( ) , ex ) ;
throw new data mapper exception ( student [ + student to be updated . get name ( ) + ] is not found ) ; }
_ state = state . dispatched ; _ async = async . not _ async ; return action . error _ dispatch ; case errored :
string parent controller package as path = parent package of controller . replace all ( \ \ . , ) ;
boolean goon = core validity ;
insets insets = tab pane . get insets ( ) ;
if ( round env . processing over ( ) & & config manager . disable kotlin extension generation ( ) ) { kotlin extension writer . generate extensions for models ( generated models ) ; } if ( controller processor . has controllers to generate ( ) & & ( are models waiting to write ( ) | | round env . processing over ( ) ) ) { this must be done after all generated model info is collected so we must wait until databinding is resolved . however , if there was an error with the databinding resolution we can at least try to finish writing the controllers before processing ends controller processor . resolve generated models and write java ( generated models ) ; }
view divider = adapter . on create view holder ( this , all apps grid adapter . view _ type _ search _ market _ divider ) . m content ;
assert that ( network . edges connecting ( n2 , n1 ) ) . is empty ( ) ; }
prepare listeners ( post _ commit _ delete , listener array ) ;
remote connection info remote connection info = assert serialization ( get remote connection info ( connection ) ) ; assert not null ( remote connection info ) ; assert equals ( 0 , remote connection info . num nodes connected ) ; assert equals ( 0 , remote connection info . seed nodes . size ( ) ) ; assert equals ( 0 , remote connection info . http addresses . size ( ) ) ; assert equals ( max num connections , remote connection info . connections per cluster ) ; assert equals ( test - cluster , remote connection info . cluster alias ) ; update seed nodes ( connection , seed nodes ) ; expect throws ( remote transport exception . class , ( ) - > get remote connection info ( connection ) ) ; for ( mock transport service s : arrays . as list ( transport1 , transport2 , transport3 ) ) { install node stats handler ( s , node1 , node2 , node3 ) ; }
execute ( alter table % s with compaction = { ' class ' : ' size tiered compaction strategy ' , ' min _ threshold ' : 3 } ) ;
assert . assert equals ( 1 , task . get fire department metrics ( ) . processed ( ) ) ; assert . assert equals ( 0 , task . get fire department metrics ( ) . unparseable ( ) ) ; assert . assert equals ( 4 , task . get fire department metrics ( ) . thrown away ( ) ) ;
assert equals ( range . closed ( 6 , 8 ) , range . intersection ( range . closed ( 6 , 8 ) ) ) ;
return new collection admin request . async collection admin request ( collection params . collection action . replacenode ) { @ override public solr params get params ( ) { modifiable solr params params = ( modifiable solr params ) super . get params ( ) ; params . set ( source , source node ) ; params . set ( target , target node ) ; if ( parallel = null ) params . set ( parallel , parallel . to string ( ) ) ; return params ; } } ;
if ( signum > = 0 ) { norm bit len | = ( 1 < < 31 ) ; } for ( int i = 0 ; i < 4 & & len > 0 ; i + + , len - - ) { final byte b = ( byte ) ( norm bit len > > > ( 8 * ( 3 - i ) ) ) ; target . put ( offset + + , b ) ; }
locale en _ us = locale . us ; assert equals ( [ m , d , y ] , arrays . to string ( icu . get date format order ( best ( en _ us , yyyy - m - dd ) ) ) ) ; assert equals ( [ m , d , y ] , arrays . to string ( icu . get date format order ( best ( en _ us , yyyy - mmm - dd ) ) ) ) ; assert equals ( [ m , d , \ u0000 ] , arrays . to string ( icu . get date format order ( best ( en _ us , mmm - dd ) ) ) ) ; locale en _ gb = locale . uk ; assert equals ( [ d , m , y ] , arrays . to string ( icu . get date format order ( best ( en _ gb , yyyy - m - dd ) ) ) ) ; assert equals ( [ d , m , y ] , arrays . to string ( icu . get date format order ( best ( en _ gb , yyyy - mmm - dd ) ) ) ) ; assert equals ( [ d , m , \ u0000 ] , arrays . to string ( icu . get date format order ( best ( en _ gb , mmm - dd ) ) ) ) ; assert equals ( [ y , m , d ] , arrays . to string ( icu . get date format order ( yyyy - ' why ' ' ' ' ddd ' mmm - dd ) ) ) ;
filter output stream . write ( get bytes ( i am compiling \ n ) ) ; assert that ( output . to string ( ) ) . is equal to ( i am compiling \ n ) ; }
try { final byte [ ] b4 = new byte [ 4 ] ; int count = 0 ; int single byte read ; while ( count < 4 ) { single byte read = stream . read ( ) ; if ( single byte read = = - 1 ) { break ; } b4 [ count ] = ( byte ) single byte read ; count + + ; } return parse bom ( b4 , count ) ; } catch ( ioexception ioe ) { failed . return new bom result ( utf - 8 , 0 ) ; }
fold same ( while ( foo ( ) , 0 ) boo ( ) ) ; fold same ( var a = ( foo ( ) , 0 ) ; ) ; fold same ( a = ( foo ( ) , 0 ) ; ) ;
conf . get ( dummy . key ) ;
if ( args [ i ] = = null ) { continue ; } if ( args [ i ] . get class ( ) . is array ( ) ) {
view group main = get main section ( ) ;
pages tree . select ( pages tree . get item ( 0 ) ) ;
d . put ( popup menu . content margins , new insets uiresource ( 6 , 1 , 6 , 1 ) ) ;
bld . append literal ( ' - ' ) ;
controller . update widget status ( result . get actions ( ) ) ; } else { update job timer . cancel ( ) ; presenter . unlock submit ( ) ; logger . info ( executed actions is null ) ; return ; }
for ( kv < ? extends unbounded source < output t , checkpoint mark t > , checkpoint mark t > restored : state for checkpoint . get ( ) ) { local split sources . add ( restored . get key ( ) ) ; local readers . add ( restored . get key ( ) . create reader ( serialized options . get ( ) , restored . get value ( ) ) ) ; }
s . persist ( new user ( john , test ) ) ; t . commit ( ) ; fail ( transaction should have timed out ) ; }
string xml version = get xmlversion ( node arg ) ;
{ error msg . stray _ otherwise _ err , < xsl : otherwise > mo \ u017eno pou \ u017ei \ u0165 len v < xsl : choose > . } ,
global shortcut config form global binding panel = new global shortcut config form ( ) ; chooser panes . add tab ( keybinding chooser activator . get resources ( ) . get i18 nstring ( plugin . keybindings . global ) , global binding panel ) ; for ( keybinding set . category category : keybinding set . category . values ( ) ) { keybinding set binding set = service . get bindings ( category ) ; if ( binding set = = null ) continue ; defaults failed to load sipchooser new chooser = new sipchooser ( ) ; new chooser . put all bindings ( binding set ) ; jpanel chooser wrapper = new transparent panel ( new border layout ( ) ) ; chooser wrapper . add ( new chooser , border layout . north ) ; jscroll pane scroller = new jscroll pane ( chooser wrapper ) ; adds listener that receives events to set bindings this . add key listener ( new chooser . make adaptor ( ) ) ; chooser panes . add tab ( keybinding chooser activator . get resources ( ) . get i18 nstring ( plugin . keybindings . + category . to string ( ) ) , scroller ) ; this . choosers . put ( binding set , new chooser ) ; }
ensure open ( ) ;
if ( config . get endpoint properties ( ) = null & & config . get endpoint properties ( ) . is empty ( ) ) { map . put all ( config . get endpoint properties ( ) ) ; } string query = urisupport . create query string ( map ) ;
row . nullify link ( column info . column object index ) ; return ; } proxy state . check valid object ( value ) ; row . get table ( ) . set link ( column info . column object index , row . get index ( ) , ( ( realm object proxy ) value ) . realm get proxy state ( ) . get row realm ( ) . get index ( ) , true ) ; return ; }
string filename = cluster . get federated test directory for ns ( ns0 ) + testrename ;
if ( meta data . has index ( index . get name ( ) ) ) { throw new illegal state exception ( index + exists in routing does not exists in metadata ) ; }
ipackage fragment pack1 = f source folder . create package fragment ( test1 , false , null ) ; string buffer buf = new string buffer ( ) ; buf . append ( package test1 ; \ n ) ; buf . append ( public class e { \ n ) ; buf . append ( public void foo ( int i ) { \ n ) ; buf . append ( if ( i = = 0 ) \ n ) ; buf . append ( system . get properties ( ) ; \ n ) ; buf . append ( } \ n ) ; buf . append ( } \ n ) ; icompilation unit cu = pack1 . create compilation unit ( e . java , buf . to string ( ) , false , null ) ; int offset = buf . to string ( ) . index of ( system . get properties ( ) ) ; assist context context = get correction context ( cu , offset , 0 ) ;
ksession . insert ( new cheese ( cheddar , 42 ) ) ;
attribute html attribute _ html = new attribute html ( dir , class _ name , constant _ pool , constant _ html ) ; method html method _ html = new method html ( dir , class _ name , methods , java _ class . get fields ( ) , constant _ html , attribute _ html ) ;
string reader reader = new string reader ( string ) ;
file _ status _ color _ map . put ( all file status , color key . create color key ( mt _ + all file status . get id ( ) , color ) ) ;
string subsystem xml = get subsystem xml ( ) ; kernel services services a = this . create kernel services builder ( ) . set subsystem xml ( subsystem xml ) . build ( ) ; model node add op = get cache add operation ( maximal , local cache resource definition . wildcard _ path . get key ( ) , fred ) ;
assertion error error = new assertion error ( false deadlock failure rate of + failure rate + is greater than 2 % ) ;
volt table partition _ table = create partitioned table ( num _ partitioned _ items , 0 ) ; load table ( client , replicated _ tester , true , repl _ table ) ; load table ( client , partition _ tester , false , partition _ table ) ; save tables with default options ( client , testnonce ) ;
get list view ( ) . set choice mode ( list view . choice _ mode _ single ) ;
load balancer simulator . run wait ( degrader load balancer strategy config . default _ update _ interval _ ms * 2 ) ; print states ( load balancer simulator ) ;
if ( has attribute ( new attribute . get name ( ) ) ) { final attribute attr = get attribute ( new attribute . get name ( ) ) ; attr . set value ( new attribute . get value ( ) ) ; return this ; }
file meta = new file ( meta path ) ;
if ( mimes . contains key ( matched mime type ) ) { return mimes . get ( matched mime type ) ; } return matched mime type ;
remote echo remote business interface = ( remote echo ) ctx . lookup ( java _ global _ namespace _ prefix + app _ name + + module _ name + + ejb name + + remote echo . class . get name ( ) ) ;
header buffer . put int ( cmd . get opaque ( ) ) ;
assert equals ( dim = publish date path = [ ] value = 2 child count = 2 \ n 2010 ( 1 ) \ n 2012 ( 1 ) \ n , r . facets . get top children ( 10 , publish date ) . to string ( ) ) ;
int ts length = graph . get input ( input vertex index ) . size ( 2 ) ; int [ ] out shape = new int [ ] { inputs [ 0 ] . size ( 0 ) , inputs [ 0 ] . size ( 1 ) , ts length } ; indarray out = nd4j . create ( out shape ) ; for ( int i = 0 ; i < ts length ; i + + ) { out . put ( new indarray index [ ] { ndarray index . all ( ) , ndarray index . all ( ) , ndarray index . point ( i ) } , inputs [ 0 ] ) ; } return out ; }
insert user ( user . get id ( ) , user . get user name ( ) , date converter . to timestamp ( user . get date ( ) ) , db ) ;
stamp = in . read long ( ) ;
position ms = window duration ms ;
processor = multi pass . processor ( check stage . stage2 _ rs _ labels , labels ) ;
return ( next token ( ) = = json token . value _ number _ int ) ? get int value ( ) : default value ;
try { type factory . resolve session factory ( ) ; fail ( should have failed with hibernate exception because session factories were not registered with the same non - null name . ) ; } catch ( hibernate exception ex ) { expected } factory . close ( ) ;
shutdown timer ( ) ;
new android binary install graph enhancer ( android install config , project filesystem , build target , android binary ) . enhance ( resolver ) ; return android binary ;
itool chain toolchain = ( itool chain ) get parent ( ) ;
tstream . reset ( ) ;
if ( view = null ) { view . set splash screen loading completion ( 0 . 0 ) ; }
non java resources . add ( member ) ;
this . heuristic network cost - = other . heuristic network cost ;
typed query < e > q = em . create query ( query ) ;
string table name = prop . get value ( ) . get table ( ) . get name ( ) ;
if ( return only stored & & sf = null & & sf . stored ( ) ) { continue ; } xlfield xl field = new xlfield ( ) ; xl field . name = field ; xl field . sf = sf ; xl fields . put ( field , xl field ) ; }
float scale x = get scale x ( ) ;
apple . load new version ( 002 , retrieve rename ( data . apple , data . apple002 ) ) ; result result = run unguarded ( caller clazz , call apple ret long , new object [ ] { 5 l } ) ; assert equals ( 10 l , result . return value ) ; }
assert equals ( - 1 , run tool ( - transition to active ) ) ;
if ( ( b _ continue _ stemming _ noun _ suffixes ) ) { return false ; }
admin client . realms ( ) . realm ( realm _ name ) . attack detection ( ) . clear all brute force ( ) ; assert statistics ( after brute force cleared , 0 , 0 , 0 ) ;
index . consistency check ( ) ;
dfs . rolling upgrade ( rolling upgrade action . prepare ) ; query for preparation ( dfs ) ; dfs . set safe mode ( safe mode action . safemode _ enter ) ; dfs . save namespace ( ) ; dfs . set safe mode ( safe mode action . safemode _ leave ) ; cluster . restart name nodes ( ) ; dfs . rolling upgrade ( rolling upgrade action . query ) ; } finally {
text = new text view ( ctx ) ; utils . set alpha ( text , 0 . 54f ) ; text . set text size ( typed value . complex _ unit _ sp , 14 ) ; text . set gravity ( gravity . start ) ; linear layout . layout params params text = new linear layout . layout params ( linear layout . layout params . match _ parent , linear layout . layout params . wrap _ content ) ; params text . set margins ( ( int ) ( 16 * density ) , 0 , ( int ) ( 16 * density ) , ( int ) ( 4 * density ) ) ; layout . add view ( text , params text ) ; this . view = layout ;
card view cab = ( card view native ) get activity ( ) . find view by id ( r . id . carddemo _ example _ card _ cab ) ; card view cab . set card ( m card cab ) ; }
roster packet . item item = new roster packet . item ( jid , item name ) ;
assert equals ( 2 l , task service . create task query ( ) . count ( ) ) ; list < task > task list = task service . create task query ( ) . order by task name ( ) . desc ( ) . list ( ) ; assert equals ( first task , task list . get ( 0 ) . get name ( ) ) ; assert equals ( escalation task 1 , task list . get ( 1 ) . get name ( ) ) ;
bits . clear ( 0 ) ;
batch task . log and throw exception ( ex , this ) ;
str . get chars ( off , off + space , buf , pos ) ; sink . write ( buf , 0 , buf . length ) ; str . get chars ( off + space , off + len , buf , 0 ) ; pos = len - space ; } else {
uri repo uri = new uri ( repo str ) ;
default folders . add ( file utils . folder from dir ( download dir ) ) ;
random access file raf = new random access file ( s lock pattern filename , rw ) ;
attribute converter manager . add attribute converter ( annotated class ) ;
map difference < byte buffer , dropped column > dropped column diff = maps . difference ( old view . metadata . dropped columns , old view . metadata . dropped columns ) ;
int limit = math . min ( _ dsrm . get num replies ( ) , single lookup job . max _ to _ follow ) ;
request < string > req = builders . < string > action ( null promise ) . build ( ) ; get client ( ) . send request ( req ) . get response ( ) ; }
m _ manager . add breakpoints ( breakpoint type . echo , common test objects . bp _ address _ 123 _ set ) ; assert equals ( 0 , listener . size ( ) ) ;
return remaining . to array ( new task attempt id [ remaining . size ( ) ] ) ; } input stream is = input ; is = crypto utils . wrap if necessary ( job conf , is , compressed length ) ; compressed length - = crypto utils . crypto padding ( job conf ) ; decompressed length - = crypto utils . crypto padding ( job conf ) ;
main presentation part pp = ( main presentation part ) presentation mlpackage . get parts ( ) . get parts ( ) . get ( new part name ( ppt presentation . xml ) ) ; styles . add all ( text styles . generate word styles from presentation part ( pp . get jaxb element ( ) . get default text style ( ) , , font scheme ) ) ;
vice president vp sales = new vice president ( ) ;
default camel context . set context counter ( 0 ) ;
file marker = new file ( deploy dir . get absolute path ( ) + file . separator + simple servlet . war . deployed ) ; assert true ( marker . exists ( ) ) ; string response = http request . get ( get base url ( url ) + simple servlet simple servlet , 10 , time unit . seconds ) ;
object referenced object = get checked ref ( data type . class , data type . class . get name ( ) ) ; if ( referenced object instanceof path ) { path path = ( path ) referenced object ;
user group information current user = user group information . get current user ( ) ; user group information . create user for testing ( current user . get user name ( ) , current user . get group names ( ) ) ; test user1 = user group information . create user for testing ( foo , new string [ ] { bar , baz } ) ; test user2 = user group information . create user for testing ( fiz , new string [ ] { buz , boz } ) ; }
meta = new htable ( conf , htable descriptor . meta _ tabledesc . get name ( ) ) ; hregion info hri = location . get region info ( ) ; hregion info a = new hregion info ( tbl . get table name ( ) , bytes . to bytes ( b ) , bytes . to bytes ( bm ) ) ;
verify ( ael , never ( ) ) . match cancelled ( any ( match cancelled event . class ) ) ; }
map < string , string > aliases = new hash map < string , string > ( ) ; map < string , string > implementations = new hash map < string , string > ( ) ; for ( entry < object , object > entry : provider . entry set ( ) ) { object k = entry . get key ( ) ; object v = entry . get value ( ) ; assert equals ( string . class , k . get class ( ) ) ; assert equals ( string . class , v . get class ( ) ) ; string key = ( string ) k ; string value = ( string ) v ;
delete delete = new delete ( row ) ; delete . add columns ( fam , split a ) ; region . delete ( delete ) ;
synchronized ( mutex for stage instance ( job identifier ) ) { synchronized ( mutex for job ( job identifier ) ) { job instance job instance = job instance service . build by id with transitions ( job identifier . get build id ( ) ) ; if ( job instance . is null ( ) | | job instance . get result ( ) = = job result . cancelled | | job instance . get state ( ) = = job state . rescheduled ) { return ; }
stream = stream . filter ( e - > { final view element definition ved = view . get element ( e . get group ( ) ) ; return ved . get pre aggregation filter ( ) = = null | | ved . get pre aggregation filter ( ) . test ( e ) ; } ) ;
sample rate = 2 ;
pending nodes . remove ( node ) ;
result meth = optimize minimize registers ( rmeth , param width , is static , steps ) ; }
final text view high score = ( text view ) find view by id ( r . id . high _ score _ text ) ;
pending executions . add ( portal ) ;
path corp = testdir . get path file ( corp ) ;
buffer . append ( limit ) ;
run test ( webtest bar , bar , webtest , false , false , true ) ;
slice _ from ( lus ) ; break ; case 27 :
builder . append formal line ( string . format ( assert . not null ( % s , % s ) ; , parameter name , get iterable to add cant be null constant ( ) . get field name ( ) ) ) ;
current counters = new counters ( ) ;
new thread ( new runnable ( ) { @ override public void run ( ) { user storage . register on tray preference change listener ( listener ) ; register latch . count down ( ) ; } } ) . start ( ) ; }
int width = ( m width = = - 1 ) ? rect . width ( ) : m width ; int height = ( m height = = - 1 ) ? rect . height ( ) : m height ; relative layout . layout params layout params = new relative layout . layout params ( width , height ) ;
if ( require response ) { throw ioe ; }
hystrix collapser . reset ( ) ;
list < string > members = new array list < string > ( ) ; members . add ( member1 ) ; members . add ( member2 ) ; latched procedure proc = new latched procedure ( coord , new foreign exception dispatcher ( ) , 100 , integer . max _ value , op , null , members ) ; final latched procedure procspy = spy ( proc ) ;
ocommand sql updatecommand = new ocommand sql ( update person set gender = ' female ' where name = ' raf ' ) ; database . command ( updatecommand ) . execute ( raf ) ; check updated doc ( database , raf , torino , female ) ; updatecommand = new ocommand sql ( update person set city = ' turin ' where name = ? ) ; database . command ( updatecommand ) . execute ( raf ) ; check updated doc ( database , raf , turin , female ) ;
i + + ; } else { string builder builder = new string builder ( len ) . append ( sequence , 0 , i ) . append ( replacement ) ; return finish collapse from ( sequence , i + 1 , len , replacement , builder , true ) ; } } }
do test header limits ( 1 , 32 * 1024 , failure mode . connection _ reset ) ; }
count down latch latch1 = new count down latch ( 1 ) ;
if ( is input = = null | | is input ) { logger . warn ( attempted to change io + io nr + to + ( new state ? on : off ) + but its direction is + ( is input = = null ? unknown : input ) ) ; return ; better not send anything if direction is not ' out ' }
try { conn = null ; conn = get connection ( mini hs2 . get jdbc url ( test db name ) , user name , password ) ; } catch ( exception e ) { fail ( not expecting exception : + e ) ; } finally { if ( conn = null ) { conn . close ( ) ; } }
else { log ( out , file drop : drag and drop is not supported with this jvm ) ;
for ( wrapper wrapper : active wrappers . values ( ) ) { wrapper . decoder . init ( config ) ; } }
list < odocument > results = db . query ( new osqlsynch query < odocument > ( select from test multiple clusters where name like : p1 + ' % ' ) , fo ) ; assert equals ( results . size ( ) , 1 ) ; results = db . query ( new osqlsynch query < odocument > ( select from test multiple clusters where name like : p1 ) , fo ) ; assert equals ( results . size ( ) , 0 ) ; }
update response update response = client . update ( request ) ; assert equals ( update response . get result ( ) , doc write response . result . updated ) ; map < string , object > source as map = update response . get get result ( ) . source as map ( ) ; assert equals ( 2 , source as map . size ( ) ) ; assert equals ( source excludes , source as map . get ( reason ) ) ; assert true ( source as map . contains key ( field ) ) ; } { update request request = new update request ( posts , doc , id ) ;
if ( generator factory . get produced generators count ( ) < session count limit ) { sub generator lists . set ( index , generator factory . new session generator for key ( random generator . choose random element ( session keys ) , get watermark ( ) ) ) ; } else {
if ( str = = null | | str . length ( ) = = 0 ) { throw new illegal argument exception ( cannot take the null string . ) ; } return str ; }
test _ util . get configuration ( ) . set int ( hconstants . thread _ wake _ frequency , 2 * 1000 ) ;
if ( existing plugin . get name ( ) . equals ( plugin . get name ( ) ) ) { if ( existing plugin . get status ( ) . compare to ( plugin . get status ( ) ) > 0 ) { log . info ( ignoring ( apparently ) less stable scanner version , id = + plugin . get id ( ) + , existing plugin [ status = + existing plugin . get status ( ) + , class = + existing plugin . get class ( ) . get canonical name ( ) + ] , less stable plugin [ status = + plugin . get status ( ) + , class = + plugin . get class ( ) . get canonical name ( ) + ] ) ; return false ; } if ( existing plugin . get status ( ) = plugin . get status ( ) ) { log . info ( replacing existing scanner with ( apparently ) stabler version , id = + plugin . get id ( ) + , existing plugin [ status = + existing plugin . get status ( ) + , class = + existing plugin . get class ( ) . get canonical name ( ) + ] , stabler plugin [ status = + plugin . get status ( ) + , class = + plugin . get class ( ) . get canonical name ( ) + ] ) ; return true ; } } log . error ( duplicate id + plugin . get id ( ) + + plugin . get class ( ) . get canonical name ( ) + + existing plugin . get class ( ) . get canonical name ( ) ) ;
for ( group representation group : realm . groups ( ) . groups ( ) ) { group resource resource = realm . groups ( ) . group ( group . get id ( ) ) ; resource . remove ( ) ; assert admin events . assert event ( test , operation type . delete , admin event paths . group path ( group . get id ( ) ) , resource type . group ) ; }
stat stat = zoo keeper . exists ( this . fully qualified znode , false ) ;
if ( current < limit ) { id = ( 00000000 + id ) . substring ( id . length ( ) ) ; } return id ;
assert true ( b . get ( 32 ) ) ; assert true ( b . get ( 255 ) ) ; assert true ( b . get ( 256 ) ) ; assert true ( b . get ( 1000000 ) ) ; }
name text . subscribe ( widget - > { if ( address text . get text ( ) . is empty ( ) ) { address text . set text ( name text . get text ( ) ) ; address text . set cursor position ( address text . get text ( ) . length ( ) ) ; } get manager ( ) . set focus ( address text ) ; } ) ;
if ( context service = = null ) { throw new null pointer exception ( context service ) ; }
session s = open session ( ) ; s . begin transaction ( ) ; versioned entity c = new versioned entity ( c1 , child - 1 ) ; versioned entity p = new versioned entity ( root , root ) ; p . get children ( ) . add ( c ) ; c . set parent ( p ) ; s . save ( p ) ; s . get transaction ( ) . commit ( ) ; s . close ( ) ; clear counts ( ) ;
if ( latest version . matches ( realm _ version _ pattern ) ) { result = latest version ; } rd . close ( ) ; } catch ( ioexception e ) {
widget config startup monitor monitor = new widget config startup monitor ( ) ; ui object2 widget = scroll and find ( widget container , by . clazz ( widget cell . class ) . has descendant ( by . text ( m widget info . get label ( m target context . get package manager ( ) ) ) ) ) ; drag to workspace ( widget , false ) ;
tuple ds . sort partition ( 3 , order . ascending ) ; }
public boolean use in office ( ) { return true ;
workspace . replace file contents ( native cxx lib . cpp , return 3 , return 4 ) ; workspace . reset build log file ( ) ; workspace . run buck build ( dex _ exopackage _ target ) . assert success ( ) ;
synchronized states manager ssm2 = new synchronized states manager ( m _ messengers . get ( site ) . get zk ( ) , state machine manager root , ssm2 , site string , state machines . values ( ) . length ) ; m _ state machine group2 [ site ] = ssm2 ; boolean state machine bsm2 = g2 boolean broken ? new broken boolean state machine ( ssm2 , bool ) : new boolean state machine ( ssm2 , bool ) ; m _ boolean state machines for group2 [ site ] = bsm2 ; byte state machine msm2 = g2 byte broken ? new broken byte state machine ( ssm2 , byte ) : new byte state machine ( ssm2 , byte ) ; m _ byte state machines for group2 [ site ] = msm2 ; }
coverage = coverage factory finder . get grid coverage factory ( hints ) . create ( coverage . get name ( ) , coverage . get rendered image ( ) , final gg , coverage . get sample dimensions ( ) , new grid coverage [ ] { coverage } , coverage . get properties ( ) ) ; }
facets facets = new fast taxonomy facet counts ( taxo reader , config , fc ) ; facet result result = facets . get top children ( 10 , author ) ; index reader . close ( ) ;
master key to use = this . previous master key ;
int ourslot = append node ( w0 , w1 , w2 , w3 ) ;
byte buffer buffer = buffer util . allocate ( 1024 ) ;
if ( namespace = namespace . for uri ( reader . get namespace uri ( ) ) ) throw unexpected element ( reader ) ; final element element = element . for name ( reader . get local name ( ) ) ; if ( encountered . add ( element ) ) { throw duplicate named element ( reader , element . get local name ( ) ) ; }
assert function ( cast ( json ' { \ 1 \ : true , \ 2 \ : false , \ 3 \ : 12 , \ 5 \ : 12 . 7 , \ 8 \ : \ 12 \ , \ 13 \ : null } ' as map < bigint , tinyint > ) , map type ( bigint , tinyint ) , as map ( immutable list . of ( 1 l , 2 l , 3 l , 5 l , 8 l , 13 l ) , as list ( ( byte ) 1 , ( byte ) 0 , ( byte ) 12 , ( byte ) 13 , ( byte ) 12 , null ) ) ) ;
current = new child ( parent , uri , local name , parent . depth + 1 , hash ) ; children [ index ] = current ; return current ; } else {
byte utils . write unsigned int le ( out , compressed length | compress method ) ; out . write ( buffer to write , 0 , compressed length ) ;
return tasks ;
try { field m assets = resources . class . get declared field ( m assets ) ; m assets . set accessible ( true ) ; m assets . set ( resources , new asset manager ) ; } catch ( throwable ignore ) { field m resources impl = resources . class . get declared field ( m resources impl ) ; m resources impl . set accessible ( true ) ; object resource impl = m resources impl . get ( resources ) ; field impl assets = resource impl . get class ( ) . get declared field ( m assets ) ; impl assets . set accessible ( true ) ; impl assets . set ( resource impl , new asset manager ) ; }
assert that ( option filters . option metadata tag . values ( ) ) . has length ( option metadata tag . values ( ) . length + 1 ) ;
for ( int i = 0 ; i < input . length ; i + + ) { assert equals ( 0 , double . compare ( expected output [ i ] , input [ i ] ) ) ; }
filter = filter factory . get all filter ( ) . get ( i ) ; try { if ( filter . is enabled ( ) ) { filter . on http request send ( http message ) ; } } catch ( exception e ) {
jsonarray a1 = new jsonarray ( java . lang . annotation . retention policy . values ( ) ) ; assert equals ( [ \ source \ , \ class \ , \ runtime \ ] , a1 . to string ( ) ) ;
final string foo1 = foos foo1 ; final string foo2 = foos foo2 ; final set < string > paths = immutable set . of ( foo1 , foo2 ) ; for ( final string path : paths ) { ensure ( path , new data pojo ( path ) ) ; }
this . num threads = props . get int ( executor _ flow _ threads , default _ num _ executing _ flows ) ;
item1 . get colors ( ) . clear ( ) ; item1 . get category ( ) . set example item ( item1 _ 1 ) ; s = open session ( ) ;
assert instance of ( e , illegal argument exception . class ) ;
remove attribute at ( f current - - ) ;
return ch ;
database service . get instance ( ) . create configuration database ( get resources ( ) ) ; m adapter = new flexible adapter < > ( database service . get instance ( ) . get database list ( ) , get activity ( ) , false ) ; } else {
create offer view . set close handler ( ( ) - > tab pane . get tabs ( ) . remove ( create offer tab ) ) ;
for ( int i = listeners . length - 2 ; i > = 0 ; i - = 2 ) { if ( listeners [ i ] = = action listener . class ) { ( ( action listener ) listeners [ i + 1 ] ) . action performed ( e ) ; } } }
jdbc test helper . insert session ( 1234 , , 0 . 0 . 0 . 0 ) ;
string empty string = hadoop store builder utils . read file contents ( fs , test path , 1024 ) ;
object [ ] array2 = set . to array ( ) ; assert equals ( num - 10 , array2 . length ) ; for ( int i = 0 ; i < array2 . length ; i + + ) { assert true ( sub2 . contains ( array2 [ i ] ) ) ; }
if ( text color = 0x000 ) { text . set text color ( text color ) ; }
final porter duff color filter color filter = new porter duff color filter ( m inactive color , porter duff . mode . src _ in ) ;
encoded arrays . remove ( 0 ) ;
insert ( id , fields , get property insertability ( ) , j , get sqlinsert strings ( ) [ j ] , object , session ) ; } }
esc set . escape = escape state . global ;
long actual = get coverage size ( coverage . get grid geometry ( ) . get grid range2 d ( ) , coverage . get rendered image ( ) . get sample model ( ) ) ; if ( actual > limit ) { throw new wcs exception ( this request is trying to read too much data , + the limit is + format bytes ( limit ) + but the actual amount of + bytes to be read is + format bytes ( actual ) ) ; } }
if ( this . mystrom client . change state ( device id , on off ) ) {
file tmp file = new file ( kc adm exec . work _ dir + + uuid . random uuid ( ) . to string ( ) + . tmp ) ;
empty statement . ignore ( ignored ) ;
for ( int k = 0 ; k < retries _ before _ lock ; + + k ) { int mcsum = 0 ; for ( int i = 0 ; i < segments . length ; + + i ) { mcsum + = mc [ i ] = segments [ i ] . mod count ; if ( segments [ i ] . contains value ( value ) ) { return true ; } } boolean clean sweep = true ; if ( mcsum = 0 ) { for ( int i = 0 ; i < segments . length ; + + i ) { if ( mc [ i ] = segments [ i ] . mod count ) { clean sweep = false ; break ; } } } if ( clean sweep ) { return false ; } }
map < string , string > m = splitter . on ( , ) . with key value separator ( : ^ & ) . split ( boy : ^ & tom , girl : ^ & tina , cat : ^ & kitty , dog : ^ & tommy ) ; immutable map < string , string > expected = immutable map . of ( boy , tom , girl , tina , cat , kitty , dog , tommy ) ; assert that ( m ) . is equal to ( expected ) ; assert that ( m . entry set ( ) ) . contains exactly elements in ( expected . entry set ( ) ) . in order ( ) ; }
http response response = client . execute ( post ) ;
thrown . expect ( hazelcast exception . class ) ; client cache manager . get cache ( any - cache ) ; }
execution manager . cancel ( execution id ) ;
throw new exception ( file not readable : + conf file . get absolute path ( ) ) ;
new channel connector builder ( name ) . build ( target ) . install ( ) ;
boolean is _ authorized = auth . check response ( ) ; rand = pick rand bytes ( ) ;
int buffer index = sync state . buffer ( 4096 ) ; byte [ ] buffer = sync state . data ; int bytes = in . read ( buffer , buffer index , 4096 ) ; sync state . wrote ( bytes ) ;
create new file ( new _ xml _ file , test project explorer context menu constants . sub menu new . xml _ file , . xml ) ;
if ( m header position = header position ) { 244 - don ' t animate if header is already visible at the first layout position int first visible item position = m adapter . get flexible layout manager ( ) . find first visible item position ( ) ; animate if headers were hidden , but don ' t if configuration changed ( rotation ) if ( display with animation & & m header position = = recycler view . no _ position & & header position = first visible item position ) { display with animation = false ; m sticky holder layout . set alpha ( 0 ) ; m sticky holder layout . animate ( ) . alpha ( 1 ) . start ( ) ; } else { m sticky holder layout . set alpha ( 1 ) ; } int old header position = m header position ; m header position = header position ; flexible view holder holder = get header view holder ( header position ) ; log . d ( swap header new header position = % s , m header position ) ; swap header ( holder , old header position ) ; } else if ( update header content ) { 299 - class cast exception after click on expanded sticky header when auto collapse is enabled m sticky header view holder = get header view holder ( header position ) ; m sticky header view holder . set backup position ( header position ) ; m adapter . on bind view holder ( m sticky header view holder , header position ) ; ensure header parent ( ) ; }
map < node id , resource option > node resource map = new hash map < node id , resource option > ( ) ; node resource map . put ( nm1 . get node id ( ) , resource option . new instance ( resource . new instance ( 2 * gb , 1 ) , - 1 ) ) ; update node resource request request = update node resource request . new instance ( node resource map ) ; rm . get admin service ( ) . update node resource ( request ) ; wait count = 0 ;
list < abstract plan node > frags = compile to fragments ( select p _ d1 from p order by p _ d3 desc , p _ d2 ) ;
byte [ ] codewords = parser . read codewords ( ) ;
file old preferences = new file ( dir , preferences . old ) ;
source data state . map2 . entry set ( ) . for each ( entry - > blackhole . consume ( map . put ( entry . get key ( ) , entry . get value ( ) ) ) ) ;
json parser mp = merged . as parser ( ctxt , p ) ;
byte read bytes [ ] = new byte [ ( int ) stream . get size ( ) ] ;
final int current index = play queue . get index ( ) ; final play queue item current item = play queue . get item ( current index ) ; if ( current item = = null ) return ; load item ( current item ) ;
applet stub stub = null ;
file segment dir = new file ( temp data dir , segment dir ) ;
return repository id . get class from type ( expected type , codebase url ) ;
value > > = 64 - ( required bytes * 8 ) ;
list < page element > pages = new array list < > ( page ids . size ( ) ) ; for ( string page id : page ids ) { page template page = template registry . get component ( page id ) ; if ( page = = null ) query . errors ( ) . add ( error message . create invalid query parameter ( could not resolve requested page template ' + page id + ' ) ) ; else pages . add ( page ) ; } return pages ;
final int group = ( int ) ( input & 0x1 f ) ; input > > > = 5 ; encoded [ - - index ] = alphabet [ group ] ;
if ( default setting name . equals ( intp setting . get name ( ) ) ) { editor = intp setting . get editor from setting by class name ( interpreter . get class name ( ) ) ; }
get fragment manager ( ) . begin transaction ( ) . replace ( android . r . id . content , new launcher settings fragment ( ) ) . commit ( ) ;
service = executors . new fixed thread pool ( 2 ) ;
media type media type = response . get entity ( ) . get media type ( ) ; if ( media type = null ) { log . debug ( setting the content - type to be { } , media type . to string ( ) ) ; exchange . get out ( ) . set header ( exchange . content _ type , media type . to string ( ) ) ; } if ( stream representation & & response . get entity ( ) instanceof stream representation ) { representation representation decoded = new decode representation ( response . get entity ( ) ) ; input stream is = representation decoded . get stream ( ) ; exchange . get out ( ) . set body ( is ) ; if ( auto close stream ) {
for ( int i = 0 ; i < m field views . size ( ) ; i + + ) { editor field view field view = m field views . get ( i ) ; field view . update displayed error ( invalid views . contains ( field view ) ) ; } if ( invalid views . is empty ( ) ) { make sure that focus is on an invalid field . editor field view focused field = get editor text field ( get current focus ( ) ) ; if ( invalid views . contains ( focused field ) ) { the focused field is invalid , but it may be scrolled off screen . scroll to it . focused field . scroll to and focus ( ) ; } else { some fields are invalid , but none of the are focused . scroll to the first invalid field and focus it . invalid views . get ( 0 ) . scroll to and focus ( ) ; } }
reflective config option loader . instance . load standard ( this . get class ( ) ) ; child = children . get ( name ) ; if ( null = = child ) { reflective config option loader . instance . load all ( this . get class ( ) ) ; child = children . get ( name ) ; } }
assert true eventually ( new assert task ( ) { @ override public void run ( ) { assert equals ( members to upgrade . length , members to upgrade [ 0 ] . get cluster ( ) . get members ( ) . size ( ) ) ; } } , 30 ) ; } } } finally {
if ( newscore = = null ) return null ; return double . value of ( newscore ) ;
if ( build config . debug ) log . d ( co coin , download database failed + code + + msg ) ;
replicating partitions . retain all ( node partitions ) ; return replicating partitions . size ( ) > 0 ; }
if ( http client api = = null ) { http client api = ( ( cxf rs endpoint ) get endpoint ( ) ) . is http client api ( ) ; } if ( http client api . boolean value ( ) ) { invoke async http client ( exchange , callback ) ; } else { invoke async proxy client ( exchange , callback ) ; } return false ;
string origin file name = test . txt ;
final int [ ] best xy = result = null ? result : new int [ 2 ] ; double best distance = double . max _ value ; final rect best rect = new rect ( - 1 , - 1 , - 1 , - 1 ) ; final stack < rect > valid regions = new stack < > ( ) ; final int count x = m count x ;
logd ( tag , found the correct route during reconnection attempt ) ;
if ( get option ( exchange , include _ headers , boolean . true ) ) { final list < string > headers = new array list < string > ( row length ) ; result . add ( headers ) ; add column headers ( headers , report extended metadata . get detail column info ( ) , detail columns ) ; } final report row [ ] report rows = fact with details . get rows ( ) ;
update progress ( get string ( r . string . creating _ your _ site ) ) ;
return line . get start offset ( ) ;
byte [ ] buf = new byte [ buffer _ length ] ;
list < org active rule dto > active rules1 = db client . active rule dao ( ) . select by profile ( db session , child ) ; assert that ( active rules1 ) . has size ( 1 ) ; assert that ( active rules1 . get ( 0 ) . get key ( ) . get rule key ( ) . rule ( ) ) . is equal to ( rule1 . get rule key ( ) ) ; assert that ( rule index . search ( new rule query ( ) . set activation ( true ) . set qprofile ( child ) , new search options ( ) ) . get ids ( ) ) . has size ( 1 ) ;
serializer . register class ( serializer registrations message . class ) ;
events listener . push expected event ( next event . tag _ definition ) ; final tag definition model dao created tag definition = tag definition dao . create ( definition name , description , internal call context ) ; assert . assert equals ( created tag definition . get name ( ) , definition name ) ; assert . assert equals ( created tag definition . get description ( ) , description ) ; assert listener status ( ) ;
switch ( exif . get attribute int ( exif interface . tag _ orientation , exif interface . orientation _ undefined ) ) { case exif interface . orientation _ rotate _ 90 : return 90 ; case exif interface . orientation _ rotate _ 180 : return 180 ; case exif interface . orientation _ rotate _ 270 : return 270 ; default : return exif interface . orientation _ undefined ; }
testlist . add ( test _ 0 ) ;
assert equals ( test b : returned wrong last index of sub list , , 0 , collections . last index of sub list ( src , sub ) ) ; sub = new array list ( src . sub list ( 2 , 5 ) ) ;
string user _ id = icq slick fixture . tester agent . get icq uin ( ) ; final string password = system . get property ( icq protocol provider slick . tested _ impl _ pwd _ prop _ name , null ) ; hashtable < string , string > props = new hashtable < string , string > ( ) ; props . put ( user _ id , user _ id ) ; props . put ( password , password ) ; try { provider factory . install account ( user _ id , props ) ; } catch ( exception e ) exception if account exists { } string second provider id = icq slick fixture . tester agent . get icq uin ( ) ;
fibonacci heap node other left = other . minimum . left ; other . minimum . left = minimum . left ; minimum . left = other left ;
test versioned interval timeline behavior for numbered shard spec ( immutable list . of ( chunk0 ) , collections . empty _ set ) ; test versioned interval timeline behavior for numbered shard spec ( immutable list . of ( chunk1 ) , collections . empty _ set ) ; test versioned interval timeline behavior for numbered shard spec ( immutable list . of ( chunk4 ) , collections . empty _ set ) ; test versioned interval timeline behavior for numbered shard spec ( immutable list . of ( chunk0 , chunk4 ) , collections . empty _ set ) ; test versioned interval timeline behavior for numbered shard spec ( immutable list . of ( chunk1 , chunk4 ) , collections . empty _ set ) ;
m handler . post delayed ( new runnable ( ) { @ override public void run ( ) { go to nav drawer item ( item id ) ; } } , navdrawer _ launch _ delay ) ;
execution vertex vertex11 = mock execution vertex ( mock execution ( ) , job vertex id1 , 0 , 3 ) ; execution vertex vertex12 = mock execution vertex ( mock execution ( ) , job vertex id1 , 1 , 3 ) ; execution vertex vertex13 = mock execution vertex ( mock execution ( ) , job vertex id1 , 2 , 3 ) ;
out . write ( func ( + class name . substring ( 0 , 1 ) . to lower case ( ) + + class name + ) ) ;
content response response3 = client . new request ( localhost , server connector . get local port ( ) ) . timeout ( 5 , time unit . seconds ) . send ( ) ; assert . assert equals ( 200 , response3 . get status ( ) ) ; assert . assert true ( response3 . get headers ( ) . contains key ( proxied _ header ) ) ; }
log . info ( reading from the sequence file . . . ) ; sequence file . reader reader = new sequence file . reader ( fs , file path , conf ) ; writable key = ( writable ) reader . get key class ( ) . new instance ( ) ;
container request event [ ] req reduce events = new container request event [ reduce _ count ] ;
ops . add ( op tasks none ) ; ops . add ( op tasks2 ) ; ops . add ( op tasks3 ) ; try { privileged operation op = privileged operation executor . squash cgroup operations ( ops ) ; string expected = new string buffer ( privileged operation . cgroup _ arg _ prefix ) . append ( c group tasks1 ) . append ( privileged operation . linux _ file _ path _ separator ) . append ( c group tasks2 ) . append ( privileged operation . linux _ file _ path _ separator ) . append ( c group tasks3 ) . to string ( ) ; we expect axactly one argument assert . assert equals ( 1 , op . get arguments ( ) . size ( ) ) ; squashed list of tasks files assert . assert equals ( expected , op . get arguments ( ) . get ( 0 ) ) ; } catch ( privileged operation exception e ) { log . info ( caught unexpected exception : + e ) ; assert . fail ( caught unexpected exception : + e ) ; }
m tint manager . set tint drawable ( uielements helper . get general action bar background ( this ) ) ; get action bar ( ) . set background drawable ( uielements helper . get general action bar background ( this ) ) ; }
nodes = new string [ h2 o . cloud . size ( ) ] ;
return word < 0 ; }
cluster . sync ( ) ;
string v = ( pretty print ) ? data . trim ( ) : data ; s . append ( escape element value ( v ) ) ; return s . to string ( ) ; }
caller context caller context = caller context . get current ( ) ; if ( caller context = null & & caller context . is context valid ( ) ) { rpccaller context proto . builder context builder = rpccaller context proto . new builder ( ) . set context ( caller context . get context ( ) ) ; if ( caller context . get signature ( ) = null ) { context builder . set signature ( byte string . copy from ( caller context . get signature ( ) ) ) ; } result . set caller context ( context builder ) ; } return result . build ( ) ;
path parent = src . get parent ( ) ;
start x + = dip8 * ratio ;
m file system . set attribute ( folder , m unset pinned ) ; assert . assert false ( m file system . get status ( folder ) . is pinned ( ) ) ; assert . assert false ( m file system . get status ( file1 ) . is pinned ( ) ) ; assert . assert equals ( new hash set < > ( m fsmaster client . get pin list ( ) ) , sets . new hash set ( status0 . get file id ( ) ) ) ;
system . out . println ( first versioned put ) ; versioned value . set object ( new value ) ; system . out . println ( * * * * * * * * * * * * * original version : + versioned value . get version ( ) ) ; version put version = store client . put ( a , versioned value ) ; system . out . println ( * * * * * * * * * * * * * updated version : + put version ) ;
menu item restore item = new menu item ( tools . get label ( messages . get string ( gui menu show main window ) ) ) ; restore item . add action listener ( rmb listener ) ; popup . add ( restore item ) ;
assert equals ( 1 , events . get all events ( ) . size ( ) ) ; assert equals ( test id 5 , events . get all events ( ) . get ( 0 ) . get entity id ( ) ) ; } finally {
assert true ( commits . size ( ) > 1 ) ;
verify ( stor iosqlite ) . put ( ) ;
string json = ( string ) mbean server . invoke ( on , explain endpoint json , new object [ ] { log : foo?group delay = 2000 & group size = 5 , true } , new string [ ] { java . lang . string , boolean } ) ; assert not null ( json ) ;
int new length = length < < 1 ;
s _ logger . debug ( adding physical network service provider f5 big ip + in to physical network + physical network id ) ; string insert pnsp = insert into `cloud` . `physical _ network _ service _ providers` ( `uuid` , `physical _ network _ id` , `provider _ name` , `state` , + `destination _ physical _ network _ id` , `vpn _ service _ provided` , `dhcp _ service _ provided` , `dns _ service _ provided` , `gateway _ service _ provided` , + `firewall _ service _ provided` , `source _ nat _ service _ provided` , `load _ balance _ service _ provided` , `static _ nat _ service _ provided` , + `port _ forwarding _ service _ provided` , `user _ data _ service _ provided` , `security _ group _ service _ provided` ) values ( ? , ? , ? , ? , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 ) ; pstmt update = conn . prepare statement ( insert pnsp ) ;
assert equals ( 0xd800 , character . high surrogate ( 0x010000 ) ) ; assert equals ( 0xdbff , character . high surrogate ( 0x10ffff ) ) ; }
function or parenthesized type . rollback to ( ) ;
success fully completed steps = success fully completed steps + , + step2 ;
url url = data utilities . file to url ( mosaic . get canonical file ( ) ) ; string body = url . to external form ( ) ; mock http servlet response response = post as servlet response ( rest base controller . root _ path + workspaces wcs coveragestores watertemp external . imagemosaic , body , text plain ) ; assert equals ( 202 , response . get status ( ) ) ; document dom = get as dom ( rest base controller . root _ path + workspaces wcs coveragestores watertemp coverages watertemp index granules . xml ) ;
indarray new input = nd4j . create ( 1 , input arr . size ( 1 ) , labels length ) ; new input . get ( ndarray index . point ( 0 ) , ndarray index . all ( ) , ndarray index . interval ( labels length - features length , labels length ) ) . assign ( input arr ) ;
grow ( t , full count , tc , per unit count , true ) ;
assert xpath evaluates to ( 2 , count ( gmlcov : metadata gmlcov : extension wcsgs : elevation domain wcsgs : single value ) , dom ) ; assert xpath evaluates to ( 0 . 0 , gmlcov : metadata gmlcov : extension wcsgs : elevation domain wcsgs : single value [ 1 ] , dom ) ; assert xpath evaluates to ( 100 . 0 , gmlcov : metadata gmlcov : extension wcsgs : elevation domain wcsgs : single value [ 2 ] , dom ) ; }
query . get set session properties ( ) . entry set ( ) . for each ( entry - > response . header ( presto _ set _ session , entry . get key ( ) + ' = ' + entry . get value ( ) ) ) ;
string var name = maybe extract variable name ( body . text ) ; if ( var name = null ) { var names . add ( var name ) ; } } }
hbase table source hbase table = new hbase table source ( get conf ( ) , test _ table ) ; hbase table . add column ( family2 , f2 col1 , byte [ ] . class ) ; hbase table . add column ( family2 , f2 col2 , byte [ ] . class ) ; table env . register table source ( h table , hbase table ) ; table env . register function ( to utf8 , new to utf8 ( ) ) ; table env . register function ( to long , new to long ( ) ) ; table result = table env . sql query ( select + to utf8 ( h . family2 . col1 ) , + to long ( h . family2 . col2 ) + from h table as h ) ;
assert true ( expected record got nothing , reader . next ( key , value ) ) ; assert equals ( wrong length for record value , 3 , value . get length ( ) ) ;
total = ( long ) mbean server . get attribute ( name , exchanges total ) ; assert equals ( 10 , total . int value ( ) ) ;
double scale factor = schema name to scale factor ( table name . get schema name ( ) ) ; if ( scale factor < 0 ) { return null ; } return new tpch table handle ( connector id , table name . get table name ( ) , scale factor ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( reserved dbinstance not found ) ) return null ; reserved dbinstance not found exception e = ( reserved dbinstance not found exception ) super . unmarshall ( node ) ; return e ; }
utils . mkdirs ( temp dir ) ; assert true ( temp dir . exists ( ) ) ;
ksession . get agenda ( ) . get agenda group ( test group ) . set focus ( ) ; assert equals ( 1 , agenda list . size ( ) ) ; final agenda group pushed event pushed event = ( agenda group pushed event ) agenda list . get ( 0 ) ; assert equals ( test group , pushed event . get agenda group ( ) . get name ( ) ) ; agenda list . clear ( ) ;
set authorization caching enabled ( false ) ;
copy directory contents ( static css * . css , get path resolver ( ) . get identifier ( resources path , static public css ) , true ) ;
span term query ( user , < 1 > kimchy ) ; < 2 >
calendar . set time ( dnd start ) ; data [ mi band2 service . inactivity _ warnings _ interval _ 1 _ end _ hours ] = ( byte ) calendar . get ( calendar . hour _ of _ day ) ; data [ mi band2 service . inactivity _ warnings _ interval _ 1 _ end _ minutes ] = ( byte ) calendar . get ( calendar . minute ) ;
if ( is logged in . compare and set ( false , true ) ) { log . info ( logging in using keytab as auto hdfs is not specified for + topology _ auto _ credentials ) ; string keytab = ( string ) conf . get ( storm _ keytab _ file _ key ) ; if ( keytab = null ) { hdfs config . set ( storm _ keytab _ file _ key , keytab ) ; } string user name = ( string ) conf . get ( storm _ user _ name _ key ) ; if ( user name = null ) { hdfs config . set ( storm _ user _ name _ key , user name ) ; } security util . login ( hdfs config , storm _ keytab _ file _ key , storm _ user _ name _ key ) ; }
controller . start ( basic crawler . class , number of crawlers ) ; }
ast lambda expression jjtn000 = new ast lambda expression ( jjtlambdaexpression ) ;
file reader reader = new file reader ( task log . get task log file ( attempt1 , log name . syslog ) ) ; int ch , bytes read = 0 ; boolean data valid = true ; while ( ( ch = reader . read ( ) ) = - 1 ) { bytes read + + ; if ( bytes read < = 150 ) { if ( ( char ) ch = ' a ' ) { log . warn ( truncation didn ' t happen properly . at + ( bytes read + 1 ) + th byte , expected ' a ' but found + ( char ) ch ) ; data valid = false ; } } else if ( bytes read < = 250 ) { if ( ( char ) ch = ' b ' ) { log . warn ( truncation didn ' t happen properly . at + ( bytes read + 1 ) + th byte , expected ' b ' but found + ( char ) ch ) ; data valid = false ; } } else if ( ( char ) ch = ' c ' ) { log . warn ( truncation didn ' t happen properly . at + ( bytes read + 1 ) + th byte , expected ' c ' but found + ( char ) ch ) ; data valid = false ; } } assert true ( log - truncation didn ' t happen properly , data valid ) ; logs monitor . monitor task logs ( ) ;
props . put ( org . quartz . thread pool . class , org . quartz . simpl . simple thread pool ) ; props . put ( org . quartz . thread pool . thread count , 10 ) ; final string sql scripts dir = get sql scripts dir ( ) ;
if ( ( item instanceof number item ) & & ( item instanceof string item ) & & ( item instanceof date time item ) ) { throw new binding config parse exception ( item ' + item . get name ( ) + ' is of type ' + item . get class ( ) . get simple name ( ) + ' , only number items , date time items or string items are allowed - please check your * . items configuration ) ; } }
after = text . decode ( utf8 java ) ;
search response search response = client ( ) . prepare search ( test ) . set query ( match all query ( ) ) . add sort ( sort builders . geo distance sort ( locations , 40 . 7143528 , - 74 . 0059731 ) . order ( sort order . asc ) ) . execute ( ) . action get ( ) ; assert hit count ( search response , 5 ) ;
for ( routine definition routine : udt . get routines ( ) ) { try { if ( routine . is sqlusable ( ) ) { static execute ( ) convenience method print convenience method procedure ( out , routine , false ) ; } else { static execute ( ) convenience method if ( routine . is aggregate ( ) ) { print convenience method function ( out , routine , false ) ; } static as field ( ) convenience method print convenience method function as field ( out , routine , false ) ; print convenience method function as field ( out , routine , true ) ; } } catch ( exception e ) { log . error ( error while generating routine + routine , e ) ; } } if ( scala ) { } else { out . tab ( 1 ) . javadoc ( no _ further _ instances _ allowed ) ; out . tab ( 1 ) . println ( private % s ( ) { , class name ) ; out . tab ( 2 ) . println ( super ( \ % s \ , null , % s , % s ) ; , udt . get output name ( ) , package id , synthetic ) ; out . tab ( 1 ) . println ( } ) ; }
catch ( exception e ) { } return null ; }
expect sleep after writing lock ( own senior ls ) ;
int split num = 10 ;
if ( ( stream instanceof buffered input stream ) ) { stream = new buffered input stream ( stream , f temp string . ch . length ) ; }
assert verify fail ( new routing spec ( ) . add table ( new routing table spec ( mytable ) . add route ( new route spec ( foo ) . add hop ( bar ) ) ) , new application spec ( ) , arrays . as list ( hop 1 in route ' foo ' in routing table ' mytable ' references ' bar ' which is neither a service , a route nor another hop . ) ) ;
assert . assert equals ( 4 , task . get fire department metrics ( ) . processed ( ) ) ; assert . assert equals ( 1 , task . get fire department metrics ( ) . unparseable ( ) ) ; assert . assert equals ( 0 , task . get fire department metrics ( ) . thrown away ( ) ) ;
if ( method name . length ( ) < 3 | | ( method name . starts with ( is ) & & method name . length ( ) < 4 ) ) continue ;
_ sent signature = _ context . dsa ( ) . sign ( signed , _ context . key manager ( ) . get signing private key ( ) ) ;
file f = new file ( file name ) ; preexists = f . length ( ) > initial _ free _ pos ;
this . collecting view . reset ( ) ; this . read view . set read position ( 0 ) ; return true ;
common component common = new common component ( ) ; log . info ( initializing + common . get class ( ) . get name ( ) ) ; ctx . set attribute ( org . eclipse . jetty . test . jmx . common , common ) ;
final schema schema = specific data . get ( ) . get schema ( avro class ) ; return ( type information < row > ) convert to type information ( avro type info , schema ) ;
dfstest util . create file ( filesystem , new path ( src ) , 128 , ( short ) 1 , 0 l ) ;
do answer ( invocation - > { cache topology topology = ( cache topology ) invocation . get arguments ( ) [ 1 ] ; if ( topology . get rebalance id ( ) = = initial topology . get rebalance id ( ) + 2 ) { log . debugf ( discarding rebalance command % s , topology ) ; return null ; } return invocation . call real method ( ) ; } ) . when ( spy local topology manager2 ) . handle rebalance ( eq ( cache _ name ) , any ( cache topology . class ) , any int ( ) , any ( address . class ) ) ;
processor processor = processors . next ( ) ;
+ + j ;
assert equals ( immutable set . of ( key . get ( interface . class ) , key . get ( string . class , named ( constant ) ) ) , capturer . get as set and clear ( ) ) ;
assert same ( key , cache . get ( key , throwing ( new exception ( ) ) ) ) ; stats = cache . stats ( ) ; assert equals ( 2 , stats . miss count ( ) ) ; assert equals ( 3 , stats . load success count ( ) ) ; assert equals ( 0 , stats . load exception count ( ) ) ; assert equals ( 2 , stats . hit count ( ) ) ; key = new object ( ) ;
assert null ( e . get cause ( ) ) ;
path cxx native libs src = context . get source path resolver ( ) . get relative path ( native files info . native libs assets dirs . get ( ) . get ( module ) ) ;
div element delimiter = document . get ( ) . create div element ( ) ;
if ( ( ioe . get cause ( ) instanceof connect exception ) ) { fail ( we should not have reached here ) ; } }
return function . identity ( ) ; }
family files . remove ( hfile name ) ; } else {
rejoin message expected = new rejoin message ( 10000l , rejoin message . type . initiation , rejoin _ 2 , 1 , null , false ) ; hsids . clear ( ) ; hsids . add ( 2l ) ; verify sent ( hsids , expected ) ;
if ( oldgs > newblock . get generation stamp ( ) ) { throw new ioexception ( cannot update block ( id = + newblock . get block id ( ) + ) generation stamp from + oldgs + to + newblock . get generation stamp ( ) ) ; }
if ( keycode = = key event . vk _ x ) { insert = ; }
if ( ( ( center * 4 ) - left - right ) 2 < black point ) { row . set ( x ) ; }
} } throw e1 ; }
try { drop schema ( data store destination , feature type name ) ; } catch ( exception e1 ) { logger . log ( level . warning , error dropping schema in rollback , e1 ) ; }
byte [ ] guid byte array = new byte [ 16 ] ; for ( int i = 0 ; i < guid byte array . length ; i + + ) { guid byte array [ i ] = from hex string ( guid string . substring ( i * 2 , ( i * 2 ) + 2 ) ) ; }
int max binary message = get max message size ( policy . get max binary message size ( ) , metadata . max binary message size ( ) ) ; int max text message = get max message size ( policy . get max text message size ( ) , metadata . max text message size ( ) ) ; policy . set max binary message size ( max binary message ) ; policy . set max text message size ( max text message ) ; return new jsr annotated event driver ( policy , ei , events ) ;
instruction writer . visit branch instruction ( clazz , method , code attribute , new offset , branch instruction ) ; new offset + = branch instruction . length ( new offset ) ;
super . on restore instance state ( bundle . get parcelable ( bundle _ id _ parent _ state ) ) ;
string exc msg = invalid parameter . ;
string explicit value = ( string ) format . get ( key ) ; if ( explicit value = = null & & value = null ) {
iterator < map . entry < string , column family store mbean > > table mbeans = probe . get column family store mbean proxies ( ) ; while ( table mbeans . has next ( ) ) { map . entry < string , column family store mbean > entry = table mbeans . next ( ) ; string keyspace name = entry . get key ( ) ; column family store mbean table proxy = entry . get value ( ) ; if ( filter . is keyspace included ( keyspace name ) ) { stats keyspace stats = keyspace stats . get ( keyspace name ) ; if ( stats = = null ) { stats = new stats keyspace ( probe , keyspace name ) ; keyspace stats . put ( keyspace name , stats ) ; } stats . add ( table proxy ) ; if ( filter . is table included ( keyspace name , table proxy . get table name ( ) ) ) selected table mbeans . put ( keyspace name , table proxy ) ; } }
transaction id + + ; connector table handle table handle = metadata . get table handle ( session , default _ test _ orders ) ; connector insert table handle insert handle = metadata . begin insert ( session , table handle ) ;
for ( int id = 7 ; id < 15 ; id + + ) { client . call procedure ( callback , table name + . insert , - id , id x + string . value of ( id ) + padded to non inline length , desc 10 , num 1 . 1 , ratio new timestamp ( 100000000 l ) ) ; past client . drain ( ) ; } }
for ( int i = 0 ; i < numdocs ; i + + ) { writer . add document ( line file docs . next doc ( ) ) ; } line file docs . close ( ) ; }
assert true ( file + should not be so big in size , was : + size , size < 34 * 1024 * 1024 ) ;
system . out . println ( present ( get focus type , exported property ) : + meth . is annotation present ( exported property . class ) ) ; system . out . println ( present ( get focus type , anno simple type ) : + meth . is annotation present ( anno simple type . class ) ) ; system . out . println ( ) ;
target . append ( str , off , off + len ) ;
return 1 ; } else {
camel spring wsendpoint mapping endpoint mapping = resolve and remove reference parameter ( parameters , endpoint mapping , camel spring wsendpoint mapping . class , null ) ;
immutable set . builder < string > interesting paths builder = new immutable set . builder < > ( ) ; for ( pair < ? , int [ ] > entry : entries ) { for ( int hash index : entry . get second ( ) ) { interesting paths builder . add ( inputs . get ( hashes . get ( hash index ) . get first ( ) ) ) ; } } immutable set < string > interesting paths = interesting paths builder . build ( ) ;
nza = nzb = 0 ; ca = char at ( a , ia ) ;
abort master ( cluster ) ;
{ if ( input . la ( 1 ) = = ' b ' | | input . la ( 1 ) = = ' d ' | | input . la ( 1 ) = = ' f ' | | input . la ( 1 ) = = ' d ' | | input . la ( 1 ) = = ' f ' ) { input . consume ( ) ; state . failed = false ; } else { if ( state . backtracking > 0 ) { state . failed = true ; return ; } mismatched set exception mse = new mismatched set exception ( null , input ) ; recover ( mse ) ; throw mse ; } } break ;
cr = client . call procedure ( @ ad hoc , select abs ( dept ) as tag , count ( wage ) from + tb + group by abs ( dept ) order by tag ) ;
return ( ks . get type ( ) . equals ( android castore ) ) ;
feature type info ft = get catalog ( ) . get feature type by name ( get layer id ( mock data . basic _ polygons ) ) ;
publish update ( data . visible ( false ) ) ;
path file1 = new path ( tmp test bad block report on transfer file1 ) ; dfstest util . create file ( fs , file1 , 1024 , repl factor , 0 ) ; dfstest util . wait replication ( fs , file1 , repl factor ) ;
throw new org . apache . axis2 . databinding . adbexception ( product description cannot be null ) ;
throw new ioexception ( failed to parse author date : + s , pe ) ; } } else if ( string utils . is only whitespace ( s ) ) {
if ( apps = = null | | apps . is empty ( ) ) { if ( user . equals ( utilities . my user handle ( ) ) ) { return ; } else { continue ; } }
assert that ( http body . length ( ) , is ( equal to ( 0 ) ) ) ;
message edit text . set on key listener ( ( view , keycode , key event ) - > { if ( messenger ( ) . is send by enter enabled ( ) ) { if ( key event . get action ( ) = = key event . action _ down & & keycode = = key event . keycode _ enter ) { on send button pressed ( ) ; return true ; } } return false ; } ) ;
card view card view = ( card view ) get activity ( ) . find view by id ( r . id . carddemo _ shadow _ layout ) ;
path t = new path ( core snap . get index dir path ( ) ) ;
expression = parser . parse expression ( apple ) ;
batch response ( cache key , request ) ; }
test file util . create random file in directory ( sub dir1 , 10 ) ; assert false ( event occurred . get ( ) ) ; thread . sleep ( 350 ) ;
assert equals ( file _ size , read input stream ( new path ( test wasb . txt ) ) ) ; }
assert equals ( entries str . get ( 2 ) , dummy - entry - 3 ) ;
non hakey = put ( cache0 , job id [ 0 ] , expected2 , transient _ blob ) ; verify key different hash different ( keys [ 0 ] , non hakey ) ; verify key different hash equals ( keys [ 1 ] , non hakey ) ;
string source classname = conf . get ( hconstants . replication _ source _ service _ classname , hconstants . replication _ service _ classname _ default ) ;
write request ( id ) ; } } catch ( ioexception e ) {
file write buffer file = new file ( new file ( meta file . get parent ( ) , mi . get session id ( ) ) , write buffer _ 0 ) ; long mod time = system . current time millis ( ) + 1000 ; precision of the mod time is 1 sec write buffer file . set last modified ( mod time ) ; log . debug ( setting mod time for + write buffer file + to + mod time + now val = + write buffer file . last modified ( ) ) ; mi = new dbus event buffer meta info ( meta file ) ; mi . load meta info ( ) ; assert . assert true ( mi . is valid ( ) ) ; we don ' t invalidate the meta file based on mod time }
if ( noshade = null ) { g . set color ( color . black ) ; g . fill rect ( x , y , width , height ) ; } else { color bg = get container ( ) . get background ( ) ; color bottom , top ; if ( bg = = null | | bg . equals ( color . white ) ) { top = color . dark gray ; bottom = color . light gray ; } else { top = color . dark gray ; bottom = color . white ; } g . set color ( bottom ) ; g . draw line ( x + width - 1 , y , x + width - 1 , y + height - 1 ) ; g . draw line ( x , y + height - 1 , x + width - 1 , y + height - 1 ) ; g . set color ( top ) ; g . draw line ( x , y , x + width - 1 , y ) ; g . draw line ( x , y , x , y + height - 1 ) ; }
if ( is valid id3v2 frame identifier ( identifier ) ) { logger . config ( invalid identifier : + identifier ) ; byte buffer . position ( byte buffer . position ( ) - ( get frame id size ( ) - 1 ) ) ; throw new invalid frame identifier exception ( get logging filename ( ) + : + identifier + : is not a valid id3v2 . 20 frame ) ; }
file proper folder = new file ( file . get parent ( ) , proper parent ) ;
assert true ( distributor . is child ( stream d . id ( ) , connection . connection stream ( ) . id ( ) , default _ priority _ weight ) ) ;
list < operator < ? > > parents = join op . get parent operators ( ) ;
long start = environment edge manager . current time ( ) ;
among _ var = find _ among _ b ( a _ 3 , 283 ) ;
query = tree . query ( 1 , 3 ) ; assert true ( segment tree query error . query = 1 - > 3 result = + query , tree , query . minimum = = 2 ) ;
catalog change group cgrp = m _ changes . get ( diff class . get ( new type ) ) ; cgrp . process addition ( new type ) ; }
root view . set on touch listener ( new view . on touch listener ( ) { @ override public boolean on touch ( view v , motion event event ) { return true ; } } ) ;
fail transaction on commit ( new transaction job ( ) { @ override public void run ( titan transaction tx ) { titan vertex v0 = tx . add vertex ( person ) ; v0 . property ( vertex property . cardinality . single , time , 1 ) ; titan vertex v1 = tx . add vertex ( person ) ; v1 . property ( vertex property . cardinality . single , time , 1 ) ; } } ) ;
this . reason = reason ;
st . set double ( index , 1 ) ;
test same ( let a = 1 ; const b = 2 ; ) ;
po . set parallelism ( this . get parallelism ( ) ) ; return po ;
string application id = yarn properties . get property ( yarn _ application _ id _ key ) ; if ( application id = = null ) { throw new illegal configuration exception ( yarn properties file found but doesn ' t contain a + yarn application id . please delete the file at + properties file . get absolute path ( ) ) ; } try { try converting id to application id converter utils . to application id ( application id ) ; } catch ( exception e ) { throw new runtime exception ( yarn properties contains an invalid entry for + application id : + application id , e ) ; }
assert . assert equals ( flume file length after s1 , fs . get file status ( flume s1 path ) . get len ( ) ) ; long flume file written data length = flume file length after s1 ;
assert that ( back off . to string ( ) , contains string ( current retry = 1 ) ) ;
message sent = not sent : + exception . get message ( ) ; }
while ( match checks . is export drained ( client ) ) { if ( system . current time millis ( ) > ( start time + ( config . duration * . 5 ) * 1000 ) ) { log . error ( timeout waiting for export to drain ) ; throw new exception ( timeout waiting for export to drain ) ; } log . info ( waiting for export table to drain ) ; thread . sleep ( 2000 ) ; } log . info ( export phase complete , + export row count + rows exported , waiting for import to drain . . . ) ;
string queue name = get scheduler app ( attempt id ) . get queue name ( ) ;
m saripaar button . set on click listener ( this ) ;
set num non zero registers ( num non zero ) ;
int split idx = category . last index of ( ' > ' ) ;
notify hierarchy changed ( ) ;
string che host = docker connector configuration . get docker host ip ( ) ;
list < route definition > routes = context . get route definitions ( ) ;
expressions . current time ( ) ;
try { final byte [ ] b4 = new byte [ 4 ] ; int count = 0 ; int single byte read ; while ( count < 4 ) { single byte read = stream . read ( ) ; if ( single byte read = = - 1 ) { break ; } b4 [ count ] = ( byte ) single byte read ; count + + ; } return parse bom ( b4 , count ) ; } catch ( ioexception ioe ) { failed . return new bom result ( utf - 8 , 0 ) ; }
network network = _ network dao . find by id ( network id ) ;
list < server name > shuffled server list = new array list < > ( ) ;
assert true ( should match with set some number with double input , method matcher . matches ( set some number , test bean . class , new double ( 12 ) ) ) ;
assume false ( base instanceof file resource ) ; resource res = base . add path ( foo ^ 3 . txt ) ;
val . set values ( true ) ; assert equals ( true , func . get boolean ( ) ) ; assert true ( func . exists ( ) ) ; val . set values ( false ) ;
log floor = math . floor ( - log floor ) ;
assert xpath evaluates to ( target polygon coords , ex : geom container [ @ gml : id = ' 1 ' ] ex : nested feature [ 2 ] ex : nested geom [ @ gml : id = ' second nested . 2 ' ] ex : nested feature ex : nested geom [ @ gml : id = ' third nested . 1 ' ] ex : geom gml : polygon gml : exterior gml : linear ring gml : pos list , doc ) ; assert xpath evaluates to ( urn : x - ogc : def : crs : epsg : 4326 , ex : geom container [ @ gml : id = ' 2 ' ] ex : nested feature [ 2 ] ex : nested geom [ @ gml : id = ' second nested . 1 ' ] ex : nested feature ex : nested geom [ @ gml : id = ' third nested . 2 ' ] ex : geom gml : point @ srs name , doc ) ;
{ numbering , multiplicative - additive } , { multiplier order , follows } ,
if ( f grammar pool = null ) { grammar [ ] grammars = f grammar pool . retrieve initial grammar set ( xmlgrammar description . xml _ dtd ) ; final int length = ( grammars = null ) ? grammars . length : 0 ; for ( int i = 0 ; i < length ; + + i ) { f grammar bucket . put grammar ( ( dtdgrammar ) grammars [ i ] ) ; } } f doc location = locator ; f namespace context = namespace context ; if ( f document handler = null ) { f document handler . start document ( locator , encoding , namespace context , augs ) ; }
start activity ( intent , opts bundle ) ; } } finally { strict mode . set vm policy ( old policy ) ; } } catch ( security exception e ) {
return get whole association path ( ( criteria impl . subcriteria ) parent ) + ' . ' + path ;
cfw . add invoke ( byte code . invokestatic , main method class , main , ( lorg mozilla javascript script ; [ ljava lang string ; ) v ) ; cfw . add ( byte code . return ) ;
regions . remove ( floor region ) ;
new output writer ( configuration ) . execute ( program class pool ) ; }
list < usage event vo > events = _ usage event dao . get recent events ( new date ( end date millis ) ) ; transaction usage txn = transaction . open ( transaction . usage _ db ) ;
if ( v = = _ map . get no entry value ( ) ) { return null ; } else { return wrap value ( v ) ; } }
assert single cache entry ( ) ; time _ service . advance ( timeout + 1 ) ;
source . set samples ( multisample ) ; string app title = source . get title ( ) ;
return arrays . as list ( new interval window ( c . timestamp ( ) , gap duration ) ) ;
base . set value ( - 4 . 2 ) . set exists ( true ) ;
set < string > keys = get aggregation repository ( ) . get keys ( ) ;
if ( nameservice ids = = null | | nameservice ids . is empty ( ) ) { client should try { @ link is default namenode address } instead return null ; }
activity test rule . run on ui thread ( new runnable ( ) { @ override public void run ( ) { col . add view ( view a ) ; col . add view ( view b , lp b ) ; } } ) ;
localized resource localized resource = localrsrc . get ( lr ) ; tracker . handle ( resource failed event ) ;
assert . assert true ( shell content . contains ( export hadoop _ yarn _ home = \ nodemanager _ yarn _ home \ ) ) ;
return new rx java2 call adapter ( void . class , scheduler , is async , false , true , false , false , false , true ) ; }
if ( _ bindings . contains key ( name ) ) continue ;
return to identifier ( transform attribute path ( source . get identifier attribute path ( ) ) , source . get building context ( ) ) ;
template . send body and header ( direct : start , b , id , null ) ; template . send body and header ( direct : start , c , id , 1 ) ;
final org . hibernate . mapping . mapped superclass superclass = binder helper . get mapped superclass or null ( class with id class , inheritance state per class , context ) ;
if ( this itr . prepare next ( min count ) | * not | | * other itr . prepare next ( min count ) ) { return false ; } } else { if ( ( this itr . to literal ( ) & other itr . word ) = concise set utils . all _ zeros _ literal ) { return true ; } this itr . word - - ;
assert pixel ( image , 36 , 31 , new color ( 255 , 255 , 255 ) ) ;
assert permission on resource ( permission . select , table mbean , proxy : : get table name ) ;
add ( ops . string ops . left , substr ( { 0 } , 1 , { 1 } ) ) ; add type name to code ( smallint , types . tinyint , true ) ;
final source manipulation info info = get source manipulation info ( element ) ; if ( name . length ( ) > 0 ) { set identifier position ( info , ast typedef name ) ; } else { set identifier position ( info , decl specifier ) ; } if ( decl specifier instanceof iastcomposite type specifier ) { set body position ( info , ast typedef name ) ; } else { set body position ( info , decl specifier . get parent ( ) ) ; } return element ;
frame type = ( math . abs ( buffer [ rtphl + 1 ] ) > > 3 ) & 0x0f ;
int children num = 1 + random ( ) . next int ( 3 ) ; list < hierarchy > child hierarchies = create mocked iterator ( type , select , children num , holder ) ; parent hierarchy . elements . add all ( child hierarchies ) ; result . add all ( child hierarchies ) ; }
for ( inode directory snapshottable dir : snapshottables . values ( ) ) { for ( snapshot s : snapshottable dir . get directory snapshottable feature ( ) . get snapshot list ( ) ) { s . write ( out ) ; } }
registry . register ( note id , class name , pre _ exec , pre exec hook ) ;
system . get property ( foo ) ; indent : 14 exp : 12 warn
if ( f align = java heuristic scanner . not _ found ) { try { a special case has been detected . iregion line = f document . get line information of offset ( f align ) ; int line offset = line . get offset ( ) ; return create indent ( line offset , f align , false ) ; } catch ( bad location exception e ) { return null ; } } if ( reference = = null ) return null ;
return kind . to string ( ) ;
object result = cx . evaluate string ( scope , obj = { a : 1 , b : [ ' x ' , ' y ' ] } , my source , 1 , null ) ; scriptable obj = ( scriptable ) scope . get ( obj , scope ) ;
map . entry < long , stored block > entry = checkpoints . floor entry ( time ) ; if ( entry = null ) return entry . get value ( ) ; block genesis = params . get genesis block ( ) . clone as header ( ) ; return new stored block ( genesis , genesis . get work ( ) , 0 ) ; } catch ( verification exception e ) {
else { b | = current bit ; }
string [ ] new segments = new string [ stack pointer ] ; system . arraycopy ( stack , 0 , new segments , 0 , stack pointer ) ; this . segments = new segments ; }
parent . replace child ( n , left . detach ( ) ) ;
throw new illegal state exception ( the document type + document type name + is not deployed . ) ; }
args . dump properties ( ) ;
if ( ( last component instanceof tree node ) ) return ; boolean is selected = path . equals ( get selection path ( ) ) ;
crlf = record . crlf ( ) ;
assert true ( delete failed , store . delete ( key , c1 ) ) ; assert equals ( 0 , store . get ( key , null ) . size ( ) ) ; }
return new sqlannotation hover ( this . get sqleditor ( ) ) ;
check simple replace rule ( wasnt this great , wasn ' t ) ;
assert true ( kill bill client . get invoice ( invoice json . get invoice id ( ) , boolean . false ) . get items ( ) . is empty ( ) ) ;
return sb . to string ( ) ;
tree = ( cols ( rows a . hex [ 0 : 4 6 7 ] ) [ 0 ] ) ;
query string = unsafe uri characters encoder . encode ( query string ) ;
assert equals ( data types . double , functions . get builtin ( stddev , immutable list . of ( type ) ) . info ( ) . return type ( ) ) ;
cursor cursor = db . query ( messages , new string [ ] { id , thread _ root , thread _ parent } , null , null , null , null , null ) ;
set priority ( stream b . id ( ) , stream a . id ( ) , default _ priority _ weight , false ) ; assert equals ( 5 , distributor . num children ( connection . connection stream ( ) . id ( ) ) ) ; assert true ( distributor . is child ( stream b . id ( ) , stream a . id ( ) , default _ priority _ weight ) ) ; assert equals ( 1 , distributor . num children ( stream a . id ( ) ) ) ; set priority ( stream c . id ( ) , stream a . id ( ) , default _ priority _ weight , false ) ; assert equals ( 4 , distributor . num children ( connection . connection stream ( ) . id ( ) ) ) ;
double [ ] pixel = new double [ 1 ] ; target coverage . get rendered image ( ) . get data ( ) . get pixel ( 1 , 24 , pixel ) ; assert equals ( expected value , pixel [ 0 ] , 1e - 6 ) ; } finally {
assert equals ( 0 , j ) ;
{ try { segment . put float ( - 1 , 0 . 0f ) ; fail ( index out of bounds exception expected ) ; } catch ( exception e ) { assert true ( e instanceof index out of bounds exception ) ; } try { segment . put float ( page _ size , 0 . 0f ) ; fail ( index out of bounds exception expected ) ; } catch ( exception e ) { assert true ( e instanceof index out of bounds exception ) ; } try { segment . get float ( - 1 ) ; fail ( index out of bounds exception expected ) ; } catch ( exception e ) { assert true ( e instanceof index out of bounds exception ) ; } try { segment . get float ( page _ size ) ; fail ( index out of bounds exception expected ) ; } catch ( exception e ) { assert true ( e instanceof index out of bounds exception ) ; } }
final long time = pause time * 3 + ( ( max wait time num retries ) * 3 ) + 300 ;
if ( debug ) log . v ( tag , abort input : no handler for view ) ; return ; }
assert parent task ( find events ( validate query action . name + [ s ] , tuple : : v1 ) , find events ( validate query action . name , tuple : : v1 ) . get ( 0 ) ) ;
switch ( to delete ) { case xml : expand war . delete ( xml ) ; break ; case ext : expand war . delete ( ext ) ; break ; case war : expand war . delete ( war ) ; break ; case dir : expand war . delete ( dir ) ; break ; default : assert . fail ( ) ; }
assert . assert equals ( consumer impl . get available permits ( ) , num consumers threads ) ; assert . assert equals ( consumer impl . num messages in queue ( ) , recv queue size - num consumers threads ) ; consumer . close ( ) ; }
event . add property ( push _ button _ n , what _ parts [ 0 ] ) ;
a = delta - min delta or zero - min delta or zero ; sets a to math . abs ( a - b )
final path foo = new path ( dir , foo + n ) ;
final big decimal account balance = invoice user api . get account balance ( account id , call context ) ;
if ( partition desc . is empty ( ) & & partition desc from weights . is empty ( ) ) { if ( partition desc . equals ( partition desc from weights ) ) { _ log . error ( inconsistency detected between partition desc and weights , partition desc , weights ) ; } }
} else { mm = hex . model metrics . get from dkv ( model , fr train ) ; } assert . assert equals ( number of trees differs , ntree , model . _ output . _ ntrees ) ; test = parse _ test _ file ( fnametrain ) ; res = model . score ( test ) ;
if ( obj = null & & obj instanceof woman pk ) { woman pk other = ( woman pk ) obj ; return get first name ( ) . equals ( other . get first name ( ) ) & & get last name ( ) . equals ( other . get last name ( ) ) ; } else { return false ; }
push longest path from ( m _ root ) ; m _ started = true ;
in function ( ( x ) = > { var y = 1 ; y ; } , ( x ) = > { x = 1 ; x ; } ) ; in function ( ( x ) = > { let y = 1 ; y ; } , ( x ) = > { x = 1 ; x ; } ) ;
int scroll y = get current scroll y ( ) ;
student oracle no sqlinteger student min = new student oracle no sqlinteger ( ) ;
trigger channel ( harmony hub binding constants . channel _ activity _ started _ trigger , get event name ( activity ) ) ; break ; case hub _ is _ turning _ off :
verify ( port allocator , never ( ) ) . allocate ( any map ( ) , any set ( ) ) ; verify ( supervisor factory ) . create ( eq ( foo _ job ) , any string ( ) , eq ( empty _ port _ allocation ) , any ( supervisor . listener . class ) ) ;
custom date editor editor = new custom date editor ( date format , true ) ;
execution . get connection ( ) . on disconnect ( null ) ;
if ( first call | | can get more data ( next token ) ) {
map < string , object > rev3 properties = new hash map < string , object > ( ) ; rev3 properties . put ( _ id , rev2 . get doc id ( ) ) ; rev3 properties . put ( foo , 2 ) ; rev3 properties . put ( bazz , false ) ; tdrevision rev3 = database . put revision ( new tdrevision ( rev3 properties ) , rev2 . get rev id ( ) , false , status ) ; assert . assert equals ( tdstatus . created , status . get code ( ) ) ; byte [ ] attach2 = < html > and this is attach2 < html > . get bytes ( ) ;
path out = new path ( output dir , source . get name ( ) ) ; log . debug ( copying + source + to + out ) ; file util . copy ( fs , source , fs , out , true , fs . get conf ( ) ) ;
if ( query out = null & & filter out = null ) { query out [ 0 ] = query ; filter out [ 0 ] = filter ; return null ; } else { return searcher . search ( query , filter , num hits ) ; }
string [ ] split = word list anonymizer utility . extract suffix ( data , known _ suffixes ) ;
final int flushed docs = 10 ; final int non flushed docs = random int between ( 0 , 10 ) ; final int num docs = flushed docs + non flushed docs ; shards . index docs ( flushed docs ) ; shards . flush ( ) ; shards . index docs ( non flushed docs ) ; index shard replica = shards . get replicas ( ) . get ( 0 ) ;
if ( branch target finder . is subroutine ( offset ) & & branch target finder . is subroutine returning ( offset ) ) {
request . set servlet path ( foo 1 ) ; request . set request uri ( foo ; test 1 ) ; assert equals ( foo 1 , helper . get request uri ( request ) ) ; }
hook all ( xaudio record . get instances ( ) , null , m secret , false ) ;
assert true ( l1 . tick count . get ( ) < 6 ) ;
project explorer . wait project explorer ( ) ;
site model site = m site store . get site by local id ( get local table blog id ( ) ) ;
wps = new wps info ( ) ;
throw new index out of bounds exception ( the ' item ' index is out of bounds . ) ; }
try { managed conn . close ( ) ; } catch ( ioexception ignored ) {
quota settings settings = quota settings factory . limit table space ( tn , size limit , space violation policy . no _ inserts ) ; test _ util . get admin ( ) . set quota ( settings ) ; quota settings ns settings = quota settings factory . limit namespace space ( tn . get namespace as string ( ) , ns limit , space violation policy . no _ inserts ) ; test _ util . get admin ( ) . set quota ( ns settings ) ;
response challenge response = error response ( response . status . unauthorized . get status code ( ) , invalid _ request , e . get message ( ) ) ; context . failure ( authentication flow error . invalid _ user , challenge response ) ; return ; }
if ( this . entity metadata . get current version field ( ) = null ) { annotation metadata builder request param annotation = new annotation metadata builder ( request _ param ) ; request param annotation . add string attribute ( value , version _ param _ name . get symbol name ( ) ) ; parameter types . add ( new annotated java type ( this . entity metadata . get current version field ( ) . get field type ( ) , request param annotation . build ( ) ) ) ; concurrency control parameter annotation metadata builder concurrency control request param = new annotation metadata builder ( request _ param ) ; concurrency control request param . add string attribute ( value , concurrency ) ; concurrency control request param . add boolean attribute ( required , false ) ; concurrency control request param . add string attribute ( default value , ) ; parameter types . add ( new annotated java type ( java type . string , concurrency control request param . build ( ) ) ) ; } parameter types . add ( new annotated java type ( spring java type . binding _ result ) ) ; parameter types . add ( model _ param ) ; method metadata existing method = get governor method ( method name , annotated java type . convert from annotated java types ( parameter types ) ) ;
adapter . set drop down view resource ( android . r . layout . simple _ spinner _ dropdown _ item ) ;
vector < integer > [ ] n cluster id = new vector [ data . num instances ( ) ] ;
buffer . get ( first , 3 , size of pages ( 10 ) ) . cancel ( true ) ;
scanner = sstable . get scanner ( make ranges ( 1 , 9 , 101 , 109 ) ) ;
final int len = 8196 ;
top nprojection top n = ( top nprojection ) reduce phase . projections ( ) . get ( 2 ) ; assert that ( ( ( input column ) top n . outputs ( ) . get ( 0 ) ) . index ( ) , is ( 0 ) ) ; assert that ( ( ( input column ) top n . outputs ( ) . get ( 1 ) ) . index ( ) , is ( 1 ) ) ; merge phase local merge = plan node . merge phase ( ) ;
vars . set stack frame ( saved start ) ;
if ( m _ index = = 0 ) return ;
unescaped chunk start = next index ;
if ( corbaloc string . ends with ( ) = true ) { corbaloc string = corbaloc string + ; } }
if ( file . exists ( ) ) { try { file = new file ( urlencoder . encode ( jar url . to string ( ) , utf - 8 ) ) ; } catch ( unsupported encoding exception e ) { throw new runtime exception ( unsupported encoding? utf - 8? that ' s unpossible . ) ; } } if ( file . exists ( ) ) { if ( log . is debug enabled ( ) ) { log . debug ( trying real file : + file . get absolute path ( ) ) ; } test url = file . to uri ( ) . to url ( ) ; if ( is jar ( test url ) ) { return test url ; } }
fs permission umask = new fs permission ( mask ) ; return perm . apply umask ( umask ) ;
if ( m max width > 0 ) { width = math . min ( m max width , width ) ; }
m measuring = true ; measure child with margins ( child , get width used ( child ) , get height used ( child ) ) ; m measuring = false ; }
procedure < ? > result = proc exec . get result ( proc id ) ;
generic test utils . assert matches ( logs1 . get output ( ) , creating iostream pair of crypto input stream and crypto output stream . ) ;
my frame . set extended state ( frame . normal ) ; }
{ partitioner < object > part = new partitioner < object > ( ) { @ override public int partition ( object key , int num partitions ) { return 0 ; } } ; requested global properties req left = new requested global properties ( ) ; req left . set custom partitioned ( keys left , part ) ; requested global properties req right = new requested global properties ( ) ; req right . set custom partitioned ( keys right , part ) ; global properties props left = new global properties ( ) ; props left . set custom partitioned ( keys left , part ) ; global properties props right = new global properties ( ) ; props right . set custom partitioned ( keys right , part ) ; assert true ( descr . are compatible ( req left , req right , props left , props right ) ) ; }
rpc manager . invoke remotely async ( collections . singleton list ( member ) , copy , default sync options ) . when complete ( ( responses , throwable ) - > { if ( throwable = null ) { all future . complete exceptionally ( throwable ) ; } else { successful response response = get successful response or fail ( responses , all future , rsp - > all future . complete exceptionally ( outdated topology exception . instance ) ) ; if ( response = = null ) { return ; } object response value = response . get response value ( ) ; merging completable future . move list items to future ( response value , all future , my offset ) ; all future . count down ( ) ; } } ) ;
int fraction digits = 13 ;
if ( is string ( backing type ) ) { expr = expr . plus ( jexpr . lit ( ) ) ; } illegal argument exception . arg ( expr ) ;
add edits ( log , hri , table name , 2 ) ;
v _ 7 = limit - cursor ; lab6 : do {
objects = session . create criteria ( test object . class ) . add ( restrictions . like ( text , pattern ) . ignore case ( ) ) . list ( ) ; assert equals ( 1 , objects . size ( ) ) ;
view group action bar view = ( view group ) decor view . find view by id ( r . id . action _ bar ) ; view home view = action bar view . get child at ( 1 ) ; return home view . find view by id ( r . id . up ) ; }
num filler tokens to insert = math . min ( pos incr att . get position increment ( ) - 1 , max shingle size - 1 ) ;
get context ( ) . get lifecycle strategies ( ) . clear ( ) ;
mock http servlet request request = create request ( foo bar ) ; mock http servlet response response = new mock http servlet response ( ) ; mock filter chain chain = new mock filter chain ( ) ; get proxy ( ) . do filter ( request , response , chain ) ; assert equals ( http servlet response . sc _ forbidden , response . get status ( ) ) ;
if ( child . get area ( ) < optimal . get area ( ) ) { optimal = child ; }
code . put byte ( opcode ) ;
if ( url . index of ( : ) > 0 ) { return url ; } else { return scheme prefix + url ; } }
update ranking ( ) ;
mgr . stop ( ) ; mgr = new mock node label manager ( ) ; mgr . init ( conf ) ; mgr . start ( ) ;
if ( environment util . on mac osx ( ) | | environment util . on minimum osversion ( 10 . 12 ) ) { locale data l = locale data . get ( new locale ( ru , ru ) ) ; assert equals ( воскресенье , l . long weekday names [ 1 ] ) ; assert equals ( вс , l . short weekday names [ 1 ] ) ; assert equals ( вс , l . tiny weekday names [ 1 ] ) ; russian stand - alone weekday names have no initial capital since cldr 28 icu 56 . assert equals ( воскресенье , l . long stand alone weekday names [ 1 ] ) ; assert equals ( вс , l . short stand alone weekday names [ 1 ] ) ; assert equals ( в , l . tiny stand alone weekday names [ 1 ] ) ; }
line number info . u2start pc = new instruction offset ( line number info . u2start pc ) ; }
previous version = persister . get version ( instance ) ;
map name map = member obfuscator . retrieve name map ( descriptor map , descriptor ) ;
long [ ] expected cdf = succeeded cdf ;
out . println ( iframe content ) ; } else {
result = param . compare to ignore case ( alert2 . param ) ; if ( result = 0 ) { return result ; } result = other info . compare to ignore case ( alert2 . other info ) ; if ( result = 0 ) { return result ; }
m action start line = null ; } else if ( view type = = line type . end ) {
if ( boolean . get boolean ( numeric _ points _ sysprop ) ) system . set property ( numeric _ docvalues _ sysprop , true ) ; system . set property ( enable . update . log , false ) ; schema12 doesn ' t support _ version _ init core ( solrconfig . xml , schema12 . xml ) ; }
return m shared preferences . get long ( key , default value ) ;
f intermediary first parameter type = type binding . get type declaration ( ) ;
assert equals ( 1 + ( short ) 1 , exec ( return 1 + ( short ) 1 ; ) ) ;
process queue loop ( key ) ;
if ( inside parenthesis = = 0 ) throw new oserialization exception ( found invalid + embedded _ end + character at position + i + of text + new string ( i source ) + . ensure it is opened and closed correctly . ) ;
path fragment exec path = path fragment . create ( line ) ;
ensure governor has method ( new method metadata builder ( index method ) ) ; ensure governor has method ( new method metadata builder ( accessibility method ) ) ; ensure governor has method ( new method metadata builder ( javasrcript templates method ) ) ;
assert equals ( the information of the provider is not stored properly , contains nothings , purely for testing the class , prov test . get info ( ) ) ;
map < long , abbreviation entry > abbrevs = parse debug abbreviation ( header ) ;
install ( alert module ( ) ) ;
query keys = new array list < byte array > ( ) ;
stored block stored new head = split point ;
alignment = compute alignment ( align ) ; }
ssl context factory . set include cipher suites ( tls _ ecdhe _ rsa _ with _ aes _ 128 _ gcm _ sha256 ) ; return ssl context factory ;
fs wrapper . mkdir ( zone1 , fs permission . get dir default ( ) , true ) ; dfs admin . create encryption zone ( zone1 , test _ key , no _ trash ) ; assert num zones ( + + num zones ) ; assert zone present ( null , zone1 . to string ( ) ) ;
req = new read input discretes request ( ref , count ) ; req . set unit id ( 0 ) ; if ( modbus . debug ) { system . out . println ( request : + req . get hex message ( ) ) ; }
if ( this . watcher = null ) { this . watcher . register listener ( this ) ; look for orphans ( ) ; }
int bind port = - 1 ; try ( server socket socket = new server socket ( 0 ) ) { bind port = socket . get local port ( ) ; } log . info ( selected port + bind port + to start + example name + example solr instance on . . . ) ;
cancel ( reason ) ;
cookie encoder cookie encoder = new cookie encoder ( true ) ;
m wake lock . release ( ) ; return ;
map = transpose ( new int [ ] [ ] { { - 1 , 0 , - 1 , - 1 , - 1 } , { - 1 , 1 , - 1 , - 1 , - 1 } , { - 11 , - 11 , - 11 , - 11 , 4 } , { - 1 , 2 , - 1 , - 1 , - 1 } , { - 1 , 3 , - 1 , - 1 , - 1 } , } ) ;
pushed elements . add ( new method ) ;
assert equals ( 1 , by parent . size ( ) ) ; only one top level task
if ( value < 1 | | value > 12 ) { break parsing ; } }
c . add ( calendar . millisecond , ( int ) millis since nitz received ) ;
spider task task = new spider task ( spider , response message . get request header ( ) . get uri ( ) , uri v , depth , http request header . get ) ;
check assignment ( tt1 , attempt _ test _ 0001 _ r _ 000001 _ 0 on tt1 ) ; check queues order ( qs , scheduler . get ordered queues ( task type . reduce ) ) ;
assert false ( job leader id service . is valid timeout ( job id , last timeout id . get ( ) ) ) ;
delete replica ( 2 , m _ cache . point in time cache ( ) . get ( 2 ) ) ; while ( volt db . was crash called ) { thread . yield ( ) ; } }
path file3 = new path ( user home fullpath . dat ) ; fsdata output stream stm3 = create file ( fs , file3 , 1 ) ; system . out . println ( test file creation namenode restart : + created file + file3 ) ; path file4 = new path ( user home fullpath4 . dat ) ; fsdata output stream stm4 = create file ( fs , file4 , 1 ) ; system . out . println ( test file creation namenode restart : + created file + file4 ) ; fs . mkdirs ( new path ( bin ) ) ;
m manager . stop ( ( w ) this ) ;
if ( _ intr = = null ) { return no _ annotations ; }
for ( cloud stack network network : networks ) { for ( cloud stack network offering required offering : reuquired offerings ) { logger . debug ( [ reqd virtual } offering : + required offering . get id ( ) + network + network . get network offering id ( ) ) ; if ( network . get network offering id ( ) . equals ( required offering . get id ( ) ) ) { return network ; } } }
set content view ( r . layout . content _ frame ) ; get support fragment manager ( ) . begin transaction ( ) . replace ( r . id . content _ frame , m content ) . commit ( ) ;
file doc base file = new file ( doc base ) ;
if ( ( ( aggregate plan node ) aggregate node ) . m _ is coordinating aggregator ) { return false ; } abstract plan node parent = aggregate node . get parent ( 0 ) ;
suite . add test suite ( varargs filter dispatch integration test . class ) ; suite . add test suite ( varargs servlet dispatch integration test . class ) ;
return duration . of seconds ( 1 ) ; }
if ( host header = = null ) { return ; } int port = - 1 ;
if ( is taking snapshot ( snapshot ) ) { snapshot sentinel handler = this . snapshot handlers . get ( snapshot table ) ; throw new snapshot creation exception ( rejected taking + client snapshot description utils . to string ( snapshot ) + because we are already running another snapshot + ( handler = null ? ( on the same table + client snapshot description utils . to string ( handler . get snapshot ( ) ) ) : with the same name ) , protobuf util . create snapshot desc ( snapshot ) ) ; }
java method < object , object > compile method = java reflection util . method ( compiler class , object . class , compile , source file class , source file class , compiler options class ) ;
path file = new path ( p , foo ) ;
dns servers table = new jtable ( dns servers table model ) ; jmeter utils . apply hi dpi ( dns servers table ) ; dns servers table . set selection mode ( list selection model . single _ selection ) ; dns servers table . set preferred scrollable viewport size ( new dimension ( 400 , 100 ) ) ; jpanel panel = new jpanel ( new border layout ( 0 , 5 ) ) ;
string controller path = get controller path ( controller ) ; if ( controller path = = null ) { throw new resource handler exception ( string . format ( controller % s not mounted . + you either need to mount it with % s + or mount cgroups before launching yarn , controller . get name ( ) , yarn configuration . nm _ linux _ container _ cgroups _ mount ) ) ; } file root hierarchy = new file ( controller path ) ;
if ( options . is compress ( ) ) { bitmap = get thumb cache ( file , options ) ; } if ( bitmap = = null ) { bitmap = decode bitmap ( file , options , cancelable ) ;
row id vector [ i ] = synthetic props . row id offset + inner reader . get row number ( ) + i ;
return invoke superclass method impl ( bcm , instance , method name , args ) ; }
select = find view by id ( r . id . select ) ; select . set enabled ( false ) ; find view by id ( r . id . select _ text ) . set enabled ( false ) ; select . set on click listener ( new view . on click listener ( ) { @ override public void on click ( view view ) { intent return intent = new intent ( ) ; return intent . put extra ( latitude , geo data . latitude ) ; return intent . put extra ( longitude , geo data . longitude ) ; set result ( result _ ok , return intent ) ; finish ( ) ; } } ) ; view cancel = find view by id ( r . id . cancel ) ;
collections . shuffle ( handlers ) ;
throw new deployment exception ( sm . get string ( pojo method mapping . duplicate annotation , on message . class , current clazz ) ) ; } } } if ( found ) { on message . add ( message handler ) ; } } else {
if ( current = null ) { buffer . append ( current ) ; } int field id = pattern _ index _ to _ date _ format _ field [ pattern char index ] ;
test property source utils . add inlined properties to environment ( this . environment , spring . profiles . active = other ) ;
if ( current topology = = null ) return ; list < address > new cluster members = transport . get members ( ) ;
if ( ret instanceof return control ) break ; } } finally { make sure we put the namespace back when we leave . if ( override namespace ) callstack . swap ( enclosing name space ) ; } return ret ; }
injector . get instance ( indices cluster state service . class ) . stop ( ) ;
if ( remove exact match covered expressions ( covering expr , exprs to cover ) ) { exact match covering exprs . add ( covering expr ) ; }
assert equals ( 18 , get number of files and directories in ( folder . get root ( ) ) ) ; }
entries . remove ( entry ) ;
if ( wcfg . use regions & & wcfg . explosion flag cancellation ) { if ( plugin . get region container ( ) . create query ( ) . get applicable regions ( defender . get location ( ) ) . test state ( null , default flag . other _ explosion ) ) { event . set cancelled ( true ) ; return ; } } }
this . removes null and revoked control peer ( peer . get peer id ( ) ) ;
final int idx = normalised index ; delegate . add ( idx , get default value ( idx ) ) ;
return create title subtree ( book . first title letter ( ) ) ; } else { boolean changed = remove book ( book ) ; changed | = create book with authors subtree ( book ) ; return changed ; } default : return super . on book event ( event , book ) ; } }
object schema . get tables ( session . get progress monitor ( ) ) ;
identity hashtable entry e = new identity hashtable entry ( ) ; e . hash = hash ; e . key = key ; e . value = value ; e . next = tab [ index ] ; tab [ index ] = e ; count + + ; return null ;
version of offline node = zkassign . create or force node offline ( master . get zoo keeper ( ) , state . get region ( ) , this . master . get server name ( ) , hijack , allow znode creation ) ;
if ( root _ element _ delivery . equals ( reader . get local name ( ) ) ) { throw unexpected element ( reader ) ; } ejbbound mdb delivery meta data meta data = new ejbbound mdb delivery meta data ( ) ; process elements ( meta data , reader , property replacer ) ; return meta data ; }
disk limit type disk limit config = disk limit ; if ( disk limit config = = null ) { return ; } list < disk limit type . feature > features = disk limit config . get feature ( ) ;
return m scale state . m drawable . get padding ( padding ) ;
if ( layer definition filter = = null ) { layer definition filter = filter . include ; } combined = ff . and ( layer definition filter , user requested filter ) ; feature type constraint [ ] feature type constraints = layer . get layer feature constraints ( ) ;
s = open session ( ) ; t = s . begin transaction ( ) ; s . delete ( gavin ) ; s . delete ( steve ) ; s . delete ( max ) ; s . delete ( emmanuel ) ; s . delete ( hibernate ) ; t . commit ( ) ; s . close ( ) ; }
assert . assert equals ( 200 , response . get status ( ) ) ;
try { client . call ( new long writable ( random . next long ( ) ) , addr , null , null , min _ sleep _ time 2 , false ) ; fail ( expected an exception to have been thrown ) ; } catch ( socket timeout exception e ) { log . info ( get a socket timeout exception , e ) ; }
map < byte [ ] , index specification > index map = new tree map < byte [ ] , index specification > ( bytes . bytes _ comparator ) ;
log manager . get log manager ( ) . reset ( ) ;
if ( data [ 2 ] = = 0 ) { no1 f1 activity sample sample = new no1 f1 activity sample ( ) ; sample . set timestamp ( ( int ) ( gregorian calendar . get instance ( ) . get time in millis ( ) 1000 l ) ) ; sample . set heart rate ( data [ 3 ] & 0xff ) ; log . info ( current heart rate is : + sample . get heart rate ( ) + bpm ) ; try ( dbhandler db handler = gbapplication . acquire db ( ) ) { long user id = dbhelper . get user ( db handler . get dao session ( ) ) . get id ( ) ; long device id = dbhelper . get device ( get device ( ) , db handler . get dao session ( ) ) . get id ( ) ; no1 f1 sample provider provider = new no1 f1 sample provider ( get device ( ) , db handler . get dao session ( ) ) ; sample . set device id ( device id ) ; sample . set user id ( user id ) ; provider . add gbactivity sample ( sample ) ; } catch ( exception ex ) { log . warn ( error saving current heart rate : + ex . get localized message ( ) ) ; } }
if ( capacity < = max _ buffer _ size - capacity ) { capacity = math . max ( capacity < < 1 , buffer _ size ) ; } else { if ( capacity = = max _ buffer _ size ) throw new out of memory error ( required array size too large ) ; capacity = max _ buffer _ size ; } buf = arrays . copy of ( buf , capacity ) ; buf [ nread + + ] = ( byte ) n ; }
for ( int i = textures loaded . size ( ) - 1 ; i > = 0 ; i - - ) { final itexture texture to be reloaded = textures loaded . get ( i ) ; if ( texture to be reloaded . is update on hardware needed ( ) ) { try { texture to be reloaded . reload to hardware ( p glstate ) ; } catch ( final ioexception e ) { debug . e ( e ) ; } } }
synchronized ( this ) { return new permissions enumerator ( perms map . values ( ) . iterator ( ) ) ; } }
& & ( i < tokens . length - 2 ) & & match postag regexp ( tokens [ i + 2 ] , infinitivo ) & & m excepcoes de . matches ( ) & & tokens [ i - 1 ] . has pos tag ( rg ) ) { replacement = relevant words . get ( token ) . get token ( ) ; }
if ( start < = index & & index < start + capacity ) { non - wrapping , or head ( right side ) of wrapping case return true ; } else if ( start + capacity > total _ size & & index < ( start + capacity ) % total _ size ) { tail ( left side ) of wrapping case return true ; } return false ; }
query write query = get write query ( policy ) ;
check sub cluster id ( sub cluster info . get sub cluster id ( ) ) ;
return list objs ; }
lock exception expected exception = null ;
resource resource = _ factory . get resource ( path in context ) ; http content loaded = load ( path in context , resource , max buffer size ) ; return loaded ; }
string filetype = matcher . group ( 0 ) ;
channel buffer slice = current buffer ;
r = run unguarded ( clazz , run m ) ; assert contains ( test invocation handler1 . invoke ( ) for m , r . stdout ) ; type registry tr = type registry . get type registry for ( bin loader ) ;
if ( cause . is permanent fail ( ) ) apn context . dec waiting apns perm fail count ( ) ; apn context . remove next waiting apn ( ) ; if ( dbg ) { log ( string . format ( on data setup complete : waiting apns . size = % d + waiting apns perm failure count down = % d , apn context . get waiting apns ( ) . size ( ) , apn context . get waiting apns perm fail count ( ) ) ) ; }
add result = security . add provider ( entrust ) ; assert true ( failed to add provider , add result = - 1 ) ; security . remove provider ( entrust . get name ( ) ) ; for ( provider provider : security . get providers ( ) ) { assert true ( the provider entrust is found after it was removed , provider . get name ( ) = entrust . get name ( ) ) ; }
operation service operation service = get operation service ( hazelcast instances [ 1 ] ) ; metrics registry metrics registry = get metrics registry ( hazelcast instances [ 1 ] ) ; assert equals ( 0 l , operation service accessor . get failed backups count ( hazelcast instances [ 1 ] ) . get ( ) ) ; map < string , string > entries = new hash map < string , string > ( ) ; entries . put ( key , random string ( ) ) ; cache . put all ( entries ) ; assert null ( cache . get ( key ) ) ;
to state = from state ; threshold to animate = previous passed threshold ; } animation manager . animate threshold ( threshold to animate , from state , to state ) ; }
byte [ ] header map bytes ; try ( input stream header map input stream = project filesystem . new file input stream ( root . resolve ( . hmap ) ) ) { header map bytes = byte streams . to byte array ( header map input stream ) ; } return header map . deserialize ( header map bytes ) ; }
field type custom type = new field type ( text field . type _ stored ) ;
final long expected = write strings [ i ] . length ( ) + append strings [ i ] . length ( ) ;
if ( this time < compare time ) { return true ; }
client response resp = m _ client . call procedure ( @ system catalog , tables ) ; system . out . println ( resp . get results ( ) [ 0 ] ) ; assert true ( find table in system catalog results ( dropme ) ) ;
if ( child instanceof folder icon ) { ( ( folder icon ) child ) . set text visible ( true ) ; }
response cache . add row split ( matrix client . get row split ( part list . get ( i ) , row index , clock ) ) ;
one loop . add ( first vertex ) ; if ( size of hole > 0 ) { hole . add ( hole first vertex ) ; } list < list < geography point value > > loops = new array list < > ( ) ; loops . add ( one loop ) ; if ( size of hole > 0 ) { loops . add ( hole ) ; } return new geography value ( loops ) ;
return ( ) - > arrays . stream ( facet field . facet method . values ( ) ) . map ( it - > new object [ ] { it } ) . iterator ( ) ; }
assert false ( reader . advance ( ) ) ;
for ( secondary table tab : sec tables . value ( ) ) { add join ( tab , null , null , false ) ; } }
assert true ( android platform target . get bootclasspath entries ( ) . contains ( add ons libs dir2 . to path ( ) . resolve ( effects . jar ) . to absolute path ( ) ) ) ;
if ( this . is active ( ) ) { return ; }
if ( cursor < i _ p1 ) { return false ; } cursor = i _ p1 ; v _ 3 = limit _ backward ; limit _ backward = cursor ; cursor = limit - v _ 2 ;
assert that ( pe . matches ( \ u4 f60 \ u597d , 7eca689f0d3389d9dea66ae112e5cfd7 ) ) . is true ( ) ;
m action menu presenter . set width limit ( get context ( ) . get resources ( ) . get display metrics ( ) . width pixels , true ) ;
entry set = sub map _ start excluded _ end excluded _ comparator . entry set ( ) ;
person person = new person ( 1 l ) ; entity manager . persist ( person ) ; person . add phone ( new phone ( 1 l , landline , 028 - 234 - 9876 ) ) ; person . add phone ( new phone ( 2 l , mobile , 072 - 122 - 9876 ) ) ;
while ( x > 0 ) { buf [ - - i ] = character . for digit ( ( int ) ( x % radix ) , radix ) ; x = radix ; } }
restart ( ) ; wait procedure ( proc id ) ; procedure testing utility . assert proc not yet completed ( proc executor , proc id ) ; assert false ( proc executor . is running ( ) ) ;
iterable < test rule > test rules = iterables . filter ( action graph and resolver . get action graph ( ) . get nodes ( ) , test rule . class ) ;
int sub normal factor = integer . number of leading zeros ( bits & float . sign _ mask ) - float . non _ mantissa _ bits ; if ( sub normal factor < 0 ) { not sub - normal values sub normal factor = 0 ; } else { factor = factor - sub normal factor ; } if ( factor > float . max _ exponent ) { return ( d > 0 ? float . positive _ infinity : float . negative _ infinity ) ; }
qname end element name = f element stack . pop element ( ) ;
return pending messages ( conn , resp ) ;
new tuple ( 0x00000000 l , 0x00000001 l , - 1 ) ,
get failed indeces list ( ) . add ( song index ) ;
if ( context . get process engine configuration ( ) . get event dispatcher ( ) . is enabled ( ) ) { context . get process engine configuration ( ) . get event dispatcher ( ) . dispatch event ( activiti event builder . create entity event ( activiti event type . task _ created , task ) ) ; } if ( skip user task ) { task entity manager . delete task ( task , null , false , false ) ; leave ( execution ) ; }
return working copy ;
send produce response ( errors . none , pid , epoch ) ;
send produce response ( errors . none , pid , epoch ) ;
statement . set null ( prepared patam index + 1 , types . bigint ) ; } else { statement . set long ( prepared patam index + 1 , column . as long ( ) ) ; } break ; case types . float : case types . double : string float value = column . as string ( ) ; if ( empty as null & & . equals ( float value ) | | float value = = null ) {
m titles = get resources ( ) . get string array ( r . array . mp _ main _ titles ) ;
throw new illegal argument exception ( unsupported request type + request . get class ( ) . get name ( ) ) ;
if ( search name = = null ) {
builder . put int32 to int32 field ( 4 , 44 ) ;
return s3 client . get object ( object . get bucket name ( ) , object . get key ( ) ) . get data input stream ( ) ;
immutable set < string > set = immutable set . of ( a , b , c , c , c , c , b , b , a , a , c , c , c , a ) ;
span query btq = new payload score query ( new span term query ( new term ( field name , value ) ) , new average payload function ( ) , payload decoder . float _ decoder ) ; btq = new span boost query ( btq , domutils . get attribute ( e , boost , 1 . 0f ) ) ; return btq ; }
client . set timeout ( 1 , time unit . seconds ) ; client . connect ( ) ; client . send standard request ( ) ; http response resp = client . expect upgrade response ( ) ; assert . assert that ( response , resp . get extensions header ( ) , contains string ( fragment ) ) ;
if ( parameter . get position ( ) = null ) { final query parameter binding binding = locate binding ( parameter . get position ( ) ) ; if ( binding = null ) { return binding ; } } return null ; }
ret . clear ( ) ;
assert rows ( execute ( select * from % s where k = 1 ) , row ( 1 , foo , null ) ) ;
when ( _ filter . on request ( any ( filter request context . class ) ) ) . then return ( completable future . completed future ( null ) ) ;
view next title = get child at ( m selected position + 1 ) ;
assert equals ( test _ size - 1 , results . last ( ) . get field long ( ) ) ; realm results < all java types > reverse list = realm . where ( all java types . class ) . find all sorted ( all java types . field _ long , sort . descending ) ; assert equals ( test _ size , reverse list . size ( ) ) ;
new key value ( rows _ two [ 2 ] , families [ 0 ] , qualifiers _ two [ 0 ] , values [ 1 ] ) , new key value ( rows _ two [ 2 ] , families [ 0 ] , qualifiers _ two [ 3 ] , values [ 1 ] ) , new key value ( rows _ two [ 2 ] , families [ 1 ] , qualifiers _ two [ 0 ] , values [ 1 ] ) , new key value ( rows _ two [ 2 ] , families [ 1 ] , qualifiers _ two [ 3 ] , values [ 1 ] ) ,
final optional < student > student to be found = mapper . find ( student . get student id ( ) ) ; log . debug ( app . main ( ) , student : + student to be found + , is searched ) ;
list < string > binded settings = notebook . get binded interpreter settings ids ( note1 . get id ( ) ) ; notebook . bind interpreters to note ( anonymous . get user ( ) , note1 . get id ( ) , new linked list < string > ( ) ) ; notebook . bind interpreters to note ( anonymous . get user ( ) , note1 . get id ( ) , binded settings ) ; note1 . run ( p1 . get id ( ) ) ; while ( p1 . get status ( ) = status . finished ) thread . yield ( ) ;
at beginning = true ;
on view ( all of ( with text ( m menu string content . get ( r . id . destination _ settings ) ) , is descendant of a ( with id ( r . id . start _ drawer ) ) ) ) . perform ( click ( ) ) ;
if ( is wait ( c next ) & & is pause ( c next ) ) { break ; }
required not null ( parameters , factory build parameters ) ;
entry tab [ ] = table ; int hash = key ; int index = ( hash & 0x7 fffffff ) % tab . length ; for ( entry e = tab [ index ] ; e = null ; e = e . next ) { if ( e . hash = = hash ) { object old = e . value ; e . value = value ; return old ; } } if ( count > = threshold ) { rehash the table if the threshold is exceeded rehash ( ) ; tab = table ; index = ( hash & 0x7 fffffff ) % tab . length ; }
vertex . query ( ) . properties ( ) . iterator ( ) . has next ( ) ;
write attribute ( connection _ address , constants . min _ pool _ size . get name ( ) , 4 ) ; write attribute ( connection _ address , constants . max _ pool _ size . get name ( ) , 10 ) ; write attribute ( connection _ address , constants . initial _ pool _ size . get name ( ) , 6 ) ; write attribute ( connection _ address , constants . blocking _ timeout _ wait _ millis . get name ( ) , 10000 ) ; write attribute ( connection _ address , constants . pool _ fair . get name ( ) , false ) ; write attribute ( connection _ address , constants . pool _ use _ strict _ min . get name ( ) , true ) ;
assert true ( all _ type . is nullable ( ) ) ;
for ( plan fragment f : select stmt . get fragments ( ) ) { if ( i = 0 ) select bottom frag = f ; i + + ; }
collections . sort ( time series list , collections . reverse order ( new time series start time comparator ( ) ) ) ;
log . debug ( invoke oem ril request raw : byte - list response length = 0 ) ;
throw e ; } } if ( image = null ) image icon = scale image within bounds ( image , width , height ) ; else if ( logger . is trace enabled ( ) ) logger . trace ( unknown image format or error reading image ) ; }
sink . manual bulk request with all pending requests ( ) ; try { test harness . process element ( new stream record < > ( next msg ) ) ; } catch ( exception e ) { the invoke should have failed with the failure assert . assert true ( e . get cause ( ) . get message ( ) . contains ( artificial failure for record ) ) ; test succeeded return ; }
out . add ( federation policies test util . create resource request ( 1 l , subcluster1 - rack1 - host1 , 1024 , 1 , 1 , 1 , null , false ) ) ;
terms enum te = terms . iterator ( ) ;
gles20 . gl pixel storei ( gles20 . gl _ unpack _ alignment , 1 ) ; } if ( pre multipy alpha ) { glutils . tex sub image2 d ( gles20 . gl _ texture _ 2 d , 0 , bitmap texture atlas source . get texture x ( ) , bitmap texture atlas source . get texture y ( ) , bitmap , gl format , gl type ) ; } else { p glstate . gl tex sub image2 d ( gles20 . gl _ texture _ 2 d , 0 , bitmap texture atlas source . get texture x ( ) , bitmap texture atlas source . get texture y ( ) , bitmap , this . m pixel format ) ; } if ( use default alignment ) {
f namespace [ f namespace size + + ] = prefix ; f namespace [ f namespace size + + ] = uri ; return true ;
string def reservation id = get reservation id from queue name ( plan queue name ) + reservation constants . default _ queue _ suffix ;
if ( original vault . get ( keystore _ url ) = null & & original vault . has defined ( keystore _ url ) ) { set < string > original vault param = original vault . keys ( ) ; iterator < string > it = original vault param . iterator ( ) ; op = util . create add operation ( vault _ path ) ; model node vault option = op . get ( vault _ options ) ; while ( it . has next ( ) ) { string param = ( string ) it . next ( ) ; vault option . get ( param ) . set ( original vault . get ( param ) ) ; } core utils . apply update ( op , management client . get controller client ( ) ) ; }
groupby col . table name = temp _ table _ name ;
if ( debug ) system . out . println ( active incremental saxsource _ filter normal stop exception ) ;
when ( thing . get configuration ( ) ) . then answer ( a - > { configuration conf = new configuration ( ) ; conf . put ( network binding constants . parameter _ hostname , 127 . 0 . 0 . 1 ) ; return conf ; } ) ; handler . initialize ( new presence detection ( handler , 2000 ) ) ;
dst [ dpos + + ] = _ base64en [ 0x30 & ( b0 < < 4 ) ] ; dst [ dpos + + ] = 61 ; } else {
ahmucevent collector collector user1 = new ahmucevent collector ( room user1 , ahmucevent collector . message _ event ) ; ahmucevent collector collector user2 = new ahmucevent collector ( room user2 , ahmucevent collector . message _ event ) ;
return allocate page ( size , consumer ) ;
int left page index ;
base . set value ( 1803 - 01 - 02 t10 : 20 : 30 z ) . set exists ( true ) ;
return type class = null ; ref constant . referenced member accept ( this ) ; return value factory . create value ( type , return type class , true ) ; }
close declaration with comment binders ( entry , enum _ entry , true ) ; return semicolon found ? parse enum entry result . semicolon _ delimiter : ( comma found ? parse enum entry result . comma _ delimiter : parse enum entry result . no _ delimiter ) ; }
assert false ( string _ object _ type . can be called ( ) ) ;
summary . get snapshot counts ( ) . add contents ( counts ) ;
list < person > people = as list ( new person ( charles babbage , 45 , new address ( 5 devonshire street , london , w11 ) ) , new person ( alan turing , 28 , new address ( bletchley hall , bletchley park , mk12 ) ) , new person ( timothy berners - lee , 61 , new address ( colehill , wimborne , null ) ) ) ; final count down latch count latch = new count down latch ( 1 ) ;
shell . set development mode ( osgi utils . is development mode ( context ) ) ; }
suite . add test suite ( binary get command unit test . class ) ;
for ( string p : arrays . as list ( name , version , arch ) ) { assert equals ( info . get ( p ) , info2 . get ( p ) ) ; }
mul ( t2 , t3 , t1 ) ; * 2 ^ 250 - 2 ^ 0 *
set < entity type > handled = new hash set < entity type > ( ) ;
for ( cached item block : multi blocks ) { cache . cache block ( block . cache key , block ) ; expected cache size + = block . cache block heap size ( ) ; assert equals ( cache . get block ( block . cache key , true , false ) , block ) ; }
path small ecfile = new path ( ec dir , small ecfile . txt ) ; fsdata output stream out = hdfs . create ( small ecfile ) ; random r = new random ( ) ; byte [ ] bytes = new byte [ 1024 * 10 ] ; r . next bytes ( bytes ) ; out . write ( bytes ) ; written files . put ( small ecfile . to string ( ) , path to file entry ( hdfs , small ecfile . to string ( ) ) ) ; files eccount + + ;
set < string > hourly segments to delete = new tree set < > ( ) ; for ( string segment name : is . get partition set ( ) ) { log . info ( segment name { } , segment name ) ; if ( segment name . index of ( hourly ) > - 1 ) { string [ ] splits = segment name . split ( _ ) ; string end day = splits [ splits . length - 2 ] . substring ( 0 , yyyy - mm - dd . length ( ) ) ; string start day = splits [ splits . length - 3 ] . substring ( 0 , yyyy - mm - dd . length ( ) ) ; log . info ( start : { } end : { } , start day , end day ) ; if ( days with daily segments . contains ( start day ) ) { hourly segments to delete . add ( segment name ) ; } } } log . info ( hourly segments that can be deleted : { } , hourly segments to delete . size ( ) ) ; log . info ( hourly segments to delete { } , hourly segments to delete . to string ( ) . replace all ( , , \ n ) ) ; ideal state new ideal state = new ideal state ( is . get record ( ) ) ; for ( string hourly segment to delete : hourly segments to delete ) { new ideal state . get record ( ) . get map fields ( ) . remove ( hourly segment to delete ) ; } return new ideal state ;
nm1 . node heartbeat ( am . get application attempt id ( ) , 1 , container state . complete ) ;
if ( ssa regs mapped . get ( source reg ) ) { map set . add ( mapper . old to new ( source reg ) ) ; } else { ssa regs . add ( source def ) ; }
reader reader = resources . get resource as reader ( org apache ibatis submitted inheritance mybatis - config . xml ) ; sql session factory = new sql session factory builder ( ) . build ( reader ) ; reader . close ( ) ;
set record ( page cache , neo store , last _ transaction _ id , tx id ) ;
set default gravity ( center view , m center gravity ) ; set default text gravity ( center view , m center text gravity ) ; set default drawable ( center view . get center text view ( ) , m center tv drawable left , m center tv drawable right , m text view drawable padding , m center tv drawable width , m center tv drawable height ) ; set default background ( center view . get center text view ( ) , m center text background ) ; set default string ( center view , m center top text string , m center text string , m center bottom text string ) ; add view ( center view ) ; }
arg1 column = - 1 ; arg2 scalar = null ; arg3 column = - 1 ; }
store current buffer ( true ) ;
if ( build . version . sdk _ int < build . version _ codes . m ) { return true ; } for ( string permission : permissions ) { final int result = check self permission ( permission ) ; if ( result = package manager . permission _ granted ) { return false ; } }
assert equals ( before , new string ( utf8 . get bytes ( before ) , utf - 8 ) ) ;
assert equals ( hello b , template . request body ( direct : start2 , b ) ) ;
assert that ( entity . many entities , not null value ( ) ) ; assert that ( entity . many entities . size ( ) , is ( 1 ) ) ; final many filterings sub entity many filterings sub entity = entity . many entities . get ( 0 ) ; assert that ( many filterings sub entity . field1 , is ( 60 ) ) ; assert that ( many filterings sub entity . field2 , is ( 0 ) ) ; assert that ( many filterings sub entity . get property1 ( ) , is ( property1 ) ) ; assert that ( many filterings sub entity . get property2 ( ) , null value ( ) ) ; }
for ( timeline entity entity : result ) { if ( entity . get id ( ) . equals ( id _ 1 ) & & entity . get id ( ) . equals ( id _ 3 ) ) { assert . fail ( incorrect filtering based on is related to ) ; } }
try { unsigned ints . parse unsigned int ( 0 , character . min _ radix - 1 ) ; fail ( ) ; } catch ( number format exception expected ) { } try { unsigned ints . parse unsigned int ( 0 , character . max _ radix + 1 ) ; fail ( ) ; } catch ( number format exception expected ) { }
date d1 = new date ( 70 , 0 , 1 , 1 , 1 , 1 ) ;
get job ( ) . set job priority ( priority from response ) ; }
value = function . reduce ( value , reuse2 ) ;
return database . save ( ( orecord ) new odocument ( ) . from json ( i string , true ) ) ;
while ( true ) { index = uri bc . index of ( . , 0 , 3 , index ) ; if ( index < 0 ) { break ; } copy bytes ( b , start + index , start + index + 2 , end - start - index - 2 ) ; end = end - 2 ; uri bc . set end ( end ) ; } index = 0 ;
{ error msg . internal _ err , errore interno xsltc irreversibile : ' ' { 0 } ' ' } ,
a = wrapped buffer ( new byte [ ] { 1 , 2 , 3 } ) . order ( order ) ; b = wrapped buffer ( wrapped buffer ( new byte [ ] { 1 , 2 } , new byte [ 1 ] ) ) . order ( order ) ; c = wrapped buffer ( new byte [ ] { 4 } ) . order ( order ) ;
assert . assert equals ( content . ref cnt ( ) , 0 ) ; ch . finish ( ) ; }
string subsystem xml = get subsystem xml ( ) ; kernel services services a = this . create kernel services builder ( ) . set subsystem xml ( subsystem xml ) . build ( ) ; model node read operation = get cache read operation ( maximal , local cache resource definition . wildcard _ path . get key ( ) , local , cache resource definition . attribute . statistics _ enabled ) ;
this . types . put all ( temp types ) ;
for ( int part idx = 0 ; part idx < partitions being built . size ( ) ; part idx + + ) { final hash partition < bt , pt > p = partitions being built . get ( part idx ) ; p . prepare probe phase ( io manager , current enumerator , write behind buffers ) ; }
return true ; } else if ( backoff handler . handle response ( request , response , supports retry ) ) {
content . get lifecycle ( ) . get dispatched event handlers ( ) . clear ( ) ; litho view . perform incremental mount ( new rect ( left , 4 , right , 10 ) , true ) ; assert that ( content . get lifecycle ( ) . get dispatched event handlers ( ) ) . contains only ( focused handler ) ;
this . set drawer header image ( r . drawable . mat2 ) ;
assert equals ( r4 , queue . offer ( r5 , 0 ) ) ; assert equals ( r1 , queue . take ( ) ) ; assert equals ( r3 , queue . take ( ) ) ; assert equals ( r5 , queue . take ( ) ) ; assert equals ( r2 , queue . take ( ) ) ; r1 = create task wrapper ( create submit work request proto ( 1 , 2 , 100 , 200 , q1 ) , true , 100000 ) ;
if ( potential match files . size ( ) < min files ) { continue ; }
default : throw new json parse exception ( jp , unexpected token : + token . to string ( ) ) ; } }
result best exact = parse ( word end + 1 , word end + 1 , cache ) ; if ( valid exact ) { best exact . parsed = current word + + best exact . parsed ; } else { best exact . invalid + = current word . length ( ) ; best exact . parsed = current word . to upper case ( ) + + best exact . parsed ; }
get log ( ) . debug ( service is not reachable anymore ( + ex . get message ( ) + ) ) ;
try { coordinator admin command . execute command ( new string [ ] { put , - d , config avro2 , - u , admin _ url , - - confirm } ) ; } catch ( exception e ) { e . print stack trace ( ) ; }
cluster block exception e = expect throws ( cluster block exception . class , ( ) - > { client ( ) . prepare index ( test1 , type1 ) . set source ( field , value ) . get ( ) ; } ) ; assert that ( e . get message ( ) , contains string ( blocked by : [ bad _ request 11 tribe node , write not allowed ] ) ) ; e = expect throws ( cluster block exception . class , ( ) - > client ( ) . prepare index ( test2 , type2 ) . set source ( field , value ) . get ( ) ) ; assert that ( e . get message ( ) , contains string ( blocked by : [ bad _ request 11 tribe node , write not allowed ] ) ) ; e = expect throws ( cluster block exception . class , ( ) - > client ( ) . admin ( ) . indices ( ) . prepare force merge ( test1 ) . get ( ) ) ; assert that ( e . get message ( ) , contains string ( blocked by : [ bad _ request 10 tribe node , metadata not allowed ] ) ) ; e = expect throws ( cluster block exception . class , ( ) - > client ( ) . admin ( ) . indices ( ) . prepare force merge ( test2 ) . get ( ) ) ;
result = 1 ;
a . write object ( object ) ; a . flush ( ) ; a . close ( ) ; this . content = b . to byte array ( ) ; b . close ( ) ;
p = loader . load properties ( class array , properties , true ) ; list < string > paths = p . get ( platform . resourcepath ) ; path directory = f . get parent file ( ) . to path ( ) ;
if ( ns attr = null ) body . append ( ns attr ) ;
case symbol : if ( join non word chars & & i = pos ) return i ;
int idx = buffer . reader index ( ) ;
string input = java somefolder badfolder somefile . java ; path input path = filesystem . get path ( input ) ;
for ( path p : paths ) { if ( is not root ( p ) ) { perform a mkdir operation without any polling of the far end first force mkdir ( p ) ; } }
locator class = ( class < ? > ) sub resource instance ;
final metadata item metadata item = get metadata service ( ) . get ( upstream dependency ) ;
map sorted map = new linked hash map < long , long > ( ) ; for ( map . entry < iced long , iced long > entry : list ) { sorted map . put ( entry . get key ( ) . _ val , entry . get value ( ) . _ val ) ; } return sorted map ; }
greeting map . put ( null , null ) ;
quaternion q = link . rigid body . get motion state ( ) . get world rotation quat ( ) ;
my generator . add event source ( conveyor + i , new production event ( res . get id ( ) ) , min _ occur _ production _ event , avg _ occur _ production _ event , 0 , 0 ) ; }
elements . get document ( ) . remove event listener ( event . mousedown , this . popup listener ) ; }
while ( mouse . next ( ) ) ;
char buffer cbuf = char buffer . wrap ( abc ) ;
default secure random = result = new secure random ( ) ;
cluster . start data nodes ( conf , 1 , true , null , new string [ ] { new rack } , new long [ ] { new capacity } , new string [ ] { new node group } ) ; total capacity + = new capacity ;
cache embedded cache = cache factory2 . get embedded cache ( ) . get advanced cache ( ) . with encoding ( identity encoder . class ) ;
type t0 = ta , t1 = tb ; shorter type in t0
oetlcommand transformer tr = new oetlcommand transformer ( ) ; odocument cnf = new odocument ( ) . field ( language , sql ) . field ( log , info ) . field ( output , prev ) . field ( command , select name from person where surname = \ = { eval ( ' input . surname ' ) } \ ) ;
val = val . subtract ( ulong _ max ) ;
int pos ;
if ( default map options = null ) { simulated conf . set ( mrjob config . map _ java _ opts , default map options ) ; }
if ( uri . get scheme ( ) = = null ) return new path ( uri . get path ( ) ) ;
program method . attributes accept ( program class , this ) ;
set timestamp ( math . round ( 1000000 l * frame number get frame rate ( ) ) ) ; }
content handler . end document ( ) ;
m image container = new container ;
simple cache = get encrypted simple cache ( key ) ;
a = wrapped buffer ( new byte [ ] { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 } ) ; b = wrapped buffer ( new byte [ ] { 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 } , 1 , 10 ) ; assert true ( channel buffers . equals ( a , b ) ) ;
collection < class or interface type details > item controllers = get controller locator ( ) . get controllers ( entity , controller type . item , view type ) ;
byte enc data [ ] = ctx . el gamal aesengine ( ) . encrypt ( clove set , target , encrypt key , wrapped tags , encrypt tag , 128 ) ; msg . set data ( enc data ) ; msg . set message expiration ( config . get expiration ( ) ) ; long time from now = config . get expiration ( ) - ctx . clock ( ) . now ( ) ;
create symlink with target file ( new folder ) ; create symlink with target folder ( new folder ) ; create symlink with non existing target ( new folder ) ;
node value node = n . get first child ( ) ;
assert true ( retval , dis . read ( b array , i * chunk _ size , chunk _ size ) = = chunk _ size ) ; }
scratch dir path = new path ( hive conf . get var ( conf , hive conf . conf vars . scratchdir ) + + user name ) ; verify scratch dir ( conf , fs , scratch dir path , expected fspermission , user name , false ) ;
return jar resources . get resource ( class name ) ;
dfstest util . create file ( fs , new path ( zone , success1 ) , 0 , ( short ) 1 , 0x feed ) ;
consumer1 sub3 = ( consumer impl ) pulsar client . subscribe ( topic name , subscriber name3 , conf ) ;
create payment ( account1 , transaction type . authorize , null , null , auth key , big decimal . ten , payment plugin status . processed ) ;
sm . add script ( script builder . replace method call ( ) . target ( new method target ( org . eclipse . jdt . internal . corext . refactoring . structure . extract interface processor , create member declarations ) ) . target ( new method target ( org . eclipse . jdt . internal . corext . refactoring . structure . extract interface processor , create method comments ) ) . method to replace ( new hook ( org . eclipse . jdt . internal . corext . refactoring . structure . astnode search util , get method declaration node , org . eclipse . jdt . core . dom . method declaration , org . eclipse . jdt . core . imethod , org . eclipse . jdt . core . dom . compilation unit ) ) . replacement method ( new hook ( lombok . launch . patch fixes hider patch fixes , get real method declaration node , org . eclipse . jdt . core . dom . method declaration , org . eclipse . jdt . core . imethod , org . eclipse . jdt . core . dom . compilation unit ) ) . transplant ( ) . build ( ) ) ;
accumulo row serializer serializer = mockito . mock ( accumulo row serializer . class ) ; string object = hello ;
single input plan node sum reducer = ( single input plan node ) ss join . get input1 ( ) . get source ( ) ; single input plan node gather mapper = ( single input plan node ) sum reducer . get input ( ) . get source ( ) ; dual input plan node edge join = ( dual input plan node ) gather mapper . get input ( ) . get source ( ) ; assert equals ( default _ parallelism , edge join . get parallelism ( ) ) ;
logger . log ( property table level , = = = { 0 } ( logging . xml : { 1 } , jdbcconfig : { 2 } ) , new object [ ] { read . get name ( ) , old val , new val } ) ; } else {
jedis jedis = new jedis ( rediss : localhost : 6390 ) ;
array list < attribute source > generated = new array list < attribute source > ( result . synonyms . length + matched . size ( ) + 1 ) ;
set . put ( build general position property ( node , x ) ) ;
descriptor desc = mbean attribute . get descriptor ( ) ; desc . set field ( mask , info . is mask ( ) ? true : false ) ;
jmethod method = holder . get generated class ( ) . method ( static | public , holder . get intent builder class ( ) , intent ) ; jvar fragment param = method . param ( get classes ( ) . fragment , fragment ) ; method . body ( ) . _ return ( _ new ( holder . get intent builder class ( ) ) . arg ( fragment param ) ) ; }
expect throws ( illegal state exception . class , ( ) - > { new index revision ( writer ) ; } ) ; writer . close ( ) ;
set < job > jobs = text utils . is empty ( tag ) ? get all jobs ( ) : get all jobs for tag ( tag ) ;
t1 . unblock ( ) ; thread0 . join ( ) ; }
return t < string > run result = xxl job trigger . run executor ( trigger param , address ) ;
node actual = parse ( var foo , goo , hoo ) ; node var node = actual . get first child ( ) ;
try { return account user api . get account by key ( account json . get external key ( ) , call context ) ; } catch ( final account api exception ignore ) { }
long start = vorbis comment chapter . get start time from value ( value ) ; chapter = new vorbis comment chapter ( id ) ; chapter . set start ( start ) ; chapters . add ( chapter ) ; } else { throw new vorbis comment reader exception ( found chapter with duplicate id ( + key + , + value + ) ) ; } } else if ( attribute . equals ( chapter _ attribute _ title ) ) {
bytes to copy = meta data . length - long . bytes ; if ( node . verbose _ files ) { dest . message ( file + name + : start copying to tmp file + tmp name + length = + ( 8 + bytes to copy ) ) ; } copy start ns = system . nano time ( ) ; this . meta data = meta data ; dest . start copy file ( name ) ; }
try { send tx completed ( local node name , involved clusters , omulti value . get singleton list ( s ) , ( ocompleted2pc task ) fix task ) ; return true ; } catch ( throwable t ) {
fs . rename ( top ezfile , renamed top ezfile ) ; fs . rename ( nested ezfile , renamed nested ezfile ) ; top ezfile = renamed top ezfile ;
set < string > tracking key set = node name vs time added . key set ( ) ; tracking key set . retain all ( new live nodes ) ;
fast vector highlighter fvh = new fast vector highlighter (
if ( network heal nightly hour > 23 ) { network heal nightly hour = - 1 ; } else if ( network heal nightly hour < 0 ) { network heal nightly hour = - 1 ; } if ( initialised = = false ) { return ; }
if ( b1 = = ' \ r ' ) { if ( b2 = ' \ n ' ) { throw new ioexception ( invalid quoted printable encoding ; cr must be followed by lf ) ; }
for ( int i = 0 ; i < num docs ; i + + ) { if ( random ( ) . next double ( ) < 0 . 4 ) { long value = ( i + 1 ) * 2 ; writer . update binary doc value ( new term ( id , doc - + i ) , val , to bytes ( value ) ) ; expected values [ i ] = value ; } } final directory reader reader ;
start = mid + 1 ;
assert equals ( session0 , cluster . get elector ( 0 ) . get zksession id for tests ( ) ) ;
decimal128 . divide ( left , right , result , scale ) ;
if ( arg . get svar ( ) . get use count ( ) = 0 ) { insn node iget = new index insn node ( insn type . iget , field info , 1 ) ; iget . add arg ( insn . get arg ( 1 ) ) ; for ( insn arg insn arg : arg . get svar ( ) . get use list ( ) ) { insn arg . wrap instruction ( iget ) ; } } return true ;
if ( get required options ( ) . is empty ( ) ) { throw new missing option exception ( get required options ( ) ) ; }
presence timer = new common timer ( new runnable ( ) { @ override public void run ( ) { presence . force notify ( ) ; presence timer . schedule ( presence _ update _ delay ) ; } } ) ; presence timer . schedule ( presence _ update _ delay ) ; }
if ( data objects = null ) { variables map = new hash map < string , object > ( data objects . size ( ) ) ; for ( valued data object data object : data objects ) { variables map . put ( data object . get name ( ) , data object . get value ( ) ) ; } } return variables map ;
this . non pooled available memory + = accumulated ; this . waiters . remove ( more memory ) ; } } } finally {
fill qname ( f element qname , uri , local name , q name ) ;
list < container > containers = am1 . allocate ( null , null ) . get allocated containers ( ) ; assert . assert equals ( container id2 , containers . get ( 0 ) . get id ( ) ) ; assert . assert not null ( containers . get ( 0 ) . get container token ( ) ) ; check used resource ( rm1 , default , 2 * gb , null ) ; fi ca scheduler app app = test utils . get fi ca scheduler app ( rm1 , app1 . get application id ( ) ) ; assert . assert equals ( 2 * gb , app . get app attempt resource usage ( ) . get used ( ) . get memory size ( ) ) ; verify available resource of scheduler node ( rm1 , nm1 . get node id ( ) , 18 * gb ) ;
iterable < target node < ? , ? > > associated tests = immutable set . of ( ) ; if ( is with tests ) { associated tests = project graph . get all ( explicit tests ) ; } target graph target graph = project graph . get subgraph ( iterables . concat ( project roots , associated tests ) ) ; return new target graph and targets ( target graph , project roots ) ; }
return conn . get input stream ( ) ;
if ( close brackets < open brackets ) { input [ index + + ] = input [ i ] ; close brackets + + ; }
range + = view compat . get minimum height ( child ) ;
string srs = wli . get srs ( ) ;
} catch ( invalid canonicalizer exception ex ) {
service status status = route . get route context ( ) . get camel context ( ) . get route status ( route . get id ( ) ) ;
declare class . put ( class entity . get qualified name ( ) , class entity ) ;
double raw interval = range label count ;
verify size compaction ( a ( kv _ a , kv _ b , kv _ c , kv _ d ) , 2 , 1 , open _ key , open _ key , a ( a ( kv _ a ) , a ( kv _ b , kv _ c , kv _ d ) ) ) ;
parsed result = extract memory info ( buffers , result ) ; if ( null = parsed result ) { total free memory + = parsed result ; continue ; }
fsdata output stream out = fs . create ( file2 ) ;
check tertiary = false ;
right = ( ( osqlquery < ? > ) right ) . set context ( i context ) . execute ( ) ;
client bootstrap = new client bootstrap ( new nio client socket channel factory ( executors . new single thread executor ( daemon ( cluster client boss , monitor ) ) , executors . new fixed thread pool ( 2 , daemon ( cluster client worker , monitor ) ) , 2 ) ) ; client bootstrap . set option ( tcp no delay , true ) ; client bootstrap . set pipeline factory ( new network node pipeline factory ( ) ) ; msg log . debug ( started network sender for + to string ( config ) ) ; }
m balloon marker drawable . set bounds ( left , top , right , bottom ) ;
final pair < string , string > abs1 = generate abs ( environment , base offset + instructions . size ( ) , first operand , first operand size , instructions ) ; final pair < string , string > abs2 = generate abs ( environment , base offset + instructions . size ( ) , second operand , second operand size , instructions ) ; final string first abs = abs1 . second ( ) ; final string second abs = abs2 . second ( ) ; base offset = offset + instructions . size ( ) ;
assert that ( response . results ( ) [ 0 ] . row count ( ) + response . results ( ) [ 1 ] . row count ( ) , is ( - 1 l ) ) ;
e . print stack trace ( ) ; } catch ( ioexception e ) {
store flush context store flush ctx = store . create flush context ( snapshot id , flush life cycle tracker . dummy ) ; store flush ctx . prepare ( ) ;
if ( direction _ keywords . contains ( property string ) & & direction string = = null ) { throw new runtime exception ( string . format ( invalid _ order _ syntax , part ) ) ; }
paint . get text bounds ( text , 0 , text . length ( ) , rect ) ; rect f . set ( rect ) ; rect f . offset ( - rect f . center x ( ) , - rect f . center y ( ) ) ; gravity utils . get movement area position ( settings , rect ) ; rect f . offset ( rect . center x ( ) , rect . center y ( ) ) ; rect f . inset ( - half size , - half size ) ;
return parameter mode . param _ in ;
cluster config state config state = config storage . snapshot ( ) ; assert equals ( 5 , config state . offset ( ) ) ; should always be next to be read , even if uncommitted assert equals ( arrays . as list ( connector _ ids . get ( 0 ) ) , new array list < > ( config state . connectors ( ) ) ) ; assert equals ( target state . started , config state . target state ( connector _ ids . get ( 0 ) ) ) ; config storage . stop ( ) ;
bos . write ( get multipart divider ( ) ) ;
assert errors ( do fsck ( conf , true ) , new error _ code [ ] { error _ code . server _ does _ not _ match _ meta } ) ;
byte buffer old buf = buf ( ) ;
node enclosing parent = enclosing fn name node . get parent ( ) ; node maybe inherits expr = ( enclosing parent . is assign ( ) ? enclosing parent . get parent ( ) : enclosing parent ) . get next ( ) ; node base class node = null ; if ( maybe inherits expr = null & & maybe inherits expr . is expr result ( ) & & maybe inherits expr . get first child ( ) . is call ( ) ) { node call node = maybe inherits expr . get first child ( ) ; if ( call node . get first child ( ) . matches qualified name ( goog . inherits ) & & call node . get last child ( ) . is qualified name ( ) ) { base class node = call node . get last child ( ) ; } } if ( base class node = = null ) { report bad goog base use ( t , n , could not find goog . inherits for base class ) ; return ; }
array list < string > copy = new array list < > ( urls ) ; urls . add all ( copy ) ; urls . add all ( copy ) ; }
class definition . declare method ( a ( public ) , is deterministic , type ( boolean . class ) ) . get body ( ) . append ( constant boolean ( determinism evaluator . is deterministic ( filter ) ) ) . ret boolean ( ) ;
logger . warn ( output port { } goes beyond the physical number of { } ports available on the matrix { } , new object [ ] { output port , number of ports , host } ) ;
return new data output stream ( new buffered output stream ( os ) ) ;
int start = 0 ;
text = this item . get text ( ) ;
result . put all ( test formatter options . get settings ( ) ) ; return result ;
unprune ( ) ;
if ( gwc operation = null & & gwc operation . equals ignore case ( get capabilities ) ) { this is a get capabilities request , we need to check if we are in the context of virtual service return get no prefixed name if virtual service ( ) ; } return info . get name ( ) ;
view . on next ( null ) ; test subscriber . assert value count ( 1 ) ;
cls = ( oclass impl ) classes . get ( ( ( string ) c . field ( name ) ) . to lower case ( locale . english ) ) ;
assert true ( cluster . restart data nodes ( true ) ) ;
map < string , controller mvcresponse service > response type services = get installed controller mvcresponse types ( ) ;
block < document > print block = new block < document > ( ) { @ override public void apply ( final document document ) { system . out . println ( document . to json ( ) ) ; } } ;
assert . assert true ( fc . delete ( new path ( new dir foo ) , false ) ) ;
if ( + + i > = end index ) throw undertow messages . messages . invalid escape character ( ) ;
iterator < s > iter ; try { iter = the registry . get service providers ( spi class , true ) ; } catch ( illegal argument exception e ) { return new string [ 0 ] ; } hash set < string > s = new hash set < string > ( ) ;
return pending messages ( conn , resp ) ;
string imsi = get imsi ( ) ;
result set group result set group = get result set ( aggregation . json ) ;
object advice ; if ( this . singleton | | this . bean factory . is singleton ( name ) ) {
bytecode expression base expression = get static ( get class ( ) , field name ) ;
recorder . set mute ( true ) ; }
require no attributes ( reader ) ; final model node subsystem = new model node ( ) ; subsystem . get ( op ) . set ( add ) ; subsystem . get ( op _ addr ) . add ( subsystem , wsextension . subsystem _ name ) ; final list < model node > endpoint configs = new array list < model node > ( ) ;
final document document = xml utils . read xml ( get file manager ( ) . get input stream ( wsdl path ) ) ;
return get interface ( ) . get installed applications ( flags , user id ) . get list ( ) ; } catch ( remote exception e ) {
simple feature type builder builder = new simple feature type builder ( ) ;
free up ( size ) ;
normalize test ( http : x . com s?q = a % 26b & m = 10 , http : x . com s?q = a % 26b & m = 10 ) ;
input stream response = null ;
set has options menu ( true ) ; }
in memory jarfile jar file = new in memory jarfile ( ) ; try { ddl reader list . get ( 0 ) . put in jar ( jar file , ddl . sql ) ; } catch ( ioexception e ) { compiler log . error ( failed to add ddl file to empty in - memory jar . ) ; return false ; } return compile internal to file ( jar output path , null , null , ddl reader list , jar file ) ; }
method specific method = class utils . get most specific method ( method , target class ) ; a annotation = annotation utils . find annotation ( specific method , annotation class ) ; if ( annotation = null ) { logger . debug ( annotation + found on specific method : + specific method ) ; return annotation ; }
client a . release exclusive ( node , 1 l ) ;
if ( notify session listeners ) { object listeners [ ] = context . get application event listeners ( ) ; if ( listeners = null & & listeners . length > 0 ) { http session event event = new http session event ( get session ( ) ) ; for ( object listener : listeners ) { if ( ( listener instanceof http session id listener ) ) continue ; http session id listener id listener = ( http session id listener ) listener ; try { id listener . session id changed ( event , old id ) ; } catch ( throwable t ) { manager . get context ( ) . get logger ( ) . error ( sm . get string ( standard session . session event ) , t ) ; } } } }
assert true ( there should be one less thread pool , before . size ( ) - 1 = = after . size ( ) ) ;
props = new properties ( ) ; props . put ( mode , challenge ) ; props . put ( topp . states . w , role _ tsw ) ; props . put ( topp . * . w , role _ tw ) ; props . put ( * . * . r , * ) ; props . put ( group . r , role _ group ) ; dao = new memory data access rule dao ( catalog , props ) ;
string [ ] tags = parse . get data ( ) . get parse meta ( ) . get values ( rel tag parser . rel _ tag ) ; if ( tags = null ) { for ( int i = 0 ; i < tags . length ; i + + ) { doc . add ( tag , tags [ i ] ) ; } } return doc ;
global configuration global cfg = cr . get global component registry ( ) . get global configuration ( ) ; mbean server = jmx util . lookup mbean server ( global cfg ) ;
float bitmap aspect ratio = ( right limit - left limit ) ( bottom limit - top limit ) ;
if ( tasks . size ( ) = = 0 ) return true ;
assert null ( get attribute ( provider coordinator , encrypt _ mbean , encrypt _ password _ key ) ) ; mc friend . set ( key1 , value1 ) ; assert equals ( could not read replicated pair key1 value1 , value1 , mc coordinator . get ( key1 ) ) ; } finally {
terms terms = multi fields . get terms ( index reader , class field name ) ; terms enum terms enum = terms . iterator ( ) ; while ( ( terms enum . next ( ) ) = null ) { cclasses . add ( bytes ref . deep copy of ( terms enum . term ( ) ) ) ; }
client . stop ( ) ; assert . assert true ( complete latch . await ( 5 , time unit . seconds ) ) ;
m float loc . x = x - m drag delta x ; m float loc . y = y - m drag delta y ; do drag float view ( true ) ;
for ( node < e > p = next ; ; + + hops ) { if ( p . item = null ) { active succ = p ; is last = false ; break ; } node < e > q = p . next ; if ( q = = null ) { if ( p . prev = = p ) return ; active succ = p ; is last = true ; break ; } else if ( p = = q ) return ; else p = q ; }
collector . cancel ( ) ; if ( response = = null ) return null ;
if ( _ context . is router context ( ) ) {
long utc millis = isochronology . get instance ( ) . get zone ( ) . get millis keep local ( utc , local millis ) ;
list < string > delivery stream names = list delivery streams ( ) ; log . info ( printing my list of delivery streams : ) ; if ( delivery stream names . is empty ( ) ) { log . info ( there are no delivery streams for account : + account id ) ; } else { log . info ( list of my delivery streams : ) ; } for ( int i = 0 ; i < delivery stream names . size ( ) ; i + + ) { log . info ( delivery stream names . get ( i ) ) ; }
reader = new expression reader ( test ( foo ) . to char array ( ) ) ; assert equals ( test , reader . read func name ( ) ) ; assert equals ( , reader . read func name ( ) ) ;
system . arraycopy ( buf , mark , buf , 0 , buf . length - mark ) ;
throw new ioexception ( compression algorithm ' + algo . get name ( ) + ' + previously failed test . ) ;
ch . write and flush ( new netty message . partition request ( new result partition id ( ) , 0 , new input channel id ( ) , 2 ) ) ;
eofpacket eof = new eofpacket ( ) ; eof . packet id = + + packet id ; buffer = eof . write ( buffer , c ) ;
return i ' m a mock service ;
player handler . remove messages ( player handler . fade _ down ) ; player handler . send empty message ( player handler . fade _ up ) ; set is supposed to be playing ( true , true ) ;
string new partition ;
string [ ] words = text . split ( [ , ] ) ;
if ( has non prototype properties ( ) ) { if ( fn = null ) { return fn . append to ( builder , ctx ) ; } return this . nominal type . append to ( builder , ctx ) ; }
string tokens = open nlp . tokenize with spaces ( qn ) ; string tagged = open nlp . tag pos ( tokens ) . to lower case ( ) ;
for ( service service : instance . get services ( ) ) { master services . register service ( service ) ; }
if ( reader . get attribute count ( ) > 0 ) { throw unexpected attribute ( reader , 0 ) ; } operation . get ( common attributes . jts ) . set ( true ) ; require no content ( reader ) ; }
view next title = get child at ( m selected position + 1 ) ;
list < simple entity > list = session . by multiple ids ( simple entity . class ) . multi load ( 1 , 2 , 3 , 2 , 2 ) ; assert equals ( 5 , list . size ( ) ) ; assert same ( list . get ( 1 ) , list . get ( 3 ) ) ; assert same ( list . get ( 1 ) , list . get ( 4 ) ) ;
if ( ( node . compare document position ( next sibling ) & node . document _ position _ contained _ by ) = = 0 ) { throw new illegal argument exception ( cannot create a domresult when the next sibling is not contained by the node . ) ; }
if ( facet . sub facets . is empty ( ) ) { assert facet counts are correct ( facet . sub facets , verify params , bucket ) ; } } }
if ( i = = 0 ) { result = new hash set < > ( available indices ) ; }
rule = entry . get value ( ) ;
resource prop file = user definitions file . get resource ( ) ;
if ( _ queued messages . contains ( msg ) ) _ queued messages . offer ( msg ) ; else if ( _ log . should log ( log . warn ) ) _ log . warn ( attempt to add duplicate msg to queue : + msg ) ;
verify ( http downloader ) . download ( any ( uri . class ) , arg that ( new has file name ( test - 1 . 0 . jar . tmp ) ) ) ;
conf . set boolean ( mapred . mapper . new - api , true ) ; conf . set ( angel conf . angel _ inputformat _ class , combine text input format . class . get name ( ) ) ; conf . set boolean ( angel conf . angel _ job _ output _ path _ deleteonexist , true ) ;
collections . shuffle ( leader indices list , random ( ) ) ;
h . post delayed ( r , 5 ) ;
coverage info coverage = get catalog ( ) . get coverage by name ( watertemp _ dynamic ) ; coverage dimension info di = coverage . get dimensions ( ) . get ( 0 ) ; di . set range ( new number range < double > ( double . class , 0 . , 0 . 5 ) ) ; get catalog ( ) . save ( coverage ) ; }
s3m _ file = read _ more ( s3m _ file , s3m _ file _ length , data _ input ) ;
final string expected result for first invocation = container interceptor one . class . get name ( ) + + non container interceptor . class . get name ( ) + + flow tracking bean . class . get name ( ) + + message ; final string first result = bean . echo ( message ) ; assert . assert equals ( unexpected result after first invocation on remote view of bean , expected result for first invocation , first result ) ; final string second message = bar ;
if ( schema name . equals ( information _ schema ) ) { schema names . add ( schema name ) ; }
log . debug ( deleting regions from meta ) ; meta editor . delete regions ( this . server . get catalog tracker ( ) , regions ) ;
fail ( osgi filter + is not a valid osgi filter ) ;
sql = select id from r1 sub6 where abs ( num - 1 ) = 1 and id > = 1 order by id ; ; vt = client . call procedure ( @ explain , sql ) . get results ( ) [ 0 ] ; assert true ( vt . to string ( ) . contains ( absidx ) ) ; check planner cache ( client , cache _ miss2 _ add1 ) ; validate table of scalar longs ( client , sql , new long [ ] { 1 , 2 } ) ;
assert true ( audio . is service running ( ) ) ;
fs . create ( file ) . close ( ) ; assert true ( test file didn ' t get created . , fs . exists ( file ) ) ;
i . set byte stream ( bais ) ; assert equals ( bais , i . get byte stream ( ) ) ;
store file writer writer = new store file writer . builder ( test conf , cache conf , this . fs ) . with file path ( region fs . create temp name ( ) ) . with file context ( meta ) . build ( ) ;
cs conf . set state ( q1 _ path , queue state . stopped ) ;
if ( password = = null ) { password = decryptor . default _ password ; } message digest hash alg = get message digest ( hash algorithm ) ;
matrix4f model matrix = new matrix4f ( ) ; model matrix . set ( light component . light attenuation range ) ; scales the modelview matrix , effectively scales the light sphere model matrix . set translation ( light position relative to camera ) ; effectively moves the light sphere in the right position relative to camera light geometry material . set matrix4 ( model matrix , model matrix , true ) ; gl call list ( light sphere display list ) ; draws the light sphere
try { session output session output = user sessions output . get session output map ( ) . get ( key ) ; if ( session output = null & & session output . get output ( ) = null & & string utils . is not empty ( session output . get output ( ) ) ) { output list . add ( session output ) ; send to audit logger system audit logger . info ( gson . to json ( new audit wrapper ( user , session output ) ) ) ; if ( enable internal audit ) { session audit db . insert terminal log ( con , session output ) ; } user sessions output . get session output map ( ) . put ( key , new session output ( session id , session output ) ) ; } } catch ( exception ex ) { log . error ( ex . to string ( ) , ex ) ; }
if ( ( max term counts . length - num terms in field ) > 1024 ) { too much waste int [ ] new max term counts = new int [ num terms in field ] ; system . arraycopy ( max term counts , 0 , new max term counts , 0 , num terms in field ) ; max term counts = new max term counts ; } log . info ( un inverted multi - valued field + to string ( ) ) ;
assert ( false ) ; return null ; } } else {
pending intent show = pending intent . get broadcast ( context , 0 , new intent ( show action ) , 0 ) ; pending intent operation = pending intent . get broadcast ( context , 0 , new intent ( op action ) , 0 ) ; alarm clock info info = new alarm clock info ( 1000 , show ) ; alarm manager . set alarm clock ( info , operation ) ; alarm clock info next = alarm manager . get next alarm clock ( ) ;
path filepath1 = new path ( filepath . to string ( ) + append test util . next int ( ) ) ;
assert that ( network . in degree ( n1 ) ) . is equal to ( 0 ) ;
s = 0 ;
input . put ( pt vector ) ; input . flip ( ) ;
string num str = the value . replace all ( [ ^ - \ \ d ] + , ) ;
list < string > attributes = arrays . as list ( filter . get attribute names ( ) ) ;
return new original class invoker ( rtype . get clazz ( ) , method member , rtype . get java method cache ( ) ) ;
assert equals ( gs . get global ( ) . get settings ( ) . get metadata ( ) . get ( restutils . quiet _ on _ not _ found _ key , boolean . class ) , true ) ;
add days and check for completion ( 15 , next event . block , next event . payment _ error , next event . invoice _ payment _ error , next event . invoice , next event . payment _ error , next event . invoice _ payment _ error ) ;
cluster . stop region server ( server a . get server name ( ) ) ; waiter . wait for ( conf , 20000 , new waiter . predicate < exception > ( ) { @ override public boolean evaluate ( ) throws exception { return manager b . get old sources ( ) . size ( ) = = 1 ; } } ) ; final hregion server server c = cluster . start region server ( ) . get region server ( ) ; server c . wait for server online ( ) ; waiter . wait for ( conf , 20000 , new waiter . predicate < exception > ( ) { @ override public boolean evaluate ( ) throws exception { return server c . get replication source service ( ) = null ; } } ) ; final replication source manager manager c = ( ( replication ) server c . get replication source service ( ) ) . get replication manager ( ) ;
writer . update document ( new term ( docid , docid ) , doc ) ; } writer . commit ( ) ; } finally {
ajp message get body message = new ajp message ( 16 ) ;
throw new runtime exception ( forcing failure for example ) ; }
assert exit invocations ( 0 ) ; assert true ( do an edit ( ) ) ;
view current tab = tabs container . get child at ( current position ) ;
cs . node update ( rm . get rmcontext ( ) . get rmnodes ( ) . get ( nm1 . get node id ( ) ) ) ; rmapp attempt metrics attempt metrics = rm . get rmcontext ( ) . get rmapps ( ) . get ( app1 . get application id ( ) ) . get current app attempt ( ) . get rmapp attempt metrics ( ) ;
this . user cookie = user cookie . parse cookie ( http cookie ) ; }
old dec = hive decimal v1 . create ( . ) ;
list . sub list ( to , list . size ( ) ) . clear ( ) ; return from = to ;
list < hregion > regions = cur server . get regions ( table _ name3 ) ;
for ( quorum server nqs : next servers . values ( ) ) { if ( qs . id = = nqs . id ) { continue ; } qs . check address duplicate ( nqs ) ; } next servers . remove ( qs . id ) ;
mapped roles . add all ( jboss web meta data . get security role names ( ) ) ;
document d = post as dom ( wps , xml . replace ( { output } , literal ) ) ;
assert invalidations ( listener1users . get invalidations and clear ( ) , 10 , 100 ) ; assert invalidations ( listener2users . get invalidations and clear ( ) , 10 , 100 ) ; cache everything ( ) ;
first digit . add child ( ampm ) ;
script = db . person . distinct ( \ person _ name \ ) ; result = ( client ) . execute script ( script ) ; result list = ( basic dblist ) result ; assert . assert equals ( vivek , result list . get ( 0 ) ) ; assert . assert equals ( 1 , result list . size ( ) ) ;
( ( text view ) view mirror . find view by id ( r . id . txt _ setting ) ) . set text color ( app compat . get color ( r . color . txt _ alpha _ gray , this ) ) ;
| | name . equals ( wait ) | | name . equals ( notify ) | | name . equals ( notify all ) ; }
assert that ( transactions . get transactions ( ) [ 0 ] . get transacation time ( ) ) . is equal to ( 1435630071 ) ;
create helix entries for high level consumer ( config , realtime table name , ideal state ) ;
long days = date writable . millis to days ( tcv . get time ( index ) ) ; if ( is positive ) { days + = num days ; } else { days - = num days ; } return days ;
field reference = null ;
router . get ( ) . route ( injection ) . with ( injection example controller : : injection ) ; router . get ( ) . route ( service init time ) . with ( injection example controller : : service init time ) ;
ilegal color = true ; return color . white ; }
unicode property dump . dump properties ( 0x c5 , 0x c5 + 1 , true , out ) ;
system . load ( temp . get absolute path ( ) ) ; }
if ( m tool tip . m on click listener = null ) { m tool tip view group . set on click listener ( m tool tip . m on click listener ) ; }
zip entry zip entry = new zip entry ( dest path ) ;
final configuration conf = get operator ( ) . get parameters ( ) ; final string local strategy = conf . get string ( optimizer . hint _ local _ strategy , null ) ; final boolean use combiner ;
m paint . set color ( m number text color ) ; m typeface = font loader . roboto _ regular . get typeface ( get context ( ) ) ; m paint . set anti alias ( true ) ; m paint . set text align ( align . center ) ; m texts = texts ;
class name = request . get class ( ) . get superclass ( ) . get simple name ( ) ;
log . info ( note : stop data node + target . get value ( ) . get display name ( ) + with internal block + target . get key ( ) ) ;
state . update ( new test pojo ( u1 , 1 ) ) ;
object scope = token stack . pop ( ) ; bufferset . set scope ( scope . to string ( ) ) ; split stack . push ( bufferset ) ; bufferset = new buffer set ( include files , include remotes ) ; }
block manager test util . update state ( nn . get namesystem ( ) . get block manager ( ) ) ;
return doc scorer . score ( doc id , freq ) ; }
metrics . put in dkv ( ) ;
int element = 93 ; fibonacci sequence . fibonacci sequence using binets formula ( element ) ; }
actual = new byte [ 1 ] ; test seek1 ( file _ size - 1 ) ; string err msg = null ;
boolean has conj = false ;
jetty configuration file = resource . new class path resource ( jetty configuration ) ; if ( jetty configuration file = = null | | jetty configuration file . exists ( ) ) { throw new file not found exception ( unable to find jetty configuration file either locally or on classpath ' + jetty configuration + ' ) ; }
if ( is interactive ( host ) ) { canvas . draw rect ( 0 , 0 , host . get width ( ) , host . get height ( ) , s interactive view paint ) ; }
log . trace ( sending a message to the queue on which the mdb + is listening ) ; trigger request response cycle on queue ( ) ; assert true ( @ post construct wasn ' t invoked on mdb , lifecycle tracker . was post construct invoked on ( this . get class ( ) . get package ( ) . get name ( ) + . lifecycle counter mdb ) ) ;
source data state . map2 . entry set ( ) . for each ( entry - > blackhole . consume ( map . put ( entry . get key ( ) , entry . get value ( ) ) ) ) ;
reset jms configuration ( instances ) ; reset events count ( instances ) ; }
parameterized type name input map type of group = parameterized type name . get ( class name . get ( map . class ) , class name . get ( string . class ) , class name . get ( route meta . class ) ) ;
if ( tbl . is materialized view ( ) ) { hive materialized views registry . get ( ) . add materialized view ( tbl ) ; }
hash map < string , object > new settings = new hash map < > ( ) ;
object prev = cache . put ( key , create value ( ) , build metadata ( ) ) ; return create success response ( ) ;
add page ( buffer , create page ( 11 ) ) ;
verify ( trigger vertex1 . get current execution attempt ( ) , times ( 1 ) ) . trigger checkpoint ( eq ( checkpoint id2 ) , eq ( timestamp2 ) , any ( checkpoint options . class ) ) ;
invoker helper . run script ( script class , arguments ) ; result . end test ( this ) ;
if ( ( get dialect ( ) instanceof sybase ase157 dialect ) ) { skip for sybase . hhh - 6425 s = open session ( ) ; s . begin transaction ( ) ; entity = s . get ( lob holder . class , entity . get id ( ) ) ; assert equals ( clob _ size , entity . get clob locator ( ) . length ( ) ) ; assert equals ( changed , extract data ( entity . get clob locator ( ) ) ) ; entity . set clob locator ( s . get lob helper ( ) . create clob ( empty ) ) ; s . get transaction ( ) . commit ( ) ; s . close ( ) ; s = open session ( ) ; s . begin transaction ( ) ; entity = s . get ( lob holder . class , entity . get id ( ) ) ; if ( entity . get clob locator ( ) = null ) { assert equals ( empty . length ( ) , entity . get clob locator ( ) . length ( ) ) ; assert equals ( empty , extract data ( entity . get clob locator ( ) ) ) ; } s . delete ( entity ) ; s . get transaction ( ) . commit ( ) ; s . close ( ) ; }
throw new ioexception ( the client is stopped ) ;
out = fs . append ( path ) ;
list < annotated java type > parameter types = this . find all global search method . get parameter types ( ) ;
m state = state _ preview ;
try { return ( string ) build . class . get field ( serial ) . get ( null ) ; } catch ( exception ignored ) { return null ; }
os . write ( new byte [ 1 ] ) ; os . hsync ( ) ; final mbean server mbs = management factory . get platform mbean server ( ) ;
int [ ] color = new int [ n ] ; progress . start ( progress , n ) ; int seen count = 0 ; linked list < linked list < node > > components = new linked list < > ( ) ;
disk lru cache cache2 = disk lru cache . open ( cache dir , app version , 2 , integer . max _ value ) ;
list < relationship > hf rels = new array list < relationship > ( ) ; for ( relationship rel : mdp . get relationships part ( ) . get relationships ( ) . get relationship ( ) ) { if ( rel . get type ( ) . equals ( namespaces . header ) | | rel . get type ( ) . equals ( namespaces . footer ) ) { hf rels . add ( rel ) ; } } for ( relationship rel : hf rels ) { mdp . get relationships part ( ) . remove relationship ( rel ) ; } word mlpackage . save ( f ) ;
exception me = null ; try { client . list partitions by filter ( db name , tbl name , p3 > = \ p12 \ , ( short ) - 1 ) ; } catch ( meta exception e ) { me = e ; } assert not null ( me ) ; assert true ( filter on int partition key , me . get message ( ) . contains ( filtering is supported only on partition keys of type string ) ) ; me = null ; try { client . list partitions by filter ( db name , tbl name , c1 > = \ p12 \ , ( short ) - 1 ) ; } catch ( meta exception e ) { me = e ; } assert not null ( me ) ; assert true ( filter on invalid key , me . get message ( ) . contains ( < c1 > is not a partitioning key for the table ) ) ; me = null ;
if ( m circle views . size ( ) = count ) { m container . remove all views ( ) ; m circle views . clear ( ) ; int i = 0 ; for ( ; i < focus pos ; i + + ) { add small circle ( ) ; } add large circle ( ) ; for ( i = focus pos + 1 ; i < count ; i + + ) { add small circle ( ) ; } } m focus position = focus pos ;
assert that ( result . get stderr ( ) , contains string ( lib jar ) ) ;
http service http service = new http service ( this , storage service , store repository , request format type . voldemort _ v1 , voldemort config . get max threads ( ) , identity node . get http port ( ) ) ; online services . add ( http service ) ;
if ( animation thread = = null ) { animation thread = new thread ( animator ) ; animation thread . start ( ) ; }
k session names . put ( new entry , new entry ) ;
actual operations . decrement and get ( ) ; } }
assert . assert true ( shell content . contains ( export hadoop _ yarn _ home = \ nodemanager _ yarn _ home \ ) ) ;
gregorian calendar calendar = bletype conversions . create calendar ( ) ; calendar . add ( calendar . day _ of _ month , - 1 ) ; return calendar ; }
assert equals ( 3 , parser . parse expression ( counter ) . get value ( e context ) ) ;
if ( do port monitoring ( remote address ) ) { return false ; }
for ( int i = 0 ; i < 5 ; i + + ) { create task ( i + , null , null , 0 ) ; } create task ( owned task , kermit , null , 0 ) ; custom task task = new custom task query ( management service ) . task owner ( kermit ) . single result ( ) ;
plain padded keys [ 0 ] = get ek _ no null byte ( rsa key length ) ;
return parse class dir ( this . get class ( ) . get class loader ( ) , new file ( new uri ( local . to string ( ) ) ) , package name . replace ( ' . ' , file . separator char ) , new class recurse dir file filter ( true ) ) ; } catch ( urisyntax exception e ) { logger . error ( e . get message ( ) , e ) ; } }
instruction replacement instruction = replacements [ offset ] ;
check blocking states dao ( changed base entitlement , cancelled add on entitlement , change date , false ) ; clock . add days ( 30 ) ;
throw new ioexception ( cannot finalize block from interrupted thread ) ; } replica info = get replica info ( b ) ; if ( replica info . get state ( ) = = replica state . finalized ) {
super . handle upstream ( ctx , e ) ; }
if ( filter query tree = = null ) { list < integer > all docs = new array list < > ( _ total docs ) ; for ( int i = 0 ; i < _ total docs ; + + i ) { all docs . add ( i ) ; } return all docs ; } final list < filter query tree > child filters = filter query tree . get children ( ) ; final boolean is leaf = ( child filters = = null ) | | child filters . is empty ( ) ; if ( is leaf ) { filter operator filter type = filter query tree . get operator ( ) ; string column = filter query tree . get column ( ) ; final list < string > value = filter query tree . get value ( ) ; return get matching doc ids ( input doc ids , filter type , column , value ) ; }
initialize missing roles ( relation base flag , relation obj , relation obj name , relation id , relation type name , role info list ) ;
set < user > users = user manager service . get users ( null , null ) ; assert that ( users , contains ( crate _ user ) ) ; users = user manager service . get users ( new users meta data ( ) , new users privileges meta data ( ) ) ; assert that ( users , contains ( crate _ user ) ) ;
. set state change listener ( this ) . attach to ( main action view ) . build ( ) ;
int index = session context . savepoints . get index ( name ) ; if ( index < 0 ) { throw error . error ( error code . x _ 3 b001 , name ) ; }
for ( sstable reader reader : cfs . get live sstables ( ) ) reader . reload sstable metadata ( ) ; commit log . instance . sync ( ) ; system . set property ( cassandra . replay list , keyspace1 + . + standard1 ) ;
string my shard id = cloud desc . get shard id ( ) ; slice my slice = coll . get slice ( my shard id ) ; state state = my slice . get state ( ) ; return state = = slice . state . construction | | state = = slice . state . recovery ; }
verify region assignment ( shuffled plan , 0 , region _ num ) ;
assert equals ( pager adapter . get count ( ) - 3 , saved pages . key at ( 0 ) ) ; assert equals ( pager adapter . get count ( ) - 2 , saved pages . key at ( 1 ) ) ; assert equals ( pager adapter . get count ( ) - 1 , saved pages . key at ( 2 ) ) ; final int second selected item = 1 ; pager . page to ( second selected item ) ; saved pages = pager adapter . get saved pages ( ) ;
form . add ( new submit link ( save ) {
v _ 2 = cursor ; lab1 : do {
url catalog jar path = test upgrade with catalog jar . class . get resource ( upgrade catalog v7 _ 4 . jar ) ; config . m _ path to catalog = catalog jar path . get path ( ) ; config . m _ path to deployment = path to deployment ; config . m _ start action = start action . create ; try { start system ( config ) ; assert false ( find table in system catalog results ( foo ) ) ; assert true ( find table in system catalog results ( contestants ) ) ; assert true ( find table in system catalog results ( votes ) ) ; m _ client . call procedure ( @ ad hoc , insert into votes values ( 4015671234 , ' ri ' , 1 ) ; ) ; m _ client . call procedure ( votes . insert , 4012345678 l , ri , 2 ) ; volt table vt = m _ client . call procedure ( @ ad hoc , select count ( * ) from votes ; ) . get results ( ) [ 0 ] ; assert true ( vt . as scalar long ( ) = = 2 ) ; } finally { teardown system ( ) ; }
let get finish signal . count down ( ) ;
for ( class < ? > clazz : classes ) { if ( clazz = = null ) continue ; path path = find or create jar ( clazz , local fs , packaged classes ) ; if ( path = = null ) { log . warn ( could not find jar for class + clazz + in order to ship it to the cluster . ) ; continue ; } if ( local fs . exists ( path ) ) { log . warn ( could not validate jar file + path + for class + clazz ) ; continue ; } jars . add ( path . to string ( ) ) ; } if ( jars . is empty ( ) ) return ;
if ( temp hash . size ( ) = = 0 ) { for ( int j = 0 ; j < m _ cumulative instances . size ( ) ; j + + ) { array list temp update = ( ( array list ) m _ cumulative instances . get ( j ) ) ; object temp o = temp update . get ( i ) ; if ( temp o instanceof string ) {
request . set attribute ( s3 constants . bucket _ attr _ key , bucket string ) ; request . set attribute ( s3 constants . object _ attr _ key , key string ) ; request . set attribute ( s3 constants . plain _ post _ access _ key , access key string ) ; request . set attribute ( s3 constants . plain _ post _ signature , signature string ) ;
ord set . clear ( ) ; for ( string counted group : groups ) { int ord = index . binary search lookup ( counted group ) ; if ( ord > = 0 ) { ord set . put ( ord ) ; } } }
try { if ( value = = null & & cluster id service . cluster id ( ) . get ( ) = null ) { value = new bytes ref ( cluster id service . cluster id ( ) . get ( ) . value ( ) . to string ( ) ) ; } } catch ( interrupted exception | execution exception e ) { return null ; }
for ( int i = 0 ; i < size ; i + + ) { map1 . get ( i ) ; }
execute async for result ( master client , deploy on server group ( main _ server _ group , main _ runtime _ name ) ) ;
if ( duration timer < duration ) { duration timer + = delta millis ; percent = duration timer ( float ) duration ; } else { if ( continuous & & emit & & emission mode = = emission mode . enabled ) controller . start ( ) ; else emit = false ; }
for ( int i = 0 ; i < field refs l . get length ( ) ; i + + ) { element field r = ( element ) field refs l . item ( i ) ; string field name = field r . get attribute ( field ) ; attribute a = full structure . attribute ( field name ) ; if ( a = = null ) { throw new exception ( [ vector dictionary ] can ' t find field ' + field name + ' in the mining schema derived fields ) ; } field meta info . optype field opt = ( a . is numeric ( ) ) ? field meta info . optype . continuous : field meta info . optype . categorical ; field ref fr = new field ref ( field r , field opt , field defs ) ; m _ vector fields . add ( fr ) ; }
ref time show ( is show day , true , is show minute , is show second , is show millisecond ) ;
if ( on complete runnable = null ) { on complete runnable . run ( ) ; } m current animation = null ;
if ( exists ( ) ) { return false ; }
default config . set property ( bkdl _ retention _ period _ in _ hours , bkdl _ retention _ period _ in _ hours _ default + 2 ) ;
zk . create ( path , test . get bytes ( ) , ids . open _ acl _ unsafe , create mode . persistent ) ;
if ( max val < 10 . 0f ) { max val = 10 . 0f ; }
error handler . check and throw exception ( ) ;
query = select s from student mongo s where s . percentage = ?1 ;
current user . get session ( ) . stop ( ) ; current user . get session ( true ) ; current user . login ( token ) ; hash set < string > roles = security utils . get roles ( ) ;
undertow = undertow . builder ( ) . set io threads ( 1 ) . add http listener ( port + 1 , host ) . set handler ( proxy handler ) . build ( ) ; undertow . start ( ) ; default server . set root handler ( new http handler ( ) { @ override public void handle request ( http server exchange exchange ) throws exception { final server connection con = exchange . get connection ( ) ; if ( active connections . contains ( con ) ) { system . out . println ( added + con ) ; active connections . add ( con ) ; con . add close listener ( new server connection . close listener ( ) { @ override public void closed ( server connection connection ) { system . out . println ( closed + connection ) ; active connections . remove ( connection ) ; } } ) ; } } } ) ;
return ints . saturated cast ( 5 l + array size + ( array size 10 ) ) ; }
valid preview sizes . add ( new size pair ( preview size , null ) ) ;
for ( int i = 0 ; i < gb attrs . dist expr nodes . size ( ) ; i + + ) { if ( gb key cols as names frm in . contains ( gb attrs . dist expr names . get ( i ) ) ) { gb keys . add ( gb attrs . dist expr nodes . get ( i ) ) ; col output name = semantic analyzer . get column internal name ( gb keys . size ( ) - 1 ) ; col info lst . add ( new column info ( col output name , gb attrs . dist expr types . get ( i ) , , false ) ) ; output col names . add ( col output name ) ; gb key cols as names frm in . add ( gb attrs . dist expr names . get ( i ) ) ; col expr map . put ( col output name , gb keys . get ( gb keys . size ( ) - 1 ) ) ; } }
lr . add field ( http accept , new log field ( log field . type _ string , lp . get next cb ( ) ) ) ;
nfs3 file attributes post op attr = null ;
if ( is enabled ( ) ) { if ( logger . is loggable ( java . util . logging . level . fine ) ) { logger . fine ( string . format ( skipping incoming service ' % s ' modified event of type ' % s ' since producer is not enabled . , event . get source ( ) . get id ( ) , event . get event type ( ) ) ) ; } return ; }
logger . info ( we were behind { } but it looks like they died . back to determination . , neighbor leader offer . get node path ( ) ) ;
output stream . write ( put _ operation ) ;
jsp factory fact = jsp factory . get default factory ( ) ;
m _ warnings . clear ( ) ;
base file name mapping . put ( get base file name ( input path ) , bucket base file names ) ; } alias bucket base file name mapping . put ( table alias , base file name mapping ) ; } }
handler = new x509 credentials authentication handler ( regex utils . create pattern ( . * ) ) ; params . add ( new object [ ] { handler , new username password credential ( ) , false , null } ) ;
writer = new index writer ( dir , new index writer config ( new mock analyzer ( random ( ) ) ) . set index deletion policy ( policy ) ) ; add doc ( writer ) ; assert equals ( 11 , writer . num docs ( ) ) ; writer . force merge ( 1 ) ; writer . close ( ) ; assert equals ( 6 , directory reader . list commits ( dir ) . size ( ) ) ;
type factory tf = ctxt . get type factory ( ) ; java type [ ] tps = tf . find type parameters ( type , class _ iterable ) ; java type elem type = ( tps = = null | | tps . length = 1 ) ? type factory . unknown type ( ) : tps [ 0 ] ; collection type ct = tf . construct collection type ( collection . class , elem type ) ;
add socket permission for port range ( policy , profile . port or range ) ;
buf . append ( \ n \ t encryption key : ) . append ( get encryption key ( ) ) ; buf . append ( \ n \ t router : ) . append ( get router ( ) ) ; buf . append ( \ n \ t tunnel id : ) . append ( get tunnel id ( ) ) ; return buf . to string ( ) ;
assert false ( actor . get ibr manager ( ) . send immediately ( ) ) ;
node actual = parse ( { { x ( ) } } ) ; node outer block node = actual . get first child ( ) ;
float impulse = k > 0 . 0f ? - c k : 0 . 0f ; float px = normal . x * impulse ; float py = normal . y * impulse ; c a . x - = px * m a ;
template . send body and header ( file : target test - classes org apache camel component stringtemplate , hello < headers . name > , exchange . file _ name , hello . tm ) ; }
wcsutils . check input limits ( wcs , coverage ) ;
if ( check if bundle is installed ( bundle ) ) { continue ; }
if ( f entity resolver = null & & resource identifier = null ) { try { input source input source = f entity resolver . resolve entity ( pub id , sys id ) ; if ( input source = null ) { string public id = input source . get public id ( ) ; string system id = input source . get system id ( ) ; string base system id = resource identifier . get base system id ( ) ; input stream byte stream = input source . get byte stream ( ) ; reader char stream = input source . get character stream ( ) ; string encoding = input source . get encoding ( ) ; xmlinput source xml input source = new xmlinput source ( public id , system id , base system id ) ; xml input source . set byte stream ( byte stream ) ; xml input source . set character stream ( char stream ) ; xml input source . set encoding ( encoding ) ; return xml input source ; } } error resolving entity catch ( saxexception e ) { exception ex = e . get exception ( ) ; if ( ex = = null ) { ex = e ; } throw new xniexception ( ex ) ; } }
color highlight end - = 4 ;
nesting = get property ( ) ; }
out . write int ( this . instance . size ( ) ) ;
tester . assert model value ( task table : list container : items : 1 : item properties : 2 : component : form : crs : wkt : wkt label , epsg : anguilla 1957 british west indies grid ) ;
region scanner scanner = region . get scanner ( new scan ( ) ) ;
if ( shallow clone & & mesh = null & & mesh . get buffer ( type . bind pose position ) = null ) { then we need to clone the mesh a little deeper this . mesh = mesh . clone for anim ( ) ; } else { do whatever the cloner wants to do about it this . mesh = cloner . clone ( mesh ) ; } this . material = cloner . clone ( material ) ;
node . handle ( new rmnode reconnect event ( node . get node id ( ) , node , null , null ) ) ; assert . assert equals ( node state . decommissioned , node . get state ( ) ) ; assert . assert equals ( active nodes , initial active , cm . get num active nms ( ) ) ; assert . assert equals ( decommissioning nodes , initial decommissioning - 1 , cm . get num decommissioning nms ( ) ) ; assert . assert equals ( decommissioned nodes , initial decommissioned + 1 , cm . get num decommisioned nms ( ) ) ; }
set double ( output col vector , vector , 0 ) ;
assert not same ( fs with auto , fs without auto ) ; file system . cache . close all ( true ) ;
region . compact stores ( true ) ;
assert false ( can access ( wo , anonymous , nurc ws , access mode . read ) ) ; assert false ( can access ( wo , anonymous , nurc ws , access mode . write ) ) ; assert true ( can access ( wo , ro user , nurc ws , access mode . read ) ) ; assert false ( can access ( wo , rw user , nurc ws , access mode . write ) ) ; assert true ( can access ( wo , root , nurc ws , access mode . write ) ) ;
return f delegate . get number of lines ( offset , length ) ;
box body . create fixture ( box poly , 10 ) ;
final int initial file length = 2 * 1024 * 1024 + 100 ;
assert equals ( execution state . canceled , vertex . get execution state ( ) ) ; assert true ( slot . is released ( ) ) ;
child name = string canonicalizer . intern ( child name ) ;
if ( job . get status ( ) . get run state ( ) = job status . running ) { continue ; }
int cache scale = tableprops . get integer property ( cache _ scale , db props . get integer property ( hsql database properties . textdb _ cache _ scale , 10 , 8 , 16 ) ) ; int cache size scale = tableprops . get integer property ( cache _ size _ scale , db props . get integer property ( hsql database properties . textdb _ cache _ size _ scale , 10 , 8 , 20 ) ) ; int lookup table length = 1 < < cache scale ; int avg row bytes = 1 < < cache size scale ; max cache size = lookup table length * 3 ;
assert equals ( 14 . 492 , get feature at ( url , 68 , 72 , sf : watertemp ) , eps ) ; }
assert null ( user1 . get company ( ) . get name ( ) ) ; raises org . hibernate . stale object state exception if 2 lcache is enabled s1 . get transaction ( ) . commit ( ) ;
string old crc ; if ( old file = = null ) { old crc = 0 ; logger . d ( dex decoder : add newly dex file : % s , parent relative ) ; } else { old crc = file operation . get zip entry crc ( config . m old apk file , relative ) ; if ( old crc = = null | | old crc . equals ( 0 ) ) { throw new tinker patch exception ( string . format ( can ' t find zip entry % s from old apk file % s , relative , config . m old apk file . get path ( ) ) ) ; } } string new crc = file operation . get zip entry crc ( config . m new apk file , relative ) ; string meta = file name + , + parent relative + , + dest md5 in dvm + , + dest md5 in art + , + dex diff md5 + , + old crc + , + new crc + , + dex mode ; logger . d ( dex decoder : write meta file data : % s , meta ) ;
return ( int ) ( l & 0x00000000ffffffff l ) ;
rm context . get amrmtoken secret manager ( ) . recover ( state ) ;
assert true ( raid fs . exists ( src path ) ) ;
update block gs ( new gs ) ; dfs client . namenode . update pipeline ( dfs client . client name , old block , block . get current block ( ) , nodes , storage ids ) ; }
final property < string > module = library . get module ( ) ;
list < byte [ ] > qualifiers = new array list < byte [ ] > ( ) ;
string url = http : 10 . 255 . 255 . 1 ; thrown . expect ( sonar exception . class ) ; thrown . expect ( has cause ( new base matcher < exception > ( ) { @ override public boolean matches ( object ex ) { return
activity behavior activity behavior = ( activity behavior ) flow node . get behavior ( ) ; if ( activity behavior = null ) { execute activity behavior ( activity behavior , flow node ) ; } else { throw new activiti exception ( expected an activity behavior in flow node + flow node . get id ( ) ) ; } }
sql = select t1 . aa aaa from ( select r1 a . a aa from r1 r1 a ) t1 where t1 . aa > 0 ; equivalent sql = select t1 . a aaa from r1 t1 where t1 . a > 0 ; check subquery simplification ( sql , equivalent sql ) ;
return exchange . get context ( ) . get type converter ( ) . convert to ( string . class , exchange , bytes ) ; }
type type = test to type ( dpt , new byte [ ] { ( byte ) 0x ff , ( byte ) 0x7 f , ( byte ) 0x ff , ( byte ) 0x ff } , decimal type . class ) ;
queued thread pool thread pool = ( queued thread pool ) web server . get thread pool ( ) ; thread pool . set daemon ( true ) ; if ( max threads = - 1 ) { thread pool . set max threads ( max threads ) ; } session manager sm = web app context . get session handler ( ) . get session manager ( ) ;
conditional step conditional step = new conditional step ( conditional , step to run when supplier is true ) ;
add ( value ) ; }
assert xpath count ( 0 , xsd : complex type , doc ) ; assert xpath count ( 0 , xsd : element , doc ) ; }
hive decimal fifteen fractional nines dec = hive decimal . create ( 0 . 999999999999999 ) ; assert . assert not null ( fifteen fractional nines dec ) ; assert . assert equals ( 0 . 999999999999999 , hive decimal . enforce precision scale ( fifteen fractional nines dec , 15 , 15 ) . to string ( ) ) ; hive decimal sixteen fractional nines = hive decimal . create ( 0 . 9999999999999999 ) ; assert . assert not null ( sixteen fractional nines ) ; assert . assert equals ( 0 . 9999999999999999 , hive decimal . enforce precision scale ( sixteen fractional nines , 16 , 16 ) . to string ( ) ) ; hive decimal seventeen fractional nines = hive decimal . create ( 0 . 99999999999999999 ) ;
return base64 . encode ( nonce buffer ) ;
if ( prev a . _ ncols = prev b . _ ncols ) throw new parse dataset . h2 oparse exception ( files conflict in number of columns . + prev a . _ ncols + vs . + prev b . _ ncols + . ) ;
set < type declaration > tdecls = new linked hash set < type declaration > ( ) ; tdecls . add ( type declaration ) ;
test harness . wait for input processing ( ) ; test harness util . assert output equals ( output was not correct . , expected output , test harness . get output ( ) ) ; test harness . process element ( new watermark ( initial time ) , 1 , 1 ) ;
executor . execute ( writer ) ;
if ( external ) { get parent cell layout for view ( m drag info . cell ) . remove view ( m drag info . cell ) ; } rect folder location = new rect ( ) ;
multi user chat muc3 = new multi user chat ( get connection ( 2 ) , room ) ;
fold ( x = 1 | 4 , x = 5 ) ; fold ( x = 1 | 3 , x = 3 ) ; fold ( x = 1 | 1 . 1 , x = 1 ) ; fold same ( x = 1 | 3 e9 ) ; fold ( x = 1 | 3000000001 , x = - 1294967295 ) ; fold ( x = 4294967295 | 0 , x = - 1 ) ; }
fix async stack trace ( throwable , thread . current thread ( ) . get stack trace ( ) , operation failed on node : + remote address ) ;
this . props . put ( common job properties . in _ nodes , string utils . join2 ( this . node . get in nodes ( ) , , ) ) ;
dispatch nested scroll ( dx consumed , dy consumed , dx unconsumed , dy unconsumed , m parent offset in window ) ;
attribute html attribute _ html = new attribute html ( dir , class _ name , constant _ pool , constant _ html ) ; method html method _ html = new method html ( dir , class _ name , methods , java _ class . get fields ( ) , constant _ html , attribute _ html ) ;
update left right buttons ( ) ; update time ( ) ;
thread factory thread factory = executors . default thread factory ( ) ;
store . install certificate ( get ca1 ( ) ) ;
key test . set certificate entry ( alias3 , cert [ 0 ] ) ;
m content stack . push ( content ) ;
loc bytes = ( out . had annotations ( ) ? lout . to byte array ( ) : null ) ;
string process definition id with tenant = deploy test process with test tenant ( ) ;
if ( e < = out buff . length - 1 ) { if breaking lines and the last byte falls right at the line length ( 76 bytes per line ) , there will be one extra byte , and the array will need to be resized . not too bad of an estimate on array size , i ' d say . byte [ ] final out = new byte [ e ] ; system . arraycopy ( out buff , 0 , final out , 0 , e ) ; system . err . println ( having to resize array from + out buff . length + to + e ) ; return final out ; }
path rootdir = new path ( util . get data test dir ( ) , name ) ; table descriptors htds = new fstable descriptors ( fs , rootdir ) ; htable descriptor htd = new htable descriptor ( name ) ; htds . add ( htd ) ; assert not null ( htds . remove ( htd . get name as string ( ) ) ) ; assert null ( htds . remove ( htd . get name as string ( ) ) ) ; }
float used width = folder cell width px * inv . num folder columns ; int max width = available width px - get total workspace padding ( ) . x - folder margin ; float scale x = max width used width ; float scale = math . min ( scale x , scale y ) ;
string name = foo company to keyize ;
final set < integer > deleted = new hash set < > ( ) ; while ( deleted . size ( ) < num _ docs 2 ) { final integer to delete = random ( ) . next int ( num _ docs ) ; if ( deleted . contains ( to delete ) ) { deleted . add ( to delete ) ; w . delete documents ( new term ( id , string . value of ( to delete ) ) ) ; if ( random ( ) . next int ( 17 ) = = 6 ) { final index reader r = w . get reader ( ) ; assert equals ( num _ docs - deleted . size ( ) , r . num docs ( ) ) ; r . close ( ) ; } } } w . close ( ) ;
s . create query ( select cast ( e . the lost number as integer ) from my entity e ) . list ( ) ;
if ( text . length ( ) = = 0 ) { return ; } writer . write ( ) ;
meta data = index meta data . builder ( index service . get meta data ( ) ) . settings ( settings . builder ( ) . put ( index service . get meta data ( ) . get settings ( ) ) . put ( index settings . index _ refresh _ interval _ setting . get key ( ) , 100ms ) ) . build ( ) ; index service . update meta data ( meta data ) ; assert not same ( refresh task , index service . get refresh task ( ) ) ; assert true ( refresh task . is closed ( ) ) ; refresh task = index service . get refresh task ( ) ;
this . resource manager . add resource ( easy mock . < grid coverage resource > any object ( ) ) ; expect last call ( ) . times ( 2 ) ; replay ( this . resource manager ) ; this . listener . progress ( new process event ( this . status , this . inputs ) ) ;
string no dot name = name . replace ( ' . ' , ' _ ' ) ;
mock meta store event listener . pop and verify last event id ( event type . drop _ partition , first event id + 3 ) ;
{ assert . assert equals ( relay puller . get current server idx ( ) , - 1 , current server index ) ; assert . assert equals ( relay puller . get curent server ( ) = = null , true , current server null ) ; assert . assert equals ( relay puller . get servers ( ) , exp server info , server set ) ; do execute and change state ( relay puller , create set server message ( true , relay puller ) ) ; assert . assert equals ( relay puller . get current server idx ( ) , - 1 , current server index ) ; assert . assert equals ( relay puller . get curent server ( ) = = null , true , current server null ) ; assert . assert equals ( relay puller . get servers ( ) , exp server info2 , server set ) ; assert . assert equals ( relay puller . to tear conn after handling response ( ) , false , tear conn after handling response ) ; assert . assert equals ( conn state . get state id ( ) , state id . pick _ server , server set change while pick _ server ) ; assert . assert equals ( relay puller . get queue list string ( ) , relay puller queue : [ pick _ server ] , queue : server set change while pick _ server ) ; }
for ( int i = 0 ; i < number of entries ; i + + ) { assert equals ( map size = + map . size ( ) , i , map . get ( i ) ) ; }
missing unit = calendar . second ;
assert true ( set future . is cancelled ( ) ) ;
immutable list . builder < object > sub lib deps = immutable list . builder ( ) ; env . for each fwd dep ( immutable set . of ( get query target ( : sublib ) ) , sub lib deps : : add ) ; assert that ( sub lib deps . build ( ) , matchers . contains ( get query target ( : bottom ) ) ) ; }
final task lock my lock = iterables . get only element ( get task locks ( toolbox . get task action client ( ) ) ) ; if ( my lock . get data source ( ) . equals ( get data source ( ) ) ) { throw new ise ( wtf? lock data source [ % s ] = task data source [ % s ] , my lock . get data source ( ) , get data source ( ) ) ; }
set notification led color ( extras , m builder ) ;
job conf . set strings ( mapred . cache . files , ) ; job conf . set strings ( mapred . cache . files . filesizes , ) ; job conf . set strings ( mapred . cache . files . visibilities , ) ; job conf . set strings ( mapred . cache . files . timestamps , ) ; }
local description tracker = true ; } else {
b _ y _ found = true ; continue replab2 ; } while ( false ) ; cursor = v _ 3 ; break replab2 ; } } while ( false ) ; cursor = v _ 2 ;
flag values = new boolean [ ] { hcolumn descriptor . default _ encode _ on _ disk } ;
if ( _ log . should log ( log . debug ) ) _ log . debug ( aborting inbound request to + req + waited + waited + ms ) pending + _ pending inbound requests . size ( ) ) ;
assert equals ( 1 + 1 l , exec ( int x = 1 ; long y = 1 ; return x + y ; ) ) ;
test ( function mul ( x , y ) { return x * y } function add ( x , y ) { return x + y } + var a = 1 + mul ( 2 , 3 ) ; var b = 2 * add ( 3 , 4 ) , var a = 1 + 2 * 3 ; var b = 2 * ( 3 + 4 ) ) ;
local workspace . remove ( ) ; } try { for ( namespace info name spaceinfo : catalog . get namespaces ( ) ) { if ( encoder . get namespaces ( ) . get uri ( name spaceinfo . get prefix ( ) ) = = null ) { encoder . get namespaces ( ) . declare prefix ( name spaceinfo . get prefix ( ) , name spaceinfo . get uri ( ) ) ; } } } finally {
moving _ = false ;
if ( range subset = = null ) return ; if ( range subset . get field subset ( ) . size ( ) > 1 ) { throw new wcs exception ( multi field coverages are not supported yet , invalid parameter value , range subset ) ; }
if ( opstr = null & & first = last ) { preconditions . check state ( child count = = 2 , bad binary operator \ % s \ : expected 2 arguments but got % s , opstr , child count ) ; int p = precedence ( n ) ; for right - hand - side of operations , only pass context if it ' s the in _ for _ init _ clause one . context rhs context = get context for no in operator ( context ) ; boolean needs parens = ( context = = context . start _ of _ expr ) & & first . is object pattern ( ) ; if ( n . is assign ( ) & & needs parens ) { add ( ( ) ; } if ( node util . is assignment op ( n ) | | type = = token . exponent ) { assignment operators and ' * * ' are the only right - associative binary operators add expr ( first , p + 1 , context ) ; cc . add op ( opstr , true ) ; add expr ( last , p , rhs context ) ; } else { unroll binary operator ( n , type , opstr , context , rhs context , p , p + 1 ) ; } if ( n . is assign ( ) & & needs parens ) { add ( ) ) ; } return ; } cc . start source mapping ( n ) ;
get to walk ( ) . add ( 0 , nd ) ;
if ( is deferred ) { call on drag end ( ) ; } }
sb . append ( css . substring ( append index , m . start ( ) ) ) ;
assert true ( results . contains ( boolean . true ) ) ; assert false ( results . contains ( boolean . false ) ) ; assert command execution events ( command1 , hystrix event type . success ) ; assert command execution events ( command2 , hystrix event type . success ) ; assert command execution events ( command3 , hystrix event type . semaphore _ rejected , hystrix event type . fallback _ missing ) ; assert equals ( 0 , circuit breaker . metrics . get current concurrent execution count ( ) ) ; assert sane hystrix request log ( 3 ) ; }
urlclass loader ucl = access controller . do privileged ( new privileged action < urlclass loader > ( ) { public urlclass loader run ( ) { return new factory urlclass loader ( urls , parent , acc ) ; } } ) ; return ucl ;
test directory . directory ( nothing to see here move along ) ; int [ ] cluster ports = new int [ ] { port authority . allocate port ( ) , port authority . allocate port ( ) , port authority . allocate port ( ) } ; final string initial hosts = initial hosts ( cluster ports ) ; final cyclic barrier barrier = new cyclic barrier ( cluster ports . length ) ; final list < thread > da threads = new array list < > ( cluster ports . length ) ; final highly available graph database [ ] dbs = new highly available graph database [ cluster ports . length ] ; for ( int i = 0 ; i < cluster ports . length ; i + + ) { final int final i = i ; thread t = new thread ( ( ) - > { try { barrier . await ( ) ; dbs [ final i ] = start db at base ( final i , initial hosts , cluster ports [ final i ] ) ; } catch ( interrupted exception | broken barrier exception e ) { throw new runtime exception ( e ) ; } } ) ; da threads . add ( t ) ; t . start ( ) ; }
list < string > joining servers = new array list < string > ( ) ;
action config base config = module config . find action config ( ancestor ) ; if ( base config = = null ) { throw new unavailable exception ( unable to find + action config for ' + ancestor + ' to extend . ) ; }
string if range = header . get ( if - range ) ; boolean header if range missing or matching = ( if range = = null | | etag . equals ( if range ) ) ; string if none match = header . get ( if - none - match ) ;
for ( int i = new pred . predecessors . next set bit ( 0 ) ; i > = 0 ; i = new pred . predecessors . next set bit ( i + 1 ) ) { ssa basic block pred block = parent . get blocks ( ) . get ( i ) ; pred block . replace successor ( index , new pred . index ) ; } return new pred ;
mapper . map ( key , value , output , reporter ) ;
public void test application attempt id pbimpl ( ) throws exception { validate pbimpl record ( application attempt id pbimpl . class , application attempt id proto . class ) ; }
list list = s . create query ( from human h inner join h . offspring as o with o . body weight < : some limit ) . set double ( some limit , 1 ) . list ( ) ; assert true ( ad - hoc on did not take effect , list . is empty ( ) ) ;
if ( value = = literals [ 0 ] ) { fixed run length = 2 ; variable run length = 0 ; } else { fixed run length = 0 ; variable run length = 2 ; } return ;
from ( direct : multiple - codec ) . to ( netty4 : tcp : localhost : { { port } } ?encoders = encoders & sync = false ) ; from ( netty4 : tcp : localhost : { { port } } ?decoders = length - decoder , string - decoder & sync = false ) . to ( mock : multiple - codec ) ;
while ( type . char at ( end - 1 ) < = ' ' ) { - - end ; } return type . substring ( i , end ) ;
assert equals ( shapezip _ basic polygons . zip , zip . get attachment file name ( fct , op ) ) ;
redeliver unacknowledged messages ( ) ; return ;
super . on after on create ( saved instance state ) ; }
wal . start cache flush ( hri1 . get encoded name as bytes ( ) , t1 . get families keys ( ) ) ;
template type map param type map = param type . get template type map ( ) ; immutable list < template type > keys = param type map . get template keys ( ) ; template type map arg type map = arg object type . get template type map ( ) ;
if ( context = = null ) { throw new illegal state exception ( cannot call acra . get acrashared preferences ( ) before acra . init ( ) . ) ; } else if ( . equals ( config . shared preferences name ( ) ) ) { return context . get shared preferences ( config . shared preferences name ( ) , config . shared preferences mode ( ) ) ; } else { return preference manager . get default shared preferences ( context ) ; }
env . execute ( basic page rank example ) ;
transaction confidence confidence = tx . get confidence ( ) ;
if ( comment byte count > 0 ) { if ( skip comments and extra ) { zip file . skip ( it0 , comment byte count ) ; } else { byte [ ] comment bytes = new byte [ comment byte count ] ; it0 . get ( comment bytes ) ; comment = new string ( comment bytes , 0 , comment bytes . length , standard charsets . utf _ 8 ) ; } }
final documents writer delete queue delete queue = this . delete queue ; long seq no = delete queue . add delete ( queries ) ; flush control . do on delete ( ) ; last seq no = math . max ( last seq no , seq no ) ; if ( apply all deletes ( delete queue ) ) { seq no = - seq no ; } return seq no ; }
return new attribute color ( attribute . intensity _ bold , attribute . reset ) ;
output . write utf ( < init > ) ;
mock message ( evt ) ;
data . put extra ( extra _ api _ version , open pgp api . api _ version ) ; intent result ;
assert equals ( 1 , unassigned info . get number of delayed unassigned ( state with delayed shard ) ) ;
a = new byte [ ( int ) runtime . get runtime ( ) . max memory ( ) - 32 ] ;
closeable reference < integer > original ref1 = new reference ( 400 ) ;
verify read ( binary sortable deserialize read , type infos [ index ] , null ) ;
web session session4 = this . store . create web session ( ) . block ( ) ; assert not null ( session4 ) ; session4 . start ( ) ; session4 . save ( ) . block ( ) ; web session session5 = this . store . create web session ( ) . block ( ) ; assert not null ( session5 ) ; session5 . start ( ) ; session5 . save ( ) . block ( ) ;
l = 5678956789 l ; i = ( int ) l ; assert ( i = = 1383989493 ) ; l = - 5678956789 l ;
final property name property = rd . translate property ( attribute name ) ; attribute descriptor ad = ( attribute descriptor ) property . evaluate ( rd . get feature type ( ) ) ; if ( ad = = null ) { return new closeable iterator adapter < string > ( new array list < string > ( ) . iterator ( ) ) ; }
volt table . column info columns [ ] = new volt table . column info [ table . get column count ( ) ] ;
update stream ( stream _ a , allocation _ quantum , true ) ; update stream ( stream _ b , allocation _ quantum , true ) ; update stream ( stream _ c , allocation _ quantum , true ) ; update stream ( stream _ d , allocation _ quantum , true ) ;
for ( int i = 1 ; i < enabled periods . length ; i + + ) { if ( enabled periods [ i ] . seek to us ( position us ) = position us ) { throw new illegal state exception ( children seeked to different positions ) ; } } return position us ;
final intent i = m activity . get base context ( ) . get package manager ( ) . get launch intent for package ( m activity . get base context ( ) . get package name ( ) ) ; i . add flags ( intent . flag _ activity _ new _ task ) ; i . add flags ( intent . flag _ activity _ clear _ top ) ; m activity . start activity ( i ) ; m activity . finish ( ) ; }
return new object [ ] { iso - 10646 - ucs - 4 , null } ;
if ( configuration . compatibility ( ) . enabled ( ) ) { return media type . application _ object ; }
if ( build config . debug ) log . d ( co coin , upload database failed + code + + msg ) ; sync progress dialog . dismiss ( ) ; new material dialog . builder ( m context ) . title ( r . string . sync _ failed ) . content ( r . string . uploading _ fail _ 0 ) . positive text ( r . string . ok _ 1 ) . cancelable ( false ) . show ( ) ; }
safe close ( connection ) ;
list < put > puts = new array list < put > ( 100 ) ;
assert true ( timeout should occur faster than + taken , taken < 4500 ) ;
table ht = test _ util . create table ( table name , families , integer . max _ value ) ; integer [ ] put rows = new integer [ ] { 1 , 3 , 5 , 7 } ;
return conf . get ( key ) ;
set < string > logged rows = new hash set < string > ( ) ;
for ( bundle f : fragments ) { if ( deps . key set ( ) . contains ( f . get symbolic name ( ) ) ) { deps . put ( f . get symbolic name ( ) , f ) ; collect required bundles ( f , admin , deps , only reexport ) ; } }
if ( ( descriptor instanceof fragment descriptor ) ) { context . get session handler ( ) . get session cookie config ( ) . set comment ( comment ) ; context . get meta data ( ) . set origin ( cookie - config . comment , descriptor ) ; } break ;
destroy machine ( target machine ) ;
for ( int arc idx = 0 ; arc idx < node . num arcs ; arc idx + + ) { final builder . arc < t > arc = node . arcs [ arc idx ] ; system . out . println ( label = + arc . label + target = + ( ( builder . compiled node ) arc . target ) . address + h = + h + output = + fst . outputs . output to string ( arc . output ) + is final? = + arc . is final ) ; h = prime * h + arc . label ; h = prime * h + ( ( builder . compiled node ) arc . target ) . address ; h = prime * h + arc . output . hash code ( ) ; h = prime * h + arc . next final output . hash code ( ) ; if ( arc . is final ) { h + = 17 ; } }
write file ( . twitter4j . properties , twitter4j . rest base url = http : somewhere . com + \ n + twitter4j . http . use ssl = false ) ;
synchronized ( this ) { set < map . entry < string , list < unresolved permission > > > set = perms . entry set ( ) ; for ( map . entry < string , list < unresolved permission > > e : set ) {
ref . set reference ( null ) ; return true ;
if ( m current origin . y < get height ( ) - m hour height * 24 - m header height - m header row padding * 2 - m header margin bottom - m time text height 2 ) m current origin . y = get height ( ) - m hour height * 24 - m header height - m header row padding * 2 - m header margin bottom - m time text height 2 ;
rule dto rule3 = db client . rule dao ( ) . select or fail by key ( db tester . get session ( ) , default organization , rule _ key3 ) ; assert that ( rule3 ) . is not null ( ) ; assert that ( rule3 . get status ( ) ) . is equal to ( rule status . ready ) ;
rsp . set return fields ( new solr return fields ( id , score , foo _ s , req ) ) ; result sheet = get wsresult for query ( req , rsp ) ;
if ( target root . equals ( target file ) & & sync or overwrite ) continue ; file system target fs = target file . get file system ( conf ) ;
return centralities . get ( node ) ;
assert that ( under test . provide ( settings . as config ( ) ) ) . is same as ( client ) ;
try { service reference < ? > [ ] references = context . get all service references ( shell . class . get name ( ) , null ) ; for ( service reference < ? > ref : references ) { shell = ( shell ) context . get service ( ref ) ; return shell ; } return null ; } catch ( invalid syntax exception e ) { logger . warning ( cannot load shell on dbre database listener impl . ) ; return null ; }
this . attributes = new attributes impl ( attributes ) ; this . element path = element path ; }
byte array ba = _ cache . acquire ( ) ; new byte array ( payload , offset , length ) ; new byte [ length ] ) ; system . arraycopy ( payload , offset , ba . get data ( ) , 0 , length ) ; ba . set valid ( length ) ; ba . set offset ( 0 ) ;
thread . sleep ( 10000 ) ; metrics record builder dn metrics = get metrics ( dn . get metrics ( ) . name ( ) ) ; metrics asserts . assert counter ( blocks cached , 1l , dn metrics ) ; metrics asserts . assert counter ( blocks uncached , 1l , dn metrics ) ; }
return pws results ;
update image metrics ( ) ; }
graph . command ( new osqlsynch query ( select from v where p1 = ' + i + ' ) ) . execute ( ) ;
while ( field id < struct fields . size ( ) ) { row builder . append null ( ) ; field id + + ; } builder . close entry ( ) ; }
if ( id = = r . id . action _ settings ) { m wave swipe refresh layout . set refreshing ( true ) ; refresh ( ) ; return true ; } return super . on options item selected ( item ) ; }
node subgroups node = xmlutils . find child ( group node , subgroups _ node _ name ) ; if ( subgroups node = = null ) return ;
finish decode ( ) ; super . channel closed ( ctx , e ) ; }
native _ flush ( ) ;
parcelable super state = in . read parcelable ( recycler view . class . get class loader ( ) ) ; this . super state = super state = null ? super state : empty _ state ; prev first visible position = in . read int ( ) ; prev first visible child height = in . read int ( ) ; prev scrolled children height = in . read int ( ) ; prev scroll y = in . read int ( ) ; scroll y = in . read int ( ) ;
g . set color ( m _ bg color highlight ) ; final rectangle r = get register bounds ( m _ highlighted register ) ;
glmparameters params = new glmparameters ( ) ;
in format = new dummy input format ( ) ;
super . draw divider ( canvas , bounds , flat list position ) ;
context . exit ( ) ; }
po . set parallelism ( this . get parallelism ( ) ) ; single input semantic properties props = new single input semantic properties ( ) ;
value = v2 . get bytes ( ) ;
statement stmt = con default . create statement ( ) ;
qname = new javax . xml . namespace . qname ( name . uri ( ) , name . local name ( ) ) ;
log . debug ( ' * ' handler ) ;
xssimple type base validator = null ;
document = new bson document ( driver _ field , template document . get document ( driver _ field ) ) ;
measure tile size = math . min ( desired tile width , desired tile height ) ; } else {
sleep ( ) ; return 0 ; }
assert equals ( 4 , target remote cache . get ( 4 ) ) ;
list < person > persons = entity manager . create query ( select p + from person p + where p . nick name is null , person . class ) . get result list ( ) ;
if ( leaves . get ( leaf . hash code ( ) ) . get tsuid ( ) . equals ( leaf . get tsuid ( ) ) ) { final leaf collision = leaves . get ( leaf . hash code ( ) ) ; if ( tree = null ) { tree . add collision ( leaf . get tsuid ( ) , collision . get tsuid ( ) ) ; }
if ( t = = null ) throw null ;
builder . prefixes . append ( p builder . prefixes ) ; builder . source . append ( p builder . source ) ; builder . suffixes . append ( p builder . suffixes ) ; builder . modifiers = p builder . modifiers ; return builder ;
sender . run ( time . milliseconds ( ) ) ; send add partitions .
s ind aug = 0 ;
for ( int i = 0 ; i < 2 ; i + + ) { do transaction ( ) ; }
mock endpoint mock = get mock endpoint ( mock : result ) ; mock . expected message count ( 1 ) ; mock . assert is satisfied ( ) ; exchange out = mock . assert exchange received ( 0 ) ;
verify ( handler , never ( ) ) . can handle ( any ( document . class ) ) ; } finally {
object output = arc . get output ( ) ;
if ( period holder . has period ( ) ) { return ; } optional < measure > ncloc data measure = measure repository . get raw measure ( file , this . ncloc data metric ) ;
for ( int i = 0 ; i < 3 ; i + + ) { string node = 0 ; test ssl channel builder server channel builder = new test ssl channel builder ( mode . server ) ; server channel builder . configure ( ssl server configs ) ; server channel builder . flush delay count = i ; server = new nio echo server ( listener name . for security protocol ( security protocol . ssl ) , security protocol . ssl , new test security config ( ssl server configs ) , localhost , server channel builder , null ) ; server . start ( ) ; create selector ( ssl client configs ) ; inet socket address addr = new inet socket address ( localhost , server . port ( ) ) ; selector . connect ( node , addr , buffer _ size , buffer _ size ) ; network test utils . wait for channel close ( selector , node , channel state . state . authentication _ failed ) ; server . close ( ) ; selector . close ( ) ; }
if ( arc . is last ( ) ) { break ; }
assert true ( s . create query ( select new org . hibernate . test . legacy . s ( s . count , s . address ) from simple s ) . list ( ) . size ( ) = = 1 ) ;
jpa query . set parameter ( index , argument ) ;
perform form based authentication ( null ) ;
ragdoll utils . set transform ( link . bone , position , tmp rot1 , false , bone list ) ;
assert xpath evaluates to ( - 1 . 2 53 . 50000003577337 - 1 . 2000000000000002 53 . 60000003565695 - 1 . 1 53 . 60000003565695 - 1 . 1 53 . 50000003577337 - 1 . 2 53 . 50000003577337 , gsml : mapped feature [ @ gml : id = ' gsml . mappedfeature . mf3 ' ] gsml : shape gml : polygon gml : exterior gml : linear ring gml : pos list , doc ) ;
string [ ] index names = new string [ ] { with _ tv , without _ tv } ;
long primary version1 = primary . flush ( 0 ) ; assert true ( primary version1 > 0 ) ; thread . sleep ( test util . next int ( random ( ) , 1 , 30 ) ) ;
catch ( sqldialect not supported exception ignore ) { }
if ( i18n . format ( config element . get language key ( ) ) . equals ( config element . get language key ( ) ) ) length = mc . font renderer . get string width ( i18n . format ( config element . get language key ( ) ) ) ; else length = mc . font renderer . get string width ( config element . get name ( ) ) ; if ( length > this . max label text width ) this . max label text width = length ; } } }
assert . assert false ( snapshot file still exists . , snapshot file . exists ( ) ) ; }
path target of tests = file system test helper . get test root path ( fs target ) ;
accum pos inc = 0 ;
if ( support common jsmodules ) { for ( compiler input input : ordered inputs ) { new process common jsmodules ( this ) . process ( * externs * null , input . get ast root ( this ) , * force module detection * false ) ; } } }
int x = view . get x ( ) ;
final list < string > plan parts = ostring serializer helper . split ( i fetch plan , ' ' ) ;
endpoint . expected minimum message count ( 2 ) ; endpoint . assert is satisfied ( ) ; list < exchange > list = endpoint . get received exchanges ( ) ; log . debug ( received : + list ) ;
unified set < integer > set = unified set . < integer > new set ( 10 ) . with ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ) ;
if ( operation = = class ) if ( obj instanceof bshtype ) { if ( to lhs ) throw new eval error ( can ' t assign . class , this , callstack ) ; name space namespace = callstack . top ( ) ; return ( ( bshtype ) obj ) . get type ( callstack , interpreter ) ; } else throw new eval error ( attempt to use . class suffix on non class . , this , callstack ) ;
expr node generic func desc addition = new expr node generic func desc ( type info factory . int type info , plus , arrays . as list ( fourty , fifty ) ) ;
assert equals ( quote ( time . to string ( ) ) , mapper . write value as string ( time ) ) ;
try { config stream = new file input stream ( properties ) ; } catch ( file not found exception | access control exception fnfe ) { the properties string is likely not a file }
throw new permanent locking exception ( local lock contention ) ;
test in function ( var e ; try { } catch ( e ) { e ; } ; try { } catch ( e ) { e ; } , var e ; try { } catch ( e jscomp 1 ) { e jscomp 1 ; } ; try { } catch ( e jscomp 2 ) { e jscomp 2 ; } ) ; test in function ( var e ; try { } catch ( e ) { e ; try { } catch ( e ) { e ; } } , var e ; try { } catch ( e jscomp 1 ) { e jscomp 1 ; try { } catch ( e jscomp 2 ) { e jscomp 2 ; } } ) ; test in function ( try { } catch ( e ) { e ; } ; try { } catch ( e ) { e ; } var e ; , try { } catch ( e jscomp 1 ) { e jscomp 1 ; } ; try { } catch ( e jscomp 2 ) { e jscomp 2 ; } var e ; ) ; test in function ( try { } catch ( e ) { e ; try { } catch ( e ) { e ; } } var e ; , try { } catch ( e jscomp 1 ) { e jscomp 1 ; try { } catch ( e jscomp 2 ) { e jscomp 2 ; } } var e ; ) ; invert = true ;
file system fs = this . parent . get filesystem ( ) ; path region dir = get split dir for daughter ( this . parent . get filesystem ( ) , this . splitdir , hri ) ; hregion r = hregion . new hregion ( this . parent . get table dir ( ) , this . parent . get log ( ) , fs , this . parent . get base conf ( ) , hri , this . parent . get table desc ( ) , rs services ) ; long half parent read request count = this . parent . get read requests count ( ) 2 ; r . read requests count . set ( half parent read request count ) ; r . set op metrics read request count ( half parent read request count ) ; long half parent write request = this . parent . get write requests count ( ) 2 ; r . write requests count . set ( half parent write request ) ; r . set op metrics write request count ( half parent write request ) ; hregion . move initial files into place ( fs , region dir , r . get region dir ( ) ) ; return r ;
if ( scope instanceof xmlwith scope ) { xml obj = ( xmlobject impl ) scope . get prototype ( ) ; if ( xml obj . has xmlproperty ( xml name ) ) { break ; } if ( first xml object = = null ) { first xml object = xml obj ; } }
load balancer simulator . shutdown ( ) ;
golab2 : while ( true ) { v _ 2 = cursor ; lab3 : do {
callback . clear last msg ( ) ;
if ( words in common < set . words in use ) system . arraycopy ( set . words , words in common , words , words in common , set . words in use - words in common ) ; recalculate words in use ( ) ;
replacement instruction = switch instruction ; } }
if ( obj = = null | | ( obj instanceof long literal node ) ) { return false ; }
boolean status result = registry . status update ( local _ region _ app _ name , seed . get id ( ) , instance status . out _ of _ service , 0 , false ) ;
if ( m _ writer = null ) m _ writer . write ( c ) ;
assert equals ( 2 , counter . get rolling sum ( hystrix rolling number event . timeout ) ) ;
final int mem alloc size = 1025 * native . wchar _ size ; final memory file path default = new memory ( mem alloc size ) ; length = psapi . instance . get module file name ex ( process , null , file path default , ( mem alloc size native . wchar _ size ) - 1 ) ; if ( length = = 0 ) throw new win32 exception ( kernel32 . instance . get last error ( ) ) ; assert true ( path didn ' t contain ' + search sub str + ' : + native . to string ( file path default . get char array ( 0 , mem alloc size native . wchar _ size ) ) , native . to string ( file path default . get char array ( 0 , mem alloc size native . wchar _ size ) ) . to lower case ( ) . contains ( search sub str ) ) ;
verify ( m view ) . show user name ( user name ) ;
create hard link mult ( parent dir , file base names , link dir , get hard link command . get max allowed cmd arg length ( ) ) ;
cs . handle ( new node update scheduler event ( rm node1 ) ) ;
node1 . cluster meet ( 127 . 0 . 0 . 1 , node info4 . get port ( ) ) ; string node7 id = jedis cluster test util . get node id ( node4 . cluster nodes ( ) ) ; jedis cluster test util . assert node is known ( node3 , node7 id , 1000 ) ; jedis cluster test util . assert node is known ( node2 , node7 id , 1000 ) ; jedis cluster test util . assert node is known ( node1 , node7 id , 1000 ) ;
final boolean ssl configured = this . setup sslfactories ( props ) ;
this . header = header ;
write chunk ( ) ; log . debug ( { } : closing underlying output stream . , id ) ;
list < user to > users = read web server users ( daemon config to ) ;
e = new edge ( row . get string ( 14 ) , row . get ( 0 ) , row . get ( 1 ) , row . get boolean ( 2 ) ) ; } e . put property ( count , row . get int ( 11 ) ) ; e . put property ( visibility , row . get string ( 12 ) ) ; element list . add ( e ) ; }
text slider view . image ( urls [ i ] ) . set scale type ( base slider view . scale type . fit ) . set on slider click listener ( this ) ;
simple bean . set long number ( 3 l ) ;
scheduler app . reset allowed locality level ( prio , node type . node _ local ) ;
log . trace ( { } is with unknown timezone : { } , date type , date . get time zone ( ) . get id ( ) ) ; start = new org . joda . time . date time ( range date , cal dav loader impl . default time zone ) ; }
assert . assert equals ( block size + 12 , stats . get bytes written ( ) ) ;
rs1 = st . get result set ( ) ;
assert that ( name found in search ( initial rule ) ) . is false ( ) ;
throw ( out of memory error ) e ; } else { log . error ( string utils . stringify exception ( e ) ) ; throw new runtime exception ( e ) ; } }
return last cq mvcc ;
blocking source context < string > source context = new blocking source context < > ( ) ; map < kafka topic partition , long > partitions with initial offsets = collections . singleton map ( new kafka topic partition ( topic , partition ) , kafka topic partition state sentinel . group _ offset ) ; keyed deserialization schema < string > schema = new keyed deserialization schema wrapper < > ( new simple string schema ( ) ) ; final kafka010 fetcher < string > fetcher = new kafka010 fetcher < > ( source context , partitions with initial offsets , null , * periodic watermark extractor * null , * punctuated watermark extractor * new test processing time service ( ) , 10 , * watermark interval * this . get class ( ) . get class loader ( ) , task _ name , new unregistered metrics group ( ) , schema , new properties ( ) , 0 l , false ) ;
if ( old value = = null ) { system . clear property ( hadoop . home . dir ) ; } else { system . set property ( hadoop . home . dir , old value ) ; } try {
public object invoke ( evaluation context ctx , @ suppress warnings ( rawtypes ) class [ ] param types , object [ ] param values ) throws elexception { target t = get target ( ctx ) ;
handle container updates ( application , update requests ) ;
needs sync data ( true ) ;
case ljava lang boolean ; z : asm . visit method insn ( invokevirtual , java lang boolean , boolean value , ( ) z , false ) ; break ; case ljava lang object ; b : asm . visit type insn ( checkcast , java lang byte ) ;
if ( time in nano = = 0 ) return na n ki b s ; long rate = ( long ) ( ( ( double ) bytes time in nano ) * 1000 * 1000 * 1000 ) ;
if ( available capacity > = 0 & & available capacity = max capacity ) { synchronized ( lock ) { available capacity = math . min ( ( available capacity + capacity ) , max capacity ) ; } }
long current term ord = cached term ords . add ( text ) ;
int [ ] pos = http text view utils . get view to header position ( view , view _ length + 1 , view _ length + 2 ) ;
distributer dist = new distributer ( ) ; dist . create connection ( localhost , , , 20000 , client auth scheme . hash _ sha1 ) ; dist . create connection ( localhost , , , 20001 , client auth scheme . hash _ sha256 ) ; thread . sleep ( 1000 ) ;
return ( t ) value ;
op = get operation ( get - proto - schema ) ;
comparator = ( ( atomic type < t > ) type info ) . create comparator ( sort order [ 0 ] , execution config ) ;
indarray predictions = nd4j . create ( new double [ ] [ ] { { 1 . 0 , 0 . 001 } , add 0 . 001 to avoid numerical rounding issues ( float vs . double , etc ) { 0 . 899 , 0 . 101 } , { 0 . 799 , 0 . 201 } , { 0 . 699 , 0 . 301 } , { 0 . 599 , 0 . 401 } , { 0 . 499 , 0 . 501 } , { 0 . 399 , 0 . 601 } , { 0 . 299 , 0 . 701 } , { 0 . 199 , 0 . 801 } , { 0 . 099 , 0 . 901 } } ) ; indarray actual = nd4j . create ( new double [ ] [ ] { { 1 , 0 } , { 1 , 0 } , { 1 , 0 } , { 1 , 0 } , { 1 , 0 } , { 0 , 1 } , { 0 , 1 } , { 0 , 1 } , { 0 , 1 } , { 0 , 1 } } ) ;
output . append ( sitemap home label = \ main menu \ { \ n ) ;
v1 = get v ( graph , id ) ; assert not null ( v1 ) ; assert empty ( graph . query ( ) . has ( name , some event ) . has ( place , somewhere ) . vertices ( ) ) ; assert not empty ( graph . query ( ) . has ( name , some event ) . vertices ( ) ) ; thread . sleep ( 1001 ) ;
counts . increment restored checkpoints ( ) ; counts . increment restored checkpoints ( ) ; counts . increment in progress checkpoints ( ) ; counts . increment completed checkpoints ( ) ; counts . increment in progress checkpoints ( ) ; counts . increment failed checkpoints ( ) ; assert equals ( restored , snapshot . get number of restored checkpoints ( ) ) ;
char [ ] ins = new char [ len instruction ] ;
send done ( umbilical ) ;
set state ( to state ) ;
netty server bootstrap configuration bootstrap configuration = resolve and remove reference parameter ( parameters , bootstrap configuration , netty server bootstrap configuration . class ) ;
comment adapter . on selected items change listener change listener = new comment adapter . on selected items change listener ( ) { @ override public void on selected items changed ( ) { if ( m action mode = null ) { if ( get selected comment count ( ) = = 0 ) { m action mode . finish ( ) ; } else { update action mode title ( ) ;
sb . append ( 1 ) ;
processor definition helper . resolve known constant fields ( this ) ;
for ( int i = 0 ; i < 512 ; i + + ) { a _ out . write bytes ( bc ) ; }
if ( ( eq _ s _ b ( 1 , s ) ) ) { break lab2 ; }
properties override = new properties ( ) ; override . put all ( prop ) ; override . put all ( override properties ) ; prop = override ; }
assert . assert true ( stream request . get header ( content _ type _ header ) . starts with ( rest constants . header _ value _ multipart _ related ) ) ;
this . failure injector = failure injector ;
int max days = 29 ; if ( eon = = null ) { if ( year = datatype constants . field _ undefined ) max days = maximum day in month for ( year , get month ( ) ) ; } else { big integer years = get eon and year ( ) ; if ( years = null ) { max days = maximum day in month for ( get eon and year ( ) , datatype constants . february ) ; } }
boolean is volume on sec = false ;
id = 0 + id ; } bytes ref encoded = uid . encode id ( id ) ; assert equals ( id , do decode id ( encoded ) ) ; assert equals ( 1 + ( id . length ( ) + 1 ) 2 , encoded . length ) ; }
rest configuration ( ) . component ( netty4 - http ) . host ( localhost ) . port ( get port ( ) ) . binding mode ( rest binding mode . auto ) ;
writer . add document ( doc ) ;
css . font weight weight value = ( css . font weight ) from . get attribute ( css . attribute . font _ weight ) ;
if ( signum > = 0 ) { norm bit len | = ( 1 < < 31 ) ; } for ( int i = 0 ; i < 4 & & len > 0 ; i + + , len - - ) { final byte b = ( byte ) ( norm bit len > > > ( 8 * ( 3 - i ) ) ) ; target . put ( offset + + , b ) ; }
expected rows = num rows ;
temp order . add ( insert after + 1 , ordering ) ;
intent service intent = new intent ( instrumentation registry . get target context ( ) , local service . class ) ;
string [ ] args ;
full http message . headers ( ) . set int ( names . stream _ id , stream id ) ;
tomcat . add servlet ( ctxt , tester servlet , new tester servlet ( ) ) ;
future = buffer . get ( first , 1 , size of buffered pages ( 10 ) ) ; assert false ( future . is done ( ) ) ;
assert true ( m counting lru map . contains ( key2 ) ) ; assert equals ( 3 , m counting lru map . get count ( ) ) ; assert equals ( 360 , m counting lru map . get size in bytes ( ) ) ; assert key order ( key1 , key2 , key3 ) ; assert value order ( 110 , 120 , 130 ) ; assert true ( m counting lru map . contains ( key1 ) ) ; assert equals ( 3 , m counting lru map . get count ( ) ) ; assert equals ( 360 , m counting lru map . get size in bytes ( ) ) ; assert key order ( key1 , key2 , key3 ) ;
free up ( size ) ;
assert equals ( 0 , alloc response . get allocated containers ( ) . size ( ) ) ;
else if ( is collection ( reverse field type class ) ) { string reverse generic type name = get generic type name ( reverse field ) ; if ( class name . equals ( reverse generic type name ) ) { if ( action = = get _ associations _ action ) { add into association model collection ( class name , generic type name , null , const . model . many _ to _ many ) ; } else if ( action = = get _ association _ info _ action ) { add into association info collection ( class name , generic type name , null , field , reverse field , const . model . many _ to _ many ) ; } reverse associations = true ; } }
if ( tabular type . get row type ( ) . is value ( value ) ) { throw new invalid open type exception ( argument value ' s composite type [ + value . get composite type ( ) + ] is not assignable to + this tabular data instance ' s row type [ + tabular type . get row type ( ) + ] . ) ; }
inflater output stream ios = new inflater output stream ( os ) ; ios . write ( compressed bytes , 0 , length ) ; string result = new string ( os . to byte array ( ) ) ; assert equals ( test string , result ) ; }
jlabel input val label = new jlabel ( jmeter utils . get res string ( foreach _ input ) ) ; non - nls - 1
ssr . throw exception on next use = false ; }
try { iterable < file result < void > > results = lists . new array list ( new file result < void > ( temp1 , 1 , null , null , null ) , new file result < void > ( temp2 , 1 , null , null , null ) , new file result < void > ( temp3 , 1 , null , null , null ) ) ; write op . build output filenames ( results ) ; fail ( should have failed . ) ; } catch ( illegal state exception exn ) { assert equals ( only generated 1 distinct file names for 3 files . , exn . get message ( ) ) ; }
out . write ( user dhruba unraidable file0 \ n . get bytes ( ) ) ; out . write ( user dhruba unraidable file1 \ n . get bytes ( ) ) ; out . close ( ) ; fsdata output stream dir out = file sys . create ( dir list path ) ; file status [ ] dirs = file sys . list status ( new path ( user rvadali dir - raidtest ) ) ; for ( file status dir : dirs ) { dir out . write ( dir . get path ( ) . to string ( ) . get bytes ( ) ) ; dir out . write ( \ n . get bytes ( ) ) ; }
collection < float > float string = get value list ( response , maxn , field facets , string _ sd , float , false ) ;
tdrevision rev d = new tdrevision ( rev2 . get doc id ( ) , null , true ) ;
return type check method argument with generics ( parameter type . get component type ( ) , argument type . get component type ( ) , last arg ) ;
handler . remove ( context ) ;
string notif type = super . get type ( ) ; if ( is valid basic ( notif type , super . get source ( ) , tmp relation id , tmp relation type name ) | | ( is valid create ( notif type ) & & is valid update ( notif type , tmp role name , tmp new role value , tmp old role value ) ) ) { super . set source ( null ) ; throw new invalid object exception ( invalid object read ) ; }
uri uri = build urifrom bean ( expected host , expected port , expected db , expected schema , expected repo id , expected user , expected password ) ;
return loc ;
try { b . set unicode locale keyword ( k , fooo ) ; fail ( ) ; } catch ( illformed locale exception ifle ) { }
properties template properties = new properties ( ) ; template properties . load ( res . in ( ) ) ; properties resolved properties = new properties ( ) ; for ( entry < object , object > prop entry : template properties . entry set ( ) ) { string value = ( string ) prop entry . get value ( ) ; if ( geo server environment . allow _ env _ parametrization ) { value = ( string ) gs environment . resolve value ( value ) ; } resolved properties . set property ( ( string ) prop entry . get key ( ) , value ) ; } final string relative = source backup folder . dir ( ) . to uri ( ) . relativize ( res . file ( ) . to uri ( ) ) . get path ( ) ;
e . print stack trace ( ) ; } }
if ( server channel . is open ( ) ) { try { server channel . close ( ) ; } catch ( ioexception e ) { log . warn ( e ) ; } } new file ( _ unix socket ) . delete ( ) ;
load model ( models gltf box inter box interleaved . gltf , new vector3f ( 0 , 0 , 0 ) , 1f ) ; probe node . attach child ( assets . get ( 0 ) ) ;
mockito . when ( storage handler . is external table ( table ) ) . then return ( true ) ;
mockito . verify ( nn spy , at least once ( ) ) . block received and deleted ( any ( datanode registration . class ) , any string ( ) , any ( storage received deleted blocks [ ] . class ) ) ;
if ( local import instance = = null ) { throw new org . apache . axis2 . databinding . adbexception ( property cannot be null ) ; }
output = < doc > + output + < doc > ; saxreader reader = new saxreader ( ) ; document document = reader . read ( new string reader ( output ) ) ; element span element = ( element ) document . get root element ( ) . elements ( ) . get ( 0 ) ; assert equals ( element , span element . get name ( ) ) ; }
boolean last = is last content to write ( len ) ;
operation = grp . group ( 1 ) ;
f . add window listener ( new window adapter ( ) { public void window closing ( window event e ) { system . exit ( 0 ) ; } } ) ;
assert that ( open sessions latch , close socket . close latch . await ( 1 , time unit . seconds ) , is ( true ) ) ;
store store = r . get store ( column _ family ) ; create store file ( r ) ; for ( int i = 0 ; i < max _ files _ to _ compact + 1 ; i + + ) { create store file ( r ) ; } count down latch latch = new count down latch ( 1 ) ;
typeref test expected = test . copy ( ) ;
numerator accum * = p ; denominator accum * = q ; numerator bits + = bits ; } }
coding step . perform coding ( input chunks , output chunks ) ; }
if ( options . extern exports path = null ) { try ( writer ee out = open extern exports stream ( options , config . js output file ) ) { ee out . append ( result . extern export ) ; } }
final set < string > referenced globals = new hash set < string > ( ) ; for ( internal knowledge package pkgref : this . pkgs . values ( ) ) { if ( pkgref = pkg ) { referenced globals . add all ( pkgref . get globals ( ) . key set ( ) ) ; } }
for ( int i = 0 ; i < strlen ; i + + ) { c = str . char at ( i ) ; if ( ( c > = 0x0001 ) & & ( c < = 0x007 f ) ) utflen + + ; else if ( c > 0x07 ff ) utflen + = 3 ; else utflen + = 2 ; } if ( utflen > 65535 ) throw new illegal argument exception ( encoded string too long : + utflen + bytes ) ;
assert handler assert handler = new assert handler ( builder , class name , hashed alpha declarations . size ( ) > 0 ) ; parser . accept ( assert handler ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( delegation set not reusable ) ) return null ; delegation set not reusable exception e = ( delegation set not reusable exception ) super . unmarshall ( node ) ;
task query task query = task service . create task query ( ) . order by task name ( ) . asc ( ) ; list < task > tasks = task query . list ( ) ; assert equals ( 2 , tasks . size ( ) ) ; task task a = tasks . get ( 0 ) ; task task b = tasks . get ( 1 ) ; assert equals ( task a , task a . get name ( ) ) ; assert equals ( task b , task b . get name ( ) ) ;
assert equals ( submit time , app state . get submit time ( ) ) ;
string input data = abc + def + ghi + jkl + mno + pqr + stu + vw + xyz ; path input file = create input file ( conf , input data ) ; conf . set ( textinputformat . record . delimiter , + ) ; for ( int buffer size = 1 ; buffer size < = input data . length ( ) ; buffer size + + ) { for ( int split size = 1 ; split size < input data . length ( ) ; split size + + ) { conf . set int ( io . file . buffer . size , buffer size ) ; test split records for file ( conf , split size , input data . length ( ) , input file ) ; } }
tester . start page ( page = new new service access rule page ( ) ) ; tester . assert rendered page ( new service access rule page . class ) ; form tester form = tester . new form tester ( form ) ;
fbo . fbo id = gl gen framebuffers ext ( ) ; gl bind framebuffer ext ( gl _ framebuffer _ ext , fbo . fbo id ) ; if ( type = type . no _ color ) { create color buffer ( fbo , dimensions , type ) ; }
test mkdir recursive with non existing dir ( blank _ test _ umask , blank _ permissions , parent _ perms _ for _ blank _ permissions ) ;
array list < range < token > > repairing range = new array list < > ( ) ; array list < token > tokens = new array list < > ( token metadata . sorted tokens ( ) ) ;
throw new ioexception ( boom ) ;
try { client . drain ( ) ; } catch ( no connections exception e ) { todo auto - generated catch block e . print stack trace ( ) ; } catch ( interrupted exception e ) { todo auto - generated catch block e . print stack trace ( ) ; }
string php unit executable = phpunit _ global ;
final count down latch latch = new count down latch ( 1 ) ; _ scheduler . schedule ( new runnable ( ) { @ override public void run ( ) { latch . count down ( ) ; } } , delay , time unit . milliseconds ) ; assert . assert true ( latch . await ( 2 * delay , time unit . milliseconds ) ) ;
group property . phone _ home _ enabled . set system property ( false ) ; group property . socket _ bind _ any . set system property ( false ) ; string license key = config . get ( causal clustering settings . hazelcast _ license _ key ) ;
if ( duplicate . is read only ( ) ) { load test data1 ( buf ) ; assert content equals ( buf , duplicate ) ; load test data2 ( duplicate ) ; assert content equals ( buf , duplicate ) ; }
if ( pattern1 . ends with ( ) | | pattern2 . starts with ( ) ) { return pattern1 + pattern2 ; }
final path relative path to jar = paths . get ( common . jar ) ;
right input adapter node ria node = context . get component factory ( ) . get node factory service ( ) . build right input node ( context . get next id ( ) , context . get tuple source ( ) , tuple source , context ) ;
list < string > tokens = tokenizer . get tokens ( ) ; assert equals ( expect . length , tokens . size ( ) ) ; }
mock http servlet response response = get as servlet response ( oseo search?http accept = + atom search response . mime ) ; assert equals ( atom search response . mime , response . get content type ( ) ) ; assert equals ( 200 , response . get status ( ) ) ; document dom = dom ( new byte array input stream ( response . get content as byte array ( ) ) ) ;
mesos task manager parameters params = new mesos task manager parameters ( resource profile . get cpu cores ( ) < 1 . 0 ? task manager parameters . cpus ( ) : resource profile . get cpu cores ( ) , task manager parameters . container type ( ) , task manager parameters . container image name ( ) , new containered task manager parameters ( resource profile . unknown . equals ( resource profile ) ? task manager parameters . containered parameters ( ) . task manager total memory mb ( ) : resource profile . get memory in mb ( ) , resource profile . unknown . equals ( resource profile ) ? task manager parameters . containered parameters ( ) . task manager heap size mb ( ) : resource profile . get heap memory in mb ( ) , resource profile . unknown . equals ( resource profile ) ? task manager parameters . containered parameters ( ) . task manager direct memory limit mb ( ) : resource profile . get direct memory in mb ( ) , 1 , new hash map < > ( task manager parameters . containered parameters ( ) . task manager env ( ) ) ) , task manager parameters . container volumes ( ) , task manager parameters . constraints ( ) , task manager parameters . command ( ) , task manager parameters . bootstrap command ( ) , task manager parameters . get task manager hostname ( ) ) ; log . debug ( launchable mesos worker parameters : { } , params ) ;
for ( int i = 0 ; i < args . length - 1 ; i + + ) { if ( - r . equals ignore case ( args [ i ] ) ) { recursive = true ; } else if ( - c . equals ignore case ( args [ i ] ) ) { do patch = false ; } else { system . err . println ( unknown option passed : + args [ i ] ) ; print usage ( system . err ) ; return ; } }
if ( segments target . length = = 0 ) { throw new illegal argument exception ( can ' t relativize an empty target uri ) ; }
map < string , sorted set < segment name > > sorted segments by kafka partition = kafka low level routing table builder util . get sorted segments by kafka partition ( external view ) ;
intent intent = new intent ( com . wire . testing . get _ document ) . set type ( mime type ) ;
final settable future < boolean > result = settable future . create ( ) ;
map side rs = gen map side rs ( input op af , gb info ) ;
cl = block cache key . class ;
boolean one or more = false ; for ( int i = 0 ; i < interim reasons mask . length & & one or more ; i + + ) { if ( reasons mask [ i ] & & interim reasons mask [ i ] ) { one or more = true ; } } if ( one or more ) { return false ; }
jtx transaction jtx = worker . maybe request transaction ( supports ( ) , ctx _ 1 ) ; assert not null ( jtx ) ; db session session = session provider . get db session ( ) ; execute update ( session , insert into girl values ( 1 , ' sophia ' , null ) ) ;
operational processes . key set ( ) . for each ( cluster node process - > { if ( cluster node process . get node uuid ( ) . equals ( hz member . get uuid ( ) ) ) { operational processes . remove ( cluster node process ) ; } } ) ;
final map < property builder . property id , object > args = new enum map < property builder . property id , object > ( property builder . property id . class ) ;
int weight = random ( ) . next int ( 1 < < 24 ) ; keys [ i ] = new input ( key , weight ) ; slow completor . add ( new term freq payload2 ( key , analyzed key , weight ) ) ;
long x = system . nano time ( ) ; x ^ = ( x < < 21 ) ; x ^ = ( x > > > 35 ) ; x ^ = ( x < < 4 ) ; return math . abs ( ( int ) x % max ) ; }
input stream = fs . open ( test file path1 ) ;
if ( args [ 0 ] instanceof async frame buffer ) { async frame buffer frame buffer = ( async frame buffer ) args [ 0 ] ; attach markers to input protocol ( frame buffer . get input protocol ( ) , true ) ; } }
clear old selections ( ) ;
if ( governor has method ( method name ) ) { return null ; }
cookie jar . remove ( cookie ) ;
if ( b = = - 1 ) { return - 1 ; } if ( name . compare to ( map [ 0 ] . name ) < 0 ) { return - 1 ; } if ( b = = 0 ) { return 0 ; }
assert equals ( class loader . get system class loader ( ) , my class . class . get class loader ( ) ) ; object target = new my class ( ) ; method public interface method = my class . class . get method ( public interface method ) ; assert equals ( boolean . true , utils . invoke ( target , public interface method , 1000 ) ) ; method protected abstract method = my class . class . get declared method ( protected abstract method ) ; assert equals ( boolean . true , utils . invoke ( target , protected abstract method , 1000 ) ) ;
for ( int i = 0 ; i < entries ; i + + ) { k key = ( k ) reflection utils . new instance ( get class ( in . read byte ( ) ) , get conf ( ) ) ; key . read fields ( in ) ; writable value = ( writable ) reflection utils . new instance ( get class ( in . read byte ( ) ) , get conf ( ) ) ; value . read fields ( in ) ; instance . put ( key , value ) ; }
list < string > legacy hashing method names = immutable list . of ( murmur2 _ 64 , fprint96 ) ;
n = s [ ( r > > 24 ) & 0xff ] ;
log . info ( test deleted table + test _ table ) ;
return fbx null attribute . class ; } else if ( subclass name . equals ( limb node ) ) {
if ( bound ) { if ( forward binding = null ) { forward binding . unbind ( ) ; } if ( reverse binding = null ) { reverse binding . unbind ( ) ; } }
this . export method = null ; this . export csv method = null ; this . export pdf method = null ; this . export xls method = null ; this . add column to report builder method = null ; this . export methods = null ; break ;
boolean designator = false ; int end date = index of ( str , start , len , ' t ' ) ; if ( end date = = - 1 ) { end date = len ; } else if ( duration type = = yearmonthduration _ type ) { throw new schema date time exception ( ) ; }
expression inversed expression = get inversed expression ( rewrite , if statement . get expression ( ) ) ;
all params constant & = param streams [ i ] . get expression type ( ) . equals ( expression type . const ) ; }
service = default _ executor _ service . get ( ) ;
name = ascii . to lower case ( dots _ matcher . replace from ( name , ' . ' ) ) ; if ( name . ends with ( . ) ) { name = name . substring ( 0 , name . length ( ) - 1 ) ; }
return new query capabilities decorator ( source . get query capabilities ( ) ) { @ override public boolean is offset supported ( ) { return true ; } @ override public boolean supports sorting ( sort by [ ] sort attributes ) { return true ; } } ;
rd . close ( ) ; }
table . set auto flush ( false ) ; table . set write buffer size ( buffer _ size ) ; return table ;
final string path = get uri ( ) . get path ( ) ;
} } , p . apply ( create1 , create . of ( ) ) . apply ( view . < string > as singleton ( ) ) ) ) ; passert . that ( output ) . contains in any order ( 1 , 2 , 3 ) ; p . run ( ) ; }
int view left = m web view . content to view x ( left < 5 ? 0 : ( left - 5 ) ) - m web view . get scroll x ( ) ;
if ( to update on client . is empty ( ) ) { final map < string , bookmark > bookmarks map = new hash map < string , bookmark > ( ) ; for ( bookmark b : to update on client ) { bookmarks map . put ( b . uid , b ) ; } context . perform ( new json request2 ( sync options . base _ url + sync bookmarks , full request data ( ids ( to update on client ) ) ) { @ override public void process response ( object response ) { for ( map < string , object > info : ( list < map < string , object > > ) response ) { final bookmark bookmark = bookmark to update ( info , bookmarks map ) ; if ( bookmark = null ) { collection . save bookmark ( bookmark ) ; } } } } ) ; }
models . add ( model ) ; log . debug ( graph of objects created : { } , model ) ; } }
assert equals ( cloud , config . get property ( event processing option . property _ name ) ) ;
five minute user user0 = new five minute user ( bob , bush , true , five minute user . gender . male , new byte [ ] { 1 , 2 , 3 , 4 , 5 } ) ;
decoder = ( ( channel handler factory ) decoder ) . new channel handler ( ) ; } pipeline . add last ( decoder - + x , decoder ) ; }
string [ ] base list = library folder . list ( standard filter ) ;
assert true ( aop utils . is jdk dynamic proxy ( bean ) ) ; assert true ( bean instanceof another scope test interface ) ; assert equals ( default _ name , bean . get name ( ) ) ; bean . set name ( modified _ name ) ; request context holder . set request attributes ( new request attributes ) ;
put = new put ( row , timestamp2 , null ) ; put . add ( contents , contents , value2 ) ; table . put ( put ) ;
if ( key start = = len ) { continue ; }
if ( m _ server = = null ) return null ; array list < string > listeners = new array list < > ( ) ; listeners . add ( localhost ) ; return listeners ; }
for ( int i loop = 0 ; i loop < count ; i loop + + ) { float draw long = long offset + ( i loop * three radius ) ; if ( m orientation = = horizontal ) { d x = draw long ; d y = short offset ; } else { d x = short offset ; d y = draw long ; } only paint fill if not completely transparent if ( m paint page fill . get alpha ( ) > 0 ) { canvas . draw circle ( d x , d y , page fill radius , m paint page fill ) ; } only paint stroke if a stroke width was non - zero if ( page fill radius = m radius ) { canvas . draw circle ( d x , d y , m radius , m paint stroke ) ; } }
length + = type writer . write to stream ( out , ( short ) get byte order ( ) ) ;
if ( entities to create serializers . contains ( parent entity ) ) { entities to create serializers . add ( parent entity ) ; }
if ( get item count ( ) % m total column count = 0 ) { max row + + ; } return max row ; }
if ( get long value ( job keys . total _ reduces ) = = 0 ) { this . _ job . put ( job keys . jobtype , map _ only ) ; } else { this . _ job . put ( job keys . jobtype , map _ reduce ) ; }
type = test to type ( dpt , new byte [ ] { 0x00 , 0x01 , 0x01 , 0x21 , 0x02 , 0x03 , 0x3 c , 0x00 } , date time type . class ) ;
epsilon = nd4j . gemm ( d ld pre mu , e zxmean w , false , true ) ; equivalent to : epsilon = e zxmean w . mmul ( d ld pre mu . transpose ( ) ) . transpose ( ) ; using ( ax b ^ t ) ^ t = bx a ^ t
iterator < string > i1 = iterables . consuming iterable ( list ) . iterator ( ) ; iterator < string > i2 = iterables . consuming iterable ( list ) . iterator ( ) ; i1 . next ( ) ;
pn = compile ( select * from r1 right join r2 on r1 . a = r2 . a full join r3 on r3 . a = r1 . a ) ;
int opcode = b [ u ] & 0x ff ;
percentile snapshot ps = new percentile snapshot ( 1000 , 1000 , 1000 , 2000 , 1000 , 500 , 200 , 200 , 1600 , 200 , 1600 , 1600 ) ; assert equals ( ps . get percentile ( 0 . 15 ) , p . get percentile ( 0 . 15 ) ) ; assert equals ( ps . get percentile ( 0 . 50 ) , p . get percentile ( 0 . 50 ) ) ; assert equals ( ps . get percentile ( 0 . 90 ) , p . get percentile ( 0 . 90 ) ) ; assert equals ( ps . get percentile ( 0 . 995 ) , p . get percentile ( 0 . 995 ) ) ; system . out . println ( 100th : + ps . get percentile ( 100 ) + + p . get percentile ( 100 ) ) ;
assert that ( input ) . has size ( 3 ) ; assert that ( input . get property ( hello ) ) . is equal to ( world ) ; assert that ( input . get property ( url ) ) . is equal to ( { env : sonar _ jdbc _ url } ) ; assert that ( input . get property ( do _ not _ change ) ) . is equal to ( { sonar _ jdbc _ url } ) ; }
try { if ( e . get id ( ) = = instance event . instance _ available ) { m _ output instance = null ; } } catch ( exception ex ) { system . err . println ( problem : notify instance produced ( ) was \ n + called with instance _ available , but output ( ) \ n + threw an exception : + ex . get message ( ) ) ; }
assert true ( pn . get child ( 1 ) instanceof order by plan node ) ; pn = pn . get child ( 1 ) ; assert true ( pn . get child ( 0 ) instanceof union plan node ) ; } { abstract plan node pn = compile ( select a from t1 union ( select b from t2 union select b from t2 limit 3 ) ) ; pn = pn . get child ( 0 ) ; assert true ( pn instanceof union plan node ) ; assert equals ( 2 , pn . get child count ( ) ) ;
test ( line _ joiner . join ( class a { , static use foo ( ) { , alert ( this . foo ) ; , } , } , a . foo = ' bar ' ; , const b = a ; , b . foo = ' baz ' ; , b . use foo ( ) ; ) , line _ joiner . join ( class a { , static use foo ( ) { , alert ( this . foo ) ; , } , } , var a foo = ' bar ' ; , const b = null ; , a foo = ' baz ' ; , a . use foo ( ) ; ) ) ;
return get current bucket ( ) ;
return 20 ; }
if ( jfif = null ) { ignore jfif = true ; warning occurred ( warning _ image _ metadata _ jfif _ mismatch ) ; } else if ( adobe = null ) { if ( adobe . transform = jpeg . adobe _ unknown ) { new adobe transform = jpeg . adobe _ unknown ; warning occurred ( warning _ image _ metadata _ adobe _ mismatch ) ; } } out cs type = jpeg . jcs _ ycca ; }
assert equals ( do extract ( extractor , 123 ) , 123 ) ; assert equals ( do extract ( extractor , - 1 ) , - 1 ) ; assert equals ( do extract ( extractor , 0 . 01 ) , 0 . 01 ) ; assert equals ( do extract ( extractor , \ abc \ ) , \ abc \ ) ; assert equals ( do extract ( extractor , \ \ ) , \ \ ) ; assert equals ( do extract ( extractor , null ) , null ) ;
assert true ( capabilities . contains key ( desired capabilities ) ) ;
tester . get or create ( leaf , * mark as modified = * true ) ; sky key other2 = graph tester . to sky key ( other2 ) ; tester . set ( other2 , new string value ( other2 ) ) ;
public void test custom trust manager factory ( ) throws exception { test tls ( cert . none , ( ) - > new trust options ( ) { @ override public trust manager factory get trust manager factory ( vertx v ) throws exception { return new trust manager factory ( new trust manager factory spi ( ) { @ override protected void engine init ( key store key store ) throws key store exception { } @ override protected void engine init ( manager factory parameters manager factory parameters ) throws invalid algorithm parameter exception { } @ override protected trust manager [ ] engine get trust managers ( ) { return new trust manager [ ] { trust all trust manager . instance } ; } } , key pair generator . get instance ( rsa ) . get provider ( ) , key pair generator . get instance ( rsa ) . get algorithm ( ) ) { } ; } @ override public trust options clone ( ) { return this ; } } , cert . server _ jks , trust . none ) . pass ( ) ;
if ( op . get responses ( ) = = null ) { op . add response ( 200 , new response ( ) ) ; }
result [ 0 ] = new replace edit ( intersect . get offset ( ) , intersect . get length ( ) , ) ; non - nls - 1
int safe index = math . min ( math . max ( 0 , tab index ) , tabs _ . size ( ) - 1 ) ; tab panel _ . select tab ( safe index ) ; }
plain padded keys [ 0 ] = get ek _ no null byte ( rsa key length ) ;
if ( web resource . get last modified ( ) = web resource internal . get last modified ( ) | | web resource . get content length ( ) = web resource internal . get content length ( ) ) { return false ; }
api key = prop . get property ( api key ) ;
ts2 = wrapper1 . token stream ( special , text ) ;
if ( p . is expected start array token ( ) ) { return handle non array ( p , ctxt , result ) ; } return _ deserialize ( p , ctxt , result ) ; }
return cache ( value , cache , key builder , predicates . < v > always true ( ) ) ; }
iterator < s > iter ; try { iter = the registry . get service providers ( spi class , true ) ; } catch ( illegal argument exception e ) { return new string [ 0 ] ; } hash set < string > s = new hash set < string > ( ) ;
assert equals ( listener was not added , listeners size + 1 , get connection ( 0 ) . get packet listeners ( ) . size ( ) ) ; message msg = new message ( get connection ( 0 ) . get user ( ) , message . type . normal ) ;
helper . measure child with margins ( view , width spec , height spec ) ;
cluster test utils . rebalance kit rebalance kit = cluster test utils . get rebalance kit ( bootstrap url , z1z3 shuffle , z1z3 stores ) ;
object name route name = object name . get instance ( org . apache . camel : context = camel - 1 , type = routes , name = \ route1 \ ) ; long completed = ( long ) mbean server . get attribute ( route name , exchanges completed ) ; assert equals ( 1 , completed . long value ( ) ) ; long last = ( long ) mbean server . get attribute ( route name , last processing time ) ; long total = ( long ) mbean server . get attribute ( route name , total processing time ) ; assert true ( should take around 0 . 1 sec : was + last , last > 90 ) ;
assume false ( windows does not automatically grant permission to the target of symlinks , constants . windows ) ; path dir = create temp dir ( ) ; path target = dir . resolve ( target ) ;
ddb . set lsn ( source node name , ( ( oabstract replicated task ) task ) . get last lsn ( ) , true ) ; } } } return result ; } catch ( interrupted exception e ) {
system . out . println ( get bit ) ;
var y = new foo ( ) ; y . b1 ( ) ; ,
iterator < contact > contacts iter = contacts ( ) ; while ( contacts iter . has next ( ) ) { contact sip impl m contact = ( contact sip impl ) contacts iter . next ( ) ; if ( m contact . get address ( ) . equals ( id ) ) return m contact ; }
int n = 0 ; while ( cache . get eviction count ( ) = = 0 ) { thread . sleep ( 200 ) ; assert true ( n + + < 20 ) ; } system . out . println ( background evictions run : + cache . get eviction count ( ) ) ;
assert that ( adapter . get view ( position , null , container ) ) . is same as ( view ) ; verify ( title text view ) . set text ( title + position ) ; }
y vals . add ( new entry ( i , val ) ) ;
volt table result = client . call procedure ( results ) . get results ( ) [ 0 ] ;
no _ entry _ key = in . read char ( ) ;
typed array a = context . obtain styled attributes ( attrs , r . styleable . title page indicator , def style , 0 ) ;
return pending messages ( conn , resp ) ;
continue ; } if ( warnings = = null ) { warnings = new array list < > ( ) ; } if ( warnings . contains ( warning ) ) {
if ( smsb = = null ) { log . e ( tag , dispatch message : message is null ) ; return intents . result _ sms _ generic _ error ; } string in ecm = system properties . get ( telephony properties . property _ inecm _ mode , false ) ;
final odocument current document = new odocument ( ) . from stream ( key1 . buffer ) ;
return immutable druid data source { + name = ' + name + ' , segments = ' + segments holder + ' , properties = ' + properties + ' } ; }
print ( t , visit , null , null , [ ] ) ; } else {
assert array equals ( new string [ ] { test property names . prop _ 1 , test property names . prop _ 2 , test property names . prop _ 3 , test property names . prop _ 4 , test property names . prop _ 5 } , schema . get edge ( test groups . edge _ 5 ) . get properties ( ) . to array ( ) ) ; }
system . set err ( new print stream ( my err ) ) ; file dump . main ( new string [ ] { db location } ) ; system . err . flush ( ) ; system . set err ( orig err ) ; err dump = new string ( my err . to byte array ( ) ) ;
endp . upgrade ( connection ) ;
( ( client thread ) seq to thread . get ( 0 ) ) . close ( ) ; wait for leader ( threads , 1 ) ; leader thread = get leader thread ( ) ;
if ( args . info = null ) { args . info . cached photo = ( drawable ) args . result ; }
shuffle . close ( ) ;
final type [ ] interfaces = clazz . get generic interfaces ( ) ;
assert equals ( 1 , list . size ( ) ) ; assert equals ( f1 , list . get ( 0 ) ) ; list . clear ( ) ; session . delete ( fh1 ) ; session . insert ( go4 ) ; session . fire all rules ( ) ; assert equals ( 0 , list . size ( ) ) ; }
group . add ( channel1 ) ; group . add ( channel3 ) ; group . set state ( new mix . state ( mix . mode . mute , true ) , channel2 ) ; sync . send ( ping , 1 , time unit . seconds ) ; 6 channel1 . send ( 1 - paused - by - 2 - solo - waits , 1 , time unit . seconds ) ;
user group information admin user = user group information . create remote user ( admin _ user ) ;
output stream os = null ; object output stream out = null ; map join table container ser de map join table serde = hts operator . map join table serdes [ tag ] ; try { os = fs . create ( path , num replication ) ; out = new object output stream ( new buffered output stream ( os , 4096 ) ) ; map join table serde . persist ( out , table container ) ; } finally { if ( out = null ) { out . close ( ) ; } else if ( os = null ) { os . close ( ) ; } } file status status = fs . get file status ( path ) ;
persistent class . add tuplizer ( mode , tuplizer . impl ( ) . get name ( ) ) ;
execute command ( schema ls , : person , index state . online . name ( ) ) ;
big score bs = make big score task ( domains , names , adapt frm , compute metrics , true , j ) . do all ( names . length , vec . t _ num , adapt frm ) ; if ( compute metrics ) bs . _ mb . make model metrics ( this , fr , adapt frm , bs . output frame ( ) ) ;
for ( int i = this . recall . length - 1 ; i > = 0 ; i - - ) { if ( this . recall [ i ] > = recall ) { return new point ( i , threshold [ i ] , precision [ i ] , this . recall [ i ] ) ; } }
if ( callstack . depth ( ) > 1 ) { callstack . clear ( ) ; callstack . push ( name space ) ; } } }
{ string [ ] args = new string [ 2 ] ; args [ 0 ] = - rm ; args [ 1 ] = my file . to string ( ) ; int val = - 1 ; try { val = shell . run ( args ) ; } catch ( exception e ) { system . err . println ( exception raised from trash . run + e . get localized message ( ) ) ; } assert true ( val = = 0 ) ; check trash ( trash root fs , trash root , my file ) ; args = new string [ 2 ] ; args [ 0 ] = - rmr ; args [ 1 ] = my path . to string ( ) ; val = - 1 ; try { val = shell . run ( args ) ; } catch ( exception e ) { system . err . println ( exception raised from trash . run + e . get localized message ( ) ) ; } assert true ( val = = 0 ) ; check trash ( trash root fs , trash root , my path ) ; }
dp . write ( ) ;
final count down latch migration start latch = new count down latch ( 1 ) ; config1 . add listener config ( new listener config ( new delay migration start ( migration start latch ) ) ) ; final test hazelcast instance factory factory = create hazelcast instance factory ( 2 ) ;
file to = new file ( components out dir , file . get name ( ) ) ; file output stream fos = new file output stream ( to , false ) ; fos . write ( text . get bytes ( ) ) ;
m contents view . reset text widths ( ) ;
string admin acl list str = conf . get init parameter ( yarn configuration . yarn _ admin _ acl ) ; if ( string utils . is empty ( admin acl list str ) ) { admin acl list str = timeline reader whitelist authorization filter . empty _ string ; log . info ( admin acl list not set , hence setting it to \ \ ) ; } admin acl list = new access control list ( admin acl list str ) ; log . info ( admin acl list = + admin acl list . get users ( ) ) ; }
current dir = get current directory ( ) ;
_ symbols . release ( ) ;
if ( ( left = = icc card . state . ready ) & & ( right = = icc card . state . ready ) ) { return state . ready ; }
return m root view ; }
request . get mapping data ( ) . recycle ( ) ; map required = true ;
this . snapshots . clear ( ) ;
fail to compile ( ( select c from t3 union select b from t2 ) order by b , error msg ) ;
char list [ index of0 - start ] = empty _ char ; char list [ index of period - start ] = ' ' ; char list [ index of slash - start ] = ' . ' ; for ( int i = index of0 + 1 ; i < end + 1 ; i + + ) { char list [ i - start ] = ( char ) ( i - 1 ) ; } return char list ;
environment . health checks ( ) . get names ( ) . for each ( name - > environment . metrics ( ) . register ( helios . + name + . ok , new health check gauge ( environment . health checks ( ) , name ) ) ) ;
for ( string f : m _ valued ) { schema field sf = h . get core ( ) . get latest schema ( ) . get field ( f ) ; assert true ( who changed the schema? test isn ' t valid : + f , sf . multi valued ( ) ) ; } for ( string f : s _ valued ) { schema field sf = h . get core ( ) . get latest schema ( ) . get field ( f ) ; assert false ( who changed the schema? test isn ' t valid : + f , sf . multi valued ( ) ) ; }
out . write ( tags ) ;
heap size = math . max ( sz , sz + 1 ) ; handle overflow
task task inner = task service . create task query ( ) . task definition key ( inner txask customer ) . single result ( ) ;
if ( context . get session handler ( ) . get session cookie config ( ) . get domain ( ) . equals ( domain ) ) throw new illegal state exception ( conflicting cookie - config domain + domain + in + descriptor . get resource ( ) ) ;
multi layer configuration conf1 = new neural net configuration . builder ( ) . list ( ) . layer ( 0 , new org . deeplearning4j . nn . conf . layers . dense layer . builder ( ) . n in ( 5 ) . n out ( 6 ) . build ( ) ) . layer ( 1 , new graves lstm . builder ( ) . n in ( 6 ) . n out ( 7 ) . build ( ) ) . layer ( 2 , new org . deeplearning4j . nn . conf . layers . dense layer . builder ( ) . n in ( 7 ) . n out ( 8 ) . build ( ) ) . layer ( 3 , new rnn output layer . builder ( ) . n in ( 8 ) . n out ( 9 ) . build ( ) ) . build ( ) ;
p = pattern . compile ( ^ abc \ \ n ^ abc , pattern . multiline ) ; m = p . matcher ( abc \ nabc ) ; assert true ( m . matches ( ) ) ; p = pattern . compile ( ^ abc \ \ n ^ abc ) ; m = p . matcher ( abc \ nabc ) ; assert false ( m . matches ( ) ) ;
bytes . flip ( ) ;
if ( has repeats ) { for ( phrase positions pp : nr pps ) { if ( ( end = advance repeats ( pp , end ) ) = = integer . min _ value ) { return integer . min _ value ; ran out of a term - - done ( no valid matches in current doc ) } } }
utils . delete all tables ( ) ;
word . set length ( k ) ;
if ( null = image view & & ( image view instanceof iphoto view ) ) { if ( scale type . matrix . equals ( image view . get scale type ( ) ) ) { throw new illegal state exception ( the image view ' s scale type has been changed since attaching a photo view attacher ) ; } }
round trip buffer ( expect success , buf , proc name , handle , timeout , false ) ;
public void test concurrent append stream3 ( ) throws exception { file src file = file . create temp file ( src _ trail _ , null ) ; file dest file = file . create temp file ( dest _ trail _ , null ) ; log . info ( src file : + src file ) ;
assert true ( s . has next short ( ) ) ;
string address = 127 . 0 . 0 . 1 : + net utils . get free socket port ( ) ; if ( check data node addr config ) { conf . set if unset ( dfs _ datanode _ address _ key , address ) ; } else { conf . set ( dfs _ datanode _ address _ key , address ) ; } add to file ( hosts file , address ) ; log . info ( adding datanode + address + to hosts file + hosts file ) ; } else {
final stream execution environment env2 = stream execution environment . get execution environment ( ) ; env2 . set parallelism ( parallelism ) ; data stream < tuple2 < integer , integer > > extra records stream = env2 . add source ( new rich parallel source function < tuple2 < integer , integer > > ( ) { private boolean running = true ; @ override public void run ( source context < tuple2 < integer , integer > > ctx ) throws exception { int count = records in each partition ; the extra records should start from the last written value int partition = get runtime context ( ) . get index of this subtask ( ) ; while ( running & & count < records in each partition + extra records in each partition ) { ctx . collect ( new tuple2 < > ( partition , count ) ) ; count + + ; } } @ override public void cancel ( ) { running = false ; } } ) ; kafka server . produce into kafka ( extra records stream , topic name , ser schema , read props , null ) ;
check default collection table name ( bug system . class , bugs , bug system _ bugs ) ; }
assert true ( graph . get stream node ( rebalance map . get id ( ) ) . get in edges ( ) . get ( 0 ) . get partitioner ( ) instanceof rebalance partitioner ) ;
client = client . new builder ( ) . certificate pinner ( certificate pinner builder . build ( ) ) . build ( ) ; request request2 = new request . builder ( ) . url ( server . url ( ) ) . build ( ) ; response response2 = client . new call ( request2 ) . execute ( ) ; assert not same ( response2 . handshake ( ) , response1 . handshake ( ) ) ; response2 . body ( ) . close ( ) ;
list < build job > next jobs = build system . take jobs to run ( ) ;
float max vert bar desired = item height * ( option listeners . size ( ) - visible options num - 0 . 5f ) + item margin . get bottom ( ) ; vertical bar . set range ( ( int ) max vert bar desired ) ; for ( int i = 0 ; i < option listeners . size ( ) ; + + i ) { read item mouse over ( canvas , i ) ; rect2i item region = rect2i . create from min and size ( 0 , item height * i - vertical bar . get value ( ) , available width , item height ) ; if outside location , then hide try ( sub region ignored = canvas . sub region ( scrollable area , true ) ) { draw item ( canvas , item margin , i , item region ) ; } }
edit log file output stream edit log stream = null ;
for ( int i = 0 ; i < population count ; i + + ) { map . evict ( i ) ; }
irecording listener listener = ( irecording listener ) scope utils . get scope service ( scope , irecording listener . class , recording listener . class ) ;
region = hregion . create hregion ( hri , root dir , test _ util . get configuration ( ) , htd , rss . get wal ( hri ) ) ; region = hregion . open hregion ( hri , htd , rss . get wal ( hri ) , test _ util . get configuration ( ) , rss , null ) ;
snmp snmp = null ; transport mapping < ? extends address > transport = null ; try { log . debug ( starting snmp producer on { } , this . endpoint . get address ( ) ) ; either tcp or udp if ( tcp . equals ( this . endpoint . get protocol ( ) ) ) { transport = new default tcp transport mapping ( ) ; } else if ( udp . equals ( this . endpoint . get protocol ( ) ) ) { transport = new default udp transport mapping ( ) ; } else { throw new illegal argument exception ( unknown protocol : { } + this . endpoint . get protocol ( ) ) ; } snmp = new snmp ( transport ) ; log . debug ( snmp : i am sending ) ; snmp . listen ( ) ; response event response event = snmp . send ( this . pdu , this . target ) ; log . debug ( snmp : sended ) ; if ( response event . get response ( ) = null ) { exchange . get in ( ) . set body ( new snmp message ( get endpoint ( ) . get camel context ( ) , response event . get response ( ) ) ) ; } else { throw new timeout exception ( snmp producer timeout ) ; } } finally { try { transport . close ( ) ; } catch ( exception e ) { } try { snmp . close ( ) ; } catch ( exception e ) { } }
test ( ( function ( f ) { f ( f ) } ) ( function ( f ) { f ( f ) } ) , { var f jscomp inline _ 0 = function ( f jscomp 1 ) { f jscomp 1 ( f jscomp 1 ) } ; + { { f jscomp inline _ 0 ( f jscomp inline _ 0 ) } } } ) ;
assert equals ( 1 , ( ( boolean query ) parsed query ) . get minimum number should match ( ) ) ;
concurrent map map = map ( ) ; assert true ( map . is empty ( ) ) ; for ( int i = 0 ; i < 20 ; i + + ) { map . put ( i , i ) ; } assert false ( map . is empty ( ) ) ; map . entry entry1 = ( map . entry ) map . entry set ( ) . iterator ( ) . next ( ) ;
set _ panning ( panning - ( volume _ column & 0x0 f ) ) ;
assert true ( data field . get ( map ) instanceof map ) ;
system . arraycopy ( array , old gap end , array , old gap start , dg ) ;
if ( parent file = = null ) { parent file = new file ( . ) ; } if ( parent file . exists ( ) ) { throw new illegal argument exception ( string . format ( command _ line _ parser _ not _ existing _ output _ directory , parent file . get absolute file ( ) ) ) ; }
throwable throwable = null ; if ( class loader = null ) { try { log . trace ( trying to load class with custom classloader : { } , class name ) ; clazz = load class ( class loader , class name ) ; } catch ( throwable t ) { throwable = t ; } } if ( clazz = = null ) { try { log . trace ( trying to load class with current thread context classloader : { } , class name ) ; clazz = load class ( thread . current thread ( ) . get context class loader ( ) , class name ) ; } catch ( throwable t ) { if ( throwable = = null ) { throwable = t ; } } if ( clazz = = null ) { try { log . trace ( trying to load class with local classloader : { } , class name ) ; clazz = load class ( reflect util . class . get class loader ( ) , class name ) ; } catch ( throwable t ) { if ( throwable = = null ) { throwable = t ; } } } }
int pd = node . get parallelism ( ) ; vertex . set parallelism ( pd ) ; vertex . set max parallelism ( pd ) ; vertex . set slot sharing group ( sharing group ) ;
select item ( current selected position ) ;
cred handle ph client credential = new cred handle ( ) ;
if ( m paint page fill . get alpha ( ) > 0 ) { canvas . draw circle ( d x , d y , page fill radius , m paint page fill ) ; }
application unused = application ;
action manager . register action ( svn _ group _ main _ menu , svn menu ) ; main menu . add ( svn menu , new constraints ( anchor . before , ide actions . group _ profile ) ) ; action manager . register action ( remote _ command _ group , remote command group ) ; svn menu . add ( remote command group ) ; svn menu . add separator ( ) ; action manager . register action ( file _ command _ group , file command group ) ; svn menu . add ( file command group ) ; svn menu . add separator ( ) ;
reduce fn tester < integer , iterable < integer > , interval window > tester = reduce fn tester . non combining ( fixed windows . of ( duration . millis ( 10 ) ) , mock trigger state machine , accumulation mode . discarding _ fired _ panes , duration . millis ( 100 ) , closing behavior . fire _ if _ non _ empty ) ;
mailbox box = mailbox . get ( davsclaus @ apache . org ) ;
student short primitive student min = new student short primitive ( ) ; student min . set age ( ( short ) get min value ( short . class ) ) ; student min . set id ( ( short ) get min value ( short . class ) ) ; student min . set name ( ( string ) get min value ( string . class ) ) ; em . persist ( student min ) ;
assert that ( result . has error ( ) ) . is true ( ) ;
connection explorer _ . set connected ( explored connection _ = null & & is connected ( explored connection _ . get id ( ) ) ) ;
giant model giant = new giant model ( health . healthy , fatigue . alert , nourishment . saturated ) ;
filename = capture + gtutils . get save date ( ) ; start tcp dump ( dir + filename ) ; return true ;
iterator = container allocate data . get racks ( ) . entry set ( ) . iterator ( ) ;
byte buffer . put int ( store size ) ;
( ( frame layout . layout params ) m request view . get layout params ( ) ) . height = layout params . wrap _ content ;
target = source ; } else {
mockito . verify ( method invocation ) . proceed ( ) ;
ok http client another client = client . new builder ( ) . hostname verifier ( new recording hostname verifier ( ) ) . build ( ) ; response response2 = another client . new call ( request ) . execute ( ) ;
put ( cipher . pbewithshaand128 bitrc2 - cbc , org . bouncycastle . jce . provider . jceblock cipher pbewith shaand128 bit rc2 ) ;
assert . assert false ( run pruner ( select count ( * ) from table where foo = ' bar ' ) ) ;
taskid to tipmap . put ( taskid , tip ) ;
move map zone moves = rebalance plan . get zone move map ( ) ;
if ( ref . get size ( ) = null ) { set size ( ref . get size ( ) ) ; }
assert file size ( fs2 , bbw _ size ) ;
try { field path entry . parse key ( ) ; fail ( ) ; } catch ( illegal argument exception e ) { assert equals ( key ' ' does not start with ' { ' , e . get message ( ) ) ; } try { field path entry . parse key ( { ) ; fail ( ) ; } catch ( illegal argument exception e ) { assert equals ( key ' { ' is incomplete . no matching ' } ' , e . get message ( ) ) ; }
sql = select t1 . key , count ( t1 . key ) as cnt from table1 t1 + join table2 t2 on ( t1 . key = t2 . key ) group by t1 . key having cnt > 5 order by cnt desc ;
fake content progress elapsed realtime ms = c . time _ unset ; fake content progress offset ms = c . time _ unset ; clear flags ( ) ; }
sock = sip stack . get network layer ( ) . create datagram socket ( ) ;
int index of minutes ; if ( time values . length = = 2 ) { index of minutes = 0 ; } else if ( time values . length = = 3 ) { result = 3600000 * ( int ) parse float ( time values [ 0 ] , 0 , false ) ; index of minutes = 1 ; } else { throw new illegal argument exception ( ) ; }
pause to let refresh delay kick in ( default _ seconds _ to _ pause ) ;
instructions . add ( reil helpers . create bsh ( base offset + + , result operand size , result operand , wd , shift value , bt , msb varr ) ) ;
return definition . get default value ( ) . as string ( ) . split ( @ ) [ 0 ] ;
broadcaster . broadcast ( new outbound event . builder ( ) . name ( size ) . data ( integer . class , event id + 1 ) . build ( ) ) ;
list < abstract type < ? > > new types = field types ( ) . stream ( ) . map ( subtype - > ( subtype . is freezable ( ) & & subtype . is multi cell ( ) ? subtype . freeze ( ) : subtype ) ) . collect ( collectors . to list ( ) ) ; return new user type ( keyspace , name , field names , new types , is multi cell ) ;
if ( random ( ) . next int ( 10 ) = 8 ) { for ( int j = 0 ; j < num _ ords ; j + + ) { string new value = generate string ( i ) ; multi valued [ i ] [ j ] = new bytes ref ( new value ) ; doc . add ( new string field ( the random unicode multi valued field , new value , field . store . yes ) ) ; } arrays . sort ( multi valued [ i ] ) ; } writer . add document ( doc ) ;
boolean top border not white = true ; while ( ( top border not white | | at least one black point found on top ) & & up > = 0 ) { top border not white = contains black point ( left , right , up , true ) ; if ( top border not white ) { up - - ; a black point found on border = true ; at least one black point found on top = true ; } else if ( at least one black point found on top ) { up - - ; } } if ( up < 0 ) { size exceeded = true ; break ; }
mgr . add to cluser node labels ( immutable set . of ( node label . new instance ( x ) , node label . new instance ( y , false ) , node label . new instance ( z , false ) ) ) ;
helpers . generate binary operation flags ( environment , offset + 1 , xor result , size , instructions ) ; offset = base offset + instructions . size ( ) ;
client representation registered client = reg . create ( client rep ) ;
list < imap response > responses = execute simple command ( string . format ( uid copy % s % s , combine ( uids , ' , ' ) , escaped destination folder name ) ) ;
return new resource config ( ) ; }
if ( deploy mode = = angel deploy mode . yarn ) { try { web app = web apps . for ( angel , amcontext . class , app context ) . with ( conf ) . start ( new angel web app ( ) ) ; log . info ( start webapp server success ) ; log . info ( web app . port ( ) = + web app . port ( ) ) ; } catch ( exception e ) { log . error ( webapps failed to start . ignoring for now : , e ) ; } } master service . start ( ) ;
node current value = array literal . get child at index ( index ) ; if ( current value . is empty ( ) ) {
class < ? > c = null ;
client template representation template rep = new client template representation ( ) ; template rep . set name ( foo - template ) ; template rep . set full scope allowed ( false ) ; string template id = create template ( template rep ) ;
if ( i % 2 = = 0 ) { multiset1 . add ( elements [ i ] ) ; } else { multiset2 . add ( elements [ i ] ) ; } } return multisets . sum ( multiset1 , multiset2 ) ; } } ; }
channel channel = conn . _ channel ; socket address client addr = channel . get local address ( ) ; channel server channel = _ dummy server . get child channel ( client addr ) ; channel pipeline server pipeline = server channel . get pipeline ( ) ;
int last index = path . length ( ) - 1 ; while ( last index > 0 & & ( path . char at ( last index ) = = file . separator char | | path . char at ( last index ) = = ' ' ) ) { last index - - ; } int count = math . max ( 0 , last index ) ;
if ( cursor < = limit _ backward ) { break lab1 ; } cursor - - ;
list < integer > node list = src store instance . get replication node list ( src store instance . get master partition id ( conflict key . get bytes ( utf - 8 ) ) ) ;
if ( database . get transaction ( ) . is active ( ) & & ( ( otransaction optimistic ) database . get transaction ( ) ) . get index operations ( ) . size ( ) = 0 & & res . is empty ( ) ) return null ; return res ; }
assert equals ( e . get response ( ) . get status ( ) , status . precondition _ failed . get status code ( ) ) ; }
if ( ctx . type ( ) = = ddl ) { ctx . data ( data _ force _ static _ statement , true ) ; default render context render = new default render context ( configuration ) ; result = new rendered ( render . param type ( inlined ) . visit ( this ) . render ( ) , null , render . peek skip update counts ( ) ) ; } else if ( execute prepared statements ( configuration ( ) . settings ( ) ) ) { try { default render context render = new default render context ( configuration ) ; render . data ( data _ count _ bind _ values , true ) ; result = new rendered ( render . visit ( this ) . render ( ) , render . bind values ( ) , render . peek skip update counts ( ) ) ; } catch ( default render context . force inline signal e ) { ctx . data ( data _ force _ static _ statement , true ) ; default render context render = new default render context ( configuration ) ; result = new rendered ( render . param type ( inlined ) . visit ( this ) . render ( ) , null , render . peek skip update counts ( ) ) ; } } else { default render context render = new default render context ( configuration ) ; result = new rendered ( render . param type ( inlined ) . visit ( this ) . render ( ) , null , render . peek skip update counts ( ) ) ; } return result ;
m renderer . on draw frame ( m gl ) ; m renderer . on draw frame ( m gl ) ; convert to bitmap ( ) ; return m bitmap ;
optional < result > filled result = future filled result . get second ( ) . get if available ( result . get query ( ) . get time left ( ) , time unit . milliseconds ) ; if ( filled result . is present ( ) ) { fill completed propagate errors ( filled result . get ( ) , result ) ; }
return bound . get subtype ( subclass ) ;
compile ( get compilation units ( test entities ) ) ; if ( ignore compilation errors ) { test util . assert no compilation error ( compilation diagnostics ) ; }
list < resolve info > list = on query package manager ( m intent ) ; collections . sort ( list , new resolve info . display name comparator ( m package manager ) ) ; array list < list item > result = new array list < list item > ( list . size ( ) ) ;
if ( ( test . get alice port ( ) = = test . get alice port from charlie ( ) ) & & ( test . get alice ip ( ) = null ) & & ( test . get alice ipfrom charlie ( ) = null ) & & ( test . get alice ip ( ) . equals ( test . get alice ipfrom charlie ( ) ) ) ) { status = comm system facade . status _ ok ; } else { status = comm system facade . status _ different ; } } else if ( test . get receive charlie time ( ) > 0 ) {
property ( server properties . monitoring _ enabled , false ) ;
apply progress bar settings ( ) ;
byte buffer filebuffer = get data ( args [ 0 ] ) ; if ( filebuffer = = null ) { system . out . println ( error loading file : + args [ 0 ] ) ; system . exit ( - 1 ) ; } system . out . println ( loaded + filebuffer . capacity ( ) ) ;
conf . set ( hadoop . proxyuser . foo . hosts , xyz ) ;
test proc with valid json ( { \ id \ : { \ foo \ : - 1 } } , client , select set field proc , id , { \ foo \ : - 1 } , 5 ) ;
case token . lb : decompiler . add token ( token . lb ) ; pn = nf . create element get ( pn , null , expr ( false ) , member type flags ) ; must match token ( token . rb , msg . no . bracket . index ) ; decompiler . add token ( token . rb ) ; break ; default :
session . wait for sync ( pair . create ( desc , new node pair ( r1 . endpoint , r2 . endpoint ) ) , ( remote sync task ) task ) ; } sync tasks . add ( task ) ; task executor . submit ( task ) ; } } return futures . all as list ( sync tasks ) ; } } , task executor ) ;
default value attribute converter ( pooled connection factory , connection factory attributes . pooled . max _ pool _ size ) ;
res . set successful ( true ) ;
string location = null ; for ( class c = exception . get class ( ) ; c = null & & location = = null ; c = c . get superclass ( ) ) { location = exception mappings . get ( c ) ; } if ( location = = null & & exception instanceof servlet exception ) { throwable root cause = ( ( servlet exception ) exception ) . get root cause ( ) ; if ( root cause = null ) { for ( class c = root cause . get class ( ) ; c = null & & location = = null ; c = c . get superclass ( ) ) { location = exception mappings . get ( c ) ; } } } if ( location = = null ) { location = get error location ( status codes . internal _ server _ error ) ; } return location ;
set gradient ( m gradient ) ;
anno = simply noted . class . get annotation ( anno simple type . class ) ;
super . visit ( node ) ;
try { scanner . lower bound ( key n . get bytes ( ) ) ; assert . fail ( cannot search in a unsorted tfile ) ; } catch ( exception e ) {
return new locale ( locale name . substring ( 0 , first ) , locale name . substring ( first + 1 , second ) , locale name . substring ( second + 1 ) ) ; }
if ( snmp type . get target ( ) = = null | | snmp type . get target ( ) . trim ( ) . length ( ) = = 0 ) { throw new illegal argument exception ( target must be specified for snmp configuration . ) ; }
final cluster health response health = client . admin ( ) . cluster ( ) . prepare health ( ) . set wait for yellow status ( ) . get ( ) ;
final no such method exception nsme = new no such method exception ( operation + sig string ( signature ) ) ; final reflection exception exception = new reflection exception ( nsme , msg ) ; if ( introspector . is mxbean ( ) ) throw exception ; no compatibility requirement here
string msg1 = null ; try { new ltrthread module ( 1 , - 1 ) ; } catch ( illegal argument exception iae ) { msg1 = iae . get message ( ) ; ; } assert true ( msg1 . equals ( num threads per request cannot be less than 1 ) ) ;
if ( show date time ) { buf . append ( date formatter . format ( new date ( ) ) ) ; buf . append ( ) ; }
if ( license file . exists ( ) & & license file . can read ( ) ) { try { import license file util . log ( null , log . warn , licensing : importing + out . get absolute path ( ) ) ; input stream is = null ; is = new file input stream ( license file . get absolute path ( ) ) ; try { output stream os = null ; try { os = new file output stream ( out . get absolute path ( ) ) ; byte [ ] buffer = new byte [ 1024 ] ; int read ; while ( ( read = is . read ( buffer ) ) = - 1 ) os . write ( buffer , 0 , read ) ; os . flush ( ) ; } finally { if ( os = null ) os . close ( ) ; } } finally { if ( is = null ) is . close ( ) ; } protect imported license file set permissions ( out . get absolute path ( ) , 0700 , process . my uid ( ) , process . my uid ( ) ) ; remove original license file license file . delete ( ) ; } catch ( file not found exception ignored ) { } catch ( throwable ex ) { util . bug ( null , ex ) ; } } return ( out . exists ( ) & & out . can read ( ) ? imported license : null ) ;
if ( dispatch nested pre scroll ( 0 , delta y , m scroll consumed , m scroll offset ) ) { delta y - = m scroll consumed [ 1 ] ; m last y = event y - m scroll offset [ 1 ] ; event . offset location ( 0 , - m scroll offset [ 1 ] ) ; m nested offset y + = m scroll offset [ 1 ] ; }
string imsi = get imsi ( ) ;
page context . set attribute ( constants . select _ key , this ) ; this . calculate match values ( ) ;
if ( sdk _ int > = 21 ) { activity manager . task description task description = new activity manager . task description ( amaze , ( ( bitmap drawable ) get resources ( ) . get drawable ( r . mipmap . ic _ launcher ) ) . get bitmap ( ) , get color preference ( ) . get color ( color usage . get primary ( main activity . current tab ) ) ) ; set task description ( task description ) ; } if ( shared pref . get boolean ( key _ preference _ bookmarks _ added , false ) ) { utils handler . add common bookmarks ( ) ; shared pref . edit ( ) . put boolean ( key _ preference _ bookmarks _ added , true ) . commit ( ) ; }
delete and get version ( b5 , params ( distrib _ update _ param , from _ leader , _ version _ , - 950 ) ) ; delete and get version ( b6 , params ( distrib _ update _ param , from _ leader , _ version _ , - 2060 ) ) ;
if ( arg . _ name . equals ( sampling _ strategy ) ) { arg . set refresh on change ( ) ; if ( regression ) { arg . disable ( random sampling for regression trees . ) ; } }
commit3 response response1 = nfsd . commit ( xdr _ req . as read only wrap ( ) , ch , 1 , security handler unpriviledged , new inet socket address ( localhost , 1234 ) ) ; assert equals ( incorrect return code : , nfs3 status . nfs3 err _ acces , response1 . get status ( ) ) ;
assert same ( proto specific contact in mock contact list . , new contact , mcl slick fixture . mock pres op set . get server stored contact list root ( ) . get contact ( new contact id ) ) ;
assert equals ( tracker is not lost upon host decommissioning , 1 , jt . get cluster status ( false ) . get task trackers ( ) ) ;
persisted session = load persisted sessions paginated ( true , 10 , 1 , 1 ) . get ( 0 ) ;
iter . on close ( ( ) - > close iterator ( origin , request id ) ) ;
reading = true ; writing = true ; clazz . constant pool entry accept ( constant instruction . constant index , this ) ; break ; case instruction constants . op _ getstatic :
throw new hibernate exception ( reassociated object has dirty collection reference ( or an array ) ) ;
file output = new file ( helper . temp dir , jnatest . xls ) ;
for ( bundle f : fragments ) { if ( deps . key set ( ) . contains ( f . get symbolic name ( ) ) ) { deps . put ( f . get symbolic name ( ) , f ) ; collect required bundles ( f , admin , deps , only reexport ) ; } }
assert print ( if ( true ) var x ; x = 4 ; , if ( true ) var x ; x = 4 ) ;
throw new exception ( ) ; } } while ( flag ) ; } } } }
install shortcut receiver . disable and flush install queue ( get context ( ) ) ; m outline provider = null ;
if ( build . version . sdk _ int > = build . version _ codes . honeycomb ) { pager . set motion event splitting enabled ( false ) ; }
is showing = false ;
sql = select id from r1 + where wage in + ( select wage from r2 ) ; ; validate table of longs ( client , sql , new long [ ] [ ] { { 100 } } ) ;
if ( this . begin description index = = 0 ) { this . begin description index = this . comment builder . index of ( * ) ; }
feature types = new file ( data , feature types ) ; feature types . mkdir ( ) ; info ( datastore _ name , sample data access data . namespace _ prefix , sample data access data . mappedfeature _ type _ name . get local part ( ) ) ;
long to skip = bytes ;
factory . set host ( bogus ) ; statistics = metrics . get value ( ) ; assert equals ( wrong number of total bytes counted : + statistics . get ( hdfs locality reporter . locality _ bytes _ total ) , long _ bytes , statistics . get ( hdfs locality reporter . locality _ bytes _ total ) ) ; assert equals ( wrong number of total blocks counted : + statistics . get ( hdfs locality reporter . locality _ blocks _ total ) , 1 , statistics . get ( hdfs locality reporter . locality _ blocks _ total ) ) ; assert equals ( counted block as local when bad hostname set : + statistics . get ( hdfs locality reporter . locality _ blocks _ local ) , 0 , statistics . get ( hdfs locality reporter . locality _ blocks _ local ) ) ;
display metrics metrics = resources . get system ( ) . get display metrics ( ) ; if ( m app . is tablet in portrait ( ) ) { 3 column layout . m width = ( metrics . width pixels ) 3 ; m height = m width + ( m width 4 ) ; } else if ( m app . is phone in landscape ( ) | | m app . is tablet in landscape ( ) ) { 4 column layout . m width = ( metrics . width pixels ) 4 ; m height = m width + ( m width 5 ) ; } else { 2 column layout . m width = ( metrics . width pixels ) 2 ; m height = m width + ( m width 3 ) ; }
standard evaluation context society context = new standard evaluation context ( ) ;
while ( node = null ) { linked list node next = node . next ; if ( node . data < x ) { * insert node at head . * node . next = head ; head = node ; } else { * insert node at tail . * tail . next = node ; tail = node ; } node = next ; } tail . next = null ; return head ;
hregion server hrs = util . get rsfor first region in table ( table _ name ) ; file system fs = hrs . get file system ( ) ;
is upgrade finalized = is upgrade finalized & & sd . get previous dir ( ) . exists ( ) ;
test for disk quota ( 2 , 3000 ) ;
private object save ( final object entity ) { log . debug ( save : { } , entity ) ; if ( get endpoint ( ) . is use persist ( ) ) { entity manager . persist ( entity ) ; return entity ; } else { return entity manager . merge ( entity ) ; } }
unique store defs . put ( store def , 1 ) ;
outstr . write int ( shared packages . size ( ) ) ; for ( string str : shared packages ) { outstr . write utf ( str ) ; }
if ( serial port = = null ) { string port name = ( string ) get thing ( ) . get configuration ( ) . get ( port ) ; if ( port name = = null ) { throw new configuration error ( serial port name not configured ) ; } try { serial port = new rxtxport ( port name ) ; } catch ( port in use exception e ) { throw new ioexception ( e ) ; } try { serial port . set serial port params ( baud , serial port . databits _ 8 , serial port . stopbits _ 1 , serial port . parity _ none ) ; } catch ( unsupported comm operation exception e ) { serial port . close ( ) ; throw new ioexception ( e ) ; } don ' t need continuous updates of the display , we still get updates when the volume , etc . , changes send ( display _ update _ manual ) ; update status ( thing status . online ) ; send ( get _ current _ power ) ; update state ( channel _ mute , on off type . off ) ; update state ( channel _ brightness , new percent type ( 100 ) ) ; }
if ( this . pos > = this . count ) { return - 1 ; } if ( length = = 0 ) { return 0 ; } int copylen = this . count - pos < length ? this . count - pos : length ;
assert equals ( 6 , result . get total epochs ( ) ) ;
assert equals ( 3 , test helpers . filter native registers ( interpreter . get defined registers ( ) ) . size ( ) ) ; assert equals ( big integer . value of ( 0x00400018 l ) , interpreter . get variable value ( ra ) ) ; assert equals ( big integer . value of ( 0x40002c l ) , interpreter . get variable value ( pc ) ) ; assert equals ( big integer . zero , big integer . value of ( interpreter . get memory size ( ) ) ) ; }
ttl = long . max _ value ; } else if ( ttl = = - 1 ) {
int time series length = 12 ; int mini batch size = 7 ; int n in = 5 ; int n out = 4 ; int n time slices = 20 ;
x500 principal iss = entry . get certificate issuer ( ) ;
mem stat check btns [ constant . pss _ total _ index ] . set selection ( true ) ;
if ( decrypted data = null ) { break ; }
shadow connectivity manager . clear all networks ( ) ;
if ( bean = = null ) { try { bean = creator . build ( ctxt , buffer ) ; } catch ( exception e ) { return wrap instantiation problem ( e , ctxt ) ; } } return bean ;
string name = ; queue new queue = new queue ( ) ; map < string , access control list > acls = new hash map < string , access control list > ( ) ; node list fields = queue node . get child nodes ( ) ;
if ( m last pressed close button = null ) m last pressed close button . on up or cancel ( ) ; m last pressed close button = null ;
log . trace ( service already stopped : { } , value ) ; return ;
for ( iproject project : projects ) { project . delete ( true , null ) ; } projects . clear ( ) ; }
update request . last doc in batch ( ) ; } handler . update ( sdoc , update request , commit within , overwrite ) ; } return collections . empty _ list ; } } ; ) { codec . unmarshal ( is ) ;
} connection . set auto commit ( true ) ; }
assert equals ( i , out1 . get length ( ) ) ;
remove subscription ( call id , subscription ) ; protocol provider service sip impl . throw operation failed exception ( failed to send the subscription , operation failed exception . network _ failure , ex , logger ) ;
batched image request request = m in flight requests . remove ( cache key ) ; if ( request = null ) { set the error for this request request . set error ( error ) ; send the batched response batch response ( cache key , request ) ; } }
if ( m modified text . to string ( ) . contains ( < ) ) { span range = get respan range for changed opening symbol ( s , < ) ; } else if ( m modified text . to string ( ) . contains ( > ) ) { span range = get respan range for changed closing symbol ( s , > ) ; } else if ( m modified text . to string ( ) . contains ( & ) ) { span range = get respan range for changed opening symbol ( s , & ) ; } else if ( m modified text . to string ( ) . contains ( ; ) ) { span range = get respan range for changed closing symbol ( s , ; ) ; } else { if the modified text didn ' t include any tag or entity symbols , restyle if the modified text is inside a tag or entity span range = get respan range for normal text ( s , < ) ; if ( span range = = null ) { span range = get respan range for normal text ( s , & ) ; } } if ( span range = null ) { update spans ( s , span range ) ; }
buffered code point = - 1 ;
if ( ( other address [ i ] & address [ i + mask offset ] ) = address [ i ] ) break ;
model node composite = new model node ( ) ; composite . get ( op ) . set ( composite ) ; composite . get ( op _ addr ) . set empty list ( ) ; composite . get ( steps ) . add ( get protocol put property operation ( maximal , mping , send _ on _ all _ interfaces , false ) ) ; composite . get ( steps ) . add ( get protocol put property operation ( maximal , mping , receive _ on _ all _ interfaces , true ) ) ; composite . get ( steps ) . add ( get transport put property operation ( maximal , tcp , tcp _ nodelay , true ) ) ; execute op in both controllers with attachments ( services , version , composite ) ;
name base type = generation util . get array base type ( db . get dialect ( ) , t , u ) ; if ( scala ) type = scala . array [ + get type ( db , schema , base type . last ( ) , p , s , base type , java type , default type , udt mode ) + ] ; else type = get type ( db , schema , base type . last ( ) , p , s , base type , java type , default type , udt mode ) + [ ] ;
for ( int i = 10 ; i < 36 ; + + i ) { assert equals ( i , encoder . get alphanumeric code ( ' a ' + i - 10 ) ) ; }
producer conf . set message routing mode ( message routing mode . round robin partition ) ;
dir . close ( ) ; }
assert that ( graph a . allows self loops ( ) ) . is equal to ( graph b . allows self loops ( ) ) ; assert that ( graph a . node order ( ) ) . is equal to ( graph b . node order ( ) ) ; assert that ( graph a ) . is equal to ( graph b ) ;
alias = matcher . group ( 3 ) ; if ( alias = = null ) {
node schema schema = get output schema ( ) ;
if ( text _ node = = n . get node type ( ) ) nexttype = text _ node ;
_ canonical name = * : * ;
if ( m _ instances test ) return true ;
gradle api groovy loader . discard types from ( ant adapter loader ) ;
owner cache . remove ownership ( global ns bundle ) . get ( ) ;
volt db . instance ( ) . on execution site rejoin completion ( 0l ) ; }
assert equals ( http status . found , token endpoint response . get status code ( ) ) ;
lb capabilities . put ( capability . traffic statistics , per public ip ) ;
test double ( 0 , 0 . 123 , 0d ) ;
list < application > all applications = atlas hacks . activity thread _ m all applications . get ( activity thread ) ; for ( int i = 0 ; i < all applications . size ( ) ; i + + ) { if ( all applications . get ( i ) = = m raw application ) {
simple feature collection features = feature source . get features ( ra ) ;
test harness . process element ( new stream record < > ( new tuple2 < > ( key1 , 1 ) , 1500 ) ) ;
if ( a . has value ( r . styleable . collapsing toolbar layout _ expanded title text appearance ) ) { m collapsing text helper . set expanded text appearance ( a . get resource id ( r . styleable . collapsing toolbar layout _ expanded title text appearance , 0 ) ) ; } if ( a . has value ( r . styleable . collapsing toolbar layout _ collapsed title text appearance ) ) { m collapsing text helper . set collapsed text appearance ( a . get resource id ( r . styleable . collapsing toolbar layout _ collapsed title text appearance , 0 ) ) ; } m scrim visible height trigger = a . get dimension pixel size ( r . styleable . collapsing toolbar layout _ scrim visible height trigger , - 1 ) ;
if ( str . is empty ( ) ) { builder . append ( str . substring ( start offset ) ) ; }
assert . assert equals ( e . get message ( ) , none of the requested protocols : [ unsupported ] are found in sslcontext ) ;
if ( found = = true ) { extension item type item = wcs20 _ factory . create extension item type ( ) ; item . set namespace ( scaling . namespace ) ; item . set name ( scaling ) ; item . set object content ( scaling ) ; gc . get extension ( ) . get contents ( ) . add ( item ) ; } }
table metadata metadata = table metadata . builder ( dummy _ ks , dummy _ tbl ) . add partition key column ( k , bytes type . instance ) . add regular column ( a , bytes type . instance ) . add regular column ( b , map type . get instance ( int32 type . instance , bytes type . instance , true ) ) . add regular column ( c , bytes type . instance ) . add regular column ( d , map type . get instance ( int32 type . instance , bytes type . instance , true ) ) . add regular column ( e , bytes type . instance ) . build ( ) ; column metadata a = metadata . get column ( new column identifier ( a , false ) ) ; column metadata b = metadata . get column ( new column identifier ( b , false ) ) ; column metadata c = metadata . get column ( new column identifier ( c , false ) ) ; column metadata d = metadata . get column ( new column identifier ( d , false ) ) ; column metadata e = metadata . get column ( new column identifier ( e , false ) ) ; row row ;
lock . notify ( ) ; } }
if ( raw type . is assignable from ( implementation type ) ) { throw errors . not asubtype ( implementation type , raw type ) . to exception ( ) ; } @ suppress warnings ( unchecked ) after the preceding check , this cast is safe . class < ? extends t > subclass = ( class < ? extends t > ) implementation type ;
binding match < ? > bm = http config requests . get binding match ( req , http : * config v2 tenant * application * environment * region * instance * * * , http : * config v2 tenant * application * * * ) ; if ( bm . group count ( ) > 6 ) return create from named list request full app id ( req , bm ) ; return create from named list request simple app id ( req , bm ) ; }
if ( service utils . is s3 usstandard endpoint ( endpoint ) ) { client region = aws host name utils . parse region name ( this . endpoint . get host ( ) , s3 _ service _ name ) ; }
string builder . ensure capacity ( char buffer . remaining ( ) ) ; while ( char buffer . has remaining ( ) ) { final char c = char buffer . get ( ) ; switch ( c ) { case ' \ n ' : log ( stream , container id , job id , string builder ) ; break ; default : string builder . append ( c ) ; } }
if ( lu . is nonsingular ( ) ) throw new exception ( matrix is singular ) ; weka . core . matrix . matrix u = lu . get u ( ) ;
usage marker . mark as used ( annotations attribute ) ; mark constant ( clazz , annotations attribute . u2attribute name index ) ;
final byte [ ] b = new byte [ ( int ) blocksize ] ;
return is unknown ( ) & & is macro ( include ) ; }
throw new org . apache . axis2 . databinding . adbexception ( subnet id cannot be null ) ;
if ( retained fragments . contains key ( position ) ) { return retained fragments . get ( position ) ; } return fragments . get ( position ) ;
if ( actual instanceof delegating cache writer ) actual . init ( ctx ) ;
double guess = ( tick label height unit height ) * unit1 . get size ( ) ; number tick unit unit2 = ( number tick unit ) tick units . get ceiling tick unit ( guess ) ; double unit2 height = exponent length to java2 d ( unit2 . get size ( ) , data area , edge ) ;
if ( key . get ( 1 ) . equals ( ranking . features ) ) return ranking . get features ( ) . get object ( key . rest ( ) . rest ( ) . to string ( ) ) ; if ( key . get ( 1 ) . equals ( ranking . properties ) ) return ranking . get properties ( ) . get ( key . rest ( ) . rest ( ) . to string ( ) ) ; } }
v _ 7 = limit - cursor ; lab6 : do {
continue ; } total count + = ranks . state . size ( ) ; min = math . min ( ranks . state . quantile ( 0 ) , min ) ; max = math . max ( ranks . state . quantile ( 1 ) , max ) ; }
int inner class index = inner classes info . u2inner class index ;
list < string > strs = this . get context data strings ( ctx . get index ( ) , record context . type _ post _ parser _ classname ) ;
if ( code < 100 ) { log . warn ( invalid return code : + code ) ; code = 500 ; } }
for ( int i = 0 ; i < date count ; i + + ) { date cell container dc = ( date cell container ) get widget ( i ) ; date dc date = dc . get date ( ) ; int comp = dc date . compare to ( start ) ; int comp2 = dc date . compare to ( end ) ; check if the date is in the range we need if ( comp > = 0 & & comp2 < = 0 ) { check if the slot is taken if ( dc . has event ( slot ) ) { return false ; } } } return true ;
graph model . destroy view ( result . get view ( ) ) ;
set scale1 = new big decimal ( 134567 . 34650 ) ;
logger . info ( ran in + ( ( system . nano time ( ) - start ) 1000000 ) + ms . ) ;
operations = ops ;
try { final optional < task status > previous status = task storage . get status ( task . get id ( ) ) ; if ( previous status . is present ( ) | | previous status . get ( ) . is runnable ( ) ) { log . make alert ( ignoring notification for already - complete task ) . add data ( task , task . get id ( ) ) . emit ( ) ; } else { task storage . set status ( task status ) ; log . info ( task done : % s , task ) ; management may be necessary . signal all ( ) ; } } catch ( exception e ) { log . make alert ( e , failed to persist status for task ) . add data ( task , task . get id ( ) ) . add data ( status code , task status . get status code ( ) ) . emit ( ) ; }
method matcher mm = pointcut . get method matcher ( ) ;
if ( link style = = linker . linkable dep type . shared ) { root deps . put ( dep . get build target ( ) , dep ) ; native linkables . put ( dep . get build target ( ) , dep ) ; }
if ( value = null ) { field . set ( this , value ) ; }
hcolumn descriptor hcd b = new hcolumn descriptor ( bytes . to string ( families [ 1 ] ) ) ;
object action = create action ( action config . action class ) ;
all call latch . await ( ) ; assert false ( error . get ( ) ) ; assert equals ( clients , server . get num open connections ( ) ) ;
if ( instruction . get opcode ( ) = = opcode . nop ) { target index + = 1 ; if ( target index < instructions . size ( ) ) { instruction = instructions . get ( target index ) ; if ( instruction . get opcode ( ) = = type ) { return instruction offset map . get instruction code offset ( target index ) ; } } }
throw e ; } catch ( throwable e ) {
counter = add send stats ( counter ) ;
if ( file util . exists ( last local version on disk ) | | new file with same name = null ) { partial file history file history for deletion = create file history for deletion ( file history , last local version ) ; new database version . add file history ( file history for deletion ) ; logger . log ( level . finer , + deleted : adding deleted version : { 0 } , file history for deletion . get last version ( ) ) ; logger . log ( level . finer , based on : { 0 } , last local version ) ; }
while ( buf off < block size ) { buf [ buf off ] = 0 ; buf off + + ; }
result = new big decimal ( r number . to string ( ) ) ; } }
verify ( counts updater ) . increment relationship count ( any , any , any , 2 l ) ;
final element body element = doc . create element ( body ) ;
int last = - 1 ;
m _ ispreserve = m _ preserves . is empty ( ) ? false : m _ preserves . pop ( ) ;
final list < resource root > deployment roots = deployment utils . all resource roots ( deployment unit ) ; for ( final resource root root : deployment roots ) { if ( sub deployment marker . is sub deployment ( root ) ) { persistence unit metadata holder holder ; array list < persistence unit metadata holder > pu list = new array list < persistence unit metadata holder > ( 1 ) ; if ( root = null & & ( holder = root . get attachment ( persistence unit metadata holder . persistence _ units ) ) = null & & holder . get persistence units ( ) . size ( ) > 0 ) {
sub builder . append ( phoneme text . sub sequence ( i , i + 1 ) ) ;
e = parser . parse expression ( madeup1 ) ; assert true ( should be writable , e . is writable ( l context ) ) ; e = parser . parse expression ( madeup2 . bar ) ; compound expression
hcolumn descriptor hcd b = new hcolumn descriptor ( bytes . to string ( families [ 1 ] ) ) ;
kie base kbase = load knowledge base ( test _ logical insertions update equal . drl ) ; kie session ksession = kbase . new kie session ( ) ; final person p = new person ( person ) ;
string str = package org . simple \ n + global java . util . list list \ n + import org . drools . compiler . alarm \ n + rule \ interval alarm \ \ n + timer ( int : 1s 1s ) \ n + when + not alarm ( ) \ n + then \ n + insert ( new alarm ( ) ) ; \ n + list . add ( \ fired \ ) ; \ n + end \ n ; kie session configuration conf = knowledge base factory . new knowledge session configuration ( ) ;
class clazz = parameter . get the class ( ) ; if ( clazz . is primitive ( ) ) { object distance + = 2 ; } else { while ( clazz = object . class & & clazz = null ) { clazz = clazz . get superclass ( ) ; object distance + = 2 ; } } }
filter set type fset = describe key pairs . get describe key pairs ( ) . get filter set ( ) ; if ( fset = null ) { ec2 request . set key filter set ( to key pair filter set ( fset ) ) ; } return to describe key pairs ( engine . describe key pairs ( ec2 request ) ) ;
string salt = attributes . get ( ' s ' ) ;
match state = new match state ( match , polish . get synthesizer ( ) ) ;
replication mapping = admin client . replica ops . get replication mapping ( 3 , new cluster , store def ) ; hash map < integer , list < integer > > expected mapping = maps . new hash map ( ) ; expected mapping . put ( 0 , lists . new array list ( 3 , 7 , 11 ) ) ; expected mapping . put ( 2 , lists . new array list ( 2 , 6 , 10 ) ) ; assert equals ( expected mapping , replication mapping ) ; }
when ( this . query runner . query ( select * from blah where ? = ? , this . handler , id , 2 ) ) . then return ( index _ 2 ) ;
if ( col . table alias = = null ) { col . table alias = col . table name ; }
buffered block cipher cipher = new padded buffered block cipher ( new cbcblock cipher ( new aesfast engine ( ) ) ) ; cipher . init ( false , key with iv ) ; byte [ ] cipher bytes = data to decrypt . encrypted bytes ;
} @ override public integer next ( ) {
assert . assert equals ( 1 , count mob files ( table name , hcd . get name as string ( ) ) ) ; assert . assert equals ( 0 , count archive mob files ( table name , hcd . get name as string ( ) ) ) ; file name = assert has one mob row ( table , table name , hcd . get name as string ( ) ) ; assert . assert false ( mob archive exist ( table name , hcd . get name as string ( ) , file name ) ) ; assert . assert true ( mob table dir exist ( table name ) ) ; } finally {
metadata . put ( service jid , service jid ) ; logger . info ( xmppclient : : execute - extracting the pid for the service jid [ + service jid + ] with inputs [ + fixed inputs + ] ) ; send message ( service jid , msg ) ; } else {
v value = data . get ( key ) ; if ( value = null ) { if ( record stats ) { stats counter . record hits ( 1 ) ; } return value ; } boolean [ ] missed = new boolean [ 1 ] ;
event bus . fire event ( new active part changed event ( mock ( part presenter . class ) ) ) ; selection changed handler handler = mock ( selection changed handler . class ) ;
sb . append ( \ t generated from ) . append ( tuple generator . class . get name ( ) ) . append ( . \ n ) ;
out err . close ( ) ; create the output files .
string sql = create table company ( idd int ) ; sql = router util . get fixed sql ( sql ) ; string upsql = sql . to upper case ( ) ;
try { field one . get as text ( local time , locale . get default ( ) ) ; assert true ( false ) ; } catch ( unsupported operation exception e ) { assert true ( true ) ; }
final list < copy field > copy fields = copy fields map . get ( source field ) ;
syntax tree node parent = get parent ( ) ; if ( parent = null & & parent instanceof literal element ) { _ literal elem parent = ( literal element ) parent ; } _ name = translate qname ( _ qname , stable ) ;
if ( ( l . status & ret ) = 0 ) { if ( l . in same subroutine ( jsr ) ) { edge e = new edge ( ) ; e . info = l . input stack top ; e . successor = jsr . successors . successor ; e . next = l . successors ; l . successors = e ; } }
if ( null . equals ( origin ) ) { return true ; }
root fsb . m _ chunk bits = m _ chunk bits ;
string cloned region name = bytes . to string ( regions map . get ( bytes . to bytes ( snapshot region name ) ) ) ; if ( cloned region name = = null ) cloned region name = snapshot region name ;
byte [ ] read data = new byte [ len1 ] ; read all ( in , read data , 0 , len1 ) ; byte [ ] expected data = new byte [ len1 ] ; system . arraycopy ( data , 0 , expected data , 0 , len1 ) ; assert . assert array equals ( read data , expected data ) ; long pos = ( ( seekable ) in ) . get pos ( ) ; assert . assert equals ( len1 , pos ) ;
file html file = new file ( destination folder , report . html ) ; file output stream output stream = new file output stream ( html file ) ; output stream writer out = new output stream writer ( output stream , utf - 8 ) ; out . append ( replace buffer . to string ( ) ) ; out . flush ( ) ; out . close ( ) ; output stream . close ( ) ; return true ; }
set . clear ( ) ; set . add ( storages [ 0 ] ) ; set . add ( storages [ 2 ] ) ; set . add ( storages [ 5 ] ) ; located block = block manager . new located block ( b , set . to array ( new datanode storage info [ set . size ( ) ] ) , 0 , false ) ; status = replicator . verify block placement ( located block . get locations ( ) , set . size ( ) ) ; assert true ( status . is placement policy satisfied ( ) ) ;
hash map map3 = new hash map ( ) ; map3 . put ( job config . run _ type , job config . run _ multiple _ instance ) ; map3 . put ( job config . run _ instance _ count , 10 ) ; job config job config3 = new job config ( ) ; job config3 . set config attributes ( map3 ) ;
for ( node expr call node : class defining calls . get ( var ) ) { compiler . report change to enclosing scope ( expr call node ) ; node util . remove child ( expr call node . get parent ( ) , expr call node ) ; }
return input . substring ( pos , limit ) ;
set < string > output streams = new hash set < > ( ) ;
notify hierarchy changed ( ) ;
logger . error ( failed to load accounts for + factory , ex ) ;
layer . m drawable = drawable . create from xml inner ( r , parser , attrs , theme ) ;
return ( int ) l ;
if ( dir . can write ( ) | | dir . is directory ( ) ) throw new illegal state exception ( temp dir + dir + not useable : writeable = + dir . can write ( ) + , dir = + dir . is directory ( ) ) ; }
double [ ] classes = instances . attribute to double array ( instances . class index ( ) ) ; int class index = instances . class index ( ) ; instances . set class index ( - 1 ) ; instances . delete attribute at ( class index ) ;
assert . assert true ( fsimage . has rollback fsimage ( ) ) ;
style builder sb = new style builder ( ) ;
app . wait for state ( map task1 , task state . succeeded ) ; app . wait for state ( map task2 , task state . running ) ;
create floating label ( ) ;
node = type check map constructor ( call , receiver , arguments ) ;
byte [ ] bytes = new byte [ bytes . to int ( int bytes ) ] ; ioutils . read fully ( in , bytes , 0 , bytes . length ) ; if ( with tags ) { return new key value ( bytes , 0 , bytes . length ) ; } else { return new no tags key value ( bytes , 0 , bytes . length ) ; } }
set < injection point > injection points ; if ( instance = null ) { try { injection points = injection point . for instance methods and fields ( instance . get class ( ) ) ; } catch ( configuration exception e ) { copy errors to binder ( e ) ; injection points = e . get partial value ( ) ; } } else { binder . add error ( binding _ to _ null ) ; injection points = immutable set . of ( ) ; } binding impl < t > base = get binding ( ) ;
if ( ( wrapper = = null ) | | ( context = = null ) ) throw new unavailable exception ( sm . get string ( host manager servlet . no wrapper ) ) ;
return ; for now } class [ ] params = writer . get parameter types ( ) ; if ( params . length = 1 ) {
handshake . put ( m , m ) ;
test same ( function a ( ) { } ; a . prototype = { get foo ( ) { return 1 } } ; var o = new a ; o . foo ) ;
task query task query = task service . create task query ( ) ;
final feature collection < t , f > fc = delegate . sort ( order ) ;
netty http security configuration security = consumer . get endpoint ( ) . get security configuration ( ) ;
_ encoding = ( string ) _ properties . get property ( output keys . encoding ) ; _ toh factory = translet output handler factory . new instance ( _ use services mechanism ) ;
this . value table desc = value table desc ; input value deserializer = ( abstract ser de ) reflection utils . new instance ( value table desc . get deserializer class ( ) , null ) ; ser de utils . initialize ser de ( input value deserializer , null , value table desc . get properties ( ) , null ) ; value object inspector = input value deserializer . get object inspector ( ) ; array list < object inspector > ois = new array list < object inspector > ( ) ;
checkpoint cp = checkpoint . create flexible checkpoint ( ) ; final dbus events statistics collector stats = new dbus events statistics collector ( 1 , test1 , true , false , null ) ;
sig alg oid = result = tbs cert . get signature ( ) . get algorithm ( ) ;
int result = dir . compare to ( other . dir ) ;
range full = new range ( 0 , length - 1 , length ) ;
long timelimit = get conf ( ) . get long ( fetcher . timelimit , - 1 ) ; if ( timelimit = - 1 ) feeder . set time limit ( timelimit ) ; feeder . start ( ) ;
if ( on & & timeout < 0 ) { throw new illegal argument exception ( timeout < 0 ) ; }
parts seen . remove ( mp initiator . mp _ init _ pid ) ; assert equals ( partitions , parts seen . size ( ) ) ; }
exception me = null ; try { client . list partitions by filter ( db name , tbl name , p3 > = \ p12 \ , ( short ) - 1 ) ; } catch ( meta exception e ) { me = e ; } assert not null ( me ) ; assert true ( filter on int partition key , me . get message ( ) . contains ( filtering is supported only on partition keys of type string ) ) ; me = null ; try { client . list partitions by filter ( db name , tbl name , c1 > = \ p12 \ , ( short ) - 1 ) ; } catch ( meta exception e ) { me = e ; } assert not null ( me ) ; assert true ( filter on invalid key , me . get message ( ) . contains ( < c1 > is not a partitioning key for the table ) ) ; me = null ;
assert equals ( remaining number of flight entries do not match the expected value , 1 , updated flights . get flight ( ) . size ( ) ) ;
user profile . init contact address ( sip provider ) ;
set < class or interface type details > entities in project = type location service . find classes or interface details with annotation ( roo java type . roo _ jpa _ entity ) ;
stm . write ( file data ) ; stm . close ( ) ;
print response ( m _ client . call procedure ( @ explain view , explain view name ) , false ) ; return ; }
list < core label > tokens = input . sentence . as core labels ( sentence : : lemmas , sentence : : ner tags ) ;
list type server root list = new list type ( ) ; server root list . set name ( root _ group _ name ) ; server root list . set display name ( root group . get list ( ) . get display name ( ) ) ; server root list . get entries ( ) . add all ( root group . get list ( ) . get entries ( ) ) ; server root list . get entry refs ( ) . add all ( root group . get list ( ) . get entry refs ( ) ) ; server root list . get externals ( ) . add all ( root group . get list ( ) . get externals ( ) ) ; server root list . set any ( root group . get list ( ) . get any ( ) ) ; server root list . set any attributes ( root group . get list ( ) . get any attributes ( ) ) ; resource lists . get list ( ) . add ( server root list ) ; x cap client . put resource lists ( resource lists ) ;
assert read values ( new buffered reader ( new input stream reader ( new deflate compressor input stream ( new file input stream ( file ) ) , standard charsets . utf _ 8 . name ( ) ) ) , abc , 123 ) ; }
writer . write start element ( ejb3 subsystem xmlelement . strict _ max _ pool . get local name ( ) ) ;
return dbpdata kind . reference ;
local address = inet4 address . any ; impl . close ( ) ; }
set test max runtime memory in mega bytes ( maps , 40 ) ;
cert path checkers . add ( ( pkixcert path checker ) checker . clone ( ) ) ; }
assert true ( fs . exists ( p1 ) ) ;
entry = reader . next ( ) ;
boolean sub ok = sub . subscribe ( timing values . get subscribe timeout ( ) ) ; throw if exception set ( sub ) ; if ( sub ok ) { sub . close ( ) ; subscription handles . remove ( handle ) ; throw new configuration runtime exception ( subscribe for ' + config key + ' timed out ( timeout was + timing values . get subscribe timeout ( ) + ms ) : + sub ) ; } }
cls = cls . as subclass ( plugin class ) ;
evaluate selected array ( batch , arg1 column , prev selected , prev size ) ;
test types ( * * @ interface \ n + * @ template q \ n + * function i ( ) { } \ n + * * @ param { t } a \ n + * @ return { t | q } \ n + * @ template t \ n + * \ n + i . prototype . method ; \ n + * * @ constructor \ n + * @ implements { i < r > } \ n + * @ template r \ n + * function c ( ) { } \ n + * * @ override * c . prototype . method = function ( a ) { } \ n + * * @ type { c < number > } var x = new c ( ) ; + * * @ type { null } * var some = x . method ( ' str ' ) ; , initializing variable \ n + found : ( number | string ) \ n + required : null ) ;
assert that ( file . select line ( 3 ) . start ( ) . line ( ) ) . is equal to ( 3 ) ;
set relationship type ( namespaces . header ) ; }
final interceptor scope invocation invocation = interceptor scope . get current invocation ( ) ;
destroy ( raw obj , true ) ;
view compat . post on animation ( this , m delayed layout ) ; }
assert not equals ( foo1 , bar ) ;
knob position . set ( half width , half height ) ;
output . assert not contains ( < spoken line > ) ;
log . info ( load table loader rowcounts + next row count + + next cp row count + insert upsert txs : + load txn count [ 0 ] + upsert hit txs : + upsert txn count [ 0 ] + copy txs : + copy txn count + delete txn : + delete txn count ) ;
x + = 360 * math . round ( ( target coverage median position . get ordinate ( 0 ) - x ) 360 ) ;
query query = new query ( ?query = hello ) ; com . yahoo . search . result result = execution . search ( query ) ; assert equals ( 3 , result . get total hit count ( ) ) ;
conn status list = cobar adapter . list connection status ( ) ; assert . assert not null ( conn status list ) ; conn statisic ( conn status list ) ; assert . assert equals ( conn num , 1 ) ; } catch ( exception e ) {
if ( parent . is stopped ( ) ) { parent . notify listeners spider task result ( new spider task result ( msg , get skipped message ( stopped ) ) ) ; log . debug ( spider process is stopped . skipping crawling task . . . ) ; parent . post task execution ( ) ; return ; }
if ( that . has headers ( ) ) { get headers ( ) . put all ( that . get headers ( ) ) ; } get attachments ( ) . clear ( ) ; if ( that . has attachments ( ) ) { get attachment objects ( ) . put all ( that . get attachment objects ( ) ) ; } }
assert equals ( cursor mark , assert cursor ( req ( params , cursor _ mark _ param , cursor mark ) , response num found = = 8 , response start = = 0 , response docs = = [ ] ) ) ;
roles . get tooltip role ( ) . set ( get element ( ) ) ;
if ( is capitalized ( tokens [ i ] . get token ( ) ) & & is capitalized ( tokens [ i - 1 ] . get token ( ) ) ) { log exception ( ) ; return true ; }
if ( line . has option ( segment ) ) { string [ ] segments = line . get option values ( segment ) ; seg paths = new path [ segments . length ] ; for ( int i = 0 ; i < segments . length ; i + + ) { seg paths [ i ] = new path ( segments [ i ] ) ; } }
try { int [ ] data = new int [ 8 ] ; ib . position ( 0 ) ; ib . put ( data , - 1 , 2 ) ; fail ( expected exception not thrown ) ; } catch ( index out of bounds exception e ) { expected }
int c ind = union . get row type ( ) . get field list ( ) . size ( ) - 1 ; for ( int index = 0 ; index < union . get row type ( ) . get field list ( ) . size ( ) ; index + + ) { if ( index = c ind ) { group set positions . add ( index ) ; } } list < aggregate call > aggregate calls = lists . new array list ( ) ;
string name = includeresource [ i ] ; if ( name . starts with ( ) ) { string s = cls . get name ( ) . replace ( ' . ' , ' ' ) ; int n = s . last index of ( ' ' ) ; if ( n > = 0 ) { name = s . substring ( 0 , n + 1 ) + name ; } includeresource [ i ] = + name ; } }
inner node count + + ; inner node path [ curr depth ] = inner node count ; long code left = set bit ( code so far , code length so far , false ) ;
if ( attacher = null ) { attacher . update ( ) ; }
log . info ( container + container id + not running , nothing to signal . ) ; return ;
am0 . unregister app attempt ( false ) ;
analyze ( select * from t1 group by t1 . a , t1 . b , t1 . c , t1 . d ) ;
mockito . when ( implementation . get ( ( byte [ ] ) mockito . any ( ) , ( get ) mockito . any ( ) ) ) . then throw ( ex ) ;
super . write internal ( out ) ;
m workspace . lock wallpaper to default page ( ) ;
mark branches ( offset , switch instruction . jump offsets ) ;
builder . start object ( fields . indices ) ; stats . to xcontent ( builder , params ) ; if ( indices . equals ( level ) ) { map < index , common stats > index stats = create stats by index ( ) ; builder . start object ( fields . indices ) ; for ( map . entry < index , common stats > entry : index stats . entry set ( ) ) { builder . start object ( entry . get key ( ) . get name ( ) ) ; entry . get value ( ) . to xcontent ( builder , params ) ; builder . end object ( ) ; } builder . end object ( ) ; } else if ( shards . equals ( level ) ) { builder . start object ( shards ) ; for ( map . entry < index , list < index shard stats > > entry : stats by shard . entry set ( ) ) { builder . start array ( entry . get key ( ) . get name ( ) ) ; for ( index shard stats index shard stats : entry . get value ( ) ) { builder . start object ( ) . start object ( string . value of ( index shard stats . get shard id ( ) . get id ( ) ) ) ; for ( shard stats shard stats : index shard stats . get shards ( ) ) { shard stats . to xcontent ( builder , params ) ; } builder . end object ( ) . end object ( ) ; } builder . end array ( ) ; } builder . end object ( ) ; }
string prior last key = null ;
result . append ( \ n ) ;
test listener . push expected event ( next event . phase ) ; current time = clock . get utcnow ( ) ; interval it = new interval ( clock . get utcnow ( ) , clock . get utcnow ( ) . plus days ( 31 ) ) ; clock . add delta from reality ( it . to duration millis ( ) ) ; current time = clock . get utcnow ( ) ; assert listener status ( ) ;
assert equals ( 6 , result . get total epochs ( ) ) ;
s _ logger . debug ( reapplying firewall rules for ip id = + ip id + as a part of disable remote access vpn ) ;
session handle session handle = setup test data ( table name , column definitions , conf overlay ) ;
final long sampled = ( long ) ( heuristic _ cost _ base * 0 . 1f ) ;
if ( m adapter = null ) m adapter . notify data set changed ( ) ;
tree set < string > left = new tree set < > ( ) ; tree set < string > right = new tree set < > ( ) ; for ( field info fi : left infos ) { left . add ( fi . name ) ; } for ( field info fi : right infos ) { right . add ( fi . name ) ; }
clazz = ( ( ometadata internal ) database . get metadata ( ) ) . get immutable schema snapshot ( ) . get class ( class name ) ;
try { string html parser class name = config . get ( html . parser , org . apache . lucene . benchmark . by task . feeds . demo htmlparser ) ; html parser = class . for name ( html parser class name ) . as subclass ( htmlparser . class ) . new instance ( ) ; } catch ( exception e ) { should not get here . throw runtime exception . throw new runtime exception ( e ) ; }
entity manager em = get entity manager ( ) ; em . get transaction ( ) . begin ( ) ; composite date id test entity dite = new composite date id test entity ( new date emb id ( new date ( ) , new date ( ) ) , x ) ; em . persist ( dite ) ; id1 = dite . get id ( ) ; em . get transaction ( ) . commit ( ) ;
long v = random int between ( 14 , 17 ) ; delete response delete response = client ( ) . prepare delete ( test , type , 1 ) . set version ( v ) . set version type ( version type . external _ gte ) . execute ( ) . action get ( ) ; assert equals ( doc write response . result . deleted , delete response . get result ( ) ) ; assert that ( delete response . get version ( ) , equal to ( v ) ) ;
if ( corrupt nodes = = null | | corrupt nodes . contains ( cur ) ) { non excess . add ( cur ) ; original datanodes . add ( cur ) ; }
path f = new path ( root _ dir , get name ( ) ) ; hfile context meta = new hfile context builder ( ) . with block size ( 8 * 1024 ) . build ( ) ;
listeners . put ( * , null ) ; mbean exporter exporter = new mbean exporter ( ) ; thrown . expect ( illegal argument exception . class ) ; exporter . set notification listener mappings ( listeners ) ; }
int nchunk = _ tmp _ espc . length ;
update j ( json add ( doc ) , null ) ;
verify ( callbacks , times ( 1 ) ) . on restore ( facebook auth data ) ;
_ expire event . remove ( peer ) ;
assert q ( req ( q , doubledv : [ 2 to 3 . 3 ] , sort , id _ i asc ) , * [ @ num found = ' 2 ' ] , result doc [ 1 ] str [ @ name = ' id ' ] [ . = 1 ] , result doc [ 2 ] str [ @ name = ' id ' ] [ . = 3 ] ) ;
file file = get file ( smalldata chicago chicago all weather . csv ) ;
f node factory . reset ( component manager ) ;
string key name = proxy target info . target class . get name ( ) + . + proxy target info . target method name ; string [ ] param names = method param names . get ( key name ) ;
assert ( tolerance _ nonzero ) ;
assert . assert equals ( this is a test , string0 . to string ( ) ) ;
assert that ( tester . process bundle ( 1 l , 2 l , 3 l , 4 l ) , has items ( 1 , 2 , 3 , 4 ) ) ;
float scale = is selected ? scale _ selected : scale _ normal ; if ( holder . image view . get scale x ( ) = scale ) { holder . image view . set scale x ( scale ) ; holder . image view . set scale y ( scale ) ; }
sms . parse sms ( ) ; int tele service = sms . get tele service ( ) ; boolean handled = false ; if ( ( sms envelope . teleservice _ vmn = = tele service ) | | ( sms envelope . teleservice _ mwi = = tele service ) ) { handling voicemail int voicemail count = sms . get num of voicemails ( ) ; log . d ( tag , voicemail count = + voicemail count ) ; store the voicemail count in preferences . shared preferences sp = preference manager . get default shared preferences ( m context ) ; shared preferences . editor editor = sp . edit ( ) ; editor . put int ( cdmaphone . vm _ count _ cdma , voicemail count ) ; editor . apply ( ) ; m phone . set voice message waiting ( 1 , voicemail count ) ; handled = true ; } else if ( ( ( sms envelope . teleservice _ wmt = = tele service ) | | ( sms envelope . teleservice _ wemt = = tele service ) ) & & sms . is status report message ( ) ) { handle cdma status report ( sms ) ; handled = true ; } else if ( ( sms . get user data ( ) = = null ) ) { if ( false ) { log . d ( tag , received sms without user data ) ; } handled = true ; }
original import iter . remove ( ) ;
file list . add ( remote ) ;
m motion down x = drag layer x ;
int num maps = 1 ;
if ( tables = null & & tables . size ( ) > 0 ) { get monitor ( ) . set archive tables ( tables ) ; } else { log . debug ( no tables to archive . ) ; only if we currently have a tracker , then clear the archive clear tables ( ) ; } }
string qualifier = ;
predicate < node > pred = new predicate < node > ( ) { @ override public boolean apply ( node n ) { return n = = expr . get root ( ) ; } } ;
data add panel . show ( ) ; } } ) ; prog add panel . get father box ( ) . add click handler ( new click handler ( ) { @ override public void on click ( click event event ) {
path element = path element . replace ( workspace wildcard , workspace . get path string ( ) ) ; path fragment path element fragment = path fragment . create ( path element ) ;
string string result = ( string ) get stat result ( p6r , string _ sd , val _ type . string ) ;
type check ( line _ joiner . join ( * * , * @ param { iobject < number , string > } x , * @ param { object } y , * , function f ( x , y ) { , x = y ; , } ) ) ; }
adapter . set message converter ( null ) ;
send update ( configs , zone , binding type . power , power update ) ;
string zk address = cluster . get zk server ( ) . get zk address ( ) ;
{ m decr ( ) ; if ( state . failed ) return ; } break ; case 20 :
work dir = new path ( get absolute test root path ( f sys ) , new path ( test ) ) ; f sys . set working directory ( work dir ) ; assert . assert equals ( work dir , f sys . get working directory ( ) ) ; path relative dir = new path ( existing dir1 ) ;
case floor :
stream execution environment env = stream execution environment . get execution environment ( ) ;
elector . ensure parent znode ( ) ; elector . join election ( app data ) ; zoo keeper server zks = get server ( server factory ) ; active standby elector test util . wait for active lock data ( null , zks , parent _ dir , app data ) ; mockito . verify ( cb , mockito . timeout ( 1000 ) ) . become active ( ) ; check fatals and reset ( ) ; log . info ( = = = = = = = = = = = = = = = = = = = = = = = = = = expiring session ) ;
assert . assert equals ( 0 , report _ nm1 . get available resource ( ) . get memory size ( ) ) ; assert . assert equals ( 4 * gb , report _ nm1 . get used resource ( ) . get memory size ( ) ) ;
server transport = new tserver socket ( port ) ;
verify ( service ) . read acls by id ( eq ( arrays . as list ( oids ) ) , any ( list . class ) ) ;
if ( ( bitfield [ i ] & ( 1 < < j ) ) = = 0 ) { system . out . println ( i * 8 + j ) ; return ; }
inet socket address inet socket address = new inet socket address ( request . get address ( ) , port ) ;
int uid = - 1 ;
super . visit ( node ) ; }
file services file = new file ( dir , services . xml ) ; if ( services file . exists ( ) ) { throw new file not found exception ( could not find services . xml under : + dir . get absolute path ( ) ) ; }
file classes jar = new file ( new file ( exploder dir , jars ) , classes . jar ) ;
binder . bind ( commands , this ) ; }
assert true ( management system . await relation index status ( graph , lives by reason , lives ) . status ( schema status . enabled ) . call ( ) . get succeeded ( ) ) ;
bundle tree set cache . clear ( ) ;
assert that ( junc0 . to file ( ) . exists ( ) ) . is false ( ) ;
apply transformation ( ) ;
if ( test ) indent : 8 exp : 8 system . get property ( blah ) ; indent : 12 exp : 12 else if ( 7 < 8 ) indent : 8 exp : 8 system . get property ( blah ) ; indent : 12 exp : 12 else if ( 8 < 9 ) indent : 8 exp : 8 system . get property ( blah ) ; indent : 12 exp : 12
builder . set custom title ( header view ) ;
final int max _ attemps = 30 ; for ( int i = 0 ; i < max _ attemps ; i + + ) { pick a random file name string temp dir name = tmp _ + ( ( int ) ( 100000 * math . random ( ) ) ) ; return if dir could successfully be created with that file name file temp dir = new file ( base dir , temp dir name ) ; if ( temp dir . mkdir ( ) ) { return temp dir ; } } throw new illegal state exception ( failed to create a temp dir under + base dir + giving up after + max _ attemps + attempts ) ;
m adapter . set display headers at start up ( true ) . set sticky headers ( true ) ;
assert that ( environment . get property ( foo ) ) . is equal to ( bar ) ;
view . on click listener sound picker listener = v - > { intent intent = new intent ( ringtone manager . action _ ringtone _ picker ) ; intent . put extra ( ringtone manager . extra _ ringtone _ type , ringtone manager . type _ notification ) ; intent . put extra ( ringtone manager . extra _ ringtone _ show _ default , true ) ; intent . put extra ( ringtone manager . extra _ ringtone _ default _ uri , ringtone manager . get default uri ( ringtone manager . type _ notification ) ) ; uri current sound = null ; string default path = null ; uri default uri = settings . system . default _ notification _ uri ; if ( default uri = null ) { default path = default uri . get path ( ) ; } string path = messenger ( ) . get preferences ( ) . get string ( global notification sound ) ; if ( path = = null ) { path = default path ; } if ( path = null & & path . equals ( none ) ) { if ( path . equals ( default path ) ) { current sound = default uri ; } else { current sound = uri . parse ( path ) ; } } intent . put extra ( ringtone manager . extra _ ringtone _ existing _ uri , current sound ) ; start activity for result ( intent , sound _ picker _ request _ code ) ; } ; res . find view by id ( r . id . sound picker cont ) . set on click listener ( sound picker listener ) ;
num times unhealthy = 1 ;
return table ;
skip ( ) ; } break ; case label _ comment _ extension : skip ( ) ; break ; case label _ plain _ text _ extension : skip ( ) ; break ; default :
return collections . unmodifiable map ( segments ) ; }
list1 = hrll ( hrl ( info0 , sn0 ) , hrl ( info1 , sn1 ) ) ;
while ( src . char at ( start + + ) = ' ' ) { }
instance = runtime service . create process instance query ( ) . variable value not equals ignore case ( upper , uiop ) . single result ( ) ;
do cluster transformation and verification ( cluster test utils . get zzzcluster ( ) , cluster test utils . get zzzcluster with nnn ( ) , cluster test utils . get zzzcluster with ppp ( ) ) ; do cluster transformation and verification ( cluster test utils . get zzcluster ( ) , cluster test utils . get zzecluster ( ) , cluster test utils . get zzecluster xxp ( ) ) ; }
cr = client . call procedure ( @ ad hoc , select abs ( dept ) , sum ( abs ( wage ) - 1 ) as tag , + ( count ( * ) + sum ( dept * 2 ) ) 2 from + tb + group by dept order by abs ( dept ) ) ;
byte array output stream o stream = new byte array output stream ( ) ; writable byte channel o channel = channels . new channel ( o stream ) ; for ( int i = 0 ; i < 2 ; + + i ) { ( ( dbus event internal readable ) events . get ( i ) ) . write to ( o channel , encoding . binary ) ; } byte [ ] write bytes = o stream . to byte array ( ) ;
test _ util . get configuration ( ) . set int ( hfile block index . max _ chunk _ size _ key , block _ size ) ; schema metrics . set use table name in test ( false ) ;
sixth width , 2 * third height , 5 * sixth width , 2 * third height } ; }
return ( managed list operator < e > ) new string list operator ( realm , os list , ( class < string > ) clazz ) ;
intent intent = new intent ( this , wplaunch activity . class ) ; intent . add flags ( intent . flag _ activity _ clear _ task | intent . flag _ activity _ new _ task ) ; start activity ( intent ) ; }
list < region info > region list = primary rsto region map . get ( server ) ;
return to test ;
if ( start string = = null | | p . length ( ) > start string . length ( ) ) { start string = p ; prefix = e . get entry arg ( 1 ) ; }
if ( input = = null ) { final error msg msg = new error msg ( error msg . file _ not _ found _ err , doc to load , this ) ; parser . report error ( constants . fatal , msg ) ; return ; } final syntax tree node root ;
if ( null = m on last item visible listener ) { m last item visible = ( total item count > 0 ) & & ( first visible item + visible item count > = total item count - 1 ) ; }
final boolean [ ] values = new boolean [ num _ options ] ; final int n iterations = ( int ) math . pow ( 2 , num _ options ) ; for ( int i = 0 ; i < n iterations ; i + + ) { toggle options for ( int j = 0 ; j < num _ options ; j + + ) { if ( i % powers [ j ] = = 0 ) { values [ j ] = values [ j ] ; } } log . debug ( options { } = { } , report _ options , values ) ; headers . clear ( ) ; for ( int j = 0 ; j < report _ options . length ; j + + ) { headers . put ( report _ options [ j ] , values [ j ] ) ; } convert results = template . request body and headers ( direct : convert results , async report results , headers , string . class ) ; assert not null ( convert results , convert results ) ; log . debug ( { } , convert results ) ; }
assert true ( sva . add ( new string value ( string . value of ( ( char ) count ) ) ) ) ;
toast . make text ( m context , you have dismissed a + card . get tag ( ) , toast . length _ short ) . show ( ) ; } } ) ;
data input stream in = new data input stream ( new byte array input stream ( buffer ) ) ; random row filter new filter = new random row filter ( ) ; new filter . read fields ( in ) ; return new filter ;
if ( from . get tag ( ) = null ) { retval . append ( colon ) ; retval . append ( from . get tag ( ) ) ; }
this . netty server channel = this . bootstrap . bind ( new inet socket address ( this . port ) ) ;
if ( get component ( ) = = null ) return ; int x = evt . get x ( ) ;
throw new error ( e ) ;
next = get move for insn ( use ) ;
map < string , string > m = splitter . on ( , ) . with key value separator ( : ^ & ) . split ( boy : ^ & tom , girl : ^ & tina , cat : ^ & kitty , dog : ^ & tommy ) ; immutable map < string , string > expected = immutable map . of ( boy , tom , girl , tina , cat , kitty , dog , tommy ) ; assert that ( m ) . is equal to ( expected ) ; assert that ( m . entry set ( ) ) . contains exactly elements in ( expected . entry set ( ) ) . in order ( ) ; }
context . get session handler ( ) . get session cookie config ( ) . set http only ( http only ) ;
for ( int i = 0 ; i < size ; i + + ) { cache entry e = cache . check or add to cache ( inet address . get by name ( 1 . 1 . 1 . + ( start entry + i ) ) , 0 ) ; assert not null ( e ) ; assert true ( e . is in progress ( ) ) ; assert false ( e . is completed ( ) ) ; }
if ( attributes . contains key ( user model . first _ name ) ) { ldap query . add where condition ( conditions builder . equal ( user model . first _ name , attributes . get ( user model . first _ name ) , escape strategy . non _ ascii _ chars _ only ) ) ; } if ( attributes . contains key ( user model . last _ name ) ) { ldap query . add where condition ( conditions builder . equal ( user model . last _ name , attributes . get ( user model . last _ name ) , escape strategy . non _ ascii _ chars _ only ) ) ; } list < ldapobject > ldap objects = ldap query . get result list ( ) ;
array list < string > event process = new array list < string > ( ) ; event process . add ( evaluate ( gsml : geologic unit [ @ gml : id = ' gsml . geologicunit . 16777549126932776 ' ] gsml : geologic history gsml : geologic event [ @ gml : id = ' gsml . geologicevent . 16777549126932777 ' ] gsml : event process [ 1 ] gsml : cgi _ term value gsml : value , doc ) ) ; event process . add ( evaluate ( gsml : geologic unit [ @ gml : id = ' gsml . geologicunit . 16777549126932776 ' ] gsml : geologic history gsml : geologic event [ @ gml : id = ' gsml . geologicevent . 16777549126932777 ' ] gsml : event process [ 2 ] gsml : cgi _ term value gsml : value , doc ) ) ; assert true ( event process . contains ( water [ process ] ) ) ; assert true ( event process . contains ( turbidity current ) ) ; assert xpath evaluates to ( urn : cgi : classifier : cgi : geologic unit type : 200811 : lithostratigraphic _ unit , gsml : geologic unit [ @ gml : id = ' gsml . geologicunit . 16777549126932776 ' ] gsml : geologic unit type @ xlink : href , doc ) ;
purchase record . id generated id = record . get id ( ) ; date timestamp = record . get timestamp ( ) ; assert not null ( generated id ) ; assert not null ( generated id . get purchase sequence ( ) ) ; assert true ( generated id . get purchase number ( ) > 0 ) ; s = open session ( ) ;
if ( second set . size ( ) > first set . size ( ) ) { hash set < graph . vertex < integer > > temp set = first set ; first set = second set ; second set = temp set ; }
enlarge input buffer if needed ( remaining samples + 2 * max required ) ;
enlist pre registered services ( ) ; try { object me = get management object strategy ( ) . get managed object for camel health ( camel context ) ; if ( me = = null ) { endpoint should not be managed return ; } manage object ( me ) ; } catch ( exception e ) { log . warn ( could not register camel health mbean . this exception will be ignored . , e ) ; }
diff = y - m last motion y ; opposite diff = x - m last motion x ; abs diff = math . abs ( diff ) ; if ( abs diff > m touch slop & & abs diff > math . abs ( opposite diff ) ) { if ( diff > = 1f & & is ready for pull start ( ) ) { m last motion y = y ; m last motion x = x ; m is being dragged = true ; } }
for ( resource override : get layered resources ( web _ fragment _ xml , template , node , instance ) ) { _ _ log . debug ( { } : web override = { } , origin , override ) ; webappcontext . add override descriptor ( override . to string ( ) ) ; }
input stream in = get input stream ( default buffer size ) ;
kc session . sessions ( ) . get user session with predicate ( realm , id , false , ( user session model user session2 ) - > { return user session2 = = null ; } ) ; return kc session . sessions ( ) . get user session ( realm , id ) ; }
obj = static members . get ( true name ) ; } if ( obj instanceof native java method ) { native java method njm = ( native java method ) obj ; methods or ctors = njm . methods ; } }
if ( old col . get name ( ) . equals ( new col . get name ( ) ) | | old col . get type ( ) . equals ( new col . get type ( ) ) ) { return false ; }
_ posting list value byte buffer = mmap utils . allocate direct byte buffer ( _ num values * v1 constants . numbers . integer _ size , null , bitmap posting list value buffer for : + _ column name ) ;
job metrics . set metrics ( immutable list . of ( make distribution metric update ( distribution name , distribution namespace , s2 , 18 l , 2 l , 2 l , 16 l , false ) , make distribution metric update ( distribution name , distribution namespace , s2 , 18 l , 2 l , 2 l , 16 l , true ) ) ) ; dataflow metrics dataflow metrics = new dataflow metrics ( job , dataflow client ) ;
this . state . update roots ( delta res . get full path ( ) , delta , this ) ;
assert that ( under test . count groups ( db . get session ( ) , builder ( ) . organization uuid ( organization dto . get uuid ( ) ) . membership ( in ) . build ( ) , user2 . get id ( ) ) ) . is equal to ( 1 ) ; assert that ( under test . count groups ( db . get session ( ) , builder ( ) . organization uuid ( organization dto . get uuid ( ) ) . membership ( out ) . build ( ) , user2 . get id ( ) ) ) . is equal to ( 2 ) ;
double sum = trigram lambda + bigram lambda + unigram lambda ; return new linear interpolation ( trigram lambda sum , bigram lambda sum , unigram lambda sum ) ; }
abstract grid format format = new net cdfformat ( ) ;
fly cam . set drag to rotate ( true ) ; fly cam . set move speed ( 50 ) ; final material debug app state debug = new material debug app state ( ) ;
final int left = scroll x - offset + width ;
ship = new ship entity ( this , ship . gif , 370 , 550 ) ; entities . add ( ship ) ;
show status ( opening multiple realms ) ;
layer info ll = catalog . get layer by name ( l . prefixed name ( ) ) ; ll . set default style ( catalog . get style by name ( s2 . get name ( ) ) ) ; catalog . save ( ll ) ;
if ( encode table = = standard _ encode _ table ) { buffer [ pos + + ] = pad ; buffer [ pos + + ] = pad ; } break ; case 2 :
functional method . set accessible ( true ) ;
if ( options . get conflict strategy ( ) = down conflict strategy . rename ) { logger . log ( level . info , conflict strategy + options . get conflict strategy ( ) + not yet implemented . ) ; result . set result code ( down result code . nok ) ; return false ; }
scope [ ] previous scopes = scope helper _ . get sweave chunks ( position , which ) ; string builder builder = new string builder ( ) ;
grid . set widget ( 5 , 0 , quit child processes on exit _ = new check box ( quit child processes on exit ) ) ; add ( grid ) ; }
hazelcast . new hazelcast instance ( config ) ;
if ( value = null ) { if ( netatmo measure type . is temperature ( measure type ) ) { value = unit system . convert temp ( value ) ; } else if ( netatmo measure type . is rain ( measure type ) ) { value = unit system . convert rain ( value ) ; } else if ( netatmo measure type . is pressure ( measure type ) ) { value = pressure unit . convert pressure ( value ) ; } else if ( netatmo measure type . is wind ( measure type ) ) { value = unit system . convert wind ( value ) ; } state = new decimal type ( value ) ; }
long aged out count = count - max total rows ; long rows to consider = math . min ( aged out count , target max rows to delete ) ;
find iterable . into ( new array list < document > ( ) , new single result callback < array list < document > > ( ) { @ override public void on result ( final array list < document > result , final throwable t ) { assert equals ( 1 , result . size ( ) ) ; } } ) ;
set vertex attrib ( vb ) ; } else {
service reference [ ] ser refs = null ; string osgi filter = ( + protocol provider factory . protocol + = + protocol names . sip + ) ; try { ser refs = bc . get service references ( protocol provider factory . class . get name ( ) , osgi filter ) ; } catch ( invalid syntax exception ex ) { this really shouldhn ' t occur as the filter expression is static . fail ( osgi filter + is not a valid osgi filter ) ; } assert true ( failed to find a provider factory service for protocol sip , ( ser refs = null ) & & ( ser refs . length > 0 ) ) ;
update configuration ( configuration ) ; if ( refresh ) { stop automatic refresh ( ) ; clear device list ( ) ; socket close ( ) ; initialize ( ) ; }
int max binary message = get max message size ( policy . get max binary message size ( ) , metadata . max binary message size ( ) ) ; int max text message = get max message size ( policy . get max text message size ( ) , metadata . max text message size ( ) ) ; policy . set max binary message size ( max binary message ) ; policy . set max text message size ( max text message ) ; return new jsr annotated event driver ( policy , ei , events ) ;
final path store path = store . get store homedir ( htable descriptor . get table dir ( fsutils . get root dir ( conf ) , table _ name ) , admin . get table regions ( table _ name ) . get ( 0 ) . get encoded name ( ) , families [ 0 ] ) ;
for ( int i = 0 ; i < m ; i + + ) { component c = components . get ( i ) ; for ( int j = 0 ; j < n ; j + + ) { posteriori [ i ] [ j ] = c . priori * c . distribution . p ( x [ j ] ) ; } }
assert same ( global function , creator . create scope ( fn foo , global scope ) ) ; assert same ( inside , global function . get var ( inside ) ) ; assert true ( global scope2 . is declared ( a , true ) ) ; still declared , scope creator is frozen assert true ( global scope2 . is declared ( b , true ) ) ; assert true ( global scope2 . is declared ( x , true ) ) ; assert true ( global scope2 . is declared ( ext , true ) ) ; assert false ( global scope2 . is declared ( nonexistant , true ) ) ;
request handler utils . handle commit ( req , processor , params , false ) ; request handler utils . handle rollback ( req , processor , params , false ) ; } } finally {
final int dot index = id . index of ( ' . ' ) ; if ( dot index = - 1 ) { id = id . substring ( 0 , dot index ) ; } return integer . parse int ( id ) ;
this . log class name = log adapter class name ;
input stream input = listener . get input stream ( ) ;
for ( int i = 0 ; i < child count ; i + + ) { view child = get child at ( i ) ; layout params lp = ( layout params ) child . get layout params ( ) ; don ' t reclaim header or footer views , or views that should be ignored if ( lp = null & & m recycler . should recycle view type ( lp . view type ) ) { views . add ( child ) ; if ( listener = null ) { pretend they went through the scrap heap listener . on moved to scrap heap ( child ) ; } } }
for ( final string edge group : edge groups ) { build seed filter ( edge group , false ) ; apply group filter ( edge group , false ) ; } for ( final string entity group : entity groups ) { build seed filter ( entity group , true ) ; apply group filter ( entity group , true ) ; } }
selection results = selection operator utils . render selection results without ordering ( selection operator utils . reduce without ordering ( data table map , selection size ) , data schema , selection operator utils . get selection columns ( selection . get selection columns ( ) , data schema ) ) ; }
for ( int i = 0 ; i < 100000 ; i + + ) { e . add value ( r . next gaussian ( ) , 1 ) ; e . add value ( r . next gaussian ( ) * 2 . 0 , 3 ) ; }
server server = new server ( ) ;
int sb avail button w = ( sb size . width - sb insets w ) ; if ( sb avail button w < sb buttons w ) { right button w = left button w = sb avail button w 2 ; right button x = sb size . width - ( sb insets . right + right button w + right gap ) ; } ( ltr ? decr button : incr button ) . set bounds ( left button x , item y , left button w , item h ) ; ( ltr ? incr button : decr button ) . set bounds ( right button x , item y , right button w , item h ) ;
list < string > names = new array list < string > ( ) ; names . add ( yaugher volcanic group ) ; names . add ( - py ) ; string name = evaluate ( gsml : mapped feature [ @ gml : id = ' mf1 ' ] gsml : specification gsml : geologic unit gml : name [ 1 ] , doc ) ; assert true ( names . contains ( name ) ) ; names . remove ( name ) ; name = evaluate ( gsml : mapped feature [ @ gml : id = ' mf1 ' ] gsml : specification gsml : geologic unit gml : name [ 2 ] , doc ) ; assert true ( names . contains ( name ) ) ; names . remove ( name ) ; assert true ( names . is empty ( ) ) ; assert xpath evaluates to ( instance , gsml : mapped feature [ @ gml : id = ' mf1 ' ] gsml : specification + gsml : geologic unit gsml : purpose , doc ) ;
if ( ends with return ( expr ) ) { if ( is lambda void body ( expr , type for expression ) ) { mark line number ( ( kt function literal ) expr . get parent ( ) , true ) ; } else { mark line number ( expr , true ) ; } if ( type for expression . get sort ( ) = = type . void ) { stack value . none ( ) . put ( return type , v ) ; } v . areturn ( return type ) ; }
while ( classes . has next ( ) ) { final persistent class pc = classes . next ( ) ; ensure we ' re in pojo , not dynamic model , mapping . if ( pc . get class name ( ) = null ) { collecting information from annotations on the persistent class pc final annotations metadata reader annotations metadata reader = new annotations metadata reader ( global configuration , reflection manager , pc ) ; final class auditing data audit data = annotations metadata reader . get audit data ( ) ; classes auditing data . add class auditing data ( pc , audit data ) ; } }
located blocks = client . get located blocks ( filename , 0 , block _ size * num _ blocks ) ;
assert equals ( correct string . length ( ) , foreign text . length ( ) - 6 ) ; }
literal names [ i ] = null ;
conf . set ( base load balancer . tables _ on _ master , none ) ;
for ( int i = count - 1 ; i > = 0 ; i - - ) {
final string echo with request and response compressed = bean . echo with no explicit data compression hint on method ( message ) ;
try { mount contexts . put ( classpath , new class path mount factory ( context . get class loader ( ) ) ) ; mount contexts . put ( file , new file mount factory ( utils . get current directory ( ) ) ) ; mount contexts . put ( war , new war mount factory ( context ) ) ; } catch ( exception e ) { log . log ( level . severe , coult not initialize classpath driver , e ) ; return ; }
int total messages = 0 ; message msg = null ; while ( true ) { msg = consumer1 . receive ( 1 , time unit . seconds ) ; if ( msg = = null ) { break ; } total messages + + ; consumer1 . acknowledge ( msg ) ; } assert . assert equals ( total messages , num msgs 2 ) ; while ( true ) { msg = consumer2 . receive ( 1 , time unit . seconds ) ; if ( msg = = null ) { break ; } total messages + + ; consumer2 . acknowledge ( msg ) ; } assert . assert equals ( total messages , num msgs ) ; assert . assert equals ( disp0 . get active consumer ( ) . consumer name ( ) , consumer conf1 . get consumer name ( ) ) ; assert . assert equals ( disp1 . get active consumer ( ) . consumer name ( ) , consumer conf2 . get consumer name ( ) ) ; assert . assert equals ( disp2 . get active consumer ( ) . consumer name ( ) , consumer conf1 . get consumer name ( ) ) ; assert . assert equals ( disp3 . get active consumer ( ) . consumer name ( ) , consumer conf2 . get consumer name ( ) ) ; total messages = 0 ; for ( int i = 0 ; i < num msgs ; i + + ) { string message = my - message - + i ; futures . add ( producer . send async ( message . get bytes ( ) ) ) ; }
val = profile . get db introduction ( ) . get rate ( 24 * 60 * 60 * 1000l ) . get current event count ( ) ; val + = 2 * 4 * profile . get db introduction ( ) . get rate ( 6 * 60 * 60 * 1000l ) . get last event count ( ) ; val + = 3 * 4 * profile . get db introduction ( ) . get rate ( 6 * 60 * 60 * 1000l ) . get current event count ( ) ; val + = 4 * 24 * profile . get db introduction ( ) . get rate ( 60 * 60 * 1000l ) . get current event count ( ) ; val = 10 ; }
assert jq ( endpoint + happy , happy = = [ ' cheerful ' , ' glad ' , ' joyful ' ] ) ;
if ( f markup depth < f entity stack [ f entity depth - 1 ] ) { report fatal error ( element entity mismatch , new object [ ] { f current element . rawname } ) ; }
if ( failure detector = null ) failure detector . destroy ( ) ;
mark up ( server , cluster , uri2 , 1 . 5d ) ; properties = store . get ( cluster ) ; assert equals ( properties . get partition data map ( uri1 ) . get ( default partition accessor . default _ partition _ id ) . get weight ( ) , 2d ) ; assert equals ( properties . get partition data map ( uri2 ) . get ( default partition accessor . default _ partition _ id ) . get weight ( ) , 1 . 5d ) ; assert equals ( properties . uris ( ) . size ( ) , 2 ) ;
create sub dir and system property ( hadoop . tmp . dir , test path , hadoop - tmp - dir ) ;
_ verify value write ( start an array ) ; _ write context = _ write context . create child array context ( ) ; if ( _ cfg pretty printer = null ) { _ cfg pretty printer . write start array ( this ) ; } else { _ write start array ( ) ; } }
file utils . copy file ( get file ( solr collection1 conf solrconfig - withgethandler . xml ) , new file ( new file ( config sets dir , configset - 2 conf ) , solrconfig . xml ) ) ; container . reload ( core1 ) ; core = container . get core ( core1 ) ;
if ( big table candidates . contains ( pos ) ) { continue ; } operator < ? > start op = join op . get parent operators ( ) . get ( pos ) ;
previous token encoded = false ; decoded text . append ( word ) ; } }
try { factory . get serialiser ( clazz ) ; fail ( exception expected ) ; } catch ( final illegal argument exception e ) { assert not null ( e . get message ( ) ) ; }
set amount ( 100 . 0f ) ;
if ( valid zone ( zone id ) ) { throw new invalid parameter value exception ( a zone with id : + zone id + does not exist . ) ; } check if zone is deletable ( zone id ) ;
pages tree . select ( pages tree . get item ( 0 ) ) ;
sentence one padded left = new byte [ 100 ] ; start = add pads ( sentence one padded left , 0 , 3 ) ; sentence one padded left len = add multi byte char sentence one ( sentence one padded left , start ) ; assert . assert true ( string expr . character count ( sentence one padded left , 0 , sentence one padded left len ) = = 3 + 10 ) ; string expr . right trim and truncate ( out v , i , sentence one padded left , 0 , sentence one padded left len , 3 + 10 ) ; expected result len = sentence one padded left len ; assert . assert true ( vector equal ( out v , i , sentence one padded left , 0 , expected result len ) ) ; i + + ;
nested filter . set expected type ( long array block . class ) ; test filter ( filter , ineffective block , true ) ;
log inspected ( element . get context ( ) ) ;
log . debug ( % s , command ) ; listening process executor . launched process process = executor . launch process ( params , listener ) ; int result = executor . wait for process ( process ) ; if ( result = 0 ) { log . error ( error running % s : % s , get description ( context ) , listener . get stderr ( ) ) ; return step execution result . of ( result ) ; }
handler . set end ( il . append ( new aload ( handler . get index ( ) ) ) ) ; index = cpg . add methodref ( string _ value _ handler , get value , ( ) + string _ sig ) ; il . append ( new invokevirtual ( index ) ) ; }
jar urlconnection jar conn = ( jar urlconnection ) url . open connection ( ) ;
assert that ( with min sq version ( 6 . 3 . 0 . 5000 ) . is compatible with ( 6 . 3 . 0 . 4000 ) ) . is false ( ) ;
result quality = doc . get elements by tag name ( om : result quality ) . item ( 3 ) ; geologic unit = result quality . get first child ( ) ; assert equals ( gu . 25682 , geologic unit . get attributes ( ) . get named item ( gml : id ) . get node value ( ) ) ;
sort builder = new script sort builder ( mock script ( mock _ script _ name ) , script sort type . number ) . set nested filter ( query builders . match all query ( ) ) ;
result types [ current + + ] = doub ; result types [ current + + ] = doub ; result types [ current + + ] = ;
block in stream is2 = null ;
value = period + value ;
return rest request . get base url ( ) ;
if ( managed ct class . is interface ( ) ) { log . debugf ( skipping enhancement of [ % s ] : it ' s an interface , managed ct class . get name ( ) ) ; return false ; }
this . add remove method interceptor ( view ) ;
vector < string > list of item names = zibase binding . get binding provider ( ) . get item names by id ( id ) ; if ( list of item names = = null ) { return ; } logger . debug ( trying to publish events for + id ) ;
if ( null = m type param ) { byte [ ] content type = part . get content type ( ) ; if ( null = content type ) { if ( true = = arrays . equals ( m type param , content type ) ) { return the _ first _ part ; } } } return the _ last _ part ;
append text child ( m _ char _ current _ start , len - m _ char _ current _ start ) ;
check alter table succeed ( alter table bar drop column num2 ; ) ; assert false ( does column exist ( bar , num2 ) ) ;
logger . error ( context + couldn ' t find free ports to listen on . ) ; return ;
final count down latch settings latch = new count down latch ( 2 ) ; session session = new client ( new session . listener . adapter ( ) { @ override public void on settings ( session session , settings frame frame ) { settings latch . count down ( ) ; } } ) ; meta data . request request = new request ( post , new http fields ( ) ) ;
tabular data value = ( tabular data ) obj ; tabular type value type = value . get tabular type ( ) ; return is assignable from ( value type ) ; }
if ( resource instanceof ifile & & resource . is synchronized ( iresource . depth _ zero ) ) { content utils . sync file ( new void progress monitor ( ) , resource ) ; }
dout . write ( buffer , 0 , buf pos ) ; buf pos = 0 ; reset buffer }
do prune = false ;
mount point fs status map = view file system util . get status ( file system , new path ( internal dir internal dir2 ) ) ; assert . assert equals ( get expected mount points ( ) , mount point fs status map . size ( ) ) ;
case a . remove ( collision _ 2 ) ;
string out = template . request body ( http : localhost : { { port } } myapp products 1234 , null , string . class ) ; assert equals ( http : localhost : + get port2 ( ) + myapp2 products index . jsp?product _ id = 1234 , out ) ; out = template . request body ( http : localhost : { { port } } myapp products 5678 , null , string . class ) ;
boolean has nulls = false ;
current manifest chunk offset + = current element chunk count ; } else {
return a . hostname ( ) . compare to ( b . hostname ( ) ) ; }
try { realm . delete realm ( config a ) ; fail ( ) ; } catch ( illegal state exception ignored ) { }
volt table explain = client . call procedure ( @ explain , sql ) . get results ( ) [ 0 ] ; assert true ( explain . to string ( ) . contains ( tb + _ pidx _ 2 ) ) ;
compact equals ( sf create ( 7 , 6 , 5 , 4 , 3 , 2 , 1 ) , 5 , 4 , 3 , 2 , 1 ) ; compact equals ( sf create ( 50 , 10 , 10 , 10 , 10 ) , 10 , 10 , 10 , 10 ) ; compact equals ( sf create ( 10 , 10 , 10 , 10 , 50 ) , 10 , 10 , 10 , 10 ) ; compact equals ( sf create ( 251 , 253 , 251 , max size - 1 ) , 251 , 253 , 251 ) ; compact equals ( sf create ( max size - 1 , max size - 1 , max size - 1 ) * empty * ) ;
vector clock fetched clock = test utils . get versioned put clock ( now , 4 , 4 , 5 , 0 ) ;
text = configuration . get property ( groovy . script . base ) ;
dfsclient dfsclient = get dfsclient ( ) ; return dfsclient . get namenode ( ) . get block locations ( filepath . to string ( ) , 0 , size kb * 1024 ) . get located blocks ( ) ; }
this . array = array . clone ( ) ;
assert invalid message ( invalid unset value for tuple field number 0 , select * from % s where k = ? and t = ( ? , ? , ? ) , unset ( ) , unset ( ) , unset ( ) , unset ( ) ) ; }
directory = origin ; archive = new file ( directory . to string ( ) + ext ) ; } else {
if ( gesture listener = null & & gesture listener . on double tap ( event ) ) { return true ; } animate state to ( state controller . toggle min max zoom ( state , event . get x ( ) , event . get y ( ) ) ) ;
event subscription entity signal subscription = new event subscription query ( ) . execution id ( execution waiting for signal . get id ( ) ) . single result ( ) ; assert not null ( signal subscription ) ; assert equals ( signal subscription , subscription ) ;
if ( is popup showing ( ) ) { return super . dispatch key event ( event ) ; }
add injections ( context , descriptor , node , jndi name , type util . from name ( type ) ) ;
assert true ( mbl . exists ( i bundle ) ) ; if ( fel . error list . size ( ) = 0 ) { fel . dump all ( ) ; }
copy key = key . substring ( prefix . length ( ) ) ; } else {
s3 object wrapper adjusted = adjust to desired range ( decrypted , desired range , null ) ; return adjusted . get s3 object ( ) ; }
assert . assert equals ( desc offer , rrs . get nodes ( ) [ 0 ] . get statement ( ) ) ; sql = desc cndb . offer ; rrs = route strategy . route ( new system config ( ) , schema , server parse . describe , sql , null , null , cache pool ) ; assert . assert equals ( false , rrs . is cache able ( ) ) ; assert . assert equals ( - 1 l , rrs . get limit size ( ) ) ; assert . assert equals ( 1 , rrs . get nodes ( ) . length ) ;
if ( input exhausted ) { read more ( ) ; reset matcher ( ) ; } }
q = em . create query ( select p from blog post p where p . liked by = : liked by ) ; q . set parameter ( liked by , 555 ) ; all posts = q . get result list ( ) ; assert . assert not null ( all posts ) ; assert . assert false ( all posts . is empty ( ) ) ; assert . assert equals ( 1 , all posts . size ( ) ) ; assert post2 ( all posts . get ( 0 ) ) ;
string [ ] dirs = new path . split ( file . separator ) ;
for ( index entry update < label schema descriptor > update : update service . convert to index updates ( node updates ) ) { updates . add ( update ) ; } }
assert array equals ( handy buf . put bytes ( some string . get bytes ( ) ) . read bytes ( ) , some string . get bytes ( ) ) ;
m down degrees = get degrees from coords ( event x , event y , force legal , is inner circle ) ; if ( m down degrees = - 1 ) {
list < string > property names = h . get property names ( ) ; list < object > new values = h . get new values ( ) ; list < object > old values = h . get old values ( ) ; before saved ( map , property names , old values , new values ) ; commit proxy ( map ) ; after saved ( map , property names , old values , new values ) ; }
for ( int i = 0 ; i < 100 ; i + + ) { create file ( fs , file + i ) ; }
required radius = m view . get width ( ) > m view . get height ( ) ? m view . get width ( ) : m view . get height ( ) ;
for ( int i = 0 ; i < relation . get len ( ) ; i + + ) { relation . get vertex ( i ) . remove relation ( relation ) ; }
extra info . remove ( channel reader . channel _ key ) ;
if ( fs . delete ( dir lock file , false ) ) { returns false if somebody else already deleted it ( to take ownership ) fsdata output stream ostream = hdfs utils . try create file ( fs , dir lock file ) ; if ( ostream = null ) { ostream . close ( ) ; } return new dir lock ( fs , dir lock file ) ; } return null ;
hregion region = get region ( region name ) ;
set popup position ( p . get x ( ) , p . get y ( ) ) ; return ; }
folder . close ( true ) ; store . close ( ) ; parent . set response code ok ( ) ; parent . set response message ok ( ) ; is ok = true ; } catch ( no class def found error | ioexception ex ) {
strategy . set strategy to call drop ( ) ;
relation _ logger . exiting ( relation service . class . get name ( ) , check role int ) ; return new integer ( 0 ) ; } }
source . get error collector ( ) . add error and continue ( new syntax error message ( new syntax exception ( @ groovy . lang . category must define ' value ' which is the class to apply this category to , annotation . get line number ( ) , annotation . get column number ( ) , annotation . get last line number ( ) , annotation . get last column number ( ) ) , source ) ) ; return null ;
motion event utils . dispatch motion events ( get instrumentation ( ) , motion events . sub list ( motion events . size ( ) 2 , motion events . size ( ) ) ) ; assert that ( m swipe touch listener . is swiping ( ) , is ( false ) ) ;
client socket channel factory channel factory = new nio client socket channel factory ( executor , executor ) ;
final double cpu = 0 . 5 ; final double mem = 1 . 6 ; final double disk = 2 . 7 ; protos . offer . builder builder = protos . offer . new builder ( ) . set id ( protos . offer id . new builder ( ) . set value ( id ) ) . set framework id ( protos . framework id . new builder ( ) . set value ( framework - id ) ) . set hostname ( hostname ) . set slave id ( protos . slave id . new builder ( ) . set value ( slave - id ) ) ; protos . resource cpu = protos . resource . new builder ( ) . set type ( protos . value . type . scalar ) . set name ( task resources . cpus _ resource _ name ) . set scalar ( protos . value . scalar . new builder ( ) . set value ( cpu ) ) . build ( ) ;
response . get output stream ( ) . set write listener ( new response body write listener ( ) ) ;
metadata . add ( topic ) ;
{ \ type \ : \ record \ , \ name \ : \ foo \ , \ fields \ : [ \ n + { \ type \ : \ int \ } \ n + ] } , is required but it is not present } , {
try { long person id = long . parse long ( json . get string ( id ) ) ; person person = new person ( person id , local table blog id ) ; person . set display name ( json . opt string ( label ) ) ; person . set username ( json . opt string ( login ) ) ; person . set avatar url ( json . opt string ( avatar ) ) ; person . set subscribed ( json . opt string ( date _ subscribed ) ) ; person . person type = is email follower ? person type . email _ follower : person type . follower ; return person ; } catch ( number format exception e ) { app log . e ( app log . t . people , the id parsed from the json couldn ' t be converted to long : + e ) ; } return null ;
timeout delay + = async start runnable . thread _ sleep _ time ;
assert . assert null ( whitebox . get internal state ( component tree , m main thread layout state ) ) ; assert . assert null ( whitebox . get internal state ( component tree , m background layout state ) ) ; assert . assert false ( component tree has size spec ( component tree ) ) ;
historic tasks = history service . create historic task instance query ( ) . order by due date nulls first ( ) . desc ( ) . list ( ) ;
set show other dates ( a . get integer ( r . styleable . material calendar view _ mcv _ show other dates , show _ defaults ) ) ; set allow click days outside current month ( a . get boolean ( r . styleable . material calendar view _ mcv _ allow click days outside current month , true ) ) ; } catch ( exception e ) {
out name = new file ( out name ) . get name ( ) ;
if ( this . user bean = null & & this . user bean bytes . length = = 0 ) { return this . user bean ; }
names = mbean server . query names ( on , null ) ;
get http invoker request executor ( ) ;
component name instance id . put ( component name , instances ) ; return new exception request ( component name instance id ) ;
data output buffer compressed data buffer = new data output buffer ( ) ; compression output stream deflate filter = codec . create output stream ( compressed data buffer ) ; data output stream deflate out = new data output stream ( new buffered output stream ( deflate filter ) ) ; deflate out . write ( data . get data ( ) , 0 , data . get length ( ) ) ; deflate out . flush ( ) ; deflate filter . finish ( ) ; log . info ( finished compressing data ) ;
new vals . add element ( att . value ( i ) ) ; } } new vals . add element ( m _ label ) ; new atts . add element ( new attribute ( att . name ( ) , new vals ) ) ; } }
result = db . execute ( string . format ( nodes , \ jyllingevej \ ) ) ; assert false ( result . has next ( ) ) ; }
long xy = put za ( fs ) ; if ( xy = = - 1 ) return this ; int x = ( int ) ( xy > > 32 ) ; int y = ( int ) xy ; for ( int i = x ; i < x + y ; i + + ) put str ( fs [ i ] ) ; return this ;
int desired width = get resized dimension ( m max width , m max height , actual width , actual height , m scale type ) ; int desired height = get resized dimension ( m max height , m max width , actual height , actual width , m scale type ) ;
if ( + + failures > = max _ retries ) { throw new ioexception ( too many failures downloading events , ie ) ; }
case ' l ' :
esc set = new escape set ( result . get reg ( ) , reg count , escape state . none ) ;
final fixed bit set confirmed = clear random bits ( set ) ;
hidden layer . backward ( hidden _ layer _ input , null , logistic _ layer _ input , dy , logistic layer . w , lr ) ;
for ( int i = 0 ; i < total msg ; i + + ) { string message = my - message - + i ; produce msgs . add ( message ) ; producer . send ( message . get bytes ( ) ) ; } log . info ( start receiving messages : ) ;
assert . assert equals ( rmapp state . failed , mem store . get state ( ) . get application state ( ) . get ( app1 . get application id ( ) ) . get state ( ) ) ; mock rm rm2 = new test security mock rm ( conf , mem store ) ; rm2 . start ( ) ;
if ( is joined by table & & is joined by map & & ( m2m annotation . mapped by ( ) = = null | | m2m annotation . mapped by ( ) . is empty ( ) ) ) { throw new invalid entity definition exception ( it ' s manadatory to use @ join table with parent side of many to many relationship . ) ; } return true ; }
updates tracker . notify population completed ( ) ; return updates tracker ;
assert that ( ( buffer . get ( buffer1 . remaining ( ) ) & 0x ff ) > > 4 , equal to ( 0 ) ) ;
@ suppress warnings ( serial ) map < string , object > service group1 = new hash map < string , object > ( ) { { put ( type , full cluster list ) ; put ( cluster list , arrays . as list ( new string [ ] { z services } ) ) ; } } ; service variants . put ( service group1 , service group1 ) ;
if ( suffix string = = null | | p . length ( ) > suffix string . length ( ) ) { suffix string = p ; suffix uri = e . get entry arg ( 1 ) ; }
if ( assignments . contains key ( load balancer . bogus _ server _ name ) ) { assignments . put ( load balancer . bogus _ server _ name , new array list < > ( ) ) ; }
final jsonobject page = ( jsonobject ) request . get attribute ( page . page ) ; if ( null = = page ) { response . send error ( http servlet response . sc _ not _ found ) ; return ; }
thread . sleep ( 1000 ) ; mock endpoint mock = get mock endpoint ( mock : result ) ;
if ( input = = null ) { final error msg msg = new error msg ( error msg . file _ not _ found _ err , doc to load , this ) ; parser . report error ( constants . fatal , msg ) ; return ; } final syntax tree node root ;
if ( get tree table row ( ) . get tree item ( ) . get parent ( ) = null & & get tree table row ( ) . get tree item ( ) . get parent ( ) . get value ( ) . get class ( ) = = recursive tree object . class ) { allow edit = false ; }
if ( get metadata ( ) . is annotated ( configuration . class . get name ( ) ) ) { if ( get metadata ( ) . is final ( ) ) { problem reporter . error ( new final configuration problem ( ) ) ; } } for ( bean method bean method : this . bean methods ) { bean method . validate ( problem reporter ) ; }
if ( i request . content . starts with ( { ) ) {
return get prefix ( element util . get package ( element ) ) + get type sub name ( element ) ; }
final int adjusted scale down = fast scale - 2 * longword _ decimal _ digits ; result0 = fast2 power of ten table [ adjusted scale down ] ;
fsdirectory . check _ reserved _ file _ names = true ; ensure cluster restart fails ( cluster ) ; }
send event ( new remote interpreter event ( remote interpreter event type . resource _ invoke _ method , invoke method . to json ( ) ) ) ;
run ksession ( ksession ) ;
if ( eviction policy . get state ( ) = null ) { ret . put ( eviction _ state _ key , ( serializable ) eviction policy . get state ( ) ) ; }
startup = true ;
list < task tracker action > kill list = new array list < task tracker action > ( ) ; for ( job id kill job id : jobs ) { kill list . add ( new kill job action ( kill job id ) ) ; log . debug ( task tracker + - > kill job action : + kill job id ) ; } return kill list ;
intent . set data and type ( uri . from file ( file ) , audio * ) ;
request . add header ( authorization , google login auth = + token ) ;
button ok button = ( button ) find view by id ( r . id . ok ) ;
final progress indicator indicator = get sync progress ( ) ; server _ . apply forward concordance ( pdf file , source location , new server request callback < source location > ( ) { @ override public void on response received ( source location source location ) { indicator . on completed ( ) ; if ( source location = null ) { desktop . get frame ( ) . external synctex view ( pdf file , source location . get file ( ) , source location . get line ( ) , source location . get column ( ) ) ; } } @ override public void on error ( server error error ) { indicator . on error ( error . get user message ( ) ) ; } } ) ; return true ;
in message . set header ( cxf constants . operation _ name , get customer ) ;
student mongo string student min = new student mongo string ( ) ;
soapmessage reply = dispatch . invoke ( request ) ;
call record r = reader . read value ( json ) ; assert null ( r . item ) ; assert not null ( r . item2 ) ; json = apos to quotes ( { ' item ' : { ' type ' : ' xevent ' , ' location ' : ' location1 ' } , ' version ' : 0 . 0 , ' application ' : ' 123 ' } ) ;
property values holder pvh left = property values holder . of int ( left , 0 , 1 ) ; property values holder pvh top = property values holder . of int ( top , 0 , 1 ) ; property values holder pvh right = property values holder . of int ( right , 0 , 1 ) ; property values holder pvh bottom = property values holder . of int ( bottom , 0 , 1 ) ; property values holder pvh scroll x = property values holder . of int ( scroll x , 0 , 1 ) ; property values holder pvh scroll y = property values holder . of int ( scroll y , 0 , 1 ) ; default change in = object animator . of property values holder ( ( object ) null , pvh left , pvh top , pvh right , pvh bottom , pvh scroll x , pvh scroll y ) ; default change in . set duration ( default _ duration ) ; default change in . set start delay ( m changing appearing delay ) ; default change in . set interpolator ( m changing appearing interpolator ) ; default change out = default change in . clone ( ) ; default change out . set start delay ( m changing disappearing delay ) ; default change out . set interpolator ( m changing disappearing interpolator ) ; default fade in = object animator . of float ( null , alpha , 0f , 1f ) ;
if ( is platform ( aix ) ) { return ; } mbean server mbean server = get mbean server ( ) ; object name on = object name . get instance ( org . apache . camel : context = 20 - camel - 1 , type = context , name = \ camel - 1 \ ) ;
_ name = parser . get qname ignore default ns ( name ) ; get symbol table ( ) . add key ( _ name , this ) ; _ match = parser . parse pattern ( this , match , null ) ; _ use = parser . parse expression ( this , use , null ) ;
assert equals ( 0 , merge buffer pool . get min remain buffer num ( ) ) ; assert equals ( 3 , merge buffer pool . get pool size ( ) ) ; }
try { while ( itr . next ( ) ) { } assert . assert true ( false ) ; } catch ( ioexception ie ) { log . info ( crc corruption , ie ) ; }
final hll sparse hll = new hll ( hlltype . sparse ) ; final int register index = math . abs ( random . next int ( ) ) % register _ count ; final int register value = ( ( math . abs ( random . next int ( ) ) % register _ max _ value ) + 1 ) ; final long raw value = construct hllvalue ( log2 m , register index , register value ) ; sparse hll . add raw ( raw value ) ; cumulative union line ( output , hll , sparse hll , schema version ) ;
admin . set quota ( quota settings factory . unthrottle user ( user name ) ) ; trigger user cache refresh ( true , table _ names ) ; assert equals ( 60 , do puts ( 60 , tables ) ) ; assert equals ( 60 , do gets ( 60 , tables ) ) ; }
valid http method array = valid http method array . sub list ( 0 , random int between ( 1 , valid http method array . size ( ) - 1 ) ) ; assert ( valid http method array . size ( ) > 0 ) ; assert ( valid http method array . size ( ) < rest request . method . values ( ) . length ) ;
variable instances = task service . get variable instances local ( task . get id ( ) , variable names ) ; assert equals ( 1 , variable instances . size ( ) ) ; assert equals ( string var , variable instances . get ( string var ) . get name ( ) ) ; assert equals ( pepsi - cola , variable instances . get ( string var ) . get value ( ) ) ;
list = new array list < > ( ) ; list < object > inner list = new array list < > ( ) ; inner list . add ( blah ) ; list . add ( inner list ) ; json array = new json array ( list ) ; arr = ( json array ) json array . get value ( 0 ) ; assert equals ( blah , arr . get string ( 0 ) ) ; }
final text cq = new text ( ) ; for ( entry < key , value > entry : scanner ) { entry . get key ( ) . get column qualifier ( cq ) ; value v = entry . get value ( ) ; byte [ ] buf = v . get ( ) ; result . put ( cq . to string ( ) , new byte array byte iterator ( buf ) ) ; } } catch ( exception e ) {
table export . paths export paths = new table export . paths ( work . get ast representation for error msg ( ) , work . get export root dir ( ) , conf , false ) ;
trash . set delete interval ( 60 l * trash policy default . msecs _ per _ minute ) ;
f target node = null ;
if ( path . index of ( % 20 ) > - 1 ) { path = path . to string ( ) . replace ( target , replacement ) ; } return path ; }
bind property ( eureka _ test _ namespace + should fetch registry , boolean . to string ( registry fetch enabled ) ) ; bind property ( eureka _ test _ namespace + client . refresh . interval , integer . to string ( 1 ) ) ;
set expand events ( false ) ; don ' t process shell and
dfs cluster . restart name node ( standby nnindex , true , - rolling upgrade , started ) ; assert . assert equals ( info , dfs active . rolling upgrade ( hdfs constants . rolling upgrade action . query ) ) ; dfs cluster . wait active ( ) ;
( ( imap < ? , ? > ) this . delay no . get native cache ( ) ) . add interceptor ( new delay imap get interceptor ( 250 ) ) ; }
assert that ( entity . field , is ( 80 ) ) ; assert that ( entity . accessor transient , is ( propertyproperty ) ) ; assert that ( entity . get property ( ) , is ( property ) ) ;
int div = ( integer ) rval ; int result = ( ( integer ) lval ) . int value ( ) % math . abs ( div ) ; if ( result > 0 & & div < 0 ) { result + = div ; make the result negative } else if ( result < 0 & & div > 0 ) { result + = div ; make the result positive } return result ;
assert true ( wildcard . match path ( cfg options . class , c????ti * c?ass ) ) ;
return get table layouts ( session , layout . get table ( ) , constraint . always true ( ) , optional . empty ( ) ) . get ( 0 ) . get table layout ( ) ; }
set < orid > edge rids = new hash set < orid > ( ) ;
assert false ( command2 . executed ) ; assert true ( command1 . get execution time in milliseconds ( ) > - 1 ) ; assert false ( command1 . is response from cache ( ) ) ; assert true ( command2 . is response from cache ( ) ) ; assert command execution events ( command1 , hystrix event type . success ) ; assert command execution events ( command2 , hystrix event type . success , hystrix event type . response _ from _ cache ) ; assert equals ( 0 , circuit breaker . metrics . get current concurrent execution count ( ) ) ; assert sane hystrix request log ( 2 ) ; }
fruit f = flist . get ( 0 ) ;
if ( _ sig type = = null ) throw new ioexception ( unknown sig type : + sig type code ) ; _ signer length = ( int ) data helper . read long ( in , 2 ) ; if ( _ signer length = _ sig type . get sig len ( ) ) throw new ioexception ( bad sig length ) ; skip ( in , 1 ) ; int _ version length = in . read ( ) ; if ( _ version length < min _ version _ bytes ) throw new ioexception ( bad version length ) ; skip ( in , 1 ) ; int signer len = in . read ( ) ; if ( signer len < = 0 ) throw new ioexception ( bad signer length ) ; _ content length = data helper . read long ( in , 8 ) ; if ( _ content length < = 0 ) throw new ioexception ( bad content length ) ; skip ( in , 1 ) ; foo = in . read ( ) ; if ( foo = type _ zip ) throw new ioexception ( bad type ) ; skip ( in , 1 ) ; int c type = in . read ( ) ; _ content type = by _ code . get ( integer . value of ( c type ) ) ; if ( _ content type = = null ) throw new ioexception ( unknown content type + c type ) ; skip ( in , 12 ) ; byte [ ] data = new byte [ _ version length ] ;
list < object > possibly shapes = effective shape tree . get sp or grp sp or graphic frame ( ) ; for ( object o : possibly shapes ) { if ( o instanceof shape ) { shape sp = ( shape ) o ; if ( sp . get nv sp pr ( ) = null & & sp . get nv sp pr ( ) . get nv pr ( ) = null & & sp . get nv sp pr ( ) . get nv pr ( ) . get ph ( ) = null ) { ctplaceholder placeholder = sp . get nv sp pr ( ) . get nv pr ( ) . get ph ( ) ; string placeholder type = placeholder . get type ( ) . to string ( ) ; log . info ( handling placeholder : + placeholder type ) ; handle ( placeholders , placeholder type , sp ) ; } } } return effective shape tree ;
super . start scroll ( start x , start y , dx , dy , ( int ) ( m duration * m scroll factor ) ) ; }
state version tracker . set version retrieved from zoo keeper ( database . get latest system state version ( ) ) ;
if ( print totals ) { result . append ( string utils . pad ( total , cell size ) ) ; for ( double col total : col totals ) { result . append ( string utils . pad left ( nf . format ( col total ) , cell size ) ) ; } result . append ( string utils . pad left ( nf . format ( total ) , cell size ) ) ; } return result . to string ( ) ; }
result + = get store ( ) . get size ( ) ; } catch ( ioexception ioe ) {
given ( ) . body ( a body ) . expect ( ) . body ( is empty or null string ( ) ) . when ( ) . head ( return content type as body ) ;
int key hash = key value helper . get hash from key ( ) ; int partition id = key hash & ( hash partitions . length - 1 ) ; hash partition hash partition = hash partitions [ partition id ] ; if ( bloom1 = null ) { bloom1 . add long ( key hash ) ; } if ( is on disk ( partition id ) | | is hash map spilled on creation ( partition id ) ) { destination on disk put to sidefile = true ;
buf . append ( ' \ ' ' ) ; boolean in literal = false ; for ( ; i < length ; i + + ) { c = pattern . char at ( i ) ; if ( c = = ' \ ' ' ) { if ( i + 1 < length & & pattern . char at ( i + 1 ) = = ' \ ' ' ) {
final configuration conf = new configuration ( ) ; final file system fs = testdir . get file system ( conf ) ; if ( fs . exists ( testdir ) ) { fs . delete ( testdir , true ) ; }
assert true ( assembler . is not ignored ( method , some other bean key ) ) ; }
original predicate = or ( and ( equal ( c _ bigint , bigint literal ( 1 l ) ) , unprocessable expression1 ( c _ bigint ) ) , and ( equal ( c _ double , double literal ( 2 . 0 ) ) , unprocessable expression1 ( c _ bigint ) ) ) ; result = from predicate ( original predicate ) ; assert equals ( result . get remaining expression ( ) , original predicate ) ; assert true ( result . get tuple domain ( ) . is all ( ) ) ;
final stateful session component instance stateful component instance = ( stateful session component instance ) context . get private data ( component instance . class ) ;
assert equals ( 1 , notebook repo sync . list ( 0 , null ) . size ( ) ) ;
navigation . navigate to ( main view . class , this . get class ( ) , offer book view . class ) ; }
final int get key index = cpg . add methodref ( translet _ class , get key index , ( ljava lang string ; ) + key _ index _ sig ) ;
if ( check meta region ( ) ) { string error msg = hbase : meta table is not consistent . ; if ( should fix assignments ( ) ) { error msg + = hbck will try fixing it . rerun once hbase : meta is back to consistent state . ; } else { error msg + = run hbck with proper fix options to fix hbase : meta inconsistency . ; } errors . report error ( error msg + exiting . . . ) ; return - 2 ; }
accumulate function ( accumulate , false , null ) ; if ( state . failed ) return ;
throw new arithmetic exception ( rounding necessary ) ;
set location by platform ( location by platform prop ) ; }
assert that ( shadow of ( handler . get looper ( ) ) . get scheduler ( ) . get current time ( ) ) . as ( current time ) . is equal to ( 100 ) ;
project explorer . select item ( project _ name ) ;
stop ( ) ; return ;
parse plugins mock plugins = mock ( parse plugins . class ) ; when ( mock plugins . rest client ( ) ) . then return ( null ) ; parse plugins . set ( mock plugins ) ;
string warning = get string ( warning . 18 , introspected table . get fully qualified table ( ) . to string ( ) ) ; non - nls - 1
assert unsafe move visibility ( line _ joiner . join ( var a ; , function f ( ) { , var l ; , do { , src : a + + ; , env : 3 ; , } while ( l ) , dest : 3 ; , } ) ) ;
rack ring info info = policy . racks map . get ( network topology . default _ rack ) ; assert null ( info ) ; hash map < node , node > empty map = new hash map < node , node > ( ) ; list < datanode descriptor > results = new array list < datanode descriptor > ( ) ; for ( int i = 0 ; i < data nodes . length ; i + + ) { policy . choose target ( 3 , data nodes [ i ] , empty map , 512 , 4 , results , true ) ; } }
if ( meta . get row type ( ) = sparse _ int ) { throw new ioexception ( model row type is not sparse int , you should check it ) ; }
int c = compare timestamp bytes ( b1 , b2 ) ;
if ( is share unit of work ( ) ) { prepare shared unit of work ( copy , exchange ) ; }
if ( verbose ) { system . out . println ( test lazy cores . test mid use unload maximum sleep millis = + maximum sleep millis ) ; } class test thread extends thread { solr core core _ to _ use = null ; @ override public void run ( ) { final int sleep _ millis = random ( ) . next int ( maximum sleep millis ) ; try { if ( sleep _ millis > 0 ) { if ( verbose ) { system . out . println ( test lazy cores . test mid use unload thread . run sleeping for + sleep _ millis + ms ) ; } thread . sleep ( sleep _ millis ) ; } } catch ( interrupted exception ie ) { if ( verbose ) { system . out . println ( test lazy cores . test mid use unload thread . run caught + ie + whilst sleeping for + sleep _ millis + ms ) ; } } assert false ( core _ to _ use . is closed ( ) ) ; not closed since we are still using it and hold a reference core _ to _ use . close ( ) ; now give up our reference to the core } } ;
for ( class node iface : get interfaces ( ) ) { map < string , method node > iface methods map = iface . get declared methods map ( ) ; for ( string meth sig : iface methods map . key set ( ) ) { if ( result . contains key ( meth sig ) ) { method node meth node = iface methods map . get ( meth sig ) ; result . put ( meth sig , meth node ) ; } } }
simple . set pay ( null ) ;
basic file attributes attrs ;
list < dish > dishes limit3 = menu . stream ( ) . filter ( d - > d . get calories ( ) > 300 ) . limit ( 3 ) . collect ( to list ( ) ) ; dishes limit3 . for each ( system . out : : println ) ;
preemption policy . handle failed container ( attempt id ) ; context . get event handler ( ) . handle ( new task attempt event ( attempt id , task attempt event type . ta _ failmsg ) ) ;
dbus event buffer relay buffer = new dbus event buffer ( _ buf cfg ) ; relay buffer . start ( 0 ) ; write events to buffer ( relay buffer , event infos , 4 ) ;
list < string > exactly100 = lists . new array list with capacity ( 100 ) ; using guava
test emulation boundary ( 0 . 80 f , fake core , fake progress , heap plugin , ( target heap usage in mb * 4 ) 5 , 2 , [ op , 80 % progress ] ) ;
return new remote process factory configuration ( remote process stub cycle sleep time , config kv ps ) ;
write file ( fs , file2 , file _ len ) ;
assert equals ( taxonomy reader . invalid _ ordinal , tr . get ordinal ( new facet label ( non - existant ) ) ) ; assert equals ( taxonomy reader . invalid _ ordinal , tr . get ordinal ( new facet label ( author , jules verne ) ) ) ; tr . close ( ) ;
runtime . get runtime ( ) . add shutdown hook ( new thread ( ) { @ override public void run ( ) { reset ( ) ; } } ) ;
assert true ( wait . at most ( new condition ( ) { @ override public boolean is true ( ) throws throwable { return m app widget manager . get app widget info ( m widget id ) = = null ; } } , default _ activity _ timeout ) ) ; }
final int number _ of _ http _ methods = 7 ;
saxparser factory sf = saxparser factory . new instance ( ) ; sf . set namespace aware ( true ) ; sf . set validating ( true ) ; saxparser parser = sf . new saxparser ( ) ; parser . set property ( http : java . sun . com xml jaxp properties schema language , http : www . w3 . org 2001 xmlschema ) ;
properties = new hash map < > ( ) ; properties . put ( http client factory . http _ protocol _ version , protocol version ) ; properties . put ( http client factory . http _ request _ timeout , string . value of ( 100 ) ) ; property not of the channel pool manager clients . add ( new transport client adapter ( client factory . get client ( properties ) , rest over stream ) ) ; } ,
check full file ( file , new length , contents ) ; fs . delete ( parent , true ) ;
modifiable solr params params = new modifiable solr params ( ) ; params . set ( action , collection action . delete . to string ( ) ) ; params . set ( name , collection1 ) ; query request request = new query request ( params ) ; request . set path ( admin collections ) ; cloud client . request ( request ) ;
create user params params = new create user params ( ) ; params . set space amount ( 1073741824 ) ; 1 gb user = box user . create app user ( get connection ( ) , camel _ test _ collaborator _ name , params ) . get resource ( ) ; final map < string , object > headers = new hash map < string , object > ( ) ;
if ( integer . value of ( to [ 0 ] ) < 0 ) { _ p = math . max ( 0 , max ) ; _ map = new int [ ( _ p * positive array of values * ) + ( - 1 * min * negative array of values * ) + 1 * one more to store max value * ] ; for ( int i = 0 ; i < to . length ; + + i ) { int v = integer . value of ( to [ i ] ) ; if ( v < 0 ) v = - 1 * v + _ p ; _ map [ v ] = i ; } return ; } _ map = new int [ max + 1 ] ;
if ( real outcomes . length ( ) = guesses . length ( ) ) throw new illegal argument exception ( unable to evaluate . outcome matrices not same length ) ;
for ( string bad pool name : bad pool names ) { job . conf . set ( pool manager . explicit _ pool _ property , bad pool name ) ; mgr . add job ( job ) ; assert false ( pool manager accepted bad pool name , bad pool name . equals ( mgr . get pool name ( job ) ) ) ; }
painter . add mouse motion listener ( gutter cursor mouse adapter ) ; add ( center , painter ) ;
succeeded ( ) ; return action . scheduled ; }
cur vol . put long ( 8 , wal _ seal ) ;
final row selection selection = query parameters . get row selection ( ) ; final integer first row ; final integer max rows ; if ( selection = null ) { first row = selection . get first row ( ) ; max rows = selection . get max rows ( ) ; } else { first row = null ; max rows = null ; } return new query key ( query string , types , values , named parameters , first row , max rows , filter keys , session . get tenant identifier ( ) , custom transformer ) ;
timing values tv = new timing values ( ) ;
final job job2 = job . new builder ( ) . set name ( test tag + memcached ) . set version ( v2 ) . set image ( memcached ) . set ports ( immutable map . of ( tcp , port mapping . of ( 11211 , external port ) ) ) . build ( ) ;
limit = default _ limit ;
cleanup ( ) ;
for ( int i = 0 ; i < size ; i + + ) { @ suppress warnings ( unchecked ) k key = ( k ) s . read object ( ) ; @ suppress warnings ( unchecked ) v value = ( v ) s . read object ( ) ; put for create ( key , value ) ; }
message first message = new message ( source list , inner message , new exception ( inner message ) ) ;
try { for ( execution job vertex ejv : vertices in creation order ) { ejv . get job vertex ( ) . finalize on master ( get user class loader ( ) ) ; } } catch ( throwable t ) { exception utils . rethrow if fatal error ( t ) ; fail global ( new exception ( failed to finalize execution on master , t ) ) ; return ; }
access test action global read write = new access test action ( ) { @ override public void run ( ) throws exception { check global perms ( test _ util , permission . action . read , permission . action . write ) ; return null ; } } ; verify global ( global read write ) ;
correlation node proc ctx corr ctx = new correlation node proc ctx ( p ctx ) ; map < rule , node processor > op rules = new linked hash map < rule , node processor > ( ) ; op rules . put ( new rule reg exp ( r1 , reduce sink operator . get operator name ( ) + % ) , new correlation node proc ( ) ) ; dispatcher disp = new default rule dispatcher ( get default proc ( ) , op rules , corr ctx ) ;
if ( authority = null & & authority . length ( ) > 0 ) path = ;
list < abstract expression > exprs for inner node = new array list < > ( exprs ) ; if ( left node . get join expression ( ) = null ) { exprs for inner node . add ( left node . get join expression ( ) ) ; } if ( right node . get join expression ( ) = null ) { exprs for inner node . add ( right node . get join expression ( ) ) ; } list < abstract expression > left node exprs ;
return ( int ) ( max _ scroll _ factor * ( get bottom ( ) - get top ( ) ) ) ; }
assert involvement ( user1 , instance id ) ;
keys = get entries ( prefixed bdb store . entries ( p ) ) ; assert equals ( partition to keys map . get ( p ) . size ( ) , keys . size ( ) ) ; assert equals ( partition to keys map . get ( p ) , keys ) ; }
byte [ ] content = codecs . utf8 encode ( hi i ' m the data ) ; rsa signer signer = new rsa signer ( rsa test key data . ssh _ private _ key _ string ) ;
assert equals ( slept for + sleeper , context . get status ( ) ) ;
registered = true ;
for ( range < token > range : ranges with sources . key set ( ) ) { if ( trivial ranges . contains ( range ) ) { logger . debug ( not optimising trivial range { } for keyspace { } , range , keyspace ) ; continue ; } final range vertex range vertex = new range vertex ( range ) ; try to only add source endpoints from same dc boolean source found = add endpoints ( capacity graph , range vertex , true ) ; if ( source found ) { logger . info ( using other dc endpoints for streaming for range : { } and keyspace { } , range , keyspace ) ; source found = add endpoints ( capacity graph , range vertex , false ) ; } if ( source found ) throw new illegal state exception ( unable to find sufficient sources for streaming range + range + in keyspace + keyspace ) ; } return capacity graph ;
dfs client conf config = new dfs client conf ( conf ) ; t proxy = ( t ) retry proxy . create ( xface , failover proxy provider , retry policies . failover on network exception ( retry policies . try _ once _ then _ fail , config . get max failover attempts ( ) , config . get max retry attempts ( ) , config . get failover sleep base millis ( ) , config . get failover sleep max millis ( ) ) ) ; text dt service ;
long proc id2 = proc exec . submit procedure ( new create namespace procedure ( proc exec . get environment ( ) , nsd ) ) ;
string p1 = p1 ; string p2 = p2 ; string p3 = p3 ; git material g1 = new git material ( g1 ) ; git material g2 = new git material ( g2 ) ; build cause p1build cause = create build cause ( new array list < > ( ) , as list ( g1 ) ) ; build cause p3build cause = create build cause ( as list ( p1 ) , as list ( g2 ) ) ;
if ( id % 2 = = 0 ) { sub stores . put ( id , new in memory storage engine < byte array , byte [ ] , byte [ ] > ( test ) ) ; } else { sub stores . put ( id , new failing reads store < byte array , byte [ ] , byte [ ] > ( test ) ) ; }
return folder name + file . separator + cache _ folder _ name ; }
if ( node labels . contains ( rmnode labels manager . no _ label ) ) { node labels . add ( rmnode labels manager . no _ label ) ; } return node labels ; }
int child width size = get measured width ( ) - get padding left ( ) - get padding right ( ) ; int child height size = measured height - get padding top ( ) - get padding bottom ( ) ;
namespace info name space a = new namespace info impl ( ) ; name space a . set prefix ( workspace - a ) ; name space a . set uri ( http : goserver . org test ) ;
wrapper = orbutil system exception . get ( corbalog domains . orb _ lifecycle ) ;
map < string , string > map = create indexed data ( ) ; map < string , object > headers = new hash map < string , object > ( ) ; headers . put ( elasticsearch constants . param _ operation , elasticsearch constants . operation _ index ) ; headers . put ( elasticsearch constants . param _ index _ name , twitter ) ; headers . put ( elasticsearch constants . param _ index _ type , tweet ) ; string index id = template . request body and headers ( direct : start , map , headers , string . class ) ;
final iterator defaults = config . find property keys ( ) ; while ( defaults . has next ( ) ) { final string key = ( string ) defaults . next ( ) ; names . add ( key ) ; } collections . sort ( names ) ;
terrain = terrain generator . create square terrain from bitmap ( terrain params , true ) ;
class specification class specification = new class specification ( null , required class access flags ( true , access , type ) , required class access flags ( false , access , type ) , annotation = null ? class util . internal type ( annotation ) : null , name = null ? class util . internal class name ( name ) : null , extends annotation = null ? class util . internal type ( extends annotation ) : null , extends _ = null ? class util . internal class name ( extends _ ) : null ) ;
if ( keep alive ) { future . add listener ( channel future listener . close ) ; }
classes . add ( function class ) ;
final path parent = new path ( dir , test ) ;
throw new invalid value ( ) ;
type serializer < object > serializer = type info . create serializer ( conf ) ; assert true ( serializer instanceof kryo serializer ) ;
long transaction id = 1 ;
consumer . run ( ) ; consumer . run ( ) ; consumer . run ( ) ; consumer . run ( ) ; assert equals ( 6 , errors ) ; consumer . stop ( ) ; }
byte [ ] buffer = m write buf ;
case 6 :
if ( get connection ( i ) . is connected ( ) ) { xmpptcpconnection con = get connection ( i ) ; con . connect ( ) ; con . login ( get username ( i ) , get username ( i ) ) ; } else if ( get connection ( i ) . is authenticated ( ) ) { get connection ( i ) . login ( get username ( i ) , get username ( i ) ) ; }
this . add to string method interceptor ( view ) ; }
assert equals ( 3 , lines . size ( ) ) ;
try { sub cluster heartbeat request request = sub cluster heartbeat request . new instance ( sub cluster id , last heart beat negative , state lost , capability ) ; federation membership state store input validator . validate ( request ) ; assert . fail ( ) ; } catch ( federation state store invalid input exception e ) { log . info ( e . get message ( ) ) ; assert . assert true ( e . get message ( ) . starts with ( invalid timestamp information . ) ) ; }
return next latitude ( ) ;
preempt orkill selected container after wait ( to preempt , current time ) ;
node = new coperand tree node ( 1 , 7 , burzel , m _ replacement , m _ references , m _ provider , module . get type manager ( ) , module . get content ( ) . get type instance container ( ) ) ; assert equals ( com . google . security . zynamics . zylib . disassembly . expression type . memderef , node . get type ( ) ) ; try { new coperand tree node ( 1 , - 1 , burzel , m _ replacement , m _ references , m _ provider , module . get type manager ( ) , module . get content ( ) . get type instance container ( ) ) ; } catch ( final illegal state exception e ) { }
if ( r _ step _ 5b ( ) ) { break lab22 ; } } while ( false ) ; cursor = limit - v _ 17 ; cursor = limit _ backward ; do , line 137 v _ 18 = cursor ; lab23 : do {
mconf . set ( graph database configuration . cluster _ max _ partitions , num partitions ) ;
throw new illegal argument exception ( the given token + token + does not map to partition + partition ) ;
if ( fs . delete ( dir lock file , false ) ) { returns false if somebody else already deleted it ( to take ownership ) fsdata output stream ostream = hdfs utils . try create file ( fs , dir lock file ) ; if ( ostream = null ) { ostream . close ( ) ; } return new dir lock ( fs , dir lock file ) ; } return null ;
data . write as text ( some file path ) . name ( textsink ) ; { plan p = env . create program plan ( ) ; assert equals ( 1 , p . get data sinks ( ) . size ( ) ) ; generic data sink base < ? > sink = p . get data sinks ( ) . iterator ( ) . next ( ) ; assert equals ( textsink , sink . get name ( ) ) ; assert equals ( source1 , sink . get input ( ) . get name ( ) ) ; }
return authentication info ;
multi user chat muc3 = new multi user chat ( get connection ( 2 ) , room ) ; history = new discussion history ( ) ; history . set max stanzas ( 2 ) ; muc3 . join ( testbot3 , null , history , smack configuration . get packet reply timeout ( ) ) ;
if ( expected type = = null ) { if ( expected type rep id = null ) { return expected type rep id ; } else if ( factory = null ) { return factory . get _ id ( ) ; } else { throw wrapper . expected type null and no rep id ( completion status . completed _ maybe ) ; } }
assert equals ( 1 , payments . size ( ) ) ; } ) ; }
s = new scanner ( 123 456 ) ; assert true ( s . has next short ( 5 ) ) ; assert equals ( 38 , s . next short ( 5 ) ) ; assert false ( s . has next short ( 5 ) ) ; try { s . next short ( 5 ) ; fail ( ) ; } catch ( input mismatch exception expected ) { }
results [ i ] = drop punctuation marks ( results [ i ] ) ;
int size = ( int ) math . min ( len - off , math . min ( blen , data io . round up ( off , blen ) - off ) ) ;
case symbols . token questionmark :
file region = new fadvised file region ( input file , position , count , false , 0 , null , null , 1024 , false ) ;
dfstest util . fs shell run ( - create snapshot sub1 sn . new , conf ) ;
phreak rule terminal node . do left tuple update ( new rtn , executor , agenda , salience int , salience , branch tuples . rtn left tuple ) ;
url = url . replace all ( . ( bundle | git ) , ) ; url = url . replace all ( [ \ u0000 - \ u0020 ] + , ) ; url = url . trim ( ) ; return url ;
fs . remove default acl ( path ) ;
if ( channel . is writable ( ) | | channel . is connected ( ) ) { this . ctx = ctx ; flush ( ctx , false ) ; } }
org . apache . hadoop . security . token . token < timeline delegation token identifier > timeline token = new org . apache . hadoop . security . token . token < timeline delegation token identifier > ( delegation token . get identifier ( ) . array ( ) , delegation token . get password ( ) . array ( ) , new text ( delegation token . get kind ( ) ) , service = = null ? new text ( ) : new text ( service ) ) ;
source = line _ joiner . join ( var dict = { ' func ' : function ( ) { } } ; , function f ( ) { var s = dict [ ' func ' ] . apply ( null ) ; } , f . apply ( null ) ) ;
int length = end pc - start pc ; if ( length > 0 ) { local variable info . u2start pc = start pc ; } local variable info . u2length = length ;
if ( next path = path ) paths . add ( next path ) ; } }
try { session = create session ( req ) ; } catch ( final user manager exception e ) { write response ( resp , login error : + e . get message ( ) ) ; } handle post ( req , resp , session ) ;
final int length = ( _ closure vars = = null ) ? 0 : _ closure vars . size ( ) ; for ( int i = 0 ; i < length ; i + + ) { variable ref base var ref = ( variable ref base ) _ closure vars . get ( i ) ; variable base var = var ref . get variable ( ) ; type var type = var . get type ( ) ; il . append ( dup ) ; find nearest closure implemented as an inner class closure variable closure = _ parent closure ; while ( variable closure = null ) { if ( variable closure . in inner class ( ) ) break ; variable closure = variable closure . get parent closure ( ) ; } use getfield if in an inner class if ( variable closure = null ) { il . append ( aload _ 0 ) ; il . append ( new getfield ( cpg . add fieldref ( variable closure . get inner class name ( ) , var . get escaped name ( ) , var type . to signature ( ) ) ) ) ; } else { use a load of instruction if in translet class il . append ( var . load instruction ( ) ) ; } store variable in new closure il . append ( new putfield ( cpg . add fieldref ( _ class name , var . get escaped name ( ) , var type . to signature ( ) ) ) ) ; }
_ scheduled executor service = executors . new scheduled thread pool ( 30 ) ;
mock http servlet request request = new mock http servlet request ( ) ; request . add parameter ( date , 2009 - 10 - 31 ) ; mock http servlet response response = new mock http servlet response ( ) ; adapter . handle ( request , response , handler method ) ; assert true ( app context . get bean ( test validator . class ) . validator invoked ) ;
prj desc = core model . get default ( ) . get project description ( f project ) ;
assert equals ( 2 , abstract fswalprovider . get num rolled log files ( wal ) ) ;
final string m = model _ info ( ) . to string ( ) ; if ( m . length ( ) > 0 ) log . info ( m ) ;
for ( int i = 0 ; i < 5 ; i + + ) { if ( read raw byte ( ) > = 0 ) { return result ; } }
byte [ ] bytes = cn = ∆ƒ , ou = über frîends , o = awesome dudes , c = us . get bytes ( utf - 8 ) ; string string = new string ( bytes , 0 ) ; assert equals ( string , ( string ) item . get ( 1 ) ) ; } else {
pipeline dao . get pipeline instances triggered with dependency material ( p1 . to upper case ( ) , new pipeline identifier ( p , 1 ) ) ; verify ( mock template , times ( 1 ) ) . query for list ( eq ( pipeline instances triggered out of dependency material ) , any string ( ) ) ;
indexed word pivot = matcher . get node ( pivot ) ;
{ error msg . not _ implemented _ err , \ u672 a \ u5 be6 \ u884 c : ' ' { 0 } ' ' \ u3002 } ,
if ( client path . equals ( ) ) { a bit of a hack , but delete ( ) will never succeed and ensures that the same semantics are maintained server path = client path ; } else { server path = prepend chroot ( client path ) ; } request header h = new request header ( ) ;
random r = new random ( ) ;
return not _ broken ;
return new int [ ] { 2 , 1 } ; }
verify ( listener , never ( ) ) . on added job graph ( any ( job id . class ) ) ;
get view tree observer ( ) . add on global layout listener ( new view tree observer . on global layout listener ( ) { @ override public void on global layout ( ) { if ( build . version . sdk _ int < build . version _ codes . jelly _ bean ) { get view tree observer ( ) . remove global on layout listener ( this ) ; } else { get view tree observer ( ) . remove on global layout listener ( this ) ; } waiter . release ( ) ; } } ) ;
list . sort ( ( o1 , o2 ) - > o2 . get trade ( ) . get date ( ) . compare to ( o1 . get trade ( ) . get date ( ) ) ) ;
new thread ( ) { @ override public void run ( ) { try { thread . sleep ( 100 ) ; } catch ( interrupted exception ignored ) { } iterator . notify of error ( new exception ( test ) ) ; } } . start ( ) ; try { iterator . has next ( ) ; } catch ( exception e ) { assert true ( e . get cause ( ) . get message ( ) . contains ( test ) ) ; }
finally { try { out . close ( ) ; } catch ( exception ex ) { }
if ( s rgb _ present ) { iiometadata node s rgb _ node = new iiometadata node ( s rgb ) ; s rgb _ node . set attribute ( rendering intent , rendering intent names [ s rgb _ rendering intent ] ) ; root . append child ( s rgb _ node ) ; }
if ( input iq . get type ( ) = = iq . type . set & & input iq . get action ( ) = input evt action . notify ) { iq ack = iq . create result iq ( input iq ) ; parent provider . get connection ( ) . send packet ( ack ) ; string call peer id = input iq . get from ( ) ; if ( call peer id = null ) { call peer call peer = get listener call peer ( call peer id ) ; if ( call peer = null ) { if ( input iq . get action ( ) = = input evt action . start ) { fire remote control granted ( call peer ) ; } else if ( input iq . get action ( ) = = input evt action . stop ) { fire remote control revoked ( call peer ) ; } } } }
logger . debug ( remove binding provider : { } , arrays . to string ( provider . get item names ( ) . to array ( ) ) ) ;
if ( ftp . follow talk ) ftp . client . add protocol command listener ( new print command listener ( ftp . log ) ) ;
assert . assert not null ( replication clients1 . get ( r2 ) ) ;
case if : fallback only insn ( insn ) ; if node if insn = ( if node ) insn ; code . add ( if ( ) ; add arg ( code , insn . get arg ( 0 ) ) ; code . add ( ' ' ) ; code . add ( if insn . get op ( ) . get symbol ( ) ) . add ( ' ' ) ; add arg ( code , insn . get arg ( 1 ) ) ; code . add ( ) goto ) . add ( method gen . get label name ( if insn . get target ( ) ) ) ; break ; case goto :
try { final boolean is result set = jdbc statement . get more results ( ) ; current return state = build current return state ( is result set ) ; } catch ( sqlexception e ) { throw convert ( e , error calling callable statement . get more results ) ; } }
searcher . explain ( q , 0 ) ; writer . close ( ) ; reader . close ( ) ; index store . close ( ) ; }
if ( job . get status ( ) . get run state ( ) = job status . running ) { continue ; }
set < big integer > arr = bl . serial blacklist ;
event helper . notify service stop failure ( this , service , e ) ;
tiff header . byte order = stream processor . read packed int ( is , 4 , false ) ; length - = 4 ; if ( tiff header . byte order = tiff _ byte _ order _ little _ end & & tiff header . byte order = tiff _ byte _ order _ big _ end ) { flog . e ( tag , invalid tiff header ) ; return 0 ; } tiff header . is little endian = ( tiff header . byte order = = tiff _ byte _ order _ little _ end ) ;
else { array list < html parse filter > filters = new array list < html parse filter > ( ) ; for ( int i = 0 ; i < ordered filters . length ; i + + ) { html parse filter filter = filter map . get ( ordered filters [ i ] ) ; if ( filter = null ) { filters . add ( filter ) ; } } object cache . set object ( html parse filter . class . get name ( ) , filters . to array ( new html parse filter [ filters . size ( ) ] ) ) ; }
else if ( jump modification = = ifne _ mod ) { final frame [ ] frames = ( frame [ ] ) access field ( analyzer . class , frames ) . get ( this ) ; final field index field = access field ( abstract insn node . class , index ) ; final insn list insns = ( insn list ) access field ( analyzer . class , insns ) . get ( this ) ; final abstract insn node goto insnn = insns . get ( successor - 1 ) ;
if ( context . get configuration ( ) . get boolean ( successful _ job _ output _ dir _ marker , true ) ) { path marker path = new path ( output path , succeeded _ file _ name ) ;
testing client . testing ( ) . export import ( ) . set provider ( single file export provider factory . provider _ id ) ; url url = export import test . class . get resource ( model testrealm . json ) ; string target file path = new file ( url . get file ( ) ) . get absolute path ( ) ; testing client . testing ( ) . export import ( ) . set file ( target file path ) ; testing client . testing ( ) . export import ( ) . set action ( export import config . action _ import ) ; testing client . testing ( ) . export import ( ) . run import ( ) ; realm resource test realm realm = admin client . realm ( test - realm ) ;
if ( m did capture ) return animation _ percentage _ zero ; return m animation percentage ;
for ( int i : seq ( window manager . expire _ events _ threshold + 1 , window manager . expire _ events _ threshold + 100 ) ) { window manager . add ( i , now - 1000 ) ; }
int aborted = 0 ;
try { signature . init sign ( private key ) ; signature . update ( message ) ; return signature . sign ( ) ; } catch ( exception e ) { log . e ( tag , exception while signing message with + private key . get algorithm ( ) + private key : + e ) ; return null ; } }
me . offset location ( 0 , - header height ) ;
assert . assert same ( integer , set . get ( new integer ( integer ) ) ) ; }
expected . expect message ( 401 unauthorized ) ;
for ( iadapter extension < item > ext : m extensions ) { ext . notify adapter data set changed ( ) ; }
cp1 . set bootstrap target scn ( 250 l ) ; handler . advance after target scn ( cp1 ) ;
write data in chunks ( file read channel , file write channel ) ;
path sys dir = new path ( local dir , nm _ private _ dir ) ; path app sys dir = new path ( sys dir , app idstr ) ; submit dir for deletion ( null , app sys dir ) ; }
key = unwrap key ( conf , master key name , key bytes ) ; } catch ( key exception e ) {
file status = hdfs . get file status ( file1 ) ; assert that ( file status . get len ( ) , is ( ( long ) orig len + to append ) ) ; fis = hdfs . open ( file1 ) ; bytes read = fis . read ( 0 , buffer , 0 , buffer . length ) ; assert that ( bytes read , is ( orig len + to append ) ) ; fis . close ( ) ;
final list < path matcher > class patterns = target . get class patterns ( ) ;
val . set values ( 4 l , - 10 l , 50 l , - 74 l ) ;
array . set ( result array , i , factory method . invoke ( null , value [ i ] . trim ( ) ) ) ; } return result array ; } catch ( exception e ) {
for ( string target name : target names ) { xyinterval series target series = new xyinterval series ( target name + - predicted , false , false ) ; xy dataset . add series ( target series ) ; } value axis time axis = null ;
if ( type = = boolean . type | | type = = script runtime . boolean class | | type = = script runtime . object class ) { return value ; } else if ( type = = script runtime . string class ) { return value . to string ( ) ; } else { report conversion error ( value , type ) ; } break ; case jstype _ number :
double theta0 = m is rtl ? 0 : math . pi ;
revoked partitions = collections . empty list ( ) ; rebalance listener . on partitions revoked ( revoked partitions ) ; assert equals ( thread . state ( ) , stream thread . state . partitions _ revoked ) ;
packaged program streaming prog = new packaged program ( new file ( streaming _ prog _ jar _ file ) ) ; test stream environment . set as context ( test cluster , parallelism , collections . singleton ( new path ( streaming _ prog _ jar _ file ) ) , collections . < url > empty list ( ) ) ; streaming prog . invoke interactive mode for execution ( ) ; }
int diff = bytes . compare to ( left , loffset , lfamilylength , right , roffset , rfamilylength ) ;
test round trip type ( array type , insert null every ( 5 , read values ) . stream ( ) . map ( orc tester : : to hive list ) . collect ( to list ( ) ) ) ;
if ( requires ordered rules ) { assert ordered fields ( m ordered fields , reason suffix ) ; }
final unified service ref meta data service ref umdm = translate ( service ref md ) ; service ref umdm . set vfs root ( get unified virtual file ( unit ) ) ; process wsfeatures ( unit , service ref md . get injection targets ( ) , service ref umdm ) ; final wsref registry ws ref registry = ashelper . get wsref registry ( unit ) ; ws ref registry . add ( get cache key ( component description , service ref umdm ) , service ref umdm ) ; return service ref umdm ; }
interpreter . set register ( a0 , big integer . value of ( 0x ffffffffl ) , operand size . dword , reil register status . defined ) ; interpreter . set register ( t0 , big integer . value of ( 0x00000000 l ) , operand size . dword , reil register status . defined ) ; final mock operand tree operand tree1 = new mock operand tree ( ) ;
soapenvelope envelope = part . get envelope ( ) ; envelope . set prefix ( namespace ) ; envelope . remove namespace declaration ( soap - env ) ; delete standard namespace which was already set envelope . add namespace declaration ( namespace , http : schemas . xmlsoap . org soap envelope ) ; name n encoding = envelope . create name ( encoding style , namespace , http : schemas . xmlsoap . org soap encoding ) ; envelope . add attribute ( n encoding , http : schemas . xmlsoap . org soap encoding ) ;
bs = dfsutil . located blocks2 locations ( new located blocks ( ) ) ; assert equals ( 0 , bs . length ) ; }
data to update . m _ total timed execution time + = duration ;
v1 . delete ( ) ;
throw new illegal argument exception ( simple types have no content types ; cannot call with conten type handler ( ) ) ;
if ( connection = null ) { if ( connection . is closed ( ) ) { connection . close ( ) ; } } }
test fired rules ( package org . drools . compiler \ n + rule sounds like \ n + when \ n + person ( name soundslike \ bob \ ) \ n + then \ n + end , 0 , mark ) ;
val . set values ( - 4 . 3 ) ; iterator < double > values1 = arrays . as list ( 4 . 3 ) . iterator ( ) ; func . stream doubles ( value - > { assert true ( values1 . has next ( ) ) ; assert equals ( values1 . next ( ) , value , . 000001 ) ; } ) ; assert false ( values1 . has next ( ) ) ;
return hibernate . is initialized ( traversable object ) & & hibernate . is property initialized ( traversable object , traversable property . get name ( ) ) ; }
final path output path = file output format . get output path ( context ) ; final path outputdir = new file output committer ( output path , context ) . get work path ( ) ; final configuration conf = context . get configuration ( ) ; final file system fs = outputdir . get file system ( conf ) ;
sql = select z , max ( a ) , max ( b ) from ttree group by z ; try order by = order by z , max ( b ) ; try post sub order by = order by z , 3 ; assert plan determinism needs ordering ( sql , try order by , try post sub order by ) ; sql = select z , max ( a ) , max ( b ) from ttree group by z ;
cal . set time in millis ( random ( ) . next long ( ) ) ; round trip ( cal ) ; }
on exception ( internal listener exception in on intermediate image set , exception ) ;
buffer . position ( 17 ) ; buffer . put ( beef . get bytes ( ) ) ; buffer . position ( 0 ) ; subscriptions . assign from user ( singleton ( tp0 ) ) ;
message builder . append ( \ n no coder has been manually specified ; ) . append ( you may do so using . set coder ( ) . ) ; if ( infer from token exception = null ) { message builder . append ( \ n inferring a coder from the coder registry failed : ) . append ( infer from token exception . get message ( ) ) ; }
results = table . coprocessor exec ( ping protocol . class , row _ ab , row _ bc , new batch . call < ping protocol , string > ( ) { public string call ( ping protocol instance ) { return instance . ping ( ) ; } } ) ;
elem desc = ( elem desc ) m _ element flags . get ( iframe ) ; elem desc . set attr ( src , elem desc . attrurl ) ; elem desc . set attr ( longdesc , elem desc . attrurl ) ;
validate subsystem ( model , jsf , version ) ; we cannot check for it as web subsystem is not present to add jsf one }
if ( e . get key ( ) . equals ( volt compiler . autogen _ ddl _ file _ name ) ) { byte [ ] ddlbytes = e . get value ( ) ; int index = 0 ; while ( ddlbytes [ index ] = ' \ n ' ) { index + + ; } byte [ ] newddlbytes = arrays . copy of range ( ddlbytes , index , ddlbytes . length ) ; crc . update ( e . get key ( ) . get bytes ( constants . utf8 encoding ) ) ; crc . update ( newddlbytes ) ; } else { crc . update ( e . get key ( ) . get bytes ( constants . utf8 encoding ) ) ; crc . update ( e . get value ( ) ) ; }
, doc int [ @ name = ' + field to update + ' ] [ . = ' 42 ' ] , doc long [ @ name = ' _ version _ ' ] , doc date [ @ name = ' timestamp ' ] , doc arr [ @ name = ' multi default ' ] str [ . = ' mu lti - default ' ] , count ( doc * ) = 6 ) ;
http urlconnection connection = ( http urlconnection ) server uri . to url ( ) . open connection ( ) ;
job manager1 . add job ( new dummy job ( new params ( 0 ) ) ) ; job manager2 . add job ( new dummy job ( new params ( 0 ) ) ) ; atomic integer active thread count1 = get active consumer count ( get consumer executor ( job manager1 ) ) . get ( ) ; atomic integer active thread count2 = get active consumer count ( get consumer executor ( job manager2 ) ) . get ( ) ; thread . sleep ( 1000 ) ; matcher assert . assert that ( there should be 1 thread actively waiting for jobs , active thread count1 . get ( ) , equal to ( 1 ) ) ; matcher assert . assert that ( there should be one thread actively waiting for jobs , active thread count2 . get ( ) , equal to ( 1 ) ) ;
long file size = dfs . get file status ( filepath ) . get len ( ) ;
get menu inflater ( ) . inflate ( org . horaapps . leafpic . r . menu . menu _ video _ player , menu ) ; track selections < mapped track info > track selections = track selector . get current selections ( ) ;
} if ( load properties ) {
return immutable list . of ( ) ; }
long wrong time = - 1 ;
remove application attempt ( application , application . get user ( ) ) ; get parent ( ) . finish application attempt ( application , queue ) ; }
s . frames = new frame v3 [ 1 ] ;
if ( this node . is head node ( ) & & persistence cache . get main cache ( ) . get head nodes ( ) . contains ( this node ) ) { persistence cache . get main cache ( ) . get head nodes ( ) . remove ( this node ) ; } }
sapp pnmas pnmas = provider . get pnmas map ( ) . get ( address . get pnmas id ( ) ) ; sapp central executer sapp central executer = sapp central executer . get instance ( ) ; sapp central executer . execute sapp7 dcommand ( pnmas . get ip ( ) , pnmas . get port ( ) , address . get address ( ) , new value ) ; break ;
if ( width = img _ size | | height = img _ size ) { image scaling helper . paint ( g , 0 , 0 , width , height , img2 , insets , insets , image scaling helper . paint type . paint9 _ stretch , image scaling helper . paint _ all ) ; } else { g . draw image ( img2 , 0 , 0 , c ) ; } img1 = null ; img2 = null ; }
if ( success ) processed defs . add ( attr def ) ; else error defs . add ( attr def ) ;
db . users ( ) . insert permission on user ( db . get default organization ( ) , admin user , administer _ quality _ gates ) ; string result = new request ( ) . set param ( organization , org . get key ( ) ) . execute ( ) . get input ( ) ;
page context . set attribute ( constants . select _ key , this ) ; this . calculate match values ( ) ;
request static injection ( ln . class ) ;
return new publish doc service page ( publish , publish , null , input ) ;
array list < integer > new list = new array list < integer > ( get playback indeces list ( ) ) ; new list . remove ( get current song index ( ) ) ;
body builder . append formal line ( throw new % s ( msg . to string ( ) , e ) ; , get name of java type ( jdk java type . illegal _ state _ exception ) ) ; body builder . indent remove ( ) ;
annotated constructor default ctor = bean desc . find default constructor ( ) ;
for ( left tuple left tuple = src left tuples . get update first ( ) ; left tuple = null ; left tuple = left tuple . get staged next ( ) ) { ltm . remove ( left tuple ) ; } for ( left tuple left tuple = src left tuples . get update first ( ) ; left tuple = null ; left tuple = left tuple . get staged next ( ) ) { ltm . add ( left tuple ) ; for ( left tuple child left tuple = left tuple . get first child ( ) ; child left tuple = null ; ) { left tuple child next = child left tuple . get handle next ( ) ; child left tuple . re add right ( ) ; child left tuple = child next ; } }
cache config . clear global instances ( ) ;
assert . assert equals ( _ internal seg map . size ( ) , _ hi - _ lo + 1 ) ; }
do call real method ( ) . when ( m rx permissions ) . is granted ( any string ( ) ) ; do return ( false ) . when ( m rx permissions ) . is marshmallow ( ) ; boolean granted = m rx permissions . is granted ( p ) ;
return false ; } } } } } return false ; }
args . dump properties ( ) ;
cal . clear ( ) ; cal . set ( calendar . year , 2002 ) ; cal . set ( calendar . week _ of _ year , 12 ) ; cal . set ( calendar . day _ of _ week , calendar . monday ) ; cal . set ( calendar . month , calendar . march ) ; cal . set ( calendar . date , 11 ) ; assert true ( incorrect result 6 : + cal . get time ( ) , cal . get time ( ) . get time ( ) = = 1015822800000 l ) ;
if ( is platform ( aix ) ) { return ; } mbean server mbean server = get mbean server ( ) ; object name on = get route object name ( mbean server ) ;
final thread t = new thread ( ) { @ override public void run ( ) { try { instance = oserver main . create ( ) ; instance . startup ( ) . activate ( ) ; instance . wait for shutdown ( ) ; } catch ( exception e ) { olog manager . instance ( ) . error ( this , error during server execution , e ) ; } } } ; t . set daemon ( false ) ;
if ( if refresh an existed segment ( segment metadata , offline segment zkmetadata , offline table name , segment name ) ) {
assert equals ( 0 , indexing stats . get total ( ) . get delete count ( ) ) ; assert equals ( 0 , indexing stats . get total ( ) . get delete current ( ) ) ; assert equals ( 0 , indexing stats . get total ( ) . get index count ( ) ) ; assert equals ( 0 , indexing stats . get total ( ) . get index current ( ) ) ; assert equals ( 0 , indexing stats . get total ( ) . get index failed count ( ) ) ; assert equals ( 2 , pre index . get ( ) ) ; assert equals ( 2 , post index . get ( ) ) ; assert equals ( 1 , pre delete . get ( ) ) ; assert equals ( 1 , post delete . get ( ) ) ; close shards ( new shard ) ;
do test ( uncovered get servlet . class . get name ( ) , false , true , true , false ) ;
run snapshot ( backend . snapshot ( 682375462378 l , 2 , stream factory , checkpoint options . for checkpoint ( ) ) ) ;
for ( method method : matching methods ) { registered method registered method = new registered method ( method , java type ) ; string reg method name = ( string ) this . name map . get ( registered method ) ; if ( ( reg method name = = null ) | | ( reg method name . equals ( name ) & & ( reg method name . length ( ) < = name . length ( ) ) ) ) { no already registered method name , or more specific method name specification now - > ( re - ) register method if ( reg method name = null ) { logger . debug ( replacing attributes for secure method [ + method + ] : current name [ + name + ] is more specific than [ + reg method name + ] ) ; } this . name map . put ( registered method , name ) ; add secure method ( registered method , attr ) ; } else { logger . debug ( keeping attributes for secure method [ + method + ] : current name [ + name + ] is not more specific than [ + reg method name + ] ) ; } }
server _ . get save plot context ( default dir . get path ( ) , new simple request callback < save plot as image context > ( ) { @ override public void on response received ( save plot as image context context ) { indicator . on completed ( ) ; export plot _ . save plot as image ( global display _ , server _ , context , export plot options . adapt to size ( ui prefs _ . get ( ) . export plot options ( ) . get value ( ) , get plot size ( ) ) , save export options operation _ ) ; } @ override public void on error ( server error error ) { indicator . on error ( error . get user message ( ) ) ; } } ) ;
callback . on response received ( spell checker result ) ; } @ override public void on error ( server error error ) { callback . on error ( error ) ; } } ) ; }
am client . release assigned container ( container . get id ( ) ) ; } if ( allocated container count < containers requested any ) {
string [ ] args3 = { create , host , hola , catalog , teststring2 } ; config = new volt db . configuration ( args3 ) ; assert true ( config . validate ( ) ) ;
int i parent = o parent set . delete parent ( n candidate parent , instances ) ; o parent set2 . add parent ( n node , instances ) ;
if ( write result = null ) { this . current message . set ( write queue . poll ( ) ) ; handler . on message sent ( this , current message . get message ( ) ) ;
packet . position ( packet . position ( ) + ( 16 - addr len ) + 64 skip server host name ( 64 chars ) + 128 ) ; skip boot file name ( 128 chars ) int dhcp magic cookie = packet . get int ( ) ;
try { constructor < ? > constructor = type ( ) . get declared constructor ( types ) ; return on ( constructor , args ) ; }
if ( brace _ count [ no ] < = brace _ max [ no ] ) { reg _ save ( save ) ; if ( regmatch ( scan . operand ( ) ) ) { return true ; * matched some more times * } reg _ restore ( save ) ; - - brace _ count [ no ] ; * matched just enough times *
get capabilities ( ) . test with fail ( data ) ;
matcher m = response _ pattern . matcher ( body . to string ( ) ) ; boolean b = m . find ( ) ; if ( b ) { ill formatted response logger . debug ( ill formatted response : ' + body + ' ) ; throw new exception ( invalid response from eco touch ) ; } return integer . parse int ( m . group ( 3 ) ) ;
class loader loader1 = new subverted class loader ( new url [ ] { get class ( ) . get resource ( test enum . jar ) } , this . get class ( ) . get class loader ( ) ) ; loader1 . load class ( org . drools . primitives ) ; loader1 . load class ( org . drools . test enum ) ; byte [ ] out = null ;
boshconfiguration bosh config = new boshconfiguration ( ( sslcontext = null ) , server , port , null , get configuration ( ) . get ( xmpp _ domain ) ) ;
if ( dbg ) log ( copy message to icc ef : status = + status + = = > + pdu = ( + arrays . to string ( pdu ) + ) ) ; enforce receive and send ( copying message to ruim ) ; synchronized ( m lock ) { m success = false ; message response = m handler . obtain message ( event _ update _ done ) ; m phone . m cm . write sms to ruim ( status , icc utils . bytes to hex string ( pdu ) , response ) ; try { m lock . wait ( ) ; } catch ( interrupted exception e ) { log ( interrupted while trying to update by index ) ; } } return m success ;
byte [ ] sentence blank ranges = new byte [ 100 ] ; int sentence blank ranges len = add multi byte char sentence blank ranges ( sentence blank ranges , 0 ) ; assert . assert true ( string expr . character count ( sentence blank ranges , 0 , sentence blank ranges len ) = = 17 ) ; string expr . truncate ( out v , i , sentence blank ranges , 0 , sentence blank ranges len , 4 ) ; expected result len = 9 ;
fail ( unable to find + test resource2 ) ;
try { loader = new test loader ( true ) ; cls = class . for name ( com . sun . jna . native , true , loader ) ; } catch ( throwable t ) { fail ( couldn ' t load class again after discarding first load : + t . get message ( ) ) ; } finally { loader = null ; cls = null ; system . gc ( ) ; }
load balancer vo load balancer = _ lb dao . find by id ( cmd . get lb rule id ( ) ) ;
group by = add ( group by , o ) ;
logger . error ( an unexpected error occurred while + constructing the event header , e ) ;
kie builder kie builder = ks . new kie builder ( kfs ) . build all ( ) ;
spark conf conf = new spark conf ( ) . set app name ( word count ) ;
data [ 1 ] = ( byte ) ( ( server hello length > > 16 ) & 0x ff ) ; data [ 2 ] = ( byte ) ( ( server hello length > > 8 ) & 0x ff ) ; data [ 3 ] = ( byte ) ( server hello length & 0x ff ) ; return data ; } catch ( alpn processing exception e ) {
return candidates . get ( 0 ) . data directory ;
cb . clustering ( ) . hash ( ) . num segments ( 0 ) ; }
num . is not null ( ) ;
list < url > managed url = get jar file urls ( ) ; if ( managed url = = null ) { managed url = new array list < url > ( 1 ) ; } if ( get exclude unlisted classes ( ) ) { managed url . add ( get persistence unit root url ( ) ) ; }
for ( int i = 1 ; i < = 7 ; i + + ) { jar . add as resources ( jboss pdpservlet initialization test case . class . get package ( ) , xacmltest utils . testobjects _ requests + scenario2 - testcase + i + - request . xml ) ; } jar . add as resource ( jboss pdpservlet initialization test case . class . get package ( ) , xacmltest utils . testobjects _ requests + med - example - request . xml ) ; return jar ;
byte [ ] read bytes = new byte [ test _ data . length ] ;
final class ownerclass = get ownerclass ( owner , class level ) ;
final int remaining chars = ( limit - start ) ;
int end of modifiers = label . index of ( ' + ' ) ;
assert equals ( 128 , base _ sampling _ level ) ;
feature type info info = get catalog ( ) . get feature type by name ( forests ) ;
columns list . append ( of ) . append ( associated entity . get entity name ( ) ) . append ( . ) . append ( columns [ 0 ] . get property name ( ) ) . append ( ) ;
int btn current sort type idx = 0 ;
_ read only map . set ( null ) ; } } }
try { if ( threaded list ) { local store . set flag for threads ( ids , flag , new state ) ; remove flag for threads from cache ( account , ids , flag ) ; } else { local store . set flag ( ids , flag , new state ) ; remove flag from cache ( account , ids , flag ) ; } } catch ( messaging exception e ) { timber . e ( e , couldn ' t set flags in local database ) ; }
if ( headless ) { while ( headless waiting ) { thread . sleep ( 100 ) ; } }
long count = query ( ) . from ( survey ) . fetch count ( ) ; assert equals ( 0 , query ( ) . from ( survey ) . where ( survey . name . eq ( s ) ) . fetch count ( ) ) ;
t1 = t2 ; break ; }
create setter method ( class node , property node , setter name , setter block ) ; } else {
assert null ( rs . next ( ) ) ;
return ( key . starts with ( : ) & & content _ type _ key . name ( ) . equals ignore case ( key ) ) & & user _ agent _ key . name ( ) . equals ignore case ( key ) ;
if ( public network ) { public ip source nat ip = _ network mgr . assign source nat ip address ( owner , guest network , _ account mgr . get system user ( ) . get id ( ) ) ; default nic . set default nic ( true ) ; default nic . set ip4 address ( source nat ip . get address ( ) . addr ( ) ) ; default nic . set gateway ( source nat ip . get gateway ( ) ) ; default nic . set netmask ( source nat ip . get netmask ( ) ) ; default nic . set mac address ( source nat ip . get mac address ( ) ) ; default nic . set broadcast type ( broadcast domain type . vlan ) ; default nic . set broadcast uri ( broadcast domain type . vlan . to uri ( source nat ip . get vlan tag ( ) ) ) ; default nic . set isolation uri ( isolation type . vlan . to uri ( source nat ip . get vlan tag ( ) ) ) ; default nic . set device id ( 2 ) ; } int count = router count - routers . size ( ) ;
final int num jobs = 3 ; debug job producer job producer = new debug job producer ( num jobs , conf ) ; configuration job conf = gridmix test utils . mrvl . get config ( ) ;
return position . create ( ( integer ) pos . get line ( ) , pos . get position ( ) ) ; }
bean definition builder context builder = bean definition builder . generic bean definition ( pig context factory bean . class ) ; namespace utils . set property value ( element , context builder , job - tracker ) ; namespace utils . set property value ( element , context builder , exec - type ) ; namespace utils . set property reference ( element , context builder , configuration - ref ) ;
hash set clients = state . get clients ( ts ) ;
if ( hri . is root region ( ) | | hri . is meta region ( ) ) { if ( perm request = = table permission . action . read ) { return auth result . allow ( request , all users allowed , user , perm request , table name ) ; } } if ( user = = null ) { return auth result . deny ( request , no user associated with request , null , perm request , table name ) ; }
final map < uuid , list < invoice model dao > > parent invoices grouped by parent account id = new hash map < uuid , list < invoice model dao > > ( ) ;
collection < double > double string = get value list ( response , percentile _ 60n , field facets , string _ sd , double , false ) ;
setter = ows utils . setter ( request . get class ( ) , property , null ) ;
sync . remove socket ( websocket1 ) ; assert null ( store1 . get ( key _ 1 ) ) ; assert not null ( store1 . get ( key _ 2 ) ) ;
watch key watch key = watch service . take ( ) ; watch key . poll events ( ) ;
tb . get age ( ) ; fail ( should have wrapped exception raised by interceptor ) ; }
return new rect ( view . get left ( ) , view . get top ( ) , view . get right ( ) , view . get bottom ( ) ) ; }
set < string > moved cross files class descs = deleted class descs ;
if ( override . is audited ( ) ) { return false ; } else { if ( override . audit join table ( ) = null ) { property data . set join table ( override . audit join table ( ) ) ; } }
sql database local database = new sql database ( test config ) ;
check and flush ( ) ; } ) ; } else {
if ( coproc environments . is empty ( ) ) { return ; }
variables . put ( name , new variable ( name , type , value , modifiers ) ) ;
derivational ( stemming zone ) ;
request . set response ( response ) ;
for ( query q : match all ) { if ( verbose ) system . out . println ( match all : q = + q + + q . get class ( ) . get name ( ) ) ; score doc [ ] hits = searcher . search ( q , 1000 ) . score docs ; assert equals ( docs . length , hits . length ) ; }
else if ( line > caret screen line & & line < struct screen line ) { gfx . fill rect ( 5 , y , 2 , line height ) ; }
test ( function a ( ) { } + if ( 0 ) { function b ( ) { } } win . set timeout ( function ( ) { a ( ) } ) , function a ( ) { } + if ( 0 ) ; win . set timeout ( function ( ) { a ( ) } ) ) ;
counts . increment restored checkpoints ( ) ; counts . increment restored checkpoints ( ) ; counts . increment in progress checkpoints ( ) ; counts . increment completed checkpoints ( ) ; counts . increment in progress checkpoints ( ) ; counts . increment failed checkpoints ( ) ; assert equals ( restored , snapshot . get number of restored checkpoints ( ) ) ;
linked blocking queue < response message > response queue = new linked blocking queue < response message > ( response _ queue _ max _ depth ) ;
try { role unres list . add ( ( role unresolved ) curr result ) ; } catch ( illegal argument exception exc ) { throw new runtime exception ( exc . get message ( ) ) ; } } }
collection < string > var names = new array list < string > ( ) ;
if ( change set parts . is empty ( ) ) { add change set parts ( parts , change set parts ) ; } final string boundary = boundary _ prefix + uuid . random uuid ( ) ; input stream batch request = entity provider . write batch request ( parts , boundary ) ;
server registration . register sub model ( connector service definition . instance ) ;
if ( mesh . _ _ gl _ mesh split edge ( e . sym ) = = null ) throw new runtime exception ( ) ;
if ( state = = null ) { string message = missing sub cluster state information . + please try again by specifying sub cluster state information . ; log . warn ( message ) ; throw new federation state store invalid input exception ( message ) ; }
byte buffer . put int ( store size ) ;
return super . check property ( property id ) ;
if ( arrays . equals ( header hmac , stored hmac ) ) { throw new invalid dbexception ( ) ; } hmac block input stream hm is = new hmac block input stream ( is data , true , hmac key ) ;
closeable reference < integer > original ref1 = new reference ( 400 ) ;
int pos = get stream position of the field ( ctx ) ; in . position ( pos ) ;
if ( fs . exists ( link rank ) ) { fs . mkdirs ( link rank ) ; }
if ( not found ( m , s ) & & m . is annotation present ( annotation type ) ) { s . add ( m ) ; }
batch . draw ( atlas . find region ( badlogicsmall ) , 360 , 100 ) ;
this . comparator . set reference ( next ) ; this . values iterator . next = next ; this . last key record = next ; this . values iterator . iterator available = true ; return true ;
if ( is drawer open ( ) ) m list view . set selection ( m app . get service ( ) . get current song index ( ) ) ;
if ( c4 = = ' - ' & & c7 = = ' - ' ) {
graphics2 d g2d = ( graphics2 d ) painter . get graphics ( ) ; g2d . set rendering hint ( rendering hints . key _ text _ antialiasing , antialias ? rendering hints . value _ text _ antialias _ on : rendering hints . value _ text _ antialias _ off ) ; font render context frc = g2d . get font render context ( ) ; messages . log ( debug : font render context is antialiased = + frc . get anti aliasing hint ( ) ) ; return new text layout ( composed . get iterator ( ) , frc ) ;
key = abcdefghijklmnopqrstuvwxyz _ 0123456789 ;
tree = ( { fun . ( fun ( fun 3 ) ) } { y . ( * y y ) } ) ;
hive decimal v1 old add dec ; hive decimal add dec ; old add dec = old dec . add ( old dec ) ;
if ( is taking snapshot ( table name ) ) { throw new restore snapshot exception ( snapshot in progress on the restore table = + table name ) ; }
final account refreshed account2 = account user api . get account by id ( account . get id ( ) , call context ) ;
boolean equals ; indarray deserialized ; try { deserialized = si . deserialize ( bb , null ) ;
final int get type = cpg . add interface methodref ( dom _ intf , get expanded type id , ( i ) i ) ; body . append ( method gen . load dom ( ) ) ; body . append ( new iload ( _ current index ) ) ; body . append ( new invokeinterface ( get type , 2 ) ) ;
updated post = update post with currently failed uploads ( updated post ) ;
close guard reporter = close guard . get reporter ( ) ;
assert false ( rs . renew lease ( ) ) ;
assert true ( display list . size ( ) = = 1 ) ; assert equals ( display list . get item ( 0 ) . url metadata . title , title ) ; assert equals ( display list . get item ( 0 ) . url metadata . groupid , groupid ) ; display list . add item ( device updated ) ;
method handle constant . java lang invoke method handle class = find class ( clazz , class constants . name _ java _ lang _ invoke _ method _ handle ) ; }
this . snapshots . clear ( ) ; this . snapshots . put all ( known ) ; }
log . info ( op . name ( ) + labels on nodes : ) ;
test str = this is awesome crs \ r \ rand awesome lfs \ n \ nwhat if we combine it? \ r \ n \ r \ n \ r \ nwow \ r \ nso standard \ n \ rmuch naver \ n ; assert . assert equals ( this is awesome crs and awesome lfs what if we combine it? wow so standard much naver , query string util . remove carriage return ( test str ) ) ; }
conf . set num map tasks ( 2 ) ; conf . set output format ( sequence file output format . class ) ; if ( fs . mkdirs ( testdir ) ) { throw new ioexception ( mkdirs failed to create + testdir . to string ( ) ) ; } if ( fs . mkdirs ( in dir ) ) { throw new ioexception ( mkdirs failed to create + in dir . to string ( ) ) ; }
payload . put ( header name , s ) ; } } } finally {
final atomic boolean need fail = new atomic boolean ( false ) ; injection handler . set ( new injection handler ( ) { @ override protected void _ process event ( injection event i event , object . . . args ) { if ( event = = injection event . dfsclient _ before _ add _ deadnodes ) { need fail . set ( true ) ; try { throw new exception ( for call stack ) ; } catch ( exception e ) { e . print stack trace ( ) ; } } } } ) ; final path p = new path ( test update available with block recovery ) ;
if ( event listener = null ) { event listener . on ad playback state ( ad playback state . copy ( ) ) ; }
final object [ ] database snapshot = get database snapshot ( session , persister , id ) ;
assert true ( iterator . next ( ) instanceof random access ) ; assert true ( iterator . next ( ) instanceof random access ) ; }
if ( state . equals ( logging _ in ) ) { return state . logged _ in ; } return state . value of ( state ) ;
m adapter . remove items ( m positions , m payload ) ;
} for ( int p = 0 ; p < i - 1 ; p + + ) { try { create node ( instance , property _ value + string . value of ( p ) , label ) ; fail ( node with + property _ value + string . value of ( p ) + should already exist ) ; } catch ( constraint violation exception e ) {
get config avro = admin client . get store client config string ( arrays . as list ( store _ name ) , admin _ url ) ;
java archive bravo = shrink wrap . create ( java archive . class ) . add class ( bravo . class ) . add as manifest resource ( new string asset ( ) , beans . xml ) ;
cluster . shift ( which edge , 1 ) ; }
for ( int i = 0 ; i < managers . length ; i + + ) { if ( managers [ i ] instanceof x509 key manager ) { x509 key manager manager = ( x509 key manager ) managers [ i ] ; new managers [ i ] = new wrapped x509 key manager ( manager , keys ) ; } else { new managers [ i ] = managers [ i ] ; } }
assert ( this . kafka appender . is present ( ) ) ; this . kafka appender = optional . of ( appender ) ; this . logger . add appender ( this . kafka appender . get ( ) ) ; this . logger . set additivity ( false ) ; this . flow logger . info ( attached new kafka appender for job + this . job id ) ; }
for ( file i : ignore ) if ( file . get absolute path ( ) . starts with ( i . get absolute path ( ) ) ) return ;
meta store client = hive meta store client . new synchronized client ( meta store client ) ;
join column = column by referenced name . get ( logical column name . to lower case ( locale . root ) ) ;
if ( mouse . is created ( ) ) { mouse . poll ( ) ; mouse . update cursor ( ) ; } if ( keyboard . is created ( ) ) { keyboard . poll ( ) ; }
presto exception exception = new presto transport exception ( too _ many _ requests _ failed , from uri ( task uri ) , format ( % s ( % s % s - % s failures , time since last success % s ) , worker _ node _ error , job description , task uri , backoff . get failure count ( ) , backoff . get time since last success ( ) . convert to ( seconds ) ) ) ;
final timeout exception oate = new timeout exception ( bogus timeout , 1 , 2 , 0 ) ;
test observer < list < io . rx _ cache2 . internal . mock > > test observer = new test observer < > ( ) ; actions list . with ( evict ( ) , cache ( ) ) . evict first n ( new actions list . func1 count ( ) { @ override public boolean call ( int count ) { return count > 10 ; } } , 5 ) . to observable ( ) . subscribe ( test observer ) ;
if ( has input types ( ) ) { return get input extensions attribute ( ) . contains ( extension ) ; } return false ;
input stream is = qjm . get image input stream ( start tx id + iteration ) . get input stream ( ) ; byte [ ] contents = new byte [ written . length ] ; is . read ( contents ) ; assert true ( arrays . equals ( written , contents ) ) ; return hash ;
prepared statement insert = session . get jdbc coordinator ( ) . get statement preparer ( ) . prepare statement ( insert sql , prepared statement . no _ generated _ keys ) ;
int earliest node = dtm . null ; if ( null = m _ iterators ) { int n = m _ iterators . length ; int iterator used = - 1 ; for ( int i = 0 ; i < n ; i + + ) { int node = m _ iterators [ i ] . get current node ( ) ; if ( dtm . null = = node ) continue ; else if ( dtm . null = = earliest node ) { iterator used = i ; earliest node = node ; } else { if ( node = = earliest node ) { found a duplicate , so skip past it . m _ iterators [ i ] . next node ( ) ; } else { dtm dtm = get dtm ( node ) ; if ( dtm . is node after ( node , earliest node ) ) { iterator used = i ; earliest node = node ; } } } } if ( dtm . null = earliest node ) { m _ iterators [ iterator used ] . next node ( ) ; increment current pos ( ) ; } else m _ found last = true ; }
target cpu usage = metrics . get cumulative cpu usage ( ) ; if ( target cpu usage < = 0 ) { enabled = false ; return ; } else { enabled = true ; } emulation interval = conf . get float ( cpu _ emulation _ progress _ interval , default _ emulation _ frequency ) ;
sb . delete char at ( i ) ;
fsdata output stream out1 = fsutils . create ( conf , fs , p1 , perms , null ) ; out1 . close ( ) ;
java _ writer = new print writer ( env . get filer ( ) . create source file ( utils . get qualified class name ( e ) , env . get element utils ( ) . get package of ( e ) ) . open writer ( ) ) ; generate java source ( e , java _ writer ) ; if ( methods . size ( ) > 0 ) { boolean no native = true ; for ( final executable element method : methods ) { alternate alt _ annotation = method . get annotation ( alternate . class ) ; if ( ( alt _ annotation = = null | | alt _ annotation . native alt ( ) ) & & method . get annotation ( reuse . class ) = = null ) { no native = false ; break ; } } if ( no native ) { return default _ value ; } try { generate native source ( e ) ; } catch ( ioexception ex ) { throw new runtime exception ( ex ) ; } }
if ( name = = null ) { throw new illegal argument exception ( sm . get string ( coyote request . set attribute . namenull ) ) ; }
listener . handle modify event ( style name modify event ) ;
dialog factory . create message dialog ( , messages . message no machine ( ) , null ) . show ( ) ; } else {
if ( new manifest package = null ) { manifest merger invoker . set override ( system property . package , new manifest package ) ; }
add error ( explicit constructors not allowed for + my _ type _ name + class : + c node . get name without package ( ) , constructor node ) ; return false ;
treap . remove ( ( integer ) 5 ) ; in order = to string ( integer . class , treap . in order ( ) ) ; assert . assert true ( in order . equals ( 9 1 2 3 6 7 8 10 11 ) ) ; move to front ( treap , 5 , 9 ) ;
r . writestate . writes enabled = true ; hstore . close check interval = orig wi ;
clear focus ( ) ;
assert equals ( 3 l , queue . poll ( ) . timestamp ) ;
execute ( delete from % s where a = ? and b = ? and c = ? , 1 , 1 , 0 ) ; assert rows ignoring order ( execute ( select a , b , c , d from mv _ test + i ) , row ( 0 , 1 , 0 , 0 ) , row ( 0 , 1 , 1 , 0 ) , row ( 1 , 1 , 1 , 0 ) , row ( 1 , 1 , 2 , 0 ) ) ;
file status [ ] paths = f sys . glob status ( get test root path ( f sys , test hadoop ? ) ) ;
assert that ( e . get message ( ) , contains string ( string . format ( line : % d , 2 * unbalanced start line + 1 ) ) ) ;
if ( ( input . length ( ) & 1 ) = = 1 ) { int k1 = input . char at ( input . length ( ) - 1 ) ; k1 = mix k1 ( k1 ) ; h1 ^ = k1 ; } return fmix ( h1 , 2 * input . length ( ) ) ;
day cell . set text ( ) ; day cell . set disable ( true ) ; } }
pre split table and verify ( expected bounds , uniform split . class . get simple name ( ) , new uniform presplit table ) ;
list < url > managed url = get jar file urls ( ) ; if ( managed url = = null ) { managed url = new array list < url > ( 1 ) ; } if ( get exclude unlisted classes ( ) ) { managed url . add ( get persistence unit root url ( ) ) ; }
temp paths [ 0 ] = lead path ; rows = row mapper . get rows for paths ( temp paths ) ; lead row = ( rows = null ) ? rows [ 0 ] : - 1 ; } else { lead row = - 1 ; } insure row continuity ( ) ; }
m paint . set color ( res . get color ( r . color . numbers _ text _ color ) ) ; string typeface family = res . get string ( r . string . radial _ numbers _ typeface ) ; m typeface light = typeface . create ( typeface family , typeface . normal ) ; string typeface family regular = res . get string ( r . string . sans _ serif ) ; m typeface regular = typeface . create ( typeface family regular , typeface . normal ) ; m paint . set anti alias ( true ) ; m paint . set text align ( align . center ) ; m texts = texts ;
frame comp frame = new frame ( ) ;
immutable list . copy of ( table privileges . key set ( ) ) . stream ( ) . filter ( key - > key . matches ( database name , table name ) ) . for each ( table privileges : : remove ) ;
assert equals ( 0 , slot provider . get number of available slots ( ) ) ;
cache . put ( key , new custom ( int value ) ) ;
rsp = query ( q , * : * , rows , 0 , fq , { tag = ff } pay _ i : [ 2000 to * ] , facet , true , facet . pivot , { key = filt } place _ s , company _ t , facet . pivot , { key = nofilt ex = ff } place _ s , company _ t , facet params . facet _ limit , 4 ) ;
configure consumer ( consumer ) ; return consumer ;
util . create initial ring ( ss , partitioner , endpoint tokens , key tokens , hosts , host ids , 7 ) ;
if ( f root = = null ) return null ; node next node = f current node ;
local fs blob store spy = spy ( store ) ; mockito . do nothing ( ) . when ( spy ) . check for blob update ( test ) ; mockito . do nothing ( ) . when ( spy ) . check for blob update ( other ) ; mockito . do nothing ( ) . when ( spy ) . check for blob update ( test - empty - subject - we ) ; mockito . do nothing ( ) . when ( spy ) . check for blob update ( test - empty - subject - def ) ; mockito . do nothing ( ) . when ( spy ) . check for blob update ( test - empty - acls ) ; map conf = utils . read storm config ( ) ; conf . put ( config . storm _ local _ dir , base file . get absolute path ( ) ) ; conf . put ( config . storm _ principal _ to _ local _ plugin , org . apache . storm . security . auth . default principal to local ) ; spy . prepare ( conf , null , null ) ; return spy ;
assert . assert true ( e . get cause ( ) . get cause ( ) . get message ( ) . contains ( artificial failure for record ) ) ;
( ( mock seekable view ) source ) . reset index ( ) ; specification = new downsampling specification ( 1hc - sum ) ; specification . set timezone ( af ) ; downsampler = new downsampler ( source , specification , 0 , long . max _ value ) ; ts = 1356996600000 l ;
em = get entity manager ( ) ;
boolean target thing = false ;
post dial state state = post dial state ;
check exclusivity match ( labels ) ;
final alert dialog dialog = new alert dialog . builder ( termux activity . this ) . set items ( urls , new dialog interface . on click listener ( ) { @ override public void on click ( dialog interface di , int which ) { string url = ( string ) urls [ which ] ; clipboard manager clipboard = ( clipboard manager ) get system service ( context . clipboard _ service ) ; clipboard . set primary clip ( new clip data ( null , new string [ ] { text plain } , new clip data . item ( url ) ) ) ; toast . make text ( termux activity . this , r . string . select _ url _ copied _ to _ clipboard , toast . length _ long ) . show ( ) ; } } ) . set title ( r . string . select _ url _ dialog _ title ) . create ( ) ;
if ( _ has other ) { ordered list . add all ( ( index < 0? 0 : index ) , tmp ) ; } return ordered list ;
context = m . invoke ( null , context path , class loader ) ; } if ( ( context instanceof jaxbcontext ) ) {
m start time = current time - ( delta time - m start delay ) ; m playing state = running ; return true ; } }
headers headers = new headers . builder ( ) . add ( www - authenticate , digest realm = \ myrealm \ , nonce = \ fjalskdflwejrlaskdfjlaskdjflaks + jdflkasdf \ , qop = \ auth \ , stale = \ false \ ) . build ( ) ;
controller . start ( basic crawler . class , number of crawlers ) ; }
stroke width = 1 . 0f get resources ( ) . get display metrics ( ) . density ; } m radius inactive - = stroke width 2 . 0f ; } m paint inactive . set color ( inactive color ) ;
if ( m _ ext ns mgr = null ) m _ ext ns mgr . register unregistered namespaces ( ) ; clear compose state ( ) ;
return ( k1 + 1 ) * ( float ) math . log ( 1 + ( num docs + 0 . 5 d ) ( total term freq + 0 . 5 d ) ) ; }
atts = new array list < attribute > ( num att ) ; for ( i = 0 ; i < num att - 1 ; i + + ) atts . add ( new attribute ( att _ + ( i + 1 ) ) ) ; atts . add ( determine class attribute ( ) ) ; if ( m _ url . equals ( http : ) ) rel name = m _ url ; else rel name = m _ file ;
clipboard . set contents ( new string selection ( message text area . get text ( ) ) , null ) ; } } ) ; menu . add ( menu item1 ) ;
if ( on complete runnable = null ) { on complete runnable . run ( ) ; }
return thread local . get ( ) ; }
fully maximize window ( window , tab ) ;
g . set color ( holdc ) ;
num containers = collect rack local candidates ( all nodes , enriched rr , ret list , black list , num containers ) ;
em . get transaction ( ) . begin ( ) ; coll1 = em . find ( map uni entity . class , coll1 . get id ( ) ) ; coll1 . get map ( ) . remove ( 1 ) ; em . get transaction ( ) . commit ( ) ;
params = new linked multi value map < > ( ) ;
queue . assign containers ( cluster resource , node _ 0 , new resource limits ( cluster resource ) , scheduling mode . respect _ partition _ exclusivity ) ; schedule to compute
panel = new jpanel ( new flow layout ( flow layout . center ) ) ; panel2 . add ( panel , border layout . center ) ; panel . add ( m _ label query ) ; pack ( ) ;
is real running = false ;
authentication simple http invoker request executor executor = new authentication simple http invoker request executor ( ) ;
loge ( tag , exception updating conference message cards subscription . , throwable ) ; }
assert xpath evaluates to ( 1 , count ( csw : record [ dc : identifier = ' urn : uuid : 9a669547 - b69b - 469f - a11f - 2d875366bbdc ' ] ) , d ) ;
buffers . clear ( ) ; return - 1 ;
expr = expression util . wrap scalar subqueries ( expr ) ;
return new value animator ( ) . get duration ( ) ;
gui package . get instance ( ) . get tree listener ( ) . get jtree ( ) . scroll path to visible ( tree path ) ; } }
polygon geo json = xcontent factory . json builder ( ) . start object ( ) . field ( type , polygon ) . start array ( coordinates ) . start array ( ) . start array ( ) . value ( - 177 . 0 ) . value ( 10 . 0 ) . end array ( ) . start array ( ) . value ( 176 . 0 ) . value ( 15 . 0 ) . end array ( ) . start array ( ) . value ( 172 . 0 ) . value ( 0 . 0 ) . end array ( ) . start array ( ) . value ( 176 . 0 ) . value ( - 15 . 0 ) . end array ( ) . start array ( ) . value ( - 177 . 0 ) . value ( - 10 . 0 ) . end array ( ) . start array ( ) . value ( - 177 . 0 ) . value ( 10 . 0 ) . end array ( ) . end array ( ) . end array ( ) . end object ( ) . string ( ) ; parser = create parser ( json xcontent . json xcontent , polygon geo json ) ;
if ( coll instanceof orecord lazy multi value ) add single edge ( doc , iterable , field name , connection , ( ( orecord lazy multi value ) coll ) . raw iterator ( ) . next ( ) , destination vid , i labels ) ; else if ( coll instanceof list < ? > ) add single edge ( doc , iterable , field name , connection , ( ( list < ? > ) coll ) . get ( 0 ) , destination vid , i labels ) ; else add single edge ( doc , iterable , field name , connection , coll . iterator ( ) . next ( ) , destination vid , i labels ) ; } else {
boolean final sub batch = is final sql & & ( sub size = = m _ batch . size ( ) ) ;
start row = bytes . to bytes ( start key ) ;
final int len = buf . get int ( ) ;
exception me = null ; try { client . list partitions by filter ( db name , tbl name , p3 > = \ p12 \ , ( short ) - 1 ) ; } catch ( meta exception e ) { me = e ; } assert not null ( me ) ; assert true ( filter on int partition key , me . get message ( ) . contains ( filtering is supported only on partition keys of type string ) ) ; me = null ; try { client . list partitions by filter ( db name , tbl name , c1 > = \ p12 \ , ( short ) - 1 ) ; } catch ( meta exception e ) { me = e ; } assert not null ( me ) ; assert true ( filter on invalid key , me . get message ( ) . contains ( < c1 > is not a partitioning key for the table ) ) ; me = null ;
page < release history > release histories = release history service . find release histories by namespace ( test app , parent cluster name , test namespace , pageable ) ;
assert false ( wmts info . is enabled ( ) ) ; }
assert inverse ( { \ name \ : \ string \ , \ color \ : \ string \ } , immutable map . of ( name , jay , color , pale ) ) ;
string [ ] tab sizes = { 2 , 4 , 8 } ; tab size = new jcombo box < string > ( tab sizes ) ; tab size . set editable ( true ) ; tab size . set selected item ( buffer . get string property ( tab size ) ) ; add component ( j edit . get property ( options . editing . tab size ) , tab size ) ;
try { new ecpoint ( big integer . zero , null ) ; fail ( 2 : expected npe not thrown ) ; } catch ( null pointer exception ok ) { }
assert null ( p . get current name ( ) ) ;
while ( max header table size - size < header size ) { remove ( ) ; } int h = ascii string . hash code ( name ) ;
return context ; }
. group by ( field0 ) . reduce ( new centroid accumulator ( ) )
i + = end quote . length ( ) ;
parent = undefined . instance ; } else { parent = get from annotation ( lib , find annotation ( curs ) ) ; } } else {
update current node ( ) ;
if ( needs sync data ( ) ) { synchronize data ( ) ; }
script engine engine = null ;
file utils . delete recursive ( f ) ;
set input limit ( - 1 ) ;
http security bean definition parser . register filter chain proxy if necessary ( pc , pc . extract source ( element ) ) ; bean definition filter chain proxy = pc . get registry ( ) . get bean definition ( bean ids . filter _ chain _ proxy ) ; filter chain proxy . get property values ( ) . add property value ( firewall , new runtime bean reference ( ref ) ) ; return null ;
tester . notify job completion ( deployment jobs . job type . production us west1 , app , true ) ;
m saved xdist = get xdist ( event ) ;
return instructions . size ( ) - 1 ;
rel builder . push ( frame . r ) . filter ( decorrelate expr ( rel . get condition ( ) ) ) ;
assert not equals ( shard routing state . started , shard routing state ) ;
task service . set owner ( task . get id ( ) , owner ) ;
add ( ops . date time ops . second , second ( { 0 } ) ) ; add ( ops . date time ops . minute , minute ( { 0 } ) ) ; add ( ops . date time ops . hour , hour ( { 0 } ) ) ; add ( ops . date time ops . week , week ( { 0 } ) ) ; add ( ops . date time ops . month , month ( { 0 } ) ) ; add ( ops . date time ops . year , year ( { 0 } ) ) ; add ( ops . date time ops . year _ month , ( year ( { 0 } ) * 100 + month ( { 0 } ) ) ) ; add ( ops . date time ops . year _ week , ( year ( { 0 } ) * 100 + week ( { 0 } ) ) ) ; add ( ops . date time ops . day _ of _ week , dayofweek ( { 0 } ) ) ; add ( ops . date time ops . day _ of _ month , day ( { 0 } ) ) ; add ( ops . date time ops . day _ of _ year , dayofyear ( { 0 } ) ) ; add ( ops . date time ops . add _ years , { fn timestampadd ( sql _ tsi _ year , { 1 } , { 0 } ) } ) ;
object h = base type . get value handler ( ) ;
options param api param = create options param api with config ( ) ;
add desired state change ( new disable depth writing ( ) ) ;
try { conf . set ( dfs _ namenode _ http _ address _ key , localhost _ server _ address ) ; cluster = new mini dfscluster . builder ( conf ) . num data nodes ( 0 ) . build ( ) ; cluster . wait active ( ) ; string address = cluster . get name node ( ) . get http address ( ) . to string ( ) ; assert true ( http bind address + address + is not wildcard . , address . starts with ( wildcard _ address ) ) ; } finally { if ( cluster = null ) { cluster . shutdown ( ) ; } }
assert not null ( body ) ; assert true ( should have bye camel , body . contains ( bye camel ) ) ; }
discard data ( ) ;
if ( args . args length ( ) = = 0 ) { targets = plugin . match players ( plugin . check player ( sender ) ) ; check permissions plugin . check permission ( sender , worldguard . heal ) ; } else if ( args . args length ( ) = = 1 ) { targets = plugin . match players ( sender , args . get string ( 0 ) ) ; check permissions plugin . check permission ( sender , worldguard . heal . other ) ; } for ( player player : targets ) { player . set health ( player . get max health ( ) ) ; player . set food level ( 20 ) ; player . set saturation ( 20 ) ; player . set exhaustion ( 0 ) ; tell the user if ( player . equals ( sender ) ) { player . send message ( chat color . yellow + healed ) ; keep track of this included = true ; } else { player . send message ( chat color . yellow + healed by + plugin . to name ( sender ) + . ) ; } }
if ( m _ recovery complete . await ( 30 , time unit . seconds ) ) { org . voltdb . volt db . crash local volt db ( timed out waiting for the agreement site to recover , false , null ) ; } }
assert equals ( item1 . to upper case ( ) , valid elm1 ) ; assert equals ( item2a . to upper case ( ) , valid elm2a ) ; assert equals ( item2b . to upper case ( ) , valid elm2b ) ;
avatar storage setup . validate ( conf , namedirs , editsdir , img0 , img1 , edit0 , edit1 ) ; file system local fs = file system . get local ( conf ) . get raw ( ) ;
socket . get output stream ( ) . write ( body . get buffer ( ) , 0 , body . get len ( ) ) ; }
log . info ( test deleted table + test _ table ) ;
advertise editing shortcuts ( global display , commands ) ;
this . timer service . set continue existing periodic tasks after shutdown policy ( false ) ; this . timer service . set execute existing delayed tasks after shutdown policy ( false ) ; }
assert equals ( r2 . ginfo . _ obj val , r3 . ginfo . _ obj val , 1e - 8 ) ; assert equals ( . 5 * glmp . _ lambda [ 0 ] * array utils . l2norm ( r3 . coefs , true ) + r3 . ginfo . _ obj val , 1e - 4 , 5e - 4 ) ; assert true ( iter expected < 100 , got + r3 . iter , r3 . iter < 100 ) ; } finally {
adapter item app item = adapter item . as app ( position + + , section name , last section info . num apps + + , info ) ; if ( last section info . first app item = = null ) { last section info . first app item = app item ; last fast scroller section info . fast scroll to item = app item ; } m adapter items . add ( app item ) ; m filtered apps . add ( info ) ; }
assert that ( is host component ( get component at ( layout state , 0 ) ) ) . is true ( ) ;
multipart config element multipart config = ( ( servlet holder . registration ) s . get registration ( ) ) . get multipart config ( ) ; if ( multipart config = null ) { out . open tag ( multipart - config , origin ( md , s . get name ( ) + . servlet . multipart - config ) ) ; if ( multipart config . get location ( ) = null ) out . tag ( location , multipart config . get location ( ) ) ; out . tag ( max - file - size , long . to string ( multipart config . get max file size ( ) ) ) ; out . tag ( max - request - size , long . to string ( multipart config . get max request size ( ) ) ) ; out . tag ( file - size - threshold , long . to string ( multipart config . get file size threshold ( ) ) ) ; out . close tag ( ) ; } out . close tag ( ) ;
return ( input row parser < t > ) new transforming string input row parser ( parser . get parse spec ( ) , ( ( string input row parser ) parser ) . get encoding ( ) , this ) ; } else {
expect throws ( illegal state exception . class , ( ) - > { new index revision ( writer ) ; } ) ; writer . close ( ) ;
string text = ris . get text ( 64 ) ; assert equals ( new string ( data , 0 , 64 , utf - 8 ) , text ) ;
return new file info ( file type . not _ raid , null ) ;
if ( _ config files = null ) { for ( string cfg : _ config files ) { try ( resource resource = resource . new resource ( cfg ) ) { xml configuration xml configuration = new xml configuration ( resource . get url ( ) ) ; xml configuration . configure ( _ server ) ; } } }
for ( map . entry < string , object > entry : properties . entry set ( ) ) { exchange . set property ( entry . get key ( ) , entry . get value ( ) ) ; } if ( pattern = null ) { exchange . set pattern ( pattern ) ; } return exchange ;
if ( h . is finished ( ) ) { sentinels . remove ( snapshot table ) ; } return h ; }
set title ( select color ) ;
queues . get ( capacity scheduler configuration . root ) . get queue resource usage ( ) . inc pending ( resources . create resource ( 1 * gb ) ) ; a . get queue resource usage ( ) . inc pending ( resources . create resource ( 1 * gb ) ) ; b . get queue resource usage ( ) . inc pending ( resources . create resource ( 1 * gb ) ) ; c . get queue resource usage ( ) . inc pending ( resources . create resource ( 1 * gb ) ) ; d . get queue resource usage ( ) . inc pending ( resources . create resource ( 1 * gb ) ) ; final string user _ 0 = user _ 0 ;
session . start ( ) ;
set < string > file set = new hash set < string > ( ) ; file set . add ( atomserverl . properties ) ; file set . add ( atomserverm _ slave . properties ) ; disconf center host files store . get instance ( ) . add just host file set ( file set ) ; disconf mgr . get instance ( ) . set application context ( application context ) ;
string rtcp port = parser . get attribute value ( , colibri conference iq . channel . rtcp _ port _ attr _ name ) ; if ( ( rtcp port = null ) & & ( rtcp port . length ( ) = 0 ) ) { channel . set rtcpport ( integer . parse int ( rtcp port ) ) ; }
intent intent = new intent ( this , wplaunch activity . class ) ; intent . add flags ( intent . flag _ activity _ clear _ task | intent . flag _ activity _ new _ task ) ; start activity ( intent ) ; }
setup servlet ( ) ; }
receive message ( ) ;
assert equals ( sink . get map count ( ) , sink . get found key count ( ) ) ; }
offset + = payload length ; if ( is last ) msg . increment fragment number ( ) ;
test header ( user - agent : air player 1 . 0 . 09 cfnetwork 485 . 13 . 9 darwin 11 . 0 . 0 , unknown renderer ) ;
assert query ( select cast ( 1 as decimal ( 3 , 2 ) ) in ( select cast ( 1 as decimal ( 3 , 1 ) ) ) , select true ) ;
assert equals ( num locations , storage . get num storage dirs ( ) ) ;
allocation node first node to discard = last node to keep . next ;
sers . put ( void . type , null serializer . class ) ; return sers . entry set ( ) ;
element spec spec = new element spec ( pattr , element spec . end tag type ) ; parse buffer . add element ( spec ) ; spec = new element spec ( pattr , element spec . start tag type ) ; parse buffer . add element ( spec ) ; if ( p paragraph . get end offset ( ) = end offset ) return element spec . join fracture direction ; element parent = p paragraph . get parent element ( ) ; if ( ( parent . get element index ( offset ) + 1 ) < parent . get element count ( ) ) return element spec . join next direction ;
client . get default request options ( ) . set retry policy factory ( new retry exponential retry ( retry policy . default _ client _ backoff , azure storage settings . get max retries ( ) ) ) ; return client ; }
string [ ] tags = letter ending for numeric helper . find tags ( left word , right word ) ;
b2 . set ( 420 ) ;
arrays . sort ( array , arbitrary ) ;
assert near cache size eventually ( context , 0 ) ;
excerpt . set num terms ( j - start token ) ;
if ( concat all . subword count > last concat count ) { if ( word pos = = concat all . start pos ) {
string [ ] sel args = null ; if ( selection = null ) { use selection if provided sel args = new string [ ] { query } ;
if ( this . read only = read only ) { final entity persister persister = session . get factory ( ) . get entity persister ( entity name ) ; if ( persister . is mutable ( ) & & read only ) { throw new illegal state exception ( cannot make proxies for immutable entities modifiable ) ; } this . read only = read only ; if ( initialized ) { entity key key = generate entity key or null ( get identifier ( ) , session , get entity name ( ) ) ; if ( key = null & & session . get persistence context ( ) . contains entity ( key ) ) { session . get persistence context ( ) . set read only ( target , read only ) ; } } }
model node result = execute ( get topic operation ( list - all - subscriptions ) , true ) ;
this . channel1 = socket channel . open ( ) ;
zz marked pos = zz marked pos l ;
if ( character . ordinal ( ) < 2 ) mojam component . sound player . play sound ( sound falling _ male . wav , ( float ) pos . x , ( float ) pos . y ) ; else mojam component . sound player . play sound ( sound falling _ female . wav , ( float ) pos . x , ( float ) pos . y ) ;
list < e > foreign keys = new array list < e > ( ) ; table schema table = table api . get table ( table name ) ; index index = schema table . get index ( p key column name ) ; index key index key = index . create index key ( ) ;
assert same ( result , async result . get value ( ) ) ;
assert that ( actual action ) . overriding error message ( expected action < % s > but was < % s > , drag event action to string ( action ) , drag event action to string ( actual action ) ) . is equal to ( action ) ; return this ;
int saved count = curve vertex count ; vertex ( x0 , y0 ) ; for ( int j = 0 ; j < curve detail ; j + + ) { x0 + = xplot1 ; xplot1 + = xplot2 ; xplot2 + = xplot3 ; y0 + = yplot1 ; yplot1 + = yplot2 ; yplot2 + = yplot3 ; vertex ( x0 , y0 ) ; }
if ( m current viewport . left = = m current viewport . right ) m current viewport . right + + ; if ( m current viewport . top = = m current viewport . bottom ) m current viewport . top + + ; }
conf . set ( hconstants . hbase _ region _ split _ policy _ key , constant size region split policy . class . get name ( ) ) ; }
out [ - - wpos ] = neg ? ( char ) ( zero _ exponent - exp ) : ( char ) ( zero _ exponent + exp ) ; return outend - wpos ; the length of the base100 int
set selected ( false ) ; jpopup menu resize menu = create resize video menu ( ) ;
compile ( get compilation units ( test entities ) ) ; if ( ignore compilation errors ) { test util . assert no compilation error ( compilation diagnostics ) ; } original statement . evaluate ( ) ; }
path kotlin home = test data directory . resolve ( faux _ kotlin _ home ) . normalize ( ) ; path kotlin compiler = kotlin home . resolve ( bin ) . resolve ( kotlinc ) ; more files . make executable ( kotlin compiler ) ; buck config buck config = fake buck config . builder ( ) . set sections ( immutable map . of ( kotlin , immutable map . of ( external , true ) ) ) . set environment ( immutable map . of ( kotlin _ home , test data directory . resolve ( faux _ kotlin _ home ) . to absolute path ( ) . to string ( ) ) ) . build ( ) ;
input stream [ ] ins = new input stream [ value count ] ; try { for ( int i = 0 ; i < value count ; i + + ) { ins [ i ] = new file input stream ( entry . get clean file ( i ) ) ; } } catch ( file not found exception e ) { a file must have been deleted manually return null ; } redundant op count + + ;
ok to ignore prefix = false ; } else {
set < string > special suppressions = immutable set . of ( const , duplicate , extra require , missing require ) ; set < string > suppressions = sets . difference ( js doc . get suppressions ( ) , special suppressions ) ; if ( suppressions . is empty ( ) ) { t . report ( n , invalid _ suppress ) ; } }
final result result2 = region2 . get ( g , null ) ; assert equals ( 2 * result . size ( ) , result2 . size ( ) ) ; wal2 . sync ( ) ;
int next index = current offset + page length * cache _ ratio + cache overlap ; if ( next index > = size ) {
get conf ( ) . set boolean ( dist cp constants . conf _ label _ simple _ listing _ randomize _ files , false ) ; simple copy listing listing = new simple copy listing ( get conf ( ) , credentials ) ; listing . build listing ( listing file , new dist cp context ( options ) ) ; assert . assert equals ( listing . get number of paths ( ) , path count ) ;
int j = evaluate expression ( frame dmc , expression _ 2 ) . int value ( ) ; assert true ( watchpoint problem : + expression _ 2 + was + j + instead of + 20 , j = = 20 ) ; }
string config name = ocmh . zk state reader . read config name ( collection name ) ; backup mgr . download config dir ( location , backup name , config name ) ;
byte p ; dest [ d + + ] = ( byte ) alphabets [ ( p = src [ s + + ] ) > > > 2 & mask _ 6 bits ] ; 6 dest [ d + + ] = ( byte ) alphabets [ ( p & mask _ 2 bits ) < < 4 | ( p = src [ s ] ) > > > 4 & mask _ 4 bits ] ; 2 4 dest [ d + + ] = ( byte ) alphabets [ ( p & mask _ 4 bits ) < < 2 ] ; 4 dest [ d ] = pad ; return ; }
map < string , object > results = super . run ( new input , engine ) ;
system . out . println ( end timer = + system . current time millis ( ) ) ;
test joins ( to coll , from coll , to doc id , false ) ; }
id = new read only row id ( rs . get row ( ) ) ;
file utils . write ( healthcheck , instant . now ( ) . to string ( ) , utf - 8 ) ; } catch ( ioexception e ) { throw new solr exception ( solr exception . error code . server _ error , unable to write healthcheck flag file , e ) ; } } else {
delete panel . set content ( constants . admin uimsg . user delete1 ( ) + user email + constants . admin uimsg . user delete2 ( ) ) ; delete panel . show ( ) ; delete panel . get confirm btn ( ) . add click handler ( new click handler ( ) { @ override public void on click ( click event event ) {
_ zk client . get zoo keeper ( ) . get data ( foo link 1 , null , callback , 1 ) ;
final byte string entity = response . get entity ( ) ; string content type = response . get header ( content _ type ) ;
ps . set string ( 1 , ( string ) map . get ( user _ id ) ) ;
options . minimum transaction id ( 2 ) . maximum transaction id ( 2 ) ; ru = of . get record updater ( root , options ) ; for ( int i = 0 ; i < values [ 1 ] . length ; + + i ) { ru . insert ( 2 , new my row ( values [ 1 ] [ i ] ) ) ; } ru . close ( false ) ; input format inf = new orc input format ( ) ;
draw header row and events ( canvas ) ;
if ( bin index > = bins ) { bin index = bins - 1 ; } } histogram bin bin = ( histogram bin ) bin list . get ( bin index ) ; bin . increment count ( ) ; }
if ( table . get partitioncolumn ( ) = null ) { return false ; } m _ mv table scan = mv table scan ;
if ( object . class . equals ( expected type ) ) { fallback candidate = info ; matches = false ; break ; } boolean matching types = is parameter matching type ( parameter type , expected type ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( insufficient storage cluster capacity ) ) return null ; insufficient storage cluster capacity exception e = ( insufficient storage cluster capacity exception ) super . unmarshall ( node ) ;
assert equals ( node2 , read decision . get node decisions ( ) . iterator ( ) . next ( ) . get node ( ) . get id ( ) ) ;
throw lse ;
query . get set session properties ( ) . entry set ( ) . for each ( entry - > response . header ( presto _ set _ session , entry . get key ( ) + ' = ' + entry . get value ( ) ) ) ;
m tab strip filter = new tab strip event filter ( context , this , new tab strip event handler ( ) , null , false , false ) ; m tab strip layout helper manager = new strip layout helper manager ( context , this , m host . get layout render host ( ) , m tab strip filter ) ;
index ( test , type1 , 3 , text , new string [ ] { } ) ; refresh ( ) ; ids query builder = query builders . ids query ( type1 ) . add ids ( 3 ) ; field . highlighter type ( plain ) ; response = client ( ) . prepare search ( test ) . set query ( ids query builder ) . highlighter ( new highlight builder ( ) . field ( field ) ) . get ( ) ; assert not highlighted ( response , 0 , text ) ; field . highlighter type ( fvh ) ; response = client ( ) . prepare search ( test ) . set query ( ids query builder ) . highlighter ( new highlight builder ( ) . field ( field ) ) . get ( ) ; assert not highlighted ( response , 0 , text ) ;
route route = get route ( route id ) ;
results = table . coprocessor exec ( ping protocol . class , row _ ab , row _ bc , new batch . call < ping protocol , string > ( ) { public string call ( ping protocol instance ) { return instance . ping ( ) ; } } ) ;
statement . set null ( prepared patam index + 1 , types . double ) ;
final batch writer writer = table utils . create batch writer ( this ) ;
final console console = make custom console ( context , verbosity , buck config ) ;
final jmxservice url url ; if ( connector port > 0 ) { url = new jmxservice url ( service : jmx : rmi : + host + : + connector port + jndi rmi : + host + : + registry port + path ) ; } else { url = new jmxservice url ( service : jmx : rmi : jndi rmi : + host + : + registry port + path ) ; } cs = jmxconnector server factory . new jmxconnector server ( url , null , server ) ;
final field field = get field ( bean , property name ) ; if ( field = null ) { try { field . set accessible ( true ) ; return field . get ( bean ) ; } catch ( exception e ) { * * } } return null ;
s . persist ( item ) ; assert true ( the item is contained in the session after deletion , s . contains ( item ) ) ; assert true ( the part is contained in the session after deletion , s . contains ( part ) ) ; s . get transaction ( ) . commit ( ) ;
assert decimal function ( bigint ' 13 ' % decimal ' 9 . 0 ' , decimal ( 4 . 0 ) ) ; assert decimal function ( bigint ' 18 ' % decimal ' 0 . 01 ' , decimal ( . 00 ) ) ; assert decimal function ( bigint ' 9 ' % decimal ' . 1 ' , decimal ( . 0 ) ) ;
return format . no _ value ;
try { query part substitute = substitutes . get ( integer . value of ( token ) ) ; render . visit ( substitute ) ; if ( bind = null ) { bind . visit ( substitute ) ; } }
if ( paths . length = num tasks ) { throw new runtime exception ( string . format ( number of specified files % d not equal to number of tasks % d , paths . length , num tasks ) ) ; }
string suffix = test util . random realistic unicode string ( random ( ) , 10 , 20 ) ; terms . add ( new bytes ref ( prefix + suffix ) ) ; } } }
result . is _ abstract = object stream class corba ext . is abstract interface ( class name ) ;
class node mr = overriding method . get return type ( ) ; class node omr = old method . get return type ( ) ; boolean equal return type = mr . equals ( omr ) ; class node testmr = correct to generics spec ( generics spec , omr ) ;
assert equals ( normalize conjuncts ( effective predicate ) , normalize conjuncts ( less than ( be , ae ) , less than ( ce , bigint literal ( 10 ) ) , equals ( de , ee ) , less than ( fe , bigint literal ( 100 ) ) , equals ( ae , de ) , equals ( be , ee ) ) ) ;
tester . get gzip handler ( ) . set excluded agent patterns ( bar , fo . * ) ;
org . apache . hadoop . yarn . api . records . queue info child = mockito . mock ( org . apache . hadoop . yarn . api . records . queue info . class ) ;
return new vector2i ( tera math . add clamp at max ( size . x , get total width ( ) ) , tera math . add clamp at max ( size . y , get total height ( ) ) ) ;
string [ ] new allocated ids = new string [ size ] ; system . arraycopy ( allocated ids , 0 , new allocated ids , 0 , allocated ids . length ) ; allocated ids = new allocated ids ; } allocated ids [ id ] = slashed class name ; next type id + + ; increase at the end once the value has been set in the array }
constants for fields . put ( field name , constant field . build ( ) ) ; return constant field . build ( ) ;
bulk iteration base < ? > iteration = ( bulk iteration base < ? > ) p . get data sinks ( ) . iterator ( ) . next ( ) . get input ( ) ; assert equals ( job name , p . get job name ( ) ) ; assert equals ( default parallelism , p . get default parallelism ( ) ) ;
if ( children = null & & children . size ( ) > 0 ) { if ( allow recipients ) { errors . add ( capitalize ( context ) + has recipients but no policy directive . ) ; return false ; } for ( string child : children ) { verify ( app , table , hop , null , child , errors , recipient ' + child + ' in + context ) ; } }
df = df . add series ( myseries , true , true , false , false , true ) ;
if ( zk props . get property ( sync limit ) = = null ) { zk props . set property ( sync limit , string . value of ( default _ zookeeper _ sync _ limit ) ) ; log . warn ( no ' sync limit ' configured . set to ' { } ' . , default _ zookeeper _ sync _ limit ) ; }
{ file system localfs = file system . get local ( job conf ) ; string test _ root _ dir = new file ( system . get property ( test . build . data , tmp ) ) . to string ( ) . replace ( ' ' , ' + ' ) ; path local in = localfs . make qualified ( new path ( test _ root _ dir + local in ) ) ; path local out = localfs . make qualified ( new path ( test _ root _ dir + local out ) ) ; result = launch word count ( job conf , local in , local out , all your base belong to us , 1 , 1 ) ; assert equals ( all \ t1 \ nbase \ t1 \ nbelong \ t1 \ nto \ t1 \ nus \ t1 \ nyour \ t1 \ n , result . output ) ; assert true ( outputs on localfs , localfs . exists ( local out ) ) ; }
cluster . sync ( slave1 ) ;
final road traffic data loader data loader = new road traffic data loader ( graph , user ) ;
assert equals ( out1 . get length ( ) , out2 . get length ( ) ) ;
if ( s rgb _ present ) { iiometadata node s rgb _ node = new iiometadata node ( s rgb ) ; s rgb _ node . set attribute ( rendering intent , rendering intent names [ s rgb _ rendering intent ] ) ; root . append child ( s rgb _ node ) ; }
slice _ from ( g ) ; break ; case 11 :
statement . set null ( prepared patam index + 1 , types . bigint ) ; } else { statement . set long ( prepared patam index + 1 , column . as long ( ) ) ; } break ; case types . float : case types . double : string float value = column . as string ( ) ; if ( empty as null & & . equals ( float value ) | | float value = = null ) {
case arith . double :
string builder expected = new string builder ( ) ;
m draw paint . set alpha ( key _ shadow _ alpha ) ;
no successor ( ) ;
if ( port = = 0 ) { sock . bind ( null ) ; server port = sock . get local port ( ) ; } else { sock . bind ( new inet socket address ( port ) ) ; } return sock ; } catch ( ioexception ioe ) {
graph . disconnect ( a , a ) ;
if ( action bar sherlock . debug ) log . d ( tag , got < activity > ) ;
wipe datanode ( node n ) ; node n = null ; } if ( node s = null ) { if ( node n = = node s ) {
class sclass = attr uri . get class ( ) ; class [ ] arg types = new class [ ] { sclass , sclass , sclass , sclass } ; meth = elem . get class ( ) . get method ( setter string , arg types ) ;
a1 . set pi ( b ) ; json serializer serializer = new json serializer ( ) . deep ( true ) ;
protocol . add response ( null , verification . request type result ) ;
set content type ( new org . docx4j . openpackaging . contenttype . content type ( org . docx4j . openpackaging . contenttype . content types . vml _ drawing ) ) ;
iterator < string > it = match list . iterator ( ) ; while ( it . has next ( ) ) { if ( . equals ( it . next ( ) ) ) { it . remove ( ) ; } } string [ ] result = new string [ match list . size ( ) ] ; return match list . to array ( result ) ; }
int idx = 0 ; for ( int value lv : iva ) { assert equals ( idx + + , lv . get value ( ) ) ; }
assert that ( adapter . get view ( position , null , container ) ) . is same as ( view ) ; verify ( title text view ) . set text ( title + position ) ; }
d = ( d < 0 ) ? math . abs ( d ) + 2 : - ( d + 2 ) ;
string file = get job id file path ( ) ; return controller . kill job ( file ) ;
block location [ ] b = { new block location ( null , null , 10 , 10 ) } ;
if ( progress mode width < progress rect . width ( ) - circle radius & & progress mode width > = circle radius ) { rect progress rect = new rect f ( progress rect . left + circle radius , progress rect . top , progress rect . left + progress mode width , progress rect . bottom ) ; }
ready to connect = true ; return ( new ops & old ops ) = 0 ; }
menu view . set layout params ( layout params ) ;
zk1 . set data ( ch1 , 1 . get bytes ( ) , - 1 ) ;
check for instance in routing table ( true , instance name ) ;
try { tuple ds . first ( 1 ) ; } catch ( exception e ) { assert . fail ( ) ; }
transformer tran = super . get transformer ( ) ;
parse detail events if exist ( line , pos , event ) ;
collection controller = filter controller by package and prefix ( collection controllers , controller package , path prefix ) ;
int type = find _ all _ prop ; string depth str = req . get header ( depth ) ;
if ( arrays . equals ( hregion info . get table name ( info . get region name ( ) ) , this . table name ) ) { return bypass ; }
crosstool string = text format . print to string ( config builder ) ; config . overwrite ( default _ osx _ crosstool _ dir + crosstool , crosstool string ) ;
if ( offset = = 0 & & buf . length = = length ) { next bytes ( buf ) ; } else { byte [ ] tmp = new byte [ length ] ; next bytes ( tmp ) ; system . arraycopy ( tmp , 0 , buf , offset , length ) ; }
httpsampler base sampler = httpsampler factory . new instance ( request . get http sampler name ( ) ) ; sampler . set property ( test element . gui _ class , http test sample gui . class . get name ( ) ) ;
assert null ( manies eeone state orig . get key ( ) ) ; assert null ( manies eeone state orig . get role ( ) ) ;
final string name = get attribute ( name ) ;
string depends = element . get attribute ( bean definition parser delegate . depends _ on _ attribute ) ; if ( string utils . has text ( depends ) ) { builder . get raw bean definition ( ) . set depends on ( string utils . tokenize to string array ( depends , bean definition parser delegate . multi _ value _ attribute _ delimiters ) ) ; } named node map attributes = element . get attributes ( ) ;
assert equals ( 1 . 2 . 3 . 4 , inet address . parse numeric address ( 1 . 2 . 3 . 4 ) . to string ( ) ) ;
final string sign id = article . opt string ( article . article _ sign _ id , 1 ) ; article . put ( article . article _ sign _ id , sign id ) ;
state . after element = true ;
task t2 = check assignment ( tt1 , attempt _ test _ 0001 _ r _ 000001 _ 0 on tt1 ) ;
m image view . set scale and center ( max scale , new point f ( image width 2 , image height 2 ) ) ;
final stylesheet sheet = stable . add stylesheet ( _ name , this ) ;
assert equals ( c4 . class . get declared method ( m1 , int [ ] [ ] . class , string [ ] [ ] . class ) , java code serializer . resolve method ( my test model store . org . reflections . test model c4 . methods . m1 _ int _ _ java _ lang _ string . class ) ) ;
add left separator ( ) ; toolbar popup menu pane layout menu = new toolbar popup menu ( ) ; pane layout menu . add item ( commands _ . layout end zoom ( ) . create menu item ( false ) ) ; pane layout menu . add separator ( ) ;
if ( message = null ) { conversation ( peer ) . add or update item ( message . change reactions ( reactions ) ) ; } return promise . success ( null ) ; }
send to light flow ( context , title , message long ) ; }
try { zoo keeper zk = cache . get zoo keeper ( ) ; for ( string path : paths ) { if ( cache . exists ( path ) ) { continue ; } try { zk utils . create full path optimistic ( zk , path , new byte [ 0 ] , ids . open _ acl _ unsafe , create mode . persistent ) ; } catch ( keeper exception . node exists exception e ) { ok } } } catch ( exception e ) { log . error ( e . get message ( ) , e ) ; throw new pulsar server exception ( e ) ; }
if ( end view = null ) { shape end shape ; if ( end view = = v1 ) { end shape = v1 . model to view ( v1 . get start offset ( ) , position . bias . forward , p1 , b1 , r1 ) ; } else { end shape = v0 . model to view ( p0 , b0 , v0 . get end offset ( ) , position . bias . backward , r0 ) ; } if ( end shape instanceof rectangle ) { ret rect . add ( ( rectangle ) end shape ) ; } else { ret rect . add ( end shape . get bounds ( ) ) ; } } return ret rect ;
element . set property ( ftpsampler . server , server . get text ( ) ) ; element . set property ( ftpsampler . port , port . get text ( ) ) ; element . set property ( ftpsampler . remote _ filename , remote file . get text ( ) ) ; element . set property ( ftpsampler . local _ filename , local file . get text ( ) ) ; element . set property ( ftpsampler . input _ data , input data . get text ( ) ) ; element . set property ( ftpsampler . binary _ mode , binary mode . is selected ( ) ) ; element . set property ( ftpsampler . save _ response , save response data . is selected ( ) ) ; element . set property ( ftpsampler . upload _ file , put box . is selected ( ) ) ; }
io . delete ( node a ) ; provider . scan ( ) ; provider . scan ( ) ; assert equals ( remove node , scanned . poll ( 1 , time unit . seconds ) ) ;
ast parent = astutil . find type in children ( this , get where clause parent token type ( ) ) ;
public void test unknown portable field _ not causes query exception _ with index ( ) { string map name = default ; config config = get config ( ) ; config . get serialization config ( ) . add portable factory ( 666 , new portable factory ( ) { public portable create ( int class id ) { return new portable employee ( ) ; } } ) ; config . get map config ( map name ) . add map index config ( new map index config ( not exist , false ) ) . add map index config ( new map index config ( n , false ) ) ; hazelcast instance hazelcast instance = create hazelcast instance ( config ) ;
cluster state = failed cluster state task executor . execute ( cluster state , failure entries ) . resulting state ; assert that ( cluster state . meta data ( ) . index ( test ) . in sync allocation ids ( 0 ) , equal to ( collections . singleton ( primary shard . allocation id ( ) . get id ( ) ) ) ) ;
if ( msg . is ack ( ) ) sip _ provider . send message ( message factory . create response ( msg , 404 , sip responses . reason of ( 404 ) , null ) ) ; else print log ( message discarded , log level . high ) ; }
send ( http : 127 . 0 . 0 . 1 : 8192 service cbrproxy , 1000 ) ; stop watch watch = new stop watch ( ) ; send ( http : 127 . 0 . 0 . 1 : 8192 service cbrproxy , count ) ; log . warn ( ran { } tests in { } ms , count , watch . taken ( ) ) ; }
assert . assert equals ( target date . to local time ( ) , reference date time . to local time ( ) ) ;
assert true ( close . has observers ( ) ) ;
reference renderer = renderer ; } else {
new state message checker ( nodes ) { @ override int expected message count ( final dummy vds node node ) { return 2 ; } } ; }
welcome screen my screen = reflection util . get field ( flat welcome frame . class , this , welcome screen . class , my screen ) ;
set < t > all mappings = this . handler methods . key set ( ) ; add matches to collection ( all mappings , message , matches ) ; }
return create token ( user login , created at , now + 5 * 60 * 1000 ) ;
int ins idx = this . controller . instance pos [ idx ] ;
assert that ( git . contains revision in branch ( git test repo . revision _ 1 ) , is ( false ) ) ;
assert . assert equals ( e . get message ( ) , none of the requested protocols : [ unsupported ] are found in sslcontext ) ;
check = mock selection key . attach ( null ) ; assert same ( o , check ) ; check = mock selection key . attach ( o ) ; assert null ( check ) ; }
s = solver . coordinate _ descent ;
document for cluster selection = ( odocument ) orecord internal . fill ( new odocument ( ) , i record id , i record version , i content , false ) ; } check for cluster ( document for cluster selection , local node name , db cfg ) ; final list < string > servers = db cfg . get servers ( cluster name , null ) ; if ( servers . is empty ( ) )
cache0 . put ( hello , world 1 ) ; assert equals ( world 1 , cache2 . get ( hello ) ) ;
selected storage = select _ 0 ;
assert good ( sie fällt auf durch ihre hilfsbereite art . zudem zeigt sie soziale kompetenz . ) ; assert good ( das ist es : kein satz . ) ; assert good ( werner dahlheim : die antike . ) ;
return rdn . unescape value ( escaped ) . to string ( ) ;
b serializer . serialize ( out , t . b ) ;
int offset = random . next int ( 0 , 1000 * byte size - byte size ) & ( byte size - 1 ) ; int length = math . min ( capacity , random . next int ( byte size , capacity - offset ) & ( byte size - 1 ) ) ; byte buffer region = buffer . get page region ( offset , length ) ;
b2 . put int32 to int32 field ( 1 , 0 ) ; m2 = b2 . build ( ) ; assert false ( m1 . equals ( m2 ) ) ;
this . factor filter list . put ( filter . get factor name ( ) , filter ) ;
get elements = new get elements . builder ( ) . input ( new entity seed ( a ) , new entity seed ( x ) ) . in out type ( include incoming outgoing type . outgoing ) . build ( ) ; results = graph . execute ( get elements , new user ( ) ) ;
last committed segment infos = store . read last committed segments info ( ) ;
world provider . set block ( block component . get position ( ) , block manager . get block ( block manager . air _ id ) ) ;
if ( b a = = hl7 acknowledgement bytes [ i + 5 ] ) { acknowledgement type = aa ; } else { acknowledgement type = ca ; }
bis = new base64 . input stream ( new java . io . buffered input stream ( new java . io . file input stream ( file ) ) , base64 . decode ) ;
init lazy fields ( oi . get all struct field refs ( ) ) ; }
_ transport . get writer ( ) . wants write ( this , outbound connected ) ; }
byte order mark = find ( ) ;
conf . set reservable ( dedicated , true ) ; conf . set capacity ( prefix + new q , 80 ) ;
on close . execute ( get current options ( options ) ) ;
collections . sort ( answer , new comparator < map < string , string > > ( ) { @ override public int compare ( map < string , string > service1 , map < string , string > service2 ) { string scheme1 = service1 . get ( scheme ) ; string scheme2 = service2 . get ( scheme ) ; if ( scheme1 = null & & scheme2 = null ) { return scheme1 . compare to ( scheme2 ) ; } else if ( scheme1 = null ) { return - 1 ; } else if ( scheme2 = null ) { return 1 ; } else { string from1 = service1 . get ( from ) ; string from2 = service2 . get ( from ) ; if ( from1 . equals ( from2 ) ) { string to1 = service1 . get ( to ) ; string to2 = service2 . get ( to ) ; return to1 . compare to ( to2 ) ; } return from1 . compare to ( from2 ) ; } } } ) ;
assert . assert true ( passivation interceptor . get post activate target ( ) = = null ) ;
get context ( ) . get package scan class resolver ( ) . remove filter ( filter ) ; }
m folded label = ( m folded label = = null ) ? no text : m folded label ; m un folded label = ( m un folded label = = null ) ? no text : m un folded label ; }
get transaction ( ) . failure ( ) ;
array list < card > cards = new array list < card > ( ) ; for ( int i = 0 ; i < 100 ; i + + ) { google play small card card = new google play small card ( this . get activity ( ) ) ; card . set title ( application example + i ) ; card . set secondary title ( a company inc . . . + i ) ; card . set rating ( ( float ) ( math . random ( ) * ( 5 . 0 ) ) ) ; card . set id ( + i ) ; only for test , change some icons if ( ( i > 10 & & i < 15 ) | | ( i > 35 & & i < 45 ) ) { card . set resource id thumbnail ( r . drawable . ic _ launcher ) ; } card . init ( ) ; cards . add ( card ) ; }
text file reader reader3 = new text file reader ( get configuration ( ) , new path ( test default path , customer3 ) , null ) ; test utils . read data and assert ( reader3 , data array3 ) ; }
urlclass loader ucl = access controller . do privileged ( new privileged action < urlclass loader > ( ) { public urlclass loader run ( ) { return new factory urlclass loader ( urls , parent , acc ) ; } } ) ; return ucl ;
font = font utils . get font ( this . get font ( ) . get font name ( ) ) ; } else {
publish update ( data . visible ( false ) ) ;
final unified service ref meta data service ref umdm = translate ( service ref md ) ; service ref umdm . set vfs root ( get unified virtual file ( unit ) ) ; process wsfeatures ( unit , service ref md . get injection targets ( ) , service ref umdm ) ; final wsref registry ws ref registry = ashelper . get wsref registry ( unit ) ; ws ref registry . add ( get cache key ( component description , service ref umdm ) , service ref umdm ) ; return service ref umdm ; }
sentence . add ( word _ missing _ person ) ;
throw new runtime exception ( get transformer fails in get content type , e ) ; }
return make filter result ( continuous query result . result type . leaving , key , null , null ) ; } else {
return new string ( chars , beg , cur - beg ) ; } break ; default : chars [ end + + ] = chars [ pos ] ; pos + + ; } }
string answer ; if ( parser instanceof augmented property name aware properties parser ) { answer = ( ( augmented property name aware properties parser ) parser ) . parse uri ( text , properties , prefix token , suffix token , property prefix , property suffix , fallback to unaugmented property , default fallback enabled ) ; } else { answer = parser . parse uri ( text , properties , prefix token , suffix token ) ; }
assert false ( there should have no xml declaration . , mock . get exchanges ( ) . get ( 0 ) . get in ( ) . get body ( string . class ) . starts with ( < ?xml version = ) ) ;
hql token t = ( hql token ) lt ( 3 ) ; if ( t . is possible id ( ) ) { set it t . set type ( ident ) ; if ( log . is debug enabled ( ) ) { log . debugf ( handle dot ident ( ) : new lt ( 3 ) token - % s , lt ( 1 ) ) ; } } }
if ( ( descriptor instanceof fragment descriptor ) ) { add filter mapping ( filter _ name , node , context , descriptor ) ; } break ;
clazz . get method ( log method , string . class ) . invoke ( logger , msg ) ; assert true ( result . is empty ( ) ) ;
user param . set user pattern ( conf . get ( hdfs client config keys . dfs _ webhdfs _ user _ pattern _ key , hdfs client config keys . dfs _ webhdfs _ user _ pattern _ default ) ) ; acl permission param . set acl permission pattern ( conf . get ( hdfs client config keys . dfs _ webhdfs _ acl _ permission _ pattern _ key , hdfs client config keys . dfs _ webhdfs _ acl _ permission _ pattern _ default ) ) ; int connect timeout = ( int ) conf . get time duration ( hdfs client config keys . dfs _ webhdfs _ socket _ connect _ timeout _ key , urlconnection factory . default _ socket _ timeout , time unit . milliseconds ) ;
if ( is last segment ) { is last segment = false ; continue ; } if ( can delete segment ( segment ) ) { close and delete segments before ( segment . segment id ( ) , because of close of cursor ) ; break ; }
assert that ( entry . get name ( ) , matchers . equal to ( output . get parent ( ) . relativize ( input ) . to string ( ) ) ) ;
path file under today dir = new path ( done path yesterday . to string ( ) , job _ 1372363578825 _ 0016 - + time before200 secs + - user - sleep + job - + time before200 secs + - 1 - 1 - succeeded - default . jhist ) ; file status file under today dir status = new file status ( 10 , false , 0 , 0 , time before200 secs , file under today dir ) ; history file manager history manager = spy ( new history file manager ( ) ) ;
if ( attribute table view chain state [ bucket ] = large count ) { attribute table view chain state [ bucket ] = large count ; attr . next = null ; attribute table view [ bucket ] = attr ; }
viewer . get control ( ) . set background ( uiutils . get color registry ( ) . get ( erdconstants . color _ erd _ diagram _ background ) ) ;
job id = node . get printable id ( . _ . ) ; }
while ( start < = end ) { char val = arr [ start ] ; if ( val = = ' - ' ) neg = neg ; else if ( val > = ' 1 ' & & val < = ' 9 ' ) break ; start + + ; }
entry count threshold threshold = new entry count threshold ( 1 ) ;
headers . put ( camel box . types , null ) ; @ suppress warnings ( rawtypes ) final java . util . list result = request body and headers ( direct : getenterpriseevents , null , headers ) ; assert not null ( get enterprise events result , result ) ; log . debug ( get enterprise events : + result ) ; }
final int get key index = cpg . add methodref ( translet _ class , get key index , ( ljava lang string ; ) + key _ index _ sig ) ;
handler list list = new handler list ( ) ; server . add handler ( list ) ; if ( debug ) { log . info ( * added debug handler . ) ; list . add handler ( new log debug handler ( ) ) ; } if ( delay ) { log . info ( * added delay handler : + ( delay val < 0 ? random delay up to + ( - delay val ) : constant delay of + delay val ) ) ; list . add handler ( new delay handler ( delay val ) ) ; }
if ( use manifest caching ( ) ) { optional < rule key > on disk rule key = on disk build info . get rule key ( build info . metadata key . dep _ file _ rule _ key ) ; if ( on disk rule key . is present ( ) ) { rule keys . add ( on disk rule key . get ( ) ) ; } }
int target branch offset = ( ( branch instruction ) target instruction ) . branch offset ; instruction new branch instruction = new branch instruction ( opcode , ( branch offset + target branch offset ) ) ;
lb device . set allocation state ( lbdevice allocation state . free ) ;
expected query = select * from ( select a . * , rownum rn from ( select e . id from employee e ) a ) where rn > 3 and rownum < = 4 ;
assert equals ( 5 , listener . get events received ( ) . size ( ) ) ;
s _ logger . debug ( adding physical network service provider f5 big ip + in to physical network + physical network id ) ; string insert pnsp = insert into `cloud` . `physical _ network _ service _ providers` ( `uuid` , `physical _ network _ id` , `provider _ name` , `state` , + `destination _ physical _ network _ id` , `vpn _ service _ provided` , `dhcp _ service _ provided` , `dns _ service _ provided` , `gateway _ service _ provided` , + `firewall _ service _ provided` , `source _ nat _ service _ provided` , `load _ balance _ service _ provided` , `static _ nat _ service _ provided` , + `port _ forwarding _ service _ provided` , `user _ data _ service _ provided` , `security _ group _ service _ provided` ) values ( ? , ? , ? , ? , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 ) ; pstmt update = conn . prepare statement ( insert pnsp ) ;
if ( m target view = null ) { final view target view = m target view ; margin layout params lp = ( margin layout params ) target view . get layout params ( ) ; final int target left = padding left + lp . left margin ; final int target top ; switch ( m style ) { case style . classic : classic target top = padding top + lp . top margin + m target offset ; break ; case style . above : above target top = padding top + lp . top margin ; break ; case style . blew : classic target top = padding top + lp . top margin + m target offset ; break ; case style . scale : classic target top = padding top + lp . top margin + m target offset ; break ; default : classic target top = padding top + lp . top margin + m target offset ; break ; } final int target right = target left + target view . get measured width ( ) ; final int target bottom = target top + target view . get measured height ( ) ; target view . layout ( target left , target top , target right , target bottom ) ; }
for ( int i = 0 ; i < hosts racks . size ( ) ; i + + ) { if ( hosts racks . get ( i ) . equals ( network topology . default _ rack ) ) { log . warn ( could not resolve rack for : + hosts in . get ( i ) + probably due to a dns issue , removing + the host since we are in startup ) ; hosts racks . remove ( i ) ; hosts reader . get hosts ( ) . remove ( hosts in . get ( i ) ) ; hosts in . remove ( i ) ; i - - ; } }
writer . write ( data ) ; different from xml
object oid = null ; if ( headers . contains key ( hazelcast constants . object _ id ) ) { oid = headers . get ( hazelcast constants . object _ id ) ; } final hazelcast operation operation = lookup operation ( exchange ) ;
if ( textarea . is selection active ( ) ) { stop line - - ; }
client . prepare response ( join group follower response ( 1 , consumer id , leader , errors . none ) ) ; client . prepare response ( new mock client . request matcher ( ) { @ override public boolean matches ( abstract request body ) { sync group request sync = ( sync group request ) body ; return sync . member id ( ) . equals ( consumer id ) & & sync . generation id ( ) = = 1 & & sync . group assignment ( ) . is empty ( ) ; } } , sync group response ( singleton list ( t1p ) , errors . none ) ) ; coordinator . join group if needed ( ) ; assert false ( coordinator . need rejoin ( ) ) ;
file dir = new file ( directory ) ; if ( dir . is absolute ( ) ) { dir = new file ( get container ( ) . get catalina base ( ) , directory ) ; } if ( dir . mkdirs ( ) & & dir . is directory ( ) ) { log . error ( sm . get string ( access log valve . open dir fail , dir ) ) ; }
mini hbase cluster cluster = test _ util . get hbase cluster ( ) ; list < hregion > regions = cluster . get regions ( table1 ) ; byte [ ] name = regions . get ( 0 ) . get region info ( ) . get region name ( ) ;
try { no selector at all . client . call procedure ( @ statistics ) ; fail ( ) ; } catch ( proc call exception ex ) { all badness gets turned into proc call exceptions , so we need to check specifically for this error , otherwise things that crash the cluster also turn into proc call exceptions and don ' t trigger failure ( eng - 2347 ) assert equals ( incorrect number of arguments to @ statistics ( expects 2 , received 0 ) , ex . get message ( ) ) ; }
result set result set mock = mockito . mock ( result set . class ) ;
string name = controller . get simple type name ( ) . concat ( link factory ) ; if ( name . contains ( controller ) ) { name = name . replace ( controller , ) ; }
create buffer ( 0 ) , create buffer ( 2 ) , create buffer ( 0 ) , create barrier ( 1 , 1 ) , create barrier ( 1 , 2 ) , create buffer ( 2 ) , create buffer ( 1 ) , create buffer ( 0 ) , create barrier ( 1 , 0 ) ,
for ( int i = 0 ; i < count ; i + + ) { assert false ( lva . is full ( ) ) ; assert equals ( i , lva . size ( ) ) ; assert true ( lva . add ( new long value ( i ) ) ) ; assert equals ( i + 1 , lva . size ( ) ) ; }
finally { try { bos . close ( ) ; } catch ( exception e ) { }
if ( i = = 1 ) { assert equals ( processinstance _ start , entry . get type ( ) ) ; map < string , object > data = object mapper . read value ( entry . get data ( ) , new type reference < hash map < string , object > > ( ) { } ) ; assert null ( data . get ( fields . tenant _ id ) ) ; }
for ( hregion info hri : regions that should be online ) { assert true ( online regions . contains ( hri ) ) ; }
. header ( rx - user , async )
for ( int i = 0 ; i < account numbers . size ( ) ; i + + ) { material account account = account manager . get ( i ) ; account . set account number ( account numbers . get ( i ) ) ; if ( account . get account number ( ) = = material account . first _ account ) { current account = account ; } } notify account data changed ( ) ;
object graph extension2 = root . plus ( new extension module ( ) ) ; main main2 = extension2 . get ( main . class ) ; assert that ( main2 . ints ) . contains exactly ( 0 , 1 , 4 , 5 ) ; }
add string op ( icode _ name _ and _ this , name ) ;
throw new read only buffer exception ( ) ; }
file txn log trunc log = new file txn log ( data dir ) ;
tmp range = doc router . default . from string ( range obj . to string ( ) ) ;
triangle . is removed = true ; nb collapsed tri + + ;
int salt length = - 1 ; int iterations = - 1 ; int key length = - 1 ;
entity manager factory builder impl builder = ( entity manager factory builder impl ) bootstrap . get entity manager factory builder ( empty , collections . singleton map ( available settings . validation _ mode , validation mode . callback . name ( ) ) ) ; assert equals ( validation mode . callback . name ( ) , builder . get configuration values ( ) . get ( available settings . validation _ mode ) ) ; }
cred handle ph client credential = new cred handle ( ) ;
throw new org . apache . axis2 . databinding . adbexception ( etag cannot be null ) ; } else {
spdy data frame partial data frame = new default spdy data frame ( stream id ) ; partial data frame . set data ( spdy data frame . get data ( ) . read slice ( new window size ) ) ; channel future write future = channels . future ( e . get channel ( ) ) ;
if ( m recycler view = null ) { m recycler view . set adapter ( m card array adapter ) ; }
string model serde class = conf . get ( angel . modelconverts . serde . class , text model line convert . class . get name ( ) ) ;
annotate class if needed ( field details ) ;
if ( map . class . is assignable from ( component class ) ) { this . delegate = new multi dynamic component mapper ( property data ) ; this . component class = hash map . class ; } else { this . delegate = new multi property mapper ( ) ; this . component class = component class ; }
if ( null = image view ref . is alive ( ) | | image view = = null ) { cancel silently ( ) ; return ; } if ( image view . get drawable ( ) = result ) { imageview is now waiting for something else now . . . cancel cancel silently ( ) ; return ; }
final string text2 use = i upper case ? parser text upper case : parser text ; final int max = text2 use . length ( ) ; parser current pos = parser current pos + parser text upper case . length ( ) - parser text . length ( ) ;
expected exception . expect ( ioexception . class ) ; expected exception . expect message ( data corruption ) ; get ( server , job id , key ) ;
if ( buffers = null ) { if ( debug ) log . debug ( flushed incomplete ) ; pending state pending = new pending state ( buffers , callback ) ; if ( update state ( _ _ writing , pending ) ) on incomplete flush ( ) ; else fail ( pending ) ; return ; }
long primary version1 = primary . flush ( 0 ) ; assert true ( primary version1 > 0 ) ;
signed info elem = xmlutils . get next element ( element . get first child ( ) ) ;
map < string , object > filtered = xcontent map values . filter ( map , new string [ ] { foo } , new string [ 0 ] ) ;
assert null ( ia . get next input split ( testhost , 0 ) ) ;
log . trace ( retrieving file : { } from : { } , name , endpoint ) ;
executor . done ( detect pull request step . this , context ) ; } } ) ; }
m paint bubble = new paint ( paint . anti _ alias _ flag ) ; m paint bubble . set color ( color . white ) ; m paint bubble . set style ( paint . style . fill ) ; m paint text = new paint ( paint . anti _ alias _ flag ) ; m paint text . set color ( color . black ) ; m paint text . set style ( paint . style . fill ) ; m paint text . set text size ( 12 * m density ) ; }
body def body def = new body def ( ) ;
res = interpreter . interpret ( search logs { \ aggs \ : { \ status _ count \ : + { \ terms \ : { \ field \ : \ status \ } } } } , ctx ) ; assert equals ( code . success , res . code ( ) ) ; res = interpreter . interpret ( search logs { \ aggs \ : { + \ length \ : { \ terms \ : { \ field \ : \ status \ } , + \ aggs \ : { \ sum _ length \ : { \ sum \ : { \ field \ : \ content _ length \ } } , \ sum _ status \ : { \ sum \ : { \ field \ : \ status \ } } } } } } , ctx ) ;
e . print stack trace ( ) ; log . error ( cannot close resources . + e . get message ( ) ) ; } }
icenegociator ice negociator = new icenegociator ( server , port , ( short ) 1 ) ; negociators map . put ( server , ice negociator ) ;
log . warn ( + async process . id + , the task was rejected by the pool . this is unexpected . + server is + server . get server name ( ) , t ) ;
class < ? > super class = non match class . get superclass ( ) ;
if ( collector . contains ( actions ) ) { component dto project = components by project uuid . get ( dto . get project uuid ( ) ) ; result . add actions ( dto . get key ( ) , list available actions ( dto , project ) ) ; }
monitor . rethrow exception ( ) ; status . set status ( restoring wals to table . . . ) ; restore wals ( ) ; status . set status ( finished restoring wals to table . ) ; return meta changes ;
final list < host selector > selectors = host selectors . stream ( ) . map ( selector str - > { final host selector parsed = host selector . parse ( selector str ) ; if ( parsed = = null ) { throw new web application exception ( response . status ( response . status . bad _ request ) . entity ( invalid host selector : + selector str ) . build ( ) ) ; } return parsed ; } ) . collect ( collectors . to list ( ) ) ; final map < string , map < string , string > > hosts and labels = get labels ( hosts ) ;
assert true ( ( ( file system ) get file system ( ) ) . rename ( original path , destination path ) ) ;
assert ( replaced ) ;
random access file local raf = raf ; synchronized ( local raf ) {
dispatch splits use location ( splits new api , workergroup number , task num in worker ) ;
last position = undecoded chunk . reader index ( ) ; } } }
spot placement placement = new spot placement ( ) ;
if ( stack . is empty ( ) ) { throw new simple parser exception ( token . get token ( ) . get type ( ) . get type ( ) + has no matching start token , token . get token ( ) . get index ( ) ) ; } block top = stack . pop ( ) ;
if ( p ui prefs _ . get ( ) . restore source documents ( ) . get value ( ) ) { source shim _ . close all source docs ( caption , ( ) - > handle unsaved changes ( caption , allow cancel , force save all , quit context ) ) ; } else { handle unsaved changes ( caption , allow cancel , force save all , quit context ) ; }
expression keys < t > ek = new expression keys < > ( field , input data set . get type ( ) ) ; this . group sort key positions = ek . compute logical key positions ( ) ;
for ( iblock = 0 ; iblock < ilbc _ constants . enh _ nblocks - ioffset ; iblock + + ) { lag = 10 ; maxcc = x corr coef ( downsampled , 60 + iblock * ilbc _ constants . enh _ blockl _ half , downsampled , 60 + iblock * ilbc _ constants . enh _ blockl _ half - lag , ilbc _ constants . enh _ blockl _ half ) ; for ( ilag = 11 ; ilag < 60 ; ilag + + ) { cc = x corr coef ( downsampled , 60 + iblock * ilbc _ constants . enh _ blockl _ half , downsampled , 60 + iblock * ilbc _ constants . enh _ blockl _ half - ilag , ilbc _ constants . enh _ blockl _ half ) ; if ( cc > maxcc ) { maxcc = cc ; lag = ilag ; } } * store the estimated lag in the non - downsampled domain * enh _ period [ iblock + ilbc _ constants . enh _ nblocks _ extra + ioffset ] = ( float ) lag * 2 ; }
if ( longs . length > 0 ) { bit set original = bit set . value of ( longs ) ; longs [ 0 ] = longs [ 0 ] ; assert false ( bit set . value of ( longs ) . equals ( original ) ) ; } }
public void set table name ( string table name ) { set db name ( table name ) ;
if ( m _ predictions = = null ) { return utils . missing value ( ) ; } else { threshold curve tc = new threshold curve ( ) ; instances result = tc . get curve ( m _ predictions , class index ) ; return threshold curve . get rocarea ( result ) ; }
olog manager . instance ( ) . warn ( this , session % s is trying to access to the database ' % s ' , but has been authenticated against the database ' % s ' , i request . session id , i request . database name , current session . get database name ( ) ) ; ohttp session manager . get instance ( ) . remove session ( i request . session id ) ; send authorization request ( i request , i response , i request . database name ) ; return false ; } else if ( authentication parts = null & & current session . get user name ( ) . equals ( authentication parts . get ( 0 ) ) ) {
segment infos sis = segment infos . read latest commit ( dir ) ; assert equals ( 1 , sis . info ( 0 ) . get next del gen ( ) ) ;
volt table stats t = get stats ( client , procedure ) ; system . out . println ( stats : + stats t . to formatted string ( ) ) ; assert true ( volt table util . table contains string ( stats t , gc , true ) ) ; system . out . println ( stats t . to formatted string ( ) ) ; map < string , long > stats = aggregate proc row ( client , gc . class . get name ( ) ) ;
assert false ( scanner . backward seek ( key value util . create last on row ( rows [ 0 ] ) ) ) ;
clz = clz . get superclass ( ) ;
expanded . append ( blob . substring ( last end , match result . get start index ( ) ) ) ;
clock . set day ( today ) ; final account account = create account with non osgi payment method ( get account data ( 1 ) ) ;
final red black tree < integer > t1 = of ( 1 , 2 , 3 , 4 , 40 , 61 , 62 , 63 , 64 , 65 ) ;
for ( join node left node : left join orders ) { for ( join node right node : right join orders ) { join node result one = new branch node ( branch node . get id ( ) , branch node . get join type ( ) , ( join node ) left node . clone ( ) , ( join node ) right node . clone ( ) ) ; join node result two = new branch node ( branch node . get id ( ) , branch node . get join type ( ) , ( join node ) right node . clone ( ) , ( join node ) left node . clone ( ) ) ; if ( branch node . get join expression ( ) = null ) { result one . set join expression ( branch node . get join expression ( ) . clone ( ) ) ; result two . set join expression ( branch node . get join expression ( ) . clone ( ) ) ; } if ( branch node . get where expression ( ) = null ) { result one . set where expression ( branch node . get where expression ( ) . clone ( ) ) ; result two . set where expression ( branch node . get where expression ( ) . clone ( ) ) ; } join orders . add ( result one ) ; join orders . add ( result two ) ; } } return join orders ;
for ( keep = 0 ; keep < byte length & & a [ keep ] = = 0 ; keep + + ) ;
assert equals ( b , it . next ( ) ) ; assert no more ( it ) ; }
ast ast = node . get ast ( ) ; string literal combined string literal = ast . new string literal ( ) ; combined string literal . set literal value ( string builder . to string ( ) ) ; astrewrite rewrite = astrewrite . create ( ast ) ;
h table . get ( new get ( row ) . add family ( cf1 ) ) ;
tester . set content servlet ( content servlet ) ; try { string test filename = string . format ( % s - % s , content servlet . get simple name ( ) , file name ) ; file test file = tester . prepare server file ( test filename , file size ) ; tester . start ( ) ; http tester . response response = tester . execute request ( get , context + test file . get name ( ) , 5 , time unit . seconds ) ; if ( response . get status ( ) = 200 ) system . err . println ( dang + response ) ; assert that ( response status , response . get status ( ) , is ( http status . ok _ 200 ) ) ; if ( expect compressed ) { must be gzip compressed assert that ( content - encoding , response . get ( content - encoding ) , contains string ( gzip handler . gzip ) ) ; } else { assert that ( content - encoding , response . get ( content - encoding ) , not ( contains string ( gzip handler . gzip ) ) ) ; } uncompressed content size content metadata content = tester . get response metadata ( response ) ; assert that ( ( uncompressed ) content length , content . size , is ( ( long ) file size ) ) ; } finally { tester . stop ( ) ; }
if ( p . valid ) { set draw with layer ( p . v , true ) ; draw child ( canvas , p . v , 0 ) ; } draw previous shadow ( canvas ) ;
msg printer . print status msg ( creating ne taggers . . . ) ;
implicit params str map . put if absent ( conf , implicit params str ) ; implicit params map . put if absent ( conf , implicit params ) ; this . implicit _ params = implicit params ;
fi ca scheduler app app _ 0 = get mock application ( application _ id + + , user _ 0 , resources . create resource ( 4 * gb , 0 ) ) ; queue . submit application attempt ( app _ 0 , user _ 0 ) ; assert equals ( 1 , queue . get num active applications ( ) ) ; assert equals ( 0 , queue . get num pending applications ( ) ) ; assert equals ( 1 , queue . get num active applications ( user _ 0 ) ) ; assert equals ( 0 , queue . get num pending applications ( user _ 0 ) ) ;
rmapp app1 = rm1 . submit app ( 1 * gb , app , user , null , a ) ; mock am am1 = mock rm . launch and register am ( app1 , rm1 , nm1 ) ; am1 . allocate ( * , 1 * gb , 38 , new array list < container id > ( ) ) ;
buffer size + = 4 ; header ; always present
string urgent data = u ; try { socket the socket = new socket ( ) ; server socket server socket = new server socket ( 0 , 5 ) ; the socket . connect ( server socket . get local socket address ( ) ) ; socket serv sock = server socket . accept ( ) ; input stream the input = the socket . get input stream ( ) ; output stream the output = serv sock . get output stream ( ) ;
builder . set custom title ( header view ) ;
add pool ( virtual server name , lb algorithm ) ;
sketch . width = wide ; sketch . height = high ;
num spaces = 16 ;
j = job queue . poll ( ) ; if ( j = = null ) continue ; if ( groovy evaluator . local _ dev ) { nc = namespace client . get beaker ( groovy evaluator . get session id ( ) ) ; nc . set output obj ( j . output object ) ; } j . output object . started ( ) ; string code = j . code to be executed ;
gbmmodel . gbmparameters parms = new gbmmodel . gbmparameters ( ) ; parms . _ train = ksplits [ 0 ] ; parms . _ valid = ksplits [ 1 ] ; parms . _ response _ column = tfr . names ( ) [ resp ] ; parms . _ learn _ rate = 0 . 05f ; parms . _ min _ split _ improvement = msi [ i ] ; parms . _ ntrees = 10 ; parms . _ score _ tree _ interval = parms . _ ntrees ; parms . _ max _ depth = 5 ; gbm job = new gbm ( parms ) ;
final element plugins element = build element . get single child ( plugins ) ;
public void verify reading mult buf ( ) throws ioexception , scn not found exception , invalid config exception , databus exception , offset not found exception { verify reading mult buf ( 2000 ) ;
string camel id = ( string ) m bean server . get attribute ( route mbean , camel id ) ; if ( camel id = null & & camel id . equals ( camel context name ) ) { string xml = ( string ) m bean server . invoke ( route mbean , dump route stats as xml , new object [ ] { full stats , include processors } , new string [ ] { boolean , boolean } ) ; return xml ; } } }
log position . position = header . get log pos ( ) ; return event ; } case log event . gtid _ event : { maria gtid log event event = new maria gtid log event ( header , buffer , description event ) ;
return new dfunc acc ( vs , fcontext , num slots ) ;
json array = null ; } }
string [ ] rm ids = yarn conf . get strings ( yarn configuration . rm _ ha _ ids ) ; if ( ( rm ids = null ) & & ( rm ids . length > 0 ) ) { yarn conf . set ( yarn configuration . rm _ ha _ id , rm ids [ 0 ] ) ; } else { throw new ioexception ( rm _ ha _ ids property is not set for ha resource + manager ) ; }
mock zook keeper . fail now ( code . sessionexpired ) ;
( ( parameter value ) p ) . set value ( merge behavior . stack . name ( ) ) ;
if ( result = null ) { exchange . get in ( ) . set body ( result ) ; return true ; }
cluster state cluster state = cluster state . builder ( create cluster state ( source , random int between ( 2 , 10 ) , 0 , settings . builder ( ) . put ( index . blocks . write , true ) . build ( ) ) ) . nodes ( discovery nodes . builder ( ) . add ( new node ( node1 ) ) ) . build ( ) ; allocation service service = new allocation service ( settings . builder ( ) . build ( ) , new allocation deciders ( settings . empty , collections . singleton ( new max retry allocation decider ( settings . empty ) ) ) , new test gateway allocator ( ) , new balanced shards allocator ( settings . empty ) , empty cluster info service . instance ) ; routing table routing table = service . reroute ( cluster state , reroute ) . routing table ( ) ; cluster state = cluster state . builder ( cluster state ) . routing table ( routing table ) . build ( ) ;
enum set < huge enum with inner class > huge enum set = enum set . of ( huge enum with inner class . a , huge enum with inner class . b , huge enum with inner class . c , huge enum with inner class . d ) ; assert equals ( 4 , huge enum set . size ( ) ) ; assert true ( huge enum set . contains ( huge enum with inner class . a ) ) ; assert true ( huge enum set . contains ( huge enum with inner class . d ) ) ; try { enum set . of ( ( huge enum with inner class ) null , null , null , null ) ; fail ( should throw null pointer exception ) ; } catch ( null pointer exception npe ) { expected }
if ( buck manifest factory . is buck ( ) ) { return new buck manifest factory ( ) ; } else if ( build constants = null & & build constants = void . class ) { return new gradle manifest factory ( ) ; } else { return new maven manifest factory ( ) ; }
class loader cl = find class loader ( ) ; is = ss . get resource as stream ( cl , service id ) ;
ctrl mode = thermostat control mode . values ( ) [ ( this . payload [ 0 ] & 0x3 ) ] ;
if ( tmp file . to file ( ) . exists ( ) ) {
if ( table metadata = null ) { columns . put ( table name , table metadata . get columns ( ) ) ; } }
driver . get ( http : www . thisurldoesnotexist . comx ) ; } catch ( illegal state exception e ) {
file log = new file ( current dir , nnstorage . get in progress edits file name ( 2 ) ) ; nnstorage storage = new nnstorage ( conf , collections . < uri > empty list ( ) , lists . new array list ( uri ) , null ) ; if ( update transaction id file ) { storage . write transaction id file to storage ( 2 , null ) ; } storage . close ( ) ; new edit log file output stream ( log , null ) . create ( ) ;
long u time = 54972994 ;
assert equals ( override , cfg . get string ( string option , override ) ) ;
reader . channel . close ( ) ;
width and height panel . add ( new html ( & nbsp ; & nbsp ; ) ) ;
ctxt . generate java source ( org . apache . jasper . tagplugins . jstl . util . import response wrapper + irw name + = new org . apache . jasper . tagplugins . jstl . util . import response wrapper ( ( http servlet response ) page context . get response ( ) ) ; ) ;
secondary . do checkpoint ( ) ; checkpoint signature sig = nn . roll edit log ( ) ;
int [ ] cols = ast col slice . col _ select ( dst . names ( ) , cols _ numlist ) ;
add batch ( map impl , schema , elements ) ;
student hbase integer student max = new student hbase integer ( ) ; student max . set age ( ( short ) get max value ( short . class ) ) ; student max . set id ( ( integer ) get max value ( integer . class ) ) ; student max . set name ( ( string ) get max value ( string . class ) ) ; em . persist ( student max ) ;
date event time = events . get ( 0 ) . event time ( ) ;
this . public key = public key . public key ;
function codegen . gen delegate ( setter , delegate to . get setter ( ) . get original ( ) , to class , field ) ;
sreq . params . set ( common params . rows , rb . shards _ rows ) ; } else {
factory class name = rd . read line ( ) ;
connections . await ( ) ; }
standard name . add ( new ajax form component updating behavior ( change ) { @ override protected void on update ( ajax request target target ) { string name = standard name . get model object ( ) ; if ( name = null & & name . is empty ( ) ) { net cdfparser bean bean = geo server extensions . bean ( net cdfparser bean . class ) ; if ( bean = null & & bean . get parser ( ) = null ) { net cdfcfparser parser = bean . get parser ( ) ; entry e = null ; if ( parser . has entry id ( name ) ) { e = parser . get entry ( name ) ; } else if ( parser . has alias id ( name ) ) { e = parser . get entry from alias ( name ) ; } if ( e = null ) { uom . set model object ( e . get canonical units ( ) ) ; target . add ( container ) ; } } } } } ) ;
set properly configured ( false ) ; return ;
assert statement ( create table if not exists bar ( like like _ table ) , new create table ( qualified name . of ( bar ) , immutable list . of ( new like clause ( qualified name . of ( like _ table ) , optional . empty ( ) ) ) , true , immutable list . of ( ) , optional . empty ( ) ) ) ;
client = client . new builder ( ) . certificate pinner ( certificate pinner builder . build ( ) ) . build ( ) ; request request2 = new request . builder ( ) . url ( server . url ( ) ) . build ( ) ; response response2 = client . new call ( request2 ) . execute ( ) ; assert not same ( response2 . handshake ( ) , response1 . handshake ( ) ) ; response2 . body ( ) . close ( ) ;
mock meta store event listener . pop and verify last event id ( event type . create _ index , first event id + 3 ) ;
string value = key value pair field . tag ( ) + this . get key value pair separator ( ) + value formatted + separator ;
arrays . sort ( symbols ) ;
assert equals ( 1 , session factory ( ) . get statistics ( ) . get update timestamps cache hit count ( ) ) ; testing jta platform impl . instance . get transaction manager ( ) . resume ( tx1 ) ;
assert equals ( 1 , counter . buckets . get last ( ) . get adder ( hystrix rolling number event . timeout ) . sum ( ) ) ; assert equals ( 1 , counter . get rolling sum ( hystrix rolling number event . timeout ) ) ;
string d = format . format ( i = = 0 ? dmp . parse math ( day ) : dmp . parse math ( day + + i + days ) ) ;
final response bad response = target ( ) . path ( events push { msg } ) . resolve template ( msg , too - late ) . request ( ) . get ( ) ;
if ( t . get type ( ) = token . eof ) buf . append ( t . get text ( ) ) ; i + + ; move to next token } else { i = op . execute ( buf ) ; execute operation and skip } }
flush manager . build flush stack ( node , event type . update ) ; flush ( ) ;
if ( random boolean ( ) ) { bytes stream output out = channel . bytes output ( ) ; assert that ( out , instance of ( releasable bytes stream output . class ) ) ; } else { try ( xcontent builder builder = channel . new builder ( ) ) {
ra . set length ( newlen ) ;
int bg res id ; bg res id = r . drawable . bg _ item _ normal _ state ; holder . m container . set background resource ( bg res id ) ; }
cur num items = math . max ( cur num items , 2 ) ;
if ( is repeating ) { output . time [ 0 ] = time [ 0 ] ; output . nanos [ 0 ] = nanos [ 0 ] ; output . is null [ 0 ] = is null [ 0 ] ; output . is repeating = true ; return ; }
tile manager . decode individual tile ( m ) ;
sig . update ( data ) ;
if ( value = = null | | array length < = 0 ) { return result ; }
dom = get as dom ( rest base controller . root _ path + workspaces wcs coveragestores watertemp coverages watertemp index granules . xml ) ; assert xpath evaluates to ( 1 , count ( gf : watertemp ) , dom ) ; assert xpath evaluates to ( 0 , count ( gf : watertemp [ gf : location = ' ncom _ wattemp _ 000 _ 20081031 t0000000 _ 12 . tiff ' ] ) , dom ) ; assert xpath evaluates to ( 2008 - 11 - 01 t00 : 00 : 00 z , gf : watertemp [ gf : location = ' ncom _ wattemp _ 000 _ 20081101 t0000000 _ 12 . tiff ' ] gf : ingestion , dom ) ; assert xpath evaluates to ( 0 , gf : watertemp [ gf : location = ' ncom _ wattemp _ 000 _ 20081101 t0000000 _ 12 . tiff ' ] gf : elevation , dom ) ; }
if ( inside function ( ) & & now all set ( before , end flags , node . end _ yields | node . end _ returns _ value ) ) { name name = ( ( function node ) current script or fn ) . get function name ( ) ; if ( name = = null | | name . length ( ) = = 0 ) add error ( msg . anon . generator . returns , ) ; else add error ( msg . generator . returns , name . get identifier ( ) ) ; } ret . set lineno ( lineno ) ;
if ( m format change observer = = null ) { m format change observer = new format change observer ( this ) ; m context . get content resolver ( ) . register content observer ( settings . system . content _ uri , true , m format change observer ) ; } update time ( ) ;
for ( dependency spec dependency : module . get dependencies ( ) ) { if ( dependency instanceof module dependency spec ) { module dependency spec module dependency = ( module dependency spec ) dependency ; if ( module dependency . get identifier ( ) . equals ( that . get module ( ) . get identifier ( ) ) ) { return true ; } } }
if ( is iconified ( ) ) { super . on measure ( width measure spec , height measure spec ) ; return ; } int width mode = measure spec . get mode ( width measure spec ) ;
string url type = file ; int colon index = url path . index of ( : ) ; if ( colon index = - 1 ) { url type = url path . substring ( 0 , colon index ) ; } url path = url . get path ( ) ;
if ( this . jitter rate > 0 & & jitter value > ( long . max _ value - this . desired max file size ) ) { this . desired max file size = long . max _ value ; } else { this . desired max file size + = jitter value ; } }
( ( text view ) dialog layout . find view by id ( r . id . seek _ bar _ alpha _ title ) ) . set text color ( get activity ( ) . get text color ( ) ) ; ( ( text view ) dialog layout . find view by id ( r . id . seek _ bar _ alpha _ title _ sub ) ) . set text color ( get activity ( ) . get sub text color ( ) ) ; dialog builder . set view ( dialog layout ) ; dialog builder . set neutral button ( get activity ( ) . get string ( r . string . cancel ) . to upper case ( ) , null ) ;
region . flushcache ( ) ;
logger . debug ( testing ( lack of ) presence notifications . ) ; presence status old status = this . operation set presence2 . get presence status ( ) ; presence status new status = get sample status1 ( ) ;
json providers . add provider ( new system context json provider ( ) ) ; json providers . add provider ( new modules json provider ( ) ) ; json providers . add provider ( new user id json provider ( ) ) ; stack trace json provider stack trace json provider = new stack trace json provider ( ) ;
assert . assert equals ( 1 , container scheduler . get num queued containers ( ) ) ;
sfsb . evict query cache ( ) ; message = sfsb . query cache check if empty ( id ) ; if ( message . equals ( ok ) ) { fail ( message ) ; } }
node avl xp = x . get parent ( store ) ;
assert that ( with master1a . supersedes ( with master1b ) , equal to ( with master1a . version ( ) > with master1b . version ( ) ) ) ;
if ( unknown host exception . class . is assignable from ( clazz ) ) { return unknown host exception : + cause . get localized message ( ) ; }
spilling resettable iterator < int value > iterator = new spilling resettable iterator < int value > ( this . reader , this . serializer , this . memman , this . ioman , 20 , this . mem owner ) ;
if ( ignored % ignore _ threshold = = 0 ) { log . warn ( [ % , d ] input row ( s ) ignored as they do not satisfy the predicate , ignored ) ; } ignored + + ;
byte [ ] [ ] split keys = null ; table descriptor htd = master procedure testing utility . create htd ( table name , f1 , f2 ) ; region info [ ] regions = modify region utils . create region infos ( htd , split keys ) ; long proc id = proc exec . submit procedure ( new create table procedure ( proc exec . get environment ( ) , htd , regions ) ) ; test recovery and double execution ( util , proc id , step ) ; master procedure testing utility . validate table creation ( util . get hbase cluster ( ) . get master ( ) , table name , regions , f1 , f2 ) ;
if ( params [ 0 ] . equals ( vlc ) & & stderr consumer . get results ( ) . get ( 0 ) . starts with ( vlc ) ) { return true ; }
assert equals ( 3 , shutdown counter . get ( ) ) ; cache . stop ( ) ;
assert equals ( 0 , lt . check ( er ist nett . er heißt max . ) . size ( ) ) ;
handled classes to notification uri . put ( weather . class , notification _ uri1 ) ; handled classes to notification uri . put ( curren weather . class , notification _ uri2 ) ; handled classes to notification uri . put ( day . class , null ) ; handled classes to notification uri . put ( forecast . class , null ) ; handled classes to notification uri . put ( night . class , null ) ; handled classes to notification uri . put ( wind . class , null ) ; m resolver = new mock notification content resolver ( ) ;
if ( this . stopper . is stopped ( ) ) { return ; }
duplicate . reset ( ) ; assert equals ( duplicate . position ( ) , 0 ) ; duplicate . clear ( ) ; assert equals ( buf . position ( ) , buf . limit ( ) ) ; buf . reset ( ) ; assert equals ( buf . position ( ) , 0 ) ;
else if ( b4 [ 0 ] = = 0x3 c & & b4 [ 1 ] = = 0x00 & & b4 [ 2 ] = = 0x00 & & b4 [ 3 ] = = 0x00 ) { is big endian = boolean . false ; }
assert false ( timed out condition . block ( 50 ) ) ;
method visitor . visit type insn ( new , missing _ property _ exception _ type ) ;
if ( object helper . is empty ( relative url ) ) { relative url = null ; } string new url ;
current size + = size ;
for ( map . entry < object , object > entry : map . entry set ( ) ) { object value = entry . get value ( ) ; object new value = convert ( value , value type ) ; if ( value = new value ) { entry . set value ( new value ) ; } } return ( map < k , v > ) map ; }
list < object > fixed times = new array list < object > ( times ) ; for ( int i = 0 ; i < fixed times . size ( ) ; i + + ) { if ( fixed times . get ( i ) = = null ) { fixed times . set ( i , get default time ( coverage ) ) ; } }
string builder path = new string builder ( ) ;
return new query results < t > ( documents , query mixin . get metadata ( ) . get modifiers ( ) , inner count ( ) ) ; }
verify cat ( 0 , 1024 * 1024 , 1024 * 1024 ) ; verify cat ( 0 , 2 * 1024 * 1024 , 888 ) ; verify cat ( 0 , 1536 , 512 ) ; verify cat ( 0 , 1024 , 1024 ) ; verify cat ( 0 , 1024 , 1277 ) ; verify cat ( 0 , 2048 , 253 ) ; }
if ( tx object . is new session holder ( ) ) { transaction synchronization manager . bind resource ( obtain session factory ( ) , tx object . get session holder ( ) ) ; }
assert not null ( invoice payment . get target invoice id ( ) ) ; final invoices invoices = kill bill client . get invoices for account ( account json . get account id ( ) , request options ) ;
return value of ( quotient , scale ) ; }
{ execution config exec config = mock ( execution config . class ) ; when ( exec config . get global job parameters ( ) ) . then return ( storm config ) ; final irich bolt bolt = mock ( irich bolt . class ) ; bolt wrapper < object , object > wrapper = new bolt wrapper < object , object > ( bolt ) ; wrapper . setup ( create mock stream task ( exec config ) , new stream config ( new configuration ( ) ) , mock ( output . class ) ) ; wrapper . open ( ) ; verify ( bolt ) . prepare ( same ( storm config ) , any ( topology context . class ) , any ( output collector . class ) ) ; }
final imap < integer , integer > client map = client . get map ( map name ) ; for ( int i = 0 ; i < map size ; i + + ) { assert not null ( client map . get ( i ) ) ; }
byte array output stream baos = new byte array output stream ( ) ; byte [ ] data = get data bytes ( ) ; baos . write ( utils . get size beint32 ( mp4 data box . data _ header _ length + data . length ) ) ; baos . write ( utils . get default bytes ( mp4 data box . identifier , iso - 8859 - 1 ) ) ; baos . write ( new byte [ ] { 0 } ) ; baos . write ( new byte [ ] { 0 , 0 , ( byte ) get field type ( ) . get file class id ( ) } ) ; baos . write ( new byte [ ] { 0 , 0 , 0 , 0 } ) ; baos . write ( data ) ; return baos . to byte array ( ) ; }
return compare range ( x , y ) ;
assert equals ( update ( int ) failed to update the checksum to the correct value , 131074 , adl . get value ( ) ) ; adl . reset ( ) ; adl . update ( integer . max _ value ) ;
try ( input stream dir stream = web utils . open connection ( get base artifact url ( ) , get repository ( ) . get auth info ( ) ) . get input stream ( ) ) { parse directory ( dir stream ) ; } catch ( xmlexception e1 ) { log . warn ( error parsing artifact directory , e ) ; }
soapmessage response = read soap response ( soap action header , sm tr064 request , _ url + tr064service . get control url ( ) ) ;
layer group info nested named = add layer group ( nested _ named , mode . named , null , lakes , neatline ) ;
low redundancy blocks . add ( gen block info ( thread local random . current ( ) . next long ( ) ) , 2 , 0 , 0 , 7 ) ;
multi phrase query . builder query4builder = new multi phrase query . builder ( ) ; expect throws ( illegal argument exception . class , ( ) - > { query4builder . add ( new term ( field1 , foo ) ) ; query4builder . add ( new term ( field2 , foobar ) ) ; } ) ; writer . close ( ) ;
module info [ ] mod info = module . get optional modules ( ) ;
final string jobdir = jobconf . get ( job _ dir _ label ) ;
throw new edit log input exception ( error message , e , num edits ) ;
servlet holder h = new servlet holder ( new servlet container ( make jersey config ( ) ) ) ;
assert equals ( def foo ( ) throws java . io . ioexception { } , pretty ( def foo ( ) throws java . io . ioexception { } ) ) ; fails after parser
assert equals ( 1 , iterables . size ( elements ) ) ; assert true ( iterables . contains ( elements , expected entity1 ) ) ;
model . add ( parse line ( line , parse position ) ) ;
assert jq ( req ( q , { join from = dept _ ss to = noexist _ s + whatever score ( ) + } * : * , fl , id ) , response = = { ' num found ' : 0 , ' start ' : 0 , ' docs ' : [ ] } ) ;
log . debug ( going to commit ) ; db conn . commit ( ) ; response . set state ( lock state . acquired ) ; } finally {
if ( new length = = this values . length + other values . length ) { we can just copy all values , because they are unique . system . arraycopy ( this values , 0 , new values , 0 , this values . length ) ; new index = this values . length ; } else { copy the values that are different from the other array . for ( int index = 0 ; index < this values . length ; index + + ) { if ( other . contains ( this values [ index ] ) ) { new values [ new index + + ] = this values [ index ] ; } } }
you tube . channels . list channel request = youtube . channels ( ) . list ( id , snippet ) ; channel request . set mine ( true ) ; channel request . set fields ( items ( id , snippet title ) ) ; channel list response channels = channel request . execute ( ) ;
final string output = create job raw output ( job . new builder ( ) . set name ( test job name ) . set version ( test job version ) . set image ( busybox ) . set hostname ( % ^ & ) . build ( ) ) ;
do return ( true ) . when ( spied ) . notify shared cache manager ( is a ( string . class ) , is a ( string . class ) ) ; assert true ( spied . call ( ) ) ;
assert equals ( a , cache ( 1 , cache name ) . compute if absent ( key , k - > c ) ) ;
group . set cleared for recency ( this . working memory . get fact handle factory ( ) . get recency ( ) ) ;
if ( xml file . exists ( ) ) { xml file . delete ( ) ; }
get action bar ( ) . set background drawable ( uielements helper . get general action bar background ( m context ) ) ;
if ( in . target = = null ) { return attr name ; } return in . target + attr name . substring ( in . name . length ( ) ) ;
expect create callback with code ( _ ok rc ) ;
class loader cl = class loader . get system class loader ( ) ;
time unit . milliseconds . sleep ( 500 ) ; assert . assert that ( ssl fills . get ( ) , matchers . less than ( 50 ) ) ; assert . assert that ( ssl flushes . get ( ) , matchers . less than ( 20 ) ) ; assert . assert that ( http parses . get ( ) , matchers . less than ( 50 ) ) ; client . close ( ) ;
all class audited = persistent properties source . get xclass ( ) . get annotation ( audited . class ) ; if ( all class audited = = null ) {
view holder . item view . set id ( hash code ( ) ) ;
visitor . visit no args ( byte ops . iaload , offset , 1 , type . byte ) ; return 1 ;
assert null ( get feature at ( base , 20 , 10 ) ) ; assert equals ( time elevation . 1 , get feature at ( base , 60 , 10 ) ) ; assert null ( get feature at ( base , 20 , 30 ) ) ; assert null ( get feature at ( base , 60 , 30 ) ) ; }
if ( preprocess delegate . is present ( ) ) { iterable < path > dependencies ; try { dependencies = depfiles . parse and verify dependencies ( context . get event bus ( ) , get project filesystem ( ) , preprocess delegate . get ( ) . get header path normalizer ( ) , preprocess delegate . get ( ) . get header verification ( ) , get dep file path ( ) , get relative input path ( context . get source path resolver ( ) ) , output , compiler delegate . get dependency tracking mode ( ) ) ; } catch ( depfiles . header verification exception e ) { throw new human readable exception ( e ) ; } inputs . add all ( preprocess delegate . get ( ) . get inputs after building locally ( dependencies ) ) ; }
if ( key it = = null | | key it . has next ( ) ) { key it = cluster map . key set ( ) . iterator ( ) ; }
long tm0 = m0 ; long tm1 = m1 ; if ( exact0 ) { tm0 = 0 ; } if ( exact1 ) { tm1 = 0 ; } final double mb = tm0 + ( tm1 - tm0 ) * l ; double s = 0 . 5 * ( tm0 + mb ) * l ; for ( int i = 0 ; i < index ; + + i ) { s + = ( bins [ i ] & count _ bits ) ; }
if ( build . version . sdk _ int > = build . version _ codes . kitkat ) { calculate navigation bar height . int navigation bar height = 0 ; int resource id = get resources ( ) . get identifier ( navigation _ bar _ height , dimen , android ) ; if ( resource id > 0 ) { navigation bar height = get resources ( ) . get dimension pixel size ( resource id ) ; } list view . set clip to padding ( false ) ; list view . set padding ( 0 , 0 , 0 , navigation bar height ) ; } return root view ;
if ( double . compare ( s , 0 . 0 ) = = 0 | | double . compare ( s , - 0 . 0 ) = = 0 ) { arrays . fill ( seasonal , 0 . 0 ) ; } else { for ( int i = 0 ; i < period ; i + + ) { seasonal [ i ] = vs [ i ] s ; } } for ( int i = period ; i < vs . length ; i + + ) { s = alpha * ( vs [ i ] seasonal [ i - period ] ) + ( 1 . 0d - alpha ) * ( last _ s + last _ b ) ; b = beta * ( s - last _ s ) + ( 1 - beta ) * last _ b ; seasonal [ i ] = gamma * ( vs [ i ] ( last _ s + last _ b ) ) + ( 1 - gamma ) * seasonal [ i - period ] ; last _ s = s ; last _ b = b ; }
connection ( ) . send stanza ( msg ) ;
if ( shown tab . get info bar container ( ) = null ) { m is info bar container shown = shown tab . get info bar container ( ) . has info bars ( ) ; }
this . z controller . send data ( wakeup command class . set interval ( integer . parse int ( value ) ) ) ;
execute ( select title , description from novels where match ( title _ desc _ fulltext , ' fish ' ) ) ;
input dir empty input dir = result . input dir ( empty dir relative . to string ( ) ) ;
get get = new get ( four ) ;
validate . not null ( get repository admin ( ) , repository admin not found ) ; for ( repository repo : get repository admin ( ) . list repositories ( ) ) { repositories . add ( repo ) ; }
create file ( configuration1 , path2 ) ; create file ( configuration2 , path3 ) ; manager . close ( ) ;
reduce sink . get conf ( ) . set output name ( reduce work . get name ( ) ) ; }
iso date format . set time zone ( time zone . get time zone ( utc ) ) ; try { return iso date format . parse ( iso formatted date ) ; } catch ( parse exception e ) { throw new invalid format exception ( error parsing as date , iso formatted date , date . class ) ; }
if ( in2 . get temp mode ( ) . is cached ( ) ) { throw new compiler exception ( no cache at point where static and dynamic parts meet . ) ; } in2 . set temp mode ( in2 . get temp mode ( ) . make non cached ( ) ) ;
boolean close ;
util . get test file system ( ) . delete ( output , true ) ; jsc . close ( ) ; }
for ( web sphere jta platform . web sphere environment web sphere environment : web sphere jta platform . web sphere environment . values ( ) ) { try { class access class = class loader service . class for name ( web sphere environment . get tm access class name ( ) ) ; return new web sphere jta platform ( access class , web sphere environment ) ; } catch ( class loading exception ignore ) { } }
instructions . add ( reil helpers . create ldm ( offset , arch size , esi , operand size , temp ) ) ; instructions . add ( reil helpers . create stm ( offset + 1 , operand size , temp , arch size , edi ) ) ;
big integer r = null ; big integer s = null ; big integer k = null ;
warmed . add ( entry of ( entry . get key ( ) , new value ) ) ;
multi user chat muc3 = new multi user chat ( get connection ( 2 ) , room ) ; history = new discussion history ( ) ; history . set max stanzas ( 2 ) ; muc3 . join ( testbot3 , null , history , smack configuration . get packet reply timeout ( ) ) ;
m bean server = registry . get registry ( null , null ) . get mbean server ( ) ; }
failure = e ;
assert equals ( 1 , lines . length ) ;
return 8afde66ea51d865689083ba6bb779fac ;
if ( replica sync id = null & & replica sync id . equals ( primary sync id ) ) { return long . max _ value ; } else { long size matched = 0 ; for ( store file meta data store file meta data : store files meta data ) { string meta data file name = store file meta data . name ( ) ; if ( primary store . file exists ( meta data file name ) & & primary store . file ( meta data file name ) . is same ( store file meta data ) ) { size matched + = store file meta data . length ( ) ; } } return size matched ; }
list < string > ip list = net utils . get local v4 ip list ( ) ; if ( ip list . is empty ( ) ) { return ip list . get ( 0 ) ; } return net utils . loopback _ address _ v4 ; }
assert count ( 0 , v . query ( ) . direction ( both ) . has ( adjacent , 110111 ) . edges ( ) ) ;
a = lists . new array list ( ) ;
assert empty match ( за яким 50 % + 1 акція закріплюються у власності держави ) ; assert empty match ( злість плюс іронія можуть вбити ) ; assert empty match ( із яких 50 % плюс одна акція знаходяться ) ; assert empty match ( матеріальна заінтересованість плюс гарна вивіска зіграли злий жарт ) ; assert empty match ( колесніков ахметов посилили ) ;
result = compare borders ( result , collapsed border value . border top ( curr section . get style ( ) . get border ( c ) , browgroup ) ) ; if ( result . hidden ( ) ) { return result ; }
jsonassert . assert equals ( ioutils . to string ( this . get class ( ) . get resource as stream ( test coverage test unit _ test _ coverage _ no _ condition - expected . json ) , utf - 8 ) , coverage , true ) ; verify compute engine temp dir is empty ( ) ;
ticker . advance ( 5 , time unit . minutes ) ; jcache . invoke ( key _ 1 , this : : process ) ; assert that ( loads , is ( 2 ) ) ; ticker . advance ( 1 , time unit . minutes ) ; jcache . invoke ( key _ 1 , this : : process ) ; assert that ( loads , is ( 2 ) ) ; }
process smaptree . clear ( ) ;
assert equals ( 3 , learner handler . get queued packets ( ) . size ( ) ) ;
person iter . set reuse same record ( true ) ; int doc num = 0 ;
try { iip = fsd . resolve path ( pc , src arg , dir op ) ; } catch ( access control exception ace ) { return null ; }
all content . add element ( ( xselement decl ) group . f particles [ i ] . f value , group . f particles [ i ] . f min occurs = = 0 ) ;
{ verify ( vertex1 . get current execution attempt ( ) , times ( 1 ) ) . trigger checkpoint ( eq ( checkpoint id new ) , eq ( timestamp new ) , any ( checkpoint options . class ) ) ; verify ( vertex2 . get current execution attempt ( ) , times ( 1 ) ) . trigger checkpoint ( eq ( checkpoint id new ) , eq ( timestamp new ) , any ( checkpoint options . class ) ) ; verify ( vertex1 . get current execution attempt ( ) , times ( 1 ) ) . notify checkpoint complete ( eq ( checkpoint id new ) , eq ( timestamp new ) ) ; verify ( vertex2 . get current execution attempt ( ) , times ( 1 ) ) . notify checkpoint complete ( eq ( checkpoint id new ) , eq ( timestamp new ) ) ; } coord . shutdown ( job status . finished ) ;
string state = ( string ) mbean server . get attribute ( on , state ) ;
if ( special ) in _ special _ map = false ; c = get next indicator ( ) ;
bus handler . push expected events ( next event . null _ invoice , next event . cancel , next event . block , next event . null _ invoice ) ;
lazy initializer < ? > o = context . state . remove ( v ) ; if ( o = null ) { this thread removed it so let ' s execute shutdown v . shutdown ( ( t ) o . get ( ) ) ; } }
best left stat . update ( left stats . sum grad , left stats . sum hess ) ;
assert false ( new request context ( 1001 , 1 , 5 , 0 , 0 ) . equals ( new request context ( 1101 , 1 , 5 , 0 , 0 ) ) ) ;
if ( grp desc = null ) { if ( local logv ) log . i ( tag , group : + grp name key + description : + grp desc . to string ( ) ) ; ret map . put ( grp name key , grp desc . to string ( ) ) ; } }
if ( leave user include trace scope ( trace ) ) { if ( logger . is info enabled ( ) ) { logger . info ( failed to leave scope of user include trace . trace = { } , sampled = { } , trace , trace . can sampled ( ) ) ; } delete unstable trace . delete user include trace ( trace ) ; return ; }
in . skip bytes ( remaining - footer length ( ) ) ;
rq . add hfile refs ( peer id , files ) ;
final int height mode = measure spec . get mode ( height measure spec ) ; int width size = measure spec . get size ( width measure spec ) ; int height size = measure spec . get size ( height measure spec ) ; final int width padding = get padding left ( ) + get padding right ( ) ;
array list < employee > respondents = new array list < employee > ( num _ respondents ) ;
search response search response = client . search scroll ( scroll request ) ;
assert translation ( from animal an where ( an . body weight > 10 and an . body weight < 100 ) or an . body weight is null ) ; }
emission checker . await next expected value ( ) ; put users blocking ( users for insert ) ;
if ( producer task id < 0 ) { number of attributes = t . get arity ( ) ; } else { number of attributes = t . get arity ( ) - 1 ; } this . storm tuple = new values ( ) ; for ( int i = 0 ; i < number of attributes ; + + i ) { this . storm tuple . add ( t . get field ( i ) ) ; } } else {
if ( ( partitioner instanceof abstract byte ordered partitioner ) ) throw new permanent backend exception ( this operation is only allowed when byte - ordered partitioner is used . ) ; try { return new key range iterator ( partitioner , key range query , store manager . get page size ( ) , key range query . get key start ( ) . as byte buffer ( ) , key range query . get key end ( ) . as byte buffer ( ) ) ; } catch ( exception e ) { throw convert exception ( e ) ; }
if ( m fix view . get parent ( ) = = null ) { helper . add fixed view ( m fix view ) ; } else { fix layout state in case1 ( orientation helper , recycler , start position , end position , helper ) ; } } else {
return new unsafe heap swapped byte buf ( this ) ; }
while ( job runner . is job submitted in remote ( ) ) { synchronized ( queue ) { try { queue . wait ( 500 ) ; } catch ( interrupted exception e ) { logger . error ( exception in remote scheduler while job runner . is job submitted in remote + queue . wait , e ) ; } } }
try { rw lock . write lock ( ) . lock ( ) ; controller paths = c paths ; parsed mtab = new mtab ; } finally { rw lock . write lock ( ) . unlock ( ) ; }
string param property = get param property ( property ) ;
save ( dt , ( concurrent hash map < long , integer > ) sessions , false ) ;
boolean mob enabled = mob utils . has mob columns ( htd ) ;
boolean enable code mirror = is code mirror supported ( ) ; container = new web markup container ( editor container ) ;
throw new illegal state exception ( cannot serialize + get class ( ) . get simple name ( ) + [ + get session identifier ( ) + ] while connected ) ;
if ( pos < buf . length ) { copy length = ( buf . length - pos > = count ) ? count : buf . length - pos ; system . arraycopy ( buf , pos , buffer , new offset , copy length ) ; new offset + = copy length ; copied chars + = copy length ;
mapping bin file . delete ( ) ;
p = pattern . compile ( ( abc ) ?c ) ; m = p . matcher ( abcc ) ; assert true ( m . matches ( ) ) ; m = p . matcher ( c ) ; assert true ( m . matches ( ) ) ; m = p . matcher ( cc ) ; assert false ( m . matches ( ) ) ; m = p . matcher ( abcabcc ) ; assert false ( m . matches ( ) ) ;
m label horizontal height + = m styles . labels space ;
rmcontainer rmc = app . get live containers ( ) . iterator ( ) . next ( ) ;
assert that ( bean , instance of ( simple greeting . class ) ) ; }
list < sub query expression < tuple > > sq = new array list < sub query expression < tuple > > ( ) ;
this . b group . add ( btn ) ;
transition manager . begin delayed transition ( results container , get transition ( r . transition . search _ show _ confirm ) ) ;
r . set position ( 0 ) ;
row type info = type info factory . get struct type info ( column names , column types ) ;
if ( m content layout = null ) { final int height = style attrs . get dimension pixel size ( r . styleable . pull to refresh header _ ptr header height , get action bar size ( activity ) ) ; m content layout . get layout params ( ) . height = height ; m content layout . request layout ( ) ; }
if ( user buf len < = 0 ) { return true ; } else { set input from saved data ( ) ; }
m _ dispatcher . create transaction ( m _ snapshot daemon adapter . connection id ( ) , spi , cat proc . get readonly ( ) , cat proc . get singlepartition ( ) , cat proc . get everysite ( ) , new int [ ] { 0 } , partition id 0 , system . nano time ( ) ) ; }
principal i = x509c . get issuer dn ( ) ;
byte [ ] bytes = ( domain id + account name + user name + system . current time millis ( ) ) . get bytes ( ) ;
field infos mapped by temporal . put ( get mapped by info key ( field . get field type ( ) . get base type ( ) , mapped by ) , info ) ; }
string builder resp = new string builder ( ) ;
if ( wai class . is interface ( ) & & modifier . is abstract ( wai class . get modifiers ( ) ) & & web application initializer . class . is assignable from ( wai class ) ) { try { initializers . add ( ( web application initializer ) reflection utils . accessible constructor ( wai class ) . new instance ( ) ) ; } catch ( throwable ex ) { throw new servlet exception ( failed to instantiate web application initializer class , ex ) ; } }
assume true ( test utilities . is local ( ) ) ;
object rule return = rule name . invoke ( parser , params ) ; if ( parser . has errors ( ) ) { system . out . println ( parser . get error messages ( ) ) ; }
if ( summary . action ran ( ) ) { total run + + ; } if ( test result . is blaze test status passed ( summary . get status ( ) ) ) { pass count + + ; }
key test . set certificate entry ( alias3 , cert [ 0 ] ) ;
while ( true ) { channel . write ( byte buffer . allocate ( buffer _ size ) ) ; }
return action mode = null & & action mode was active ; } } ) ;
new cast resolver ( unit ) . run ( ) ; ticker . tick ( cast resolver ) ;
namespace = dom . lookup namespace ( node , prefix ) ;
string icq test agent name = system . get property ( testing _ impl _ user _ id _ prop _ name , null ) ;
f viewer . set input ( root vmc ) ;
final int task trackers = 4 ; final int job tracker port = 60050 ; dfs = new mini dfscluster ( conf , 6 , true , null ) ;
for ( field old field : old schema . get fields ( ) ) { if ( new schema . get field ( old field . name ( ) ) = null ) { string old index type = old field . get prop ( index type ) ; string new index type = new schema . get field ( old field . name ( ) ) . get prop ( index type ) ; check if added indexing . if ( old index type = = null & & new index type = null ) { messages . add ( new message ( level . error , cannot add indexing to + old field . name ( ) + . adding indexing to fields created without indexing is not supported . ) ) ; } check if changed indexing if ( old index type = null & & old index type . equals ( new index type ) ) { messages . add ( new message ( level . error , cannot change indexing from + old index type + to + new index type + for + old field . name ( ) + . changing indexing method is not supported . ) ) ; } } }
for ( int i = 0 ; i < assigned replicas ; i + + ) { replica states [ i ] = random from ( shard routing state . initializing , shard routing state . started , shard routing state . relocating ) ; }
if ( child decl . name . to string ( ) . starts with ( ) ) continue ; long field flags = child decl . mods . flags ;
while ( ( half height in sample size ) > req height & & ( half width in sample size ) > req width ) { in sample size * = 2 ; }
status code = client . execute method ( method ) ;
for ( int i = 0 ; i < num output arrays ; i + + ) { get output layer ( i ) . clear noise weight params ( ) ; } }
return new result ( false , null ) ; }
intent light flow = new intent ( com . klinker . android . twitter . cleared _ notification ) ; this . send broadcast ( light flow ) ; shared prefs . edit ( ) . put boolean ( new _ notification , false ) . commit ( ) ;
panel = new jpanel ( new border layout ( ) ) ; get content pane ( ) . add ( panel , border layout . south ) ; panel3 = new jpanel ( new border layout ( ) ) ; panel . add ( panel3 , border layout . south ) ; panel2 = new jpanel ( new flow layout ( flow layout . right ) ) ; panel3 . add ( panel2 , border layout . east ) ; m _ button clear . set mnemonic ( ' c ' ) ;
bindings . put ( wps . complex data type , complex data type binding . class ) ;
switch ( m device . get state ( ) ) { case authentication _ required : fall through case authenticating : return true ; abort the whole thing default : return false ; }
if ( existing role . name ( ) . equals ( updated role . name ( ) ) ) { throw new illegal argument exception ( the attempt to update the role from ' + existing role . name ( ) + ' to ' + updated role . name ( ) + ' failed . changing a roles name is not allowed . ) ; }
data . add vector layer ( point _ reduced , collections . empty _ map , get class ( ) , get catalog ( ) ) ;
ee one = get entity entry ( s , one ) ;
int new length = capacity < = 65536 ? capacity < < 1 : capacity + capacity > > 1 ;
table = ( tmp . length = = 0 ) ? null : tmp ;
assert equals ( class - v1 , system . get property ( some class . last _ loaded ) ) ;
assert equals ( sac . get bean ( autowired indexed test bean ) , singleton to be proxied . get nested indexed bean ( ) ) ; test interceptor ti = ( test interceptor ) sac . get bean ( test interceptor ) ;
e . print stack trace ( ) ; } catch ( read only file exception e ) {
url url = new url ( cruise _ server _ url ) ; while ( ( slept * sleep _ millis 1000 ) < = max _ sleep _ seconds ) { thread . sleep ( sleep _ millis ) ; progress pane . progress bar . set value ( slept ) ; slept + + ; try { http urlconnection url connection = ( http urlconnection ) url . open connection ( ) ; url connection . connect ( ) ; if ( url connection . get response code ( ) = = 200 ) { log . info ( server up , let ' s go ) ; started ok = true ; break ; } } catch ( exception e ) { don ' t care log . info ( server not up yet , sleeping . . . ) ; } } if ( started ok ) { string errormsg = server not up within + max _ sleep _ seconds + seconds . ; log . severe ( errormsg ) ; server . destroy ( ) ; progress pane . progress bar . set visible ( false ) ; progress pane . label . set text ( errormsg + please see var log system . log for more info . ) ; frame . pack ( ) ; frame . set size ( frame . get preferred size ( ) ) ; thread . sleep ( 15000 ) ; system . exit ( 1 ) ; }
qp . set date resolution ( date tools . resolution . millisecond ) ;
final list view lv = get list view ( ) ; lv . set clip to padding ( false ) ; final int vert padding = get resources ( ) . get dimension pixel size ( r . dimen . list _ vertical _ padding ) ; lv . set padding ( 0 , vert padding , 0 , vert padding ) ; views created = true ;
assert rows ( execute ( string . format ( select * from % % s where expr ( % s , ' foo bar baz ' ) , index name ) ) , row ) ; assert rows ( execute ( string . format ( select * from % % s where expr ( \ % s \ , ' foo bar baz ' ) , index name ) ) , row ) ; assert rows ( execute ( string . format ( select * from % % s where expr ( % s , foo \ bar baz ) , index name ) ) , row ) ;
m email edit text . set text ( m last credential . get id ( ) ) ;
assert equals ( ca , result [ 54 ] ) ; assert equals ( a , result [ 104 ] ) ; ng = new default name generator ( reserved _ names , x , null ) ; result = generate ( ng , x , 132 ) ;
if ( digits [ 0 ] > = ' 5 ' ) { result [ 0 ] = ' 1 ' ; } return result ; }
for ( int i = 0 ; i < total versions ; i + + ) { create or update ( create or update secret request v2 . builder ( ) . content ( encoder . encode to string ( format ( supa secret20 _ v % d , i ) . get bytes ( utf _ 8 ) ) ) . description ( format ( secret20 , version % d , i ) ) . expiry ( now + 86400 * 2 ) . metadata ( immutable map . of ( version , integer . to string ( i ) ) ) . build ( ) , secret20 ) ; sleep ( sleep interval ) ; }
search request . source ( search source builder ) ;
write end tag ( must chunk ) ;
for ( int k = left ; k < right ; run [ count ] = k ) { if ( a [ k ] < a [ k + 1 ] ) { ascending while ( + + k < = right & & a [ k - 1 ] < = a [ k ] ) ; } else if ( a [ k ] > a [ k + 1 ] ) { descending while ( + + k < = right & & a [ k - 1 ] > = a [ k ] ) ; for ( int lo = run [ count ] - 1 , hi = k ; + + lo < - - hi ; ) { float t = a [ lo ] ; a [ lo ] = a [ hi ] ; a [ hi ] = t ; } } else { equal for ( int m = max _ run _ length ; + + k < = right & & a [ k - 1 ] = = a [ k ] ; ) { if ( - - m = = 0 ) { sort ( a , left , right , true ) ; return ; } } } * * the array is not highly structured , * use quicksort instead of merge sort . * if ( + + count = = max _ run _ count ) { sort ( a , left , right , true ) ; return ; } }
test service grpc . new stub ( in process channel ) . streaming input call ( response observer ) ; assert true ( finish latch . await ( 900 , time unit . milliseconds ) ) ;
pseudo clock . advance time ( 10000 , time unit . milliseconds ) ;
try { attempt . get write lock ( ) . lock ( ) ; fsleaf queue old queue = ( fsleaf queue ) app . get queue ( ) ; string dest queue name = handle move to plan queue ( new queue ) ; fsleaf queue target queue = queue mgr . get leaf queue ( dest queue name , false ) ; if ( target queue = = null ) { throw new yarn exception ( target queue + new queue + not found or is not a leaf queue . ) ; } if ( old queue . is runnable app ( attempt ) ) { verify move does not violate constraints ( attempt , old queue , target queue ) ; } } finally { attempt . get write lock ( ) . unlock ( ) ; }
p = em . find ( person redis . class , 1 ) ;
hash set < integer > rows folded = new hash set < integer > ( ) ; for ( ace fold f : js util . as iterable ( doc display _ . get folds ( ) ) ) rows folded . add ( f . get start ( ) . get row ( ) ) ; scope list scope list = new scope list ( doc display _ ) ;
for ( versioned < slop > vs : undelivered ) { slop slop = vs . get value ( ) ; assert equals ( slop is gone , 1 , repo . get slop store ( ) . get ( slop . make key ( ) , null ) . size ( ) ) ; }
intent intent = new intent ( ) ; intent . put extra ( small . extras _ key _ ret , ret ) ; set result ( result _ ok , intent ) ; super . finish ( ) ; }
ticker ticker = market data service . get ticker ( currency pair . xaur _ btc ) ; system . out . println ( received data . ) ; system . out . println ( ticker ) ; }
decode rle4 ( im size , padding , values , bdata ) ;
if ( link field type = = otype . link ) { if ( result instanceof collection < ? > ) { if ( ( ( collection ) result ) . is empty ( ) ) result = ( ( collection ) result ) . iterator ( ) . next ( ) ; else result = null ; } } else if ( link field type = = otype . linkset ) { if ( ( result instanceof collection ) ) { final set < oidentifiable > res = new hash set < oidentifiable > ( ) ; res . add ( ( oidentifiable ) result ) ; result = res ; } } else if ( link field type = = otype . linklist ) { if ( ( result instanceof collection ) ) { final list < oidentifiable > res = new array list < oidentifiable > ( ) ; res . add ( ( oidentifiable ) result ) ; result = res ; } }
test context test context3b = test context test utils . build test context ( class hierarchy context hierarchy level3b test case . class , context cache ) ; test context3b . get application context ( ) ; assert context cache statistics ( context cache , level 3 , a and b , 4 , 1 , 4 ) ; assert parent context count ( 2 ) ;
ngram3 middle = new probability ( ( ngram3 left . get prob ( ) + ngram3 right . get prob ( ) ) 2 , 1 . 0f ) ; } else {
return null ; } else if ( cluster . equals ( protocol ) ) {
clean test location ( transfer manager ) ;
for ( string field : vertex . get property keys ( ) ) { final object v = vertex . get property ( field ) ; if ( v = null ) json . write attribute ( field , v ) ; } json . end object ( ) ; } json . end collection ( ) ;
assert equals ( null , cache . get block ( single blocks [ 9 ] . cache key , true , false , true ) ) ;
result & = start ;
card thumbnail thumb = new card thumbnail ( get activity ( ) ) ;
collection < kie package > kpkgs = load knowledge packages ( . . test _ dynamic1 _ 0 . drl ) ; kpkgs = serialization helper . serialize object ( kpkgs ) ; internal knowledge base k base = ( internal knowledge base ) get knowledge base ( ) ; k base . add packages ( kpkgs ) ; k base = serialization helper . serialize object ( k base ) ; list results = new array list ( ) ;
final string authorization key = uuid . random uuid ( ) . to string ( ) ; final payment authorization = payment processor . create authorization ( true , null , account , null , null , ten , currency , payment external key , authorization key , null , null , should _ lock _ account , plugin properties to drive transation to pending , call context , internal call context ) ; final payment transaction pending transaction = authorization . get transactions ( ) . get ( 0 ) ; assert . assert equals ( pending transaction . get transaction status ( ) , transaction status . pending ) ; final uuid transaction id = pending transaction . get id ( ) ;
assert recovery state ( node crecovery states . get ( 0 ) , 0 , peer recovery source . instance , false , stage . done , node b , node c ) ;
final file file = get resource ( simple _ class3 _ file _ path ) ; final string file contents = get resource contents ( file ) ; final class or interface type details simple interface details = type parsing service . get type from string ( file contents , simple _ class3 _ declared _ by _ mid , simple _ class3 _ type ) ;
log ceil = math . ceil ( upper ) ; use as - is
list < oauth client . access token response > token responses = create initial sessions ( true ) ; int offline sessions01 = get testing client for started node in dc ( 0 ) . testing ( ) . cache ( infinispan connection provider . offline _ user _ session _ cache _ name ) . size ( ) ;
wait for second message . count down ( ) ;
return class . for name ( class name , false , factory finder . class . get class loader ( ) ) ;
main process name = context . get application info ( ) . process name ;
saved start = vars . get stack frame ( ) ; vars . set stack frame ( m _ stack frame ) ;
out . write ( long . to string ( cache dfs used ) + + long . to string ( timer . now ( ) ) ) ; out . flush ( ) ; } } catch ( ioexception ioe ) {
try { read write file channel . read ( ( byte buffer ) null ) ; fail ( should throw closed channel exception ) ; } catch ( null pointer exception e ) { } catch ( closed channel exception e ) { } try { read only file channel . write ( ( byte buffer ) null ) ; fail ( should throw closed channel exception ) ; } catch ( null pointer exception e ) { } catch ( closed channel exception e ) { } write only file channel . close ( ) ;
if ( readers = = null ) { set hints ( null ) ; } return decode internal ( image ) ;
req = new read input discretes request ( ref , count ) ; req . set unit id ( unitid ) ; req . set headless ( ) ; if ( modbus . debug ) { system . out . println ( request : + req . get hex message ( ) ) ; }
init ( reconnected ) ; return ; case stopped : if ( being reconnected = = true ) {
batch = new sprite batch ( program ) ; } catch ( exception e ) {
reset to false ( invocation state ) ; assert true ( always true . and ( always true2 ) . test ( arg1 , arg2 ) ) ; assert true ( always true invoked . get ( ) & & always true2 invoked . get ( ) ) ;
reloadable properties = new reloadable properties impl ( ) ;
at beginning = true ;
if ( ( f features & namespacedecls ) = 0 ) { if ( . equals ( prefix ) | | . equals ( namespace uri ) ) { ( ( element ) node ) . set attribute ns ( xmlns _ uri , xmlns _ prefix , namespace uri ) ; } else { ( ( element ) node ) . set attribute ns ( xmlns _ uri , xmlns _ prefix + : + prefix , namespace uri ) ; } }
close . set weight ( this . current weight ) ;
assert xpath evaluates to ( abstract app schema mock data . gsml _ schema _ location _ url , xsd : include @ schema location , doc ) ;
throw new illegal state exception ( sm . get string ( application context . add role . ise , get context path ( ) ) ) ;
if ( incl items . is empty ( ) ) { result = stream . of ( result ) . filter ( song - > stream . of ( incl items ) . any match ( incl item - > string utils . contains ignore case ( song . path , incl item . path ) ) ) . to list ( ) ; } return result ; } ) . subscribe ( songs relay , error - > log utils . log exception ( tag , get songs relay threw error , error ) ) ;
return new hdfs data output stream ( dfsos , statistics , start pos ) ;
string value = properties . get property ( option ) ;
select base currency network combo box = add label combo box ( root , grid row , res . get with col ( settings . preferences . select currency network ) , layout . first _ row _ distance ) . second ; select base currency network combo box . set converter ( new string converter < base currency network > ( ) { @ override public string to string ( base currency network base currency network ) { return dev env . dev _ mode ? ( base currency network . get currency name ( ) + _ + base currency network . get network ( ) ) : base currency network . get currency name ( ) ; } @ override public base currency network from string ( string string ) { return null ; } } ) ;
buffers [ i ] = pooled [ i ] . get buffer ( ) . duplicate ( ) ;
type type = hcat fs . get type ( ) ;
if ( ( descriptor instanceof fragment descriptor ) ) { add filter mapping ( filter _ name , node , context , descriptor ) ; } break ;
scheduler . next heartbeat time = now - ( heartbeat _ interval _ ms * 10 ) ;
assert that ( ch . read inbound ( ) , is ( null value ( ) ) ) ;
input stream is = bitstamp adapter test . class . get resource as stream ( marketdata example - full - depth - data . json ) ;
chunk entry chunk a1 = new chunk entry ( new chunk checksum ( new byte [ ] { 1 , 2 , 3 , 4 , 5 , 7 , 8 , 9 , 0 } ) , 12 ) ; chunk entry chunk a2 = new chunk entry ( new chunk checksum ( new byte [ ] { 9 , 8 , 7 , 6 , 5 , 4 , 3 , 2 , 1 } ) , 34 ) ; chunk entry chunk a3 = new chunk entry ( new chunk checksum ( new byte [ ] { 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 } ) , 56 ) ; chunk entry chunk a4 = new chunk entry ( new chunk checksum ( new byte [ ] { 2 , 2 , 2 , 2 , 2 , 2 , 2 , 2 , 2 } ) , 78 ) ; new database version . add chunk ( chunk a1 ) ; new database version . add chunk ( chunk a2 ) ; new database version . add chunk ( chunk a3 ) ; new database version . add chunk ( chunk a4 ) ;
string protocol = u . get protocol ( ) ;
convertermap . put ( set clob , class name converter ) ;
return non insertable fake ? false : entity tools . entities equal ( session , referenced entity name , new obj , old obj ) ;
analytics helper . send screen view ( feedback : + model . get session title ( ) , get activity ( ) ) ;
if ( m current scroll state = = on scroll state changed listener . scroll state . scroll _ state _ fling ) { set current scroll state ( on scroll state changed listener . scroll state . scroll _ state _ idle ) ; } } else {
entrances . add ( this ) ; }
draw ascii panel ( buffer graphics ) ;
for ( int i = 0 ; i < mappings ; i + + ) { @ suppress warnings ( unchecked ) k key = ( k ) s . read object ( ) ; @ suppress warnings ( unchecked ) v value = ( v ) s . read object ( ) ; put val ( hash ( key ) , key , value , false , false ) ; }
int rotation = display configuration . get rotation ( ) ; int degrees = 0 ; switch ( rotation ) { case surface . rotation _ 0 : degrees = 0 ; break ; case surface . rotation _ 90 : degrees = 90 ; break ; case surface . rotation _ 180 : degrees = 180 ; break ; case surface . rotation _ 270 : degrees = 270 ; break ; } int result ;
thread factory = global configuration . listener thread pool ( ) . thread factory ( ) ;
case symbols . token semicolon : skip to statement start ( false , false ) ; return f token = = symbols . token do ;
for ( component child : component . get children ( ) ) { no need to keep the children in memory . they can be garbage - collected . counters child counters = counters by component ref . remove ( child . get report attributes ( ) . get ref ( ) ) ; current counters . add ( child counters ) ; }
base . set values ( ) ; comp . set value ( 1800 - 01 - 02 t10 : 20 : 30 z ) . set exists ( true ) ; func . stream booleans ( value - > { assert true ( there should be no values to stream , false ) ; } ) ; base . set values ( 1800 - 01 - 02 t10 : 20 : 30 z ) ;
htable table = new htable ( new configuration ( util . get configuration ( ) ) , table name ) ;
lock b . lock ( ) ;
assert equals ( 1 , conn listener . action count by data store . size ( ) ) ;
if ( lastfm user session . get session ( this ) = null ) { last fm client . get instance ( this ) . scrobble ( null ) ; }
req . get configuration ( ) . clean up cycle = 100 ;
item position = data to show on graph . length - 1 ; }
try { parse file utils . copy file ( file , get cache file ( new state ) ) ; } catch ( ioexception e ) {
assert . assert equals ( tobi , packet . get nsp ( ) ) ;
last . get path ( ) . delete ( ) ;
if ( path specs [ j ] . equals ( constraint mappings . get ( i ) . get path spec ( ) ) ) { exists = true ; break ; }
reader = new buffered reader ( new file reader ( input file ) ) ; content = ; while ( ( line = reader . read line ( ) ) = null ) { if ( content . equals ( ) ) content + = \ n ; content + = line ; } reader . close ( ) ;
no _ entry _ value = in . read long ( ) ; }
if ( max num retries = = 0 ) { throw new ioexception ( failed to send message ' + value + ' to socket server at + host name + : + port + . connection re - tries are not enabled . , e ) ; } log . error ( failed to send message ' + value + ' to socket server at + host name + : + port + . trying to reconnect . . . , e ) ;
reference = context . get service reference ( session factory . class . get name ( ) ) ; session factory session factory = ( session factory ) context . get service ( reference ) ; session factory locator . set session factory ( session factory ) ; }
int height size and state = resolve size and state ( height size , height measure spec , 0 ) ;
updates . add ( new new contribution panel update ( ) ) ; update view ( context , updates ) ; } }
adjust toolbar for scroll views ( scroll state , view ) ; adjust toolbar for list views ( scroll state , view ) ; }
cached http content content = _ cache . get ( path in context ) ;
if ( res . status ( ) . code ( ) = 200 ) { byte buf buf = unpooled . copied buffer ( res . status ( ) . to string ( ) , charset util . utf _ 8 ) ; res . content ( ) . write bytes ( buf ) ; buf . release ( ) ; set content length ( res , res . content ( ) . readable bytes ( ) ) ; }
value pointer paint . set color ( color . hsvto color ( new float [ ] { 0f , 0f , 1f - color hsv [ 2 ] } ) ) ; double value angle = ( color hsv [ 2 ] - 0 . 5f ) * math . pi ; float value angle x = ( float ) math . cos ( value angle ) ;
record property name ( proto prop . get first child ( ) . get last child ( ) ) ; return true ;
unread bytes = din . read int ( ) ;
log floor = math . floor ( - log floor ) ;
spannable string builder ssb = new spannable string builder ( text ) ;
set lowercase expanded terms ( false ) ;
assert array equals ( ( test get scanner results + pad ( i , ( byte ) 2 ) ) . get bytes ( ) , results . get ( i ) . get row ( ) ) ; }
this . dispatcher . await ( ) ; assert true ( app event handler . receive log handling finish event ( ) ) ; app event handler . reset log handling event ( ) ;
begin phase . arrive and await advance ( ) ;
after transaction process = new cache cleanup process ( key , persister , lock ) ; }
local availability zone tracker = true ;
output size = optional . of ( long . parse long ( on disk build info . get value ( build info . metadata key . output _ size ) . get ( ) ) ) ; string hash string = on disk build info . get value ( build info . metadata key . output _ hash ) . get ( ) ; output hash = optional . of ( hash code . from string ( hash string ) ) ; }
long u = r > > > 1 ; while ( u + m - ( r = u % n ) < 0 l ) { u = random . next long ( ) > > > 1 ; } return r ; }
if ( total to pay as coin . get ( ) = null & & is btc wallet funded . get ( ) & & wallet funded notification = = null & & dev env . dev _ mode ) { wallet funded notification = new notification ( ) . head line ( res . get ( notification . wallet update . headline ) ) . notification ( res . get ( notification . wallet update . msg , formatter . format coin with code ( total to pay as coin . get ( ) ) ) ) . auto close ( ) ; wallet funded notification . show ( ) ; }
assert false ( wrapper . get file status ( link abs ) . is symlink ( ) ) ;
streamlet < string > base streamlet2 = streamlet impl . create supplier streamlet ( ( ) - > i love you ) ; kvstreamlet < string , integer > right stream = base streamlet2 . flat map ( x - > arrays . as list ( x . split ( ) ) ) . map to kv ( x - > new key value < > ( x , 1 ) ) ;
holder . m flip view . flip ( adapter . is selected ( position ) , 200 l ) ;
for ( int i = 0 ; i < statements . size ( ) ; i + + ) { exec ( statements . get ( i ) ) ; }
final atomic integer successes = new atomic integer ( 0 ) ;
thing builder thing builder = edit thing ( ) ; channel channel = channel builder . create ( channel uid , number ) . with type ( new channel type uid ( binding _ id , thermostat _ mode _ cc _ channel ) ) . with label ( thermostat mode ( command class ) ) . with description ( possible modes : + modes . to string ( ) ) . with properties ( properties ) . build ( ) ; thing builder . with channel ( channel ) ; thing builder . with label ( thing . get label ( ) ) ;
try { factory . create graph ( ) ; } catch ( final illegal argument exception e ) { assert equals ( graph id is required , e . get message ( ) ) ; } }
if ( application action . is quit ( ) ) { rstudio ginjector . instance . get global display ( ) . show yes no message ( message dialog . question , caption , are you sure you want to quit the r session? , quit operation , true ) ; } else { quit operation . execute ( ) ; } return ;
assert that ( dimensions utils . extract dimensions ( wms , get layer info ( ) ) . size ( ) , is ( 0 ) ) ;
test _ util . get configuration ( ) . set int ( hconstants . hbase _ client _ retries _ number , 3 ) ;
errmsg = get need to set value message ( conf key ) ;
alert alert2 = new alert ( 2 ) ;
if ( entity type . has declared version attribute ( ) ) { register attribute ( metamodel class , entity type . get declared version ( ) ) ; }
this . trigger factory = trigger factory ; source binding = source ; forward trigger binding = forward trigger ; set target binding ( target ) ; rebuild bindings ( ) ; }
double delta = value - mean ;
hbase testing utility . set max recovery error count ( wal . get output stream ( ) , 1 ) ; return wal ; }
wrapped message context request context = new wrapped message context ( new hash map < string , object > ( ) , null , scope . application ) ; camel exchange . set property ( message . mtom _ enabled , string . value of ( endpoint . is mtom enabled ( ) ) ) ;
exchange . get request headers ( ) . remove ( authority ) ; exchange . get request headers ( ) . remove ( path ) ; exchange . get request headers ( ) . remove ( scheme ) ; exchange . get request headers ( ) . remove ( method ) ; connectors . execute root handler ( root handler , exchange ) ;
if ( hash algo = = null ) hash algo = hash algorithm . sha512 ; excel 2013 if ( password = = null ) { return ; we ' ve alreadt done what we need to do } else if ( hash algo = = hash algorithm . none ) { int hash = crypto functions . create xor verifier1 ( password ) ; sheet protection . set password ( datatype converter . parse hex binary ( integer . to hex string ( hash ) ) ) ; return ; }
assert changes ( 1 , 0 , rm1 ) ; assert blacklist additions and removals ( 0 , 0 , rm1 ) ; int completed container = allocate response . get completed containers statuses ( ) . size ( ) ; pending release - = completed container ;
checkpoint cp = checkpoint . create flexible checkpoint ( ) ;
do score = boolean . parse boolean ( props . get property ( constants . score _ prop , false ) ) ;
if ( is = = null ) { is = ioutils . class . get class loader ( ) . get resource as stream ( name . replace all ( \ \ \ \ , ) ) ; classpath doesn ' t like double slashes ( e . g . , home user foo . txt ) if ( is = = null ) { is = ioutils . class . get class loader ( ) . get resource as stream ( name . replace all ( \ \ \ \ , ) . replace all ( + , ) ) ; } }
thread . sleep ( 100 ) ; assert true ( event . starts with ( beginbegincommit ) ) ; }
string md5a1 = get digest ( username , realm ) ; if ( md5a1 = = null ) return null ; md5a1 = md5a1 . to lower case ( locale . english ) ; string server digest value ; if ( qop = = null ) { server digest value = md5a1 + : + nonce + : + md5a2 ; } else { server digest value = md5a1 + : + nonce + : + nc + : + cnonce + : + qop + : + md5a2 ; } byte [ ] value bytes = null ;
student hbase integer student max = new student hbase integer ( ) ; student max . set age ( ( short ) get max value ( short . class ) ) ; student max . set id ( ( integer ) get max value ( integer . class ) ) ; student max . set name ( ( string ) get max value ( string . class ) ) ; em . persist ( student max ) ;
if ( this . get route headers ( ) = null ) { cancel . set header ( ( sipheader list < ? > ) this . get route headers ( ) . clone ( ) ) ; } if ( message factory impl . get default user agent header ( ) = null ) { cancel . set header ( message factory impl . get default user agent header ( ) ) ; } return cancel ;
final int child capacity = list col vector . child . is null . length ; final int child count = list col vector . child count ; if ( child capacity < child count 0 . 75 ) { list col vector . child . ensure size ( child capacity * 2 , true ) ; } store complex field row column ( element col vector , list helper . get element field ( ) , offset , can retain byte ref ) ;
assert equals ( 0 , paramter counts . get ( 0 ) . int value ( ) ) ;
dfstest util . fs shell run ( - mkdir - p sub1 . snapshot , conf ) ;
dest last modified time = fs . get file status ( dest folder ) . get modification time ( ) ;
final long time = pause time * 3 + ( ( max wait time num retries ) * 3 ) + 300 ;
final list < string > children = new array list < > ( 2 ) ;
for ( string key : pref . keys ( ) ) { pref . remove ( context + _ + key ) ; }
cache0 . put ( hello , world ) ;
inet socket address mock rm address = new inet socket address ( localhost , 4444 ) ; text rm token sevice = security util . build token service ( mock rm address ) ; inet socket address mock hs address = new inet socket address ( localhost , 9200 ) ;
injector . get instance ( persist service . class ) . start ( ) ; }
m icons = new bitmap [ record numbers . length ] ; m record numbers = record numbers ; m current record index = 0 ; m state = state _ multi _ icons ; start loading icon ( record numbers [ 0 ] ) ; }
paint . set style ( paint . style . fill ) ;
name text . subscribe ( widget - > { if ( address text . get text ( ) . is empty ( ) ) { address text . set text ( name text . get text ( ) ) ; address text . set cursor position ( address text . get text ( ) . length ( ) ) ; } get manager ( ) . set focus ( address text ) ; } ) ;
if ( dimension . starts with ( http : www . opengis . net def axis ogc 0 ) ) { dimension = dimension . substring ( http : www . opengis . net def axis ogc 0 . length ( ) ) ; } else if ( dimension . starts with ( http : opengis . net def axis ogc 0 ) ) { dimension = dimension . substring ( http : opengis . net def axis ogc 0 . length ( ) ) ; } else if ( dimension . starts with ( http : opengis . net def crs iso 2004 ) ) { dimension = dimension . substring ( http : opengis . net def crs iso 2004 . length ( ) ) ; }
initializer . initialize ( geo server ) ; verify ( tile layer catalog , times ( 1 ) ) . save ( eq ( layer info ) ) ; assert false ( legacy tile layer info loader . has tile layer def ( layer . get metadata ( ) ) ) ; verify ( raw catalog , times ( 1 ) ) . save ( eq ( layer ) ) ; verify ( tile layer catalog , times ( 1 ) ) . save ( eq ( group info ) ) ; assert false ( legacy tile layer info loader . has tile layer def ( group . get metadata ( ) ) ) ;
get mock endpoint ( mock : result ) . expected message count ( 1 ) ; get mock endpoint ( mock : result ) . message ( 0 ) . body ( ) . is null ( ) ; template . send body ( direct : a , hello world ) ;
postal area converter . clear counts ( ) ; session = open session ( ) ;
local launch permission tracker = true ;
assert . assert equals ( 3 , ( ( sequence id revision entity ) result1 [ 1 ] ) . get id ( ) ) ;
object [ ] [ ] row = get rows ( execute ( select s , writetime ( s ) from % s where k = 0 ) ) ; assert equals ( 42 , row [ 0 ] [ 0 ] ) ; assert true ( ( long ) row [ 0 ] [ 1 ] > 0 ) ; execute ( insert into % s ( k , p , s , v ) values ( 0 , 0 , 12 , 0 ) ) ; execute ( insert into % s ( k , p , s , v ) values ( 0 , 1 , 24 , 1 ) ) ; flush ( force flush ) ;
hive col stats map . put ( non part col indxs that rqr stats . get ( i ) , hive col stats . get ( i ) ) ;
list < limit order > asks = btceadapters . adapt orders ( btce depth wrapper . get depth ( btceadapters . get pair ( currency pair ) ) . get asks ( ) , currency pair , ask , ) ; list < limit order > bids = btceadapters . adapt orders ( btce depth wrapper . get depth ( btceadapters . get pair ( currency pair ) ) . get bids ( ) , currency pair , bid , ) ; return new order book ( null , asks , bids ) ;
order . verify ( mock member comms , never ( ) ) . send member acquired ( eq ( spy sub ) ) ; order . verify ( spy sub , never ( ) ) . inside barrier ( ) ; order . verify ( mock member comms , never ( ) ) . send member completed ( eq ( spy sub ) ) ;
asserts . assert contains ( pe . get message ( ) , 1 ) error in custom provider , java . lang . illegal state exception : boom ) ;
assert equals ( true , tx read . is active ( ) ) ; tx read . abort ( ) ; assert equals ( false , tx read . is active ( ) ) ;
show dialog ( r . id . dialog _ attachment _ progress ) ; }
log . debug ( e ) ;
if ( topo conf . contains key ( windowing configs . topology _ bolts _ sliding _ interval _ count ) ) { sliding interval count = new count ( ( ( number ) topo conf . get ( windowing configs . topology _ bolts _ sliding _ interval _ count ) ) . int value ( ) ) ; } else if ( topo conf . contains key ( windowing configs . topology _ bolts _ sliding _ interval _ duration _ ms ) ) { sliding interval duration ms = ( long ) topo conf . get ( windowing configs . topology _ bolts _ sliding _ interval _ duration _ ms ) ; } else { default is a sliding window of count 1 sliding interval count = new count ( 1 ) ; }
bean = my mapper . reader with view ( view aa . class ) . for type ( defaults bean . class ) . read value ( { \ a \ : 1 , \ b \ : 2 } ) ;
final osession storage performance statistic performance statistic = ( ( oabstract paginated storage ) storage ) . complete gathering performance statistic for current thread ( ) ; if ( performance statistic = null ) request . get result listener ( ) . result ( performance statistic . to document ( ) ) ; else { odocument result = new odocument ( ) ; result . field ( result , error : profiling of storage was not started . ) ; request . get result listener ( ) . result ( result ) ; }
if ( get verbs ( ) . is empty ( ) ) { throw new illegal argument exception ( must add verb first , such as get post delete ) ; } to definition to = new to definition ( uri ) ; verb definition verb = get verbs ( ) . get ( get verbs ( ) . size ( ) - 1 ) ; verb . set to ( to ) ; return this ;
motion event cancel event = motion event . obtain ( motion event ) ;
connector port register port register = mock ( connector port register . class ) ; when ( port register . get local address ( bolt ) ) . then return ( new hostname port ( localhost , 7687 ) ) ; when ( neo server . get database ( ) . get graph ( ) . get dependency resolver ( ) . resolve dependency ( connector port register . class ) ) . then return ( port register ) ; }
string storage string = journal . get storage ( ) . to colon separated string ( ) ;
tr pr . get cnf style or div id or grid before ( ) . remove ( existing ) ;
if ( no _ entry _ value = ( float ) 0 ) { arrays . fill ( _ set , no _ entry _ value ) ; }
conn = send request ( server , get , db _ design design _ view view , headers , null ) ;
if ( this . resource name = null ) { if ( this . resource name . equals ( name ) ) { return new resource property source ( this . resource name , null , this . source ) ; } else { return new resource property source ( name , this . resource name , this . source ) ; } } else { current name is resource name - > preserve it in the extra field . . . return new resource property source ( name , this . name , this . source ) ; }
realm dc0 = get admin client for started node in dc ( 0 ) . realms ( ) . realm ( realm _ name ) . to representation ( ) ; assert . assert equals ( cool realm , realm dc0 . get display name ( ) ) ; assert . assert false ( realm dc0 . is registration allowed ( ) ) ; atomic integer i = new atomic integer ( 0 ) ;
stats = new data statistics ( 100 , 5 , false ) ;
student couch dbbyte wrapper student = new student couch dbbyte wrapper ( ) ; student . set age ( ( short ) get random value ( short . class ) ) ; student . set id ( ( byte ) get random value ( byte . class ) ) ; student . set name ( ( string ) get random value ( string . class ) ) ; em . persist ( student ) ; em . close ( ) ; }
string parent name = get next ancestor name ( n ) ; inner node parent node = ( inner node ) children map . get ( parent name ) ; if ( parent node = = null ) {
animator set show = new animator set ( ) ;
local bean interface in ear lib local business interface in ear lib = ( local bean interface in ear lib ) ctx . lookup ( java _ global _ namespace _ prefix + app _ name + + module _ name + + ejb name + + local bean interface in ear lib . class . get name ( ) ) ; assert . assert not null ( null object returned for local business interface lookup in java : global namespace , local business interface in ear lib ) ; local bean interface in ejb jar local business interface in ejb jar = ( local bean interface in ejb jar ) ctx . lookup ( java _ global _ namespace _ prefix + app _ name + + module _ name + + ejb name + + local bean interface in ejb jar . class . get name ( ) ) ; assert . assert not null ( null object returned for local business interface lookup in java : global namespace , local business interface in ejb jar ) ;
if ( show memory ) { gl push matrix ( ) ; gl translatef ( 320 - ( float ) bar width 2 , 20 , 0 ) ; draw memory bar ( ) ; gl pop matrix ( ) ; }
while ( live data nodes = num data nodes ) { try { dafs = get file system ( nn index ) ; thread . sleep ( 200 ) ; live data nodes = dafs . get live data node stats ( false ) . length ; log state change ( waiting for data nodes : live = + live data nodes + , total = + num data nodes ) ; } catch ( exception e ) { log . warn ( exception waiting for datanodes : , e ) ; } finally { if ( dafs = null ) { dafs . close ( ) ; } } } log state change ( waiting for data nodes - completed ) ;
if ( local name = null & & . equals ( local name ) ) { f serializer . add attribute ( attr ns , local name , attr name , type , attr value ) ; }
final count down latch drop latch2 = new count down latch ( 1 ) ;
token comment = new token ( ) ; comment . type = token . comment ; comment . spacing = spacing . substring ( 0 , n ) ; comment . value = + spacing . substring ( n ) + + keyword . spacing + keyword ; tokens . add ( comment ) ; string value = ;
packet . set resend delay ( con . get options ( ) . get resend delay ( ) 1000 ) ; if ( con . get options ( ) . get profile ( ) = = connection options . profile _ interactive ) packet . set flag ( packet . flag _ profile _ interactive , true ) ; else packet . set flag ( packet . flag _ profile _ interactive , false ) ; packet . set flag ( packet . flag _ signature _ requested , con . get options ( ) . get require fully signed ( ) ) ;
dfstest util . verify file replicas on storage type ( fs , client , path1 , ram _ disk ) ;
final settings . builder prepare shrink settings = settings . builder ( ) . put ( index . routing . allocation . require . _ name , merge node ) . put ( index . blocks . write , true ) ; client ( ) . admin ( ) . indices ( ) . prepare update settings ( source ) . set settings ( prepare shrink settings ) . get ( ) ; ensure green ( ) ; final index meta data index meta data = index meta data ( client ( ) , source ) ;
scan . set stop row ( hbase timeline storage utils . calculate the closest next row key for prefix ( sub application row key prefix . get row key prefix ( ) ) ) ;
sb . append ( \ t \ t @ suppress warnings ( \ unchecked \ ) \ n ) ;
try { new factory6 builder ( 22 ) . reality ( 1 ) . reality ( 2 ) . build ( ) ; check ( false ) ; } catch ( illegal state exception ex ) { }
case instruction constants . op _ nop : case instruction constants . op _ aconst _ null : case instruction constants . op _ iconst _ m1 : case instruction constants . op _ iconst _ 0 : case instruction constants . op _ iconst _ 1 : case instruction constants . op _ iconst _ 2 : case instruction constants . op _ iconst _ 3 : case instruction constants . op _ iconst _ 4 : case instruction constants . op _ iconst _ 5 : case instruction constants . op _ lconst _ 0 : case instruction constants . op _ lconst _ 1 : case instruction constants . op _ fconst _ 0 : case instruction constants . op _ fconst _ 1 : case instruction constants . op _ fconst _ 2 : case instruction constants . op _ dconst _ 0 : case instruction constants . op _ dconst _ 1 : case instruction constants . op _ bipush :
public void test server set change _ start scn response success ( ) throws exception { bootstrap pull thread bs puller = create bootstrap pull thread ( false , false , false ) ; checkpoint cp = _ ckpt handler source1 . create initial bootstrap checkpoint ( null , 0 l ) ;
operation handle operation handle = client . execute statement ( session handle , sql , null ) ; row set row set result = client . fetch results ( operation handle ) ; assert . assert equals ( 500 , row set result . num rows ( ) ) ; assert . assert equals ( 238 , row set result . iterator ( ) . next ( ) [ 0 ] ) ; assert . assert equals ( val _ 238 , row set result . iterator ( ) . next ( ) [ 1 ] ) ; return session handle ; }
int prev count = counter [ 0 ] ;
ldaptest utils . update group mapper config options ( mapper model , group mapper config . preserve _ group _ inheritance , false ) ; realm . update component ( mapper model ) ; new group ldapstorage mapper factory ( ) . create ( session , mapper model ) . sync data from federation provider to keycloak ( realm ) ;
logger . info ( get data column error : + caught . get message ( ) ) ; } @ override public void on success ( linked hash map < string , integer > result ) {
decode removal reentry protection ( ctx , in , out ) ;
final realm mock realm = mock ( realm . class ) ;
match get member ( clazz , method , code attribute , offset , instruction , null , constant get constructor matcher2 , get constructor matcher2 , false , false , class constants . method _ name _ init , null ) ;
relation obj name = safe get object name ( tmp relation obj name ) ; new role value = safe get object name list ( tmp new role value ) ; old role value = safe get object name list ( tmp old role value ) ; unregister mbean list = safe get object name list ( tmp unreg mbean list ) ; relation id = tmp relation id ;
if ( params . has ( output ) ) { prediction . write as text ( params . get ( output ) ) ; } else { system . out . println ( printing result to stdout . use - - output to specify output path . ) ; prediction . print ( ) ; }
try { ds1 . cross ( ds2 ) . project first ( ) . project second ( ) ; } catch ( exception e ) { assert . fail ( ) ; }
executor . shutdown ( ) ; }
exchange signed = get mandatory endpoint ( direct : alias - sign ) . create exchange ( ) ; signed . get in ( ) . copy from ( unsigned . get out ( ) ) ; signed . get in ( ) . set header ( signature _ public _ key _ or _ cert , pair . get public ( ) ) ; template . send ( direct : headerkey - verify , signed ) ; assert mock endpoints satisfied ( ) ;
for ( int i = 0 ; i < interfaces implemented . length ; i + + ) { set < reloadable type > l = jdk proxies for interface . get ( interfaces implemented [ i ] ) ; if ( l = = null ) { l = new hash set < reloadable type > ( ) ; jdk proxies for interface . put ( interfaces implemented [ i ] , l ) ; } l . add ( rtype ) ; } } }
for ( long i = 0 ; i < num ords ; i + + ) { long random ord = test util . next long ( random ( ) , 0 , num ords - 1 ) ; expected . seek exact ( random ord ) ; actual . seek exact ( expected . term ( ) ) ; assert equals ( expected . ord ( ) , actual . ord ( ) ) ; assert equals ( expected . term ( ) , actual . term ( ) ) ; }
assert false ( names . contains ( ejb ) ) ;
assert equals ( row result2a . columns . get ( column bname ) . value , value bname ) ;
list < string > watch roots = new array list < > ( ) ; for ( int i = 1 ; i < non option args . size ( ) ; i + + ) { watch roots . add ( non option args . get ( i ) . to string ( ) ) ; }
return new located striped block ( b , datanode storage info . to datanode infos ( storages ) , datanode storage info . to storage ids ( storages ) , datanode storage info . to storage types ( storages ) , indices , start offset , corrupt , null ) ; }
endpoint pool config . set connect max tries ( modbus . default _ retries ) ;
map < compressed content format , ? extends http content > precompressed contents = check precompressed variants?content . get precompressed contents ( ) : null ;
for ( immutable bit set col mask : child unique key set ) { immutable bit set . builder tmp mask = immutable bit set . builder ( ) ; boolean complete key projected = true ; for ( int bit : col mask ) { if ( map in to out pos . contains key ( bit ) ) { tmp mask . set ( map in to out pos . get ( bit ) ) ; } else {
xmlassert . assert xpath evaluates to ( 1 , count ( html body table tr th [ . = ' red _ band ' ] ) , dom ) ; xmlassert . assert xpath evaluates to ( 1 , count ( html body table tr th [ . = ' green _ band ' ] ) , dom ) ; xmlassert . assert xpath evaluates to ( 1 , count ( html body table tr th [ . = ' blue _ band ' ] ) , dom ) ; }
assert matches configuration from filename ( abc - def , abc - def - v0 ) . is true ( ) ;
local name tracker = true ; } else {
if ( rule . get action ( ) = = strip _ space ) strip [ s count + + ] = il . append ( new if _ icmpeq ( null ) ) ; else preserve [ p count + + ] = il . append ( new if _ icmpeq ( null ) ) ; } }
if ( ( f facets defined & facet _ maxlength ) = = 0 & & ( f base . f facets defined & facet _ maxlength ) = 0 ) { f facets defined | = facet _ maxlength ; f max length = f base . f max length ; max length annotation = f base . max length annotation ; }
builder . put int32 to int32 field ( 4 , 44 ) ;
config . set property ( default dialect option . property _ name , java ) ;
case hsqldb :
assert that ( actual type ) . overriding error message ( expected phone type < % s > but was < % s > . , phone type to string ( type ) , phone type to string ( actual type ) ) . is equal to ( type ) ; return this ;
eventually ( ( ) - > connection pool . get num active ( ) = = 0 , 1000 ) ; assert exist key value ( k3 , v3 ) ;
char c = search . char at ( idx ) ; boolean case fold = ( match flags & match _ caseindependent ) = 0 ;
segment data manager . _ responses . add ( commit failed ) ;
multi user chat muc2 = new multi user chat ( get connection ( 1 ) , room ) ; discussion history history = new discussion history ( ) ; history . set seconds ( 2 ) ; muc2 . join ( testbot2 , null , history , smack configuration . get packet reply timeout ( ) ) ; message msg ;
set max up bw ( _ max up bw ) ;
if ( free sweep allocation threshold < 1 ) { throw new illegal argument exception ( free sweep allocation threshold : + free sweep allocation threshold + ( expected : > 0 ) ) ; } free task = new runnable ( ) { @ override public void run ( ) { free0 ( ) ; } } ; death watch thread = thread . current thread ( ) ;
if ( state . get ( ) . can add pages ( ) ) { return immediate future ( true ) ; }
resolver = new class path resolver ( immutable list . < string > of ( ) , immutable list . < string > of ( ) , class path , dex file ) ;
assert . assert equals ( mock key , cache . get key version ( k1 @ 0 ) ) ;
this . scheduled executor service = scheduled executor service ;
for ( oauth client . access token response resp : token responses ) { oauth client . access token response new response = oauth . do refresh token request ( resp . get refresh token ( ) , password ) ; assert . assert null ( new response . get error ( ) ) ; assert . assert not null ( new response . get access token ( ) ) ; } }
replace instruction ( clazz , offset , branch instruction , new branch instruction ( instruction constants . op _ ifne , branch instruction . branch offset ) ) ;
_ server = new server ( new queued thread pool ( 3 ) ) ;
long proc id = proc exec . submit procedure ( new disable table procedure ( proc exec . get environment ( ) , table name , false ) ) ; test recovery and double execution ( util , proc id , step ) ; master procedure testing utility . validate table is disabled ( util . get hbase cluster ( ) . get master ( ) , table name ) ;
init mock cursor with session in schedule ( m mock cursor ) ;
boolean use props = ( param name = null ) | | ( inject id = null ) ;
edge . increment time ( 5000 ) ; r = region . get ( new get ( row ) ) ;
if ( retval = = grow _ none & & r . contains ( ( int ) x , ( int ) y ) ) { retval = move ; } return retval ; }
use configuration ( - - interface _ shared _ objects ) ;
network offering vo default shared network offering = new network offering vo ( network offering . default shared network offering , offering for shared networks , traffic type . guest , false , true , null , null , true , availability . optional , null , network . guest type . shared , true , true ) ; default shared network offering . set state ( network offering . state . enabled ) ;
set < partition result > parts not in ms = create parts not in ms ( 23 ) ; hive spy db = mockito . spy ( db ) ;
out . write char ( no _ entry _ key ) ;
if ( r _ combo _ suffix ( ) ) { break lab1 ; } continue replab0 ; } while ( false ) ; cursor = limit - v _ 1 ; break replab0 ; }
generic file < t > result = file . copy from ( file ) ;
property table properties = new property table ( header _ block , data _ blocks ) ;
return string . format ( format _ delete _ class , device , root _ qdisc _ handle , class id ) ;
test query ( select count ( distinct trim ( both ' ' from dim1 ) ) from druid . foo where trim ( dim1 ) < > ' ' , immutable list . of ( druids . new timeseries query builder ( ) . data source ( calcite tests . datasource1 ) . intervals ( qss ( filtration . eternity ( ) ) ) . filters ( not ( selector ( dim1 , , null ) ) ) . granularity ( granularities . all ) . virtual columns ( expression _ virtual _ column ( a0 : v , trim ( \ dim1 \ , ' ' ) , value type . string ) ) . filters ( expression _ filter ( ( trim ( \ dim1 \ , ' ' ) = ' ' ) ) ) . aggregators ( aggs ( new cardinality aggregator factory ( a0 , null , dims ( new default dimension spec ( a0 : v , a0 : v , value type . string ) ) , false , true ) ) ) . context ( timeseries _ context _ default ) . build ( ) ) , immutable list . of ( new object [ ] { 5 l } ) ) ;
qr = a . get array copy ( ) ; m = a . get row dimension ( ) ; n = a . get column dimension ( ) ; rdiag = new double [ n ] ;
fold same ( function f ( ) { try { foo ( ) } catch ( e ) { bar ( e ) } finally { baz ( ) } } ) ;
context . unset ( ) ;
g . set color ( arrow color ) ; int start x = ( ( ( w + 1 ) - arrow height ) 2 ) + arrow height - 1 ; int start y = ( h 2 ) ;
for ( enumeration inet addrs = ni . get inet addresses ( ) ; inet addrs . has more elements ( ) ; ) { inet address inet addr = ( inet address ) inet addrs . next element ( ) ;
sorting strategy = to sorting strategy ( saved instance state . get int ( sorting _ strategy ) ) ;
int partition = value % num partitions ; my partitions . add ( partition ) ; if ( my partitions . size ( ) > max partitions ) { throw new exception ( error : elements from too many different partitions : + my partitions + . expect elements only from + max partitions + partitions ) ; } return value ; }
volt table stats t = get stats ( client , procedure ) ; system . out . println ( stats : + stats t . to formatted string ( ) ) ; assert equals ( 0 , stats t . get row count ( ) ) ; local server . shutdown ( ) ; local server . join ( ) ; }
available width = expanded width ; } }
logger . on completion ( 1 , result ) ;
internal entry < object , object , ? > null entry = segment . new entry for testing ( null , hash , entry ) ;
this ( activity . get support fragment manager ( ) ) ; }
is connection closed = false ;
final non reusing block resettable iterator < record > iterator = new non reusing block resettable iterator < record > ( this . memman , this . reader , this . serializer , 1 , mem owner ) ;
assert equals ( expected map mb , simulated conf . get memory required ( task type . map ) ) ;
if ( context . is stopping ( ) ) { return ; } hregion info region = policy based chaos monkey . select random item ( regions . to array ( new hregion info [ regions . size ( ) ] ) ) ;
for ( map . entry < string , string > entry : kv pairs . entry set ( ) ) { if ( entry . get key ( ) . equals ( first key ) ) { assert equals ( online write overwritten , dst primary resolving store client . get ( first key ) . get value ( ) , before forklift ) ; } else if ( entry . get key ( ) . equals ( last key ) ) { assert equals ( can ' t update value after forklift , dst primary resolving store client . get ( last key ) . get value ( ) , after forklift ) ; } else if ( entry . get key ( ) . equals ( conflict key ) ) { assert equals ( conflict resolution incorrect , dst primary resolving store client . get ( conflict key ) . get value ( ) , winning value ) ; } else { assert equals ( fork lift data missing , dst primary resolving store client . get ( entry . get key ( ) ) . get value ( ) , entry . get value ( ) ) ; } }
string tasknode1 = zksplit log . get encoded node name ( zkw , orphan 1 ) ; final server name worker1 = server name . value of ( worker1 , 1 , 1 ) ; split log task slt = new split log task . owned ( worker1 , this . mode ) ; zkw . get recoverable zoo keeper ( ) . create ( tasknode1 , slt . to byte array ( ) , ids . open _ acl _ unsafe , create mode . persistent ) ; slm = new split log manager ( master , conf ) ; wait for counter ( tot _ mgr _ orphan _ task _ acquired , 0 , 1 , to 2 ) ;
connected = true ; call connection connected listener ( ) ; return this ; }
pattern . set offset ( context . get current pattern offset ( ) ) ;
for ( final element element : elements ) { final boolean expected result = element instanceof entity ; final pair < key , key > keys = converter . get keys from element ( element ) ; assert equals ( failed for element : + element . to string ( ) , expected result , filter . accept ( keys . get first ( ) , value ) ) ; if ( null = keys . get second ( ) ) { entities and self edges are not added the other way round assert equals ( failed for element : + element . to string ( ) , expected result , filter . accept ( keys . get second ( ) , value ) ) ; } }
return container . get base uri ( ) . get port ( ) ;
xmlassert . assert xpath evaluates to ( 1 , count ( ogc : service exception ) , doc ) ;
assert equals eventually ( new callable < integer > ( ) { @ override public integer call ( ) throws exception { return query cache . size ( ) ; } } , 1 ) ;
nano httpd . safe close ( this . input stream ) ;
return break iterator . get word instance ( locale ) ; default : throw new illegal argument exception ( invalid boundary scanner type : + type . to string ( ) ) ; } }
file util . un tar ( simple tar , tmp ) ;
assert replica information ( http ) ; test migrate ssl ( new ssltest config ( true , false ) ) ; test migrate ssl ( new ssltest config ( false , false ) ) ; }
offset x = this . get parent ( ) . get bounds in local ( ) . get width ( ) ; offset y = this . get parent ( ) . get bounds in local ( ) . get height ( ) ; animation = get show animation ( transition type . get ( ) ) ; }
p . set person name ( newvivek ) ;
tmp = tmp . substring ( 0 , tmp . length ( ) - 1 ) ;
log . warn ( removing jmeter property : { } , name ) ; jmeter props . remove ( name ) ; }
assert that ( dom , has xpath ( count ( at : feed at : entry owc : offering ) , equal to ( 3 ) ) ) ;
if ( m menu inflater = = null ) { if ( get action bar ( ) = null ) { m menu inflater = new menu inflater ( get themed context ( ) , m activity ) ; } else { m menu inflater = new menu inflater ( m activity ) ; } } return m menu inflater ;
transfer fs image . get file server ( response . get output stream ( ) , image file , get throttler ( conf , parsed params . is throttler disabled ( ) ) ) ;
return this . online servers . size ( ) ;
merged . add ( spec1 ) ;
artifact hello = create source artifact ( hello ) ; file system utils . create directory and parents ( hello . get path ( ) . get parent directory ( ) ) ; file system utils . write content as latin1 ( hello . get path ( ) , content1 ) ; artifact goodbye = create derived artifact ( goodbye ) ; button button = create action button ( sets . new hash set ( hello ) , sets . new hash set ( goodbye ) ) ; button . pressed = false ;
res = function . reduce ( res , value ) ;
if ( serial filter = null & & serial filter = object input filter . config . get serial filter ( ) ) { throw new illegal state exception ( filter can not be set more than once ) ; }
this . connection = connection ;
assert false ( degrader load balancer strategy v2 _ 1 . is new state healthy ( new state v2 , config , client updaters ) ) ;
success fully completed steps = success fully completed steps + , + step2 ;
screen position . set all ( lens flare . get position ( ) . clone ( ) ) ; screen position . multiply ( view matrix ) ; screen position . project ( proj matrix ) ;
user info u = ui [ 0 ] ;
connect parent to children ( x9 , x8 ) ; connect parent to children ( x10 , x8 ) ; connect parent to children ( x11 , x8 ) ; connect parent to children ( x12 , x8 ) ; junction tree builder jt builder = new junction tree builder ( graph ) ;
} finally { client . close ( ) ; }
return ( mm . is runtime ( ) | | mm . matches ( method , target class , args ) ) ; } }
odistributed server log . debug ( this , d manager . get local node name ( ) , null , direction . none , all responses collected % s , but no quorum reached ( req id = % s ) , responses , request . get id ( ) ) ; break ; } request . get task ( ) . check is valid ( d manager ) ; if ( missing active nodes = = 0 ) {
directory dir2 = new directory ( dir ) ; dir . close ( ) ; new random index writer ( random ( ) , dir2 ) . close ( ) ; dir2 . close ( ) ;
assert correct ( el tràiler té una picada d ' ullet quan diu que \ no es pot fer una pel·lícula ' slasher ' com si fos una sèrie \ . ) ; assert correct ( el tràiler –que té una picada d ' ullet quan diu que \ no es pot fer una pel·lícula ' slasher ' com si fos una sèrie \ – ja ) ;
input stream is = cryptonit trades jsontest . class . get resource as stream ( marketdata example - trades - data . json ) ;
json array = new jsonarray ( ) ;
easy mock . expect ( member . member id ( ) ) . and stub return ( member ) ;
char ch = seg . array [ word position ] ;
system . out . println ( testing good ping invocation with bad protocol version . ) ;
return arrange nr ( container , g2 , constraint ) ;
new online banking lambda ( ) . process customer ( 1 , ( customer c ) - > system . out . println ( hello + c . get name ( ) ) ) ;
lr . add field ( session id , new log field ( log field . type _ string , lp . get next cb ( ) ) ) ;
result & = relative _ layout _ direction ; }
super . on create ( saved instance state ) ; }
int larger multiple b = 1 ;
throw new illegal argument exception ( size < 0 ) ;
assert true ( response . contains ( < li > ninja properties . get context path ( ) : < li > ) ) ; assert true ( response . contains ( < li > context . get context path ( ) : < li > ) ) ; }
ogw . start walking ( top nodes , null ) ; return pctx ; }
result . append ( sql query . substring ( curr ) ) ;
set background drawable ( bg ) ;
string value point = value . substring ( open idx + 1 , close idx ) ;
char b ;
parameter node parameter = ( parameter node ) ast factory . create ( named _ param , name ) ; parameter . set text ( ? ) ; named parameter specification param spec = new named parameter specification ( delimiter node . get line ( ) , delimiter node . get column ( ) , name ) ; parameter . set hql parameter specification ( param spec ) ; parameters . add ( param spec ) ;
fields . put ( host , authority ) ;
cancel latch . trigger ( ) ;
state = old state ; }
out dex file . get parent file ( ) . mkdirs ( ) ;
test unmanaged archive deployment ( ) ; redeploy test ( ) ; }
int scratch bytes col = ocm . allocate output column ( type info factory . string type info ) ; class < ? > cl = ( mode = = vector expression descriptor . mode . filter ? filter struct column in list . class : struct column in list . class ) ;
current pos = line . index of ( - > , end of next number ) + 2 ; boolean has total heap = true ;
options options = server util . build commandline options ( new options ( ) ) ; command line = server util . parse cmd line ( mqnamesrv , args , build commandline options ( options ) , new posix parser ( ) ) ; if ( null = = command line ) { system . exit ( - 1 ) ; return null ; } final namesrv config namesrv config = new namesrv config ( ) ;
block cluster state processing disruption = new block cluster state processing ( data node , random ( ) ) ;
set < injection point > injection points ; if ( instance = null ) { try { injection points = injection point . for instance methods and fields ( instance . get class ( ) ) ; } catch ( configuration exception e ) { for ( message message : e . get error messages ( ) ) { binder . add error ( message ) ; } injection points = unmodifiable set ( new hash set < injection point > ( e . get partial value ( ) ) ) ; } } else { binder . add error ( binding _ to _ null ) ; injection points = empty set ( ) ; } binding impl < t > base = get binding ( ) ;
assert equals ( 3 , test sql util . run sql select ( select distinct substr _ count ( ' a b c ' , ' ' ) from information _ schema . system _ tables , connection ) ) ; connection . create statement ( ) . execute ( shutdown ) ;
write frame ( frame header , headers payload ) ;
long col . no nulls = true ; str col . no nulls = true ; dbl col . no nulls = true ; out col . init buffer ( ) ; b . size = 2 ; return b ;
put ( table ) ; assert versions ( table , new long [ ] { hconstants . latest _ timestamp , t2 , t1 } ) ; delete ( table , t2 ) ; assert versions ( table , new long [ ] { hconstants . latest _ timestamp , t1 , t0 } ) ;
uri host url = new uri ( url ) ; http host target = new http host ( host url . get host ( ) , host url . get port ( ) , http host . default _ scheme _ name ) ; client = create http client ( context ) ;
if ( garageopener . get status ( ) . in motion ( ) ) { begin rapid poll ( false ) ; }
final int child count = get child count ( ) ; for ( int i = 0 ; i < child count ; i + + ) { final view child = get child at ( i ) ; if ( child . get visibility ( ) = = visible ) { final item info ii = info for child ( child ) ; if ( ii = null & & ii . position = = m cur item & & child . dispatch populate accessibility event ( event ) ) { return true ; } } } return false ;
if ( scopes . is singleton ( injector . get binding ( filter key ) ) ) { throw new servlet exception ( filters must be bound as singletons . + filter key + was not bound in singleton scope . ) ; } filter filter = injector . get instance ( filter key ) ; this . filter . set ( filter ) ;
if ( ( b . get locations ( ) = = null ) | | ( b . get locations ( ) . length = = 0 ) ) { safe mode exception se = new safemode exception ( zero blocklocations for + src arg ) ; if ( ha enabled & & ha context = null & & ha context . get state ( ) . get service state ( ) = = haservice state . active ) { throw new retriable exception ( se ) ; } else { throw se ; } }
merge insert ( min pos , insert at , value , 1 ) ; }
assert null ( app saved state . get attempt ( am1 . get application attempt id ( ) ) . get state ( ) ) ; rm2 = new mock rm ( conf , mem store ) ; rm2 . start ( ) ; rmapp recovered app1 = rm2 . get rmcontext ( ) . get rmapps ( ) . get ( app1 . get application id ( ) ) ; assert equals ( rmapp state . finished , recovered app1 . get state ( ) ) ;
char x = s [ end index s ] ;
client config . get security config ( ) . set credentials ( new custom credentials ( ) ) ;
assert pixel ( image , 120 , 74 , new color ( 25 , 25 , 243 ) ) ;
log . info ( starting two more nodes ) ;
try { grant global using access control client ( test _ util , system user connection , user name , permission . action . write ) ; } catch ( throwable e ) { log . error ( error during call of access control client . grant . , e ) ; }
img , image to display new context information ( img , display string , display string ) , the context information associated with this proposal proposal type , null , object ) ; }
check xpath ( doc , path to signature properties + etsi : signing time text ( ) , prefix2 namespace , not _ empty ) ;
super . put ( key , endpoint ) ; return answer ;
check one term ( a , τηλεόραση , τηλεορασ ) ; check one term ( a , τηλεόρασης , τηλεορασ ) ; check one term ( a , τηλεοράσεις , τηλεορασ ) ; check one term ( a , τηλεοράσεων , τηλεορασ ) ;
if ( this . addrs . length = that . addrs . length ) { return false ; } inet address [ ] that addrs = that . addrs ;
object field = hit . get field ( field name ) ; if ( field instanceof char sequence & & ( ( char sequence ) field ) . length ( ) = = 0 ) return false ;
return resource . get color ( r . color . text _ _ primary _ dark ) ; } else {
column our _ column = catalog _ tbl . get columns ( ) . get ignore case ( catalog _ colref . get type name ( ) ) ; assert ( our _ column = null ) ; our _ columns + = col _ add + our _ column . get type name ( ) ; column fkey _ column = catalog _ colref . get column ( ) ; assert ( fkey _ column = null ) ;
m styles . put ( null , new kml style ( ) ) ; }
if ( missing bytes in last group = 0 ) { int ch0 = base64to int ( s . char at ( in cursor + + ) ) ; int ch1 = base64to int ( s . char at ( in cursor + + ) ) ; result [ out cursor + + ] = ( byte ) ( ( ch0 < < 2 ) | ( ch1 > > 4 ) ) ; if ( missing bytes in last group = = 1 ) { int ch2 = base64to int ( s . char at ( in cursor + + ) ) ; result [ out cursor + + ] = ( byte ) ( ( ch1 < < 4 ) | ( ch2 > > 2 ) ) ; } }
if ( content = = null ) { try { content = remote views . apply ( m context , this ) ; if ( logd ) log . d ( tag , had to inflate new layout ) ; } catch ( runtime exception e ) { exception = e ; } } m layout id = layout id ;
string new refresh token = response . get refresh token ( ) ; assert . assert not null ( new refresh token ) ; assert . assert not equals ( old token . get id ( ) , refreshed token . get id ( ) ) ; assert . assert equals ( user id , refreshed token . get subject ( ) ) ; assert . assert true ( refreshed token . get realm access ( ) . is user in role ( user ) ) ; assert . assert true ( refreshed token . get realm access ( ) . is user in role ( constants . offline _ access _ role ) ) ; assert . assert equals ( 1 , refreshed token . get resource access ( test - app ) . get roles ( ) . size ( ) ) ; assert . assert true ( refreshed token . get resource access ( test - app ) . is user in role ( customer - user ) ) ; event representation refresh event = events . expect refresh ( offline token . get id ( ) , session id ) . client ( offline - client ) . user ( user id ) . remove detail ( details . updated _ refresh _ token _ id ) . detail ( details . refresh _ token _ type , token util . token _ type _ offline ) . assert event ( ) ; assert . assert not equals ( old token . get id ( ) , refresh event . get details ( ) . get ( details . token _ id ) ) ; set time offset ( 0 ) ;
id asc xpath checks [ i + 1 ] = result doc [ + ( 1 + i ) + ] int [ @ name = ' field ( + field + ) ' ] [ . = ' + values . get ( i ) + ' ] ;
translator = create new query translator ( select sum ( h . id ) from human h ) ;
mysql con . exec cmd ( xa end + xa tx id + ; ) ; mysql con . exec cmd ( xa rollback + xa tx id + ; ) ; } else { conn . rollback ( ) ; } + + started ; } }
buf = new string builder ( ) ;
for ( internal activation group group : this . activation groups . values ( ) ) { clear and cancel activation group ( group ) ; }
assert equals ( 1 , rule . match ( lang tool . get analyzed sentence ( на західній україни ) ) . length ) ;
if ( out instanceof send definition ) { send definition send = ( send definition ) out ; list < processor definition < ? > > children = send . get outputs ( ) ; do find type ( children , type , found , + + current , max deep ) ; }
source mock sequence = new source mock ( 1 ) ; optimizer optimizer = build hilo optimizer ( - 1 , increment ) ; for ( int i = 1 ; i < = increment ; i + + ) { next = ( long ) optimizer . generate ( sequence ) ; assert equals ( i , next . int value ( ) ) ; } assert equals ( 1 , sequence . get times called ( ) ) ; once to initialze state assert equals ( 1 , sequence . get current value ( ) ) ;
int length = lexical representation . length ( ) ; for ( int i = 0 ; i < length ; + + i ) { char c = lexical representation . char at ( i ) ; if ( c = = ' d ' | | c = = ' t ' ) { throw new illegal argument exception ( invalid year month duration value : + lexical representation ) ; } } return new duration ( lexical representation ) ; }
path info with servlet style matching ( path some path of . jsp , path , thing * , null , some path of . jsp ) ;
final linear layout ll example v = dialog layout . find view by id ( r . id . affix _ example _ vertical ) ;
context . nesting = 0 ; for ( int i = 0 ; i < new wrappers . length ; i + + ) { int slash count = slash count ( new wrappers [ i ] . name ) ; if ( slash count > context . nesting ) { context . nesting = slash count ; } } context . wildcard wrappers = new wrappers ; } } else if ( path . starts with ( * . ) ) {
list < object > current line = lines . get ( this . current line index ) ;
vector var dep elements = new vector ( _ globals ) ; iterator < syntax tree node > elements = elements ( ) ; while ( elements . has next ( ) ) { syntax tree node element = elements . next ( ) ; if ( element instanceof key ) { var dep elements . add ( element ) ; } }
replicated map2 . put ( 1 , 2 ) ; assert true eventually ( new assert task ( ) { @ override public void run ( ) throws exception { assert equals ( 2 , ( int ) replicated map1 . get ( 1 ) ) ; } } ) ;
char sequence new query = m suggestions adapter . convert to string ( c ) ;
process namenodes for shutdown ( threads ) ;
path small file = new path ( sfile ) ; int s file len = 10 ; dfstest util . create file ( dfs , small file , s file len , repl _ factor , 1 ) ; log . info ( trying the second concat operation . ) ; dfs . concat ( trg path , new path [ ] { small file } , restricted ) ; log . info ( second concat operation successful . ) ; f status = nn . get file info ( trg ) ;
scan . set attribute ( attribute1 , bytes . to bytes ( value12 ) ) ; assert . assert true ( arrays . equals ( bytes . to bytes ( value12 ) , scan . get attribute ( attribute1 ) ) ) ; assert . assert equals ( 1 , scan . get attributes map ( ) . size ( ) ) ; assert . assert true ( arrays . equals ( bytes . to bytes ( value12 ) , scan . get attributes map ( ) . get ( attribute1 ) ) ) ;
return escape text value ( s ) ; }
result . add ( new object [ ] { test type . ipv6 , [ : : 1 ] , integer . value of ( - 1 ) , null } ) ;
rect . paint ( canvas . get offline image ( ) , canvas . get offline graphics ( ) ) ;
try { print writer new print writer = ( value ) ? new print writer ( system . out ) : null ; driver manager . set log writer ( new print writer ) ; } catch ( exception e ) { }
for ( slot acc acc : other accs ) { acc . reset ( ) ; todo - make reset take num docs and num slots? } return ;
final map < oraw buffer , list < string > > candidates grouped by content = new hash map < oraw buffer , list < string > > ( ) ;
set storage info ( dn index , get storage info ( last node ) ) ;
afe . init cause ( exceptions . get first ( ) ) ;
throw new runtime exception ( slider item hasn ' t attached to slider menu , i cannot do anything ) ;
keep alive keepalive = new keep alive ( 240000 , 8 ) ; synchronized ( keepalive ) { keepalive . start ( ) ; try { keepalive . wait ( ) ; } catch ( interrupted exception e ) {
try { flink file system . delete ( ha data directory , true ) ; } catch ( throwable t ) { exception = exception utils . first or suppressed ( t , exception ) ; }
return roles . master ;
dbeaver ui . sync exec ( new runnable ( ) { @ override public void run ( ) { update meta info ( events ) ; } } ) ;
locs . add all ( entry . get value ( ) ) ;
if ( cpindex = = 0 ) { m _ cut points [ index ] = null ; } else { double [ ] cp = new double [ cpindex ] ; for ( int i = 0 ; i < cpindex ; i + + ) { cp [ i ] = cut points [ i ] ; } m _ cut points [ index ] = cp ; } }
assert equals ( memory changed event problem : expected 0 events , 0 , get event count ( ) ) ; }
string [ ] s = { a , b , c } ; string joined = launchable task . join ( s , - - ) ; assert . assert equals ( a - - b - - c , joined ) ; }
return invoke superclass method impl ( bcm , instance , method name , args ) ; }
row . nullify link ( column info . column object index ) ; return ; } proxy state . check valid object ( value ) ; row . get table ( ) . set link ( column info . column object index , row . get index ( ) , ( ( realm object proxy ) value ) . realm get proxy state ( ) . get row realm ( ) . get index ( ) , true ) ; return ; }
for ( byte array k : keys ) { total key bytes + = k . get ( ) . length ; requested values + + ; }
float metadata value = float . parse float ( buffer . get meta data ( ) . get ( numeric field writables [ i ] ) . to string ( ) ) ;
script = db . person . find ( { \ age \ : { gt : 15 } } ) . to array ( ) ;
list < ? extends type mirror > ast interfaces = null ; if ( node instanceof type declaration ) { ast interfaces = ( ( type declaration ) node ) . get super interface type mirrors ( ) ; } else if ( node instanceof enum declaration ) { ast interfaces = ( ( enum declaration ) node ) . get super interface type mirrors ( ) ; } else { annotation type declaration return element util . get interfaces ( node . get type element ( ) ) ; } list < type element > result = new array list < > ( ) ;
immutable bit set . builder input fields used = immutable bit set . builder ( ) ; for ( int bit : fields used plus ) { if ( bit > = input start pos & & bit < input start pos + input field count ) { input fields used . set ( bit - input start pos ) ; } } set < rel data type field > input extra fields = collections . < rel data type field > empty set ( ) ;
final atomic integer i = new atomic integer ( 0 ) ; note : would be racy if not an atomic integer
{ error msg . illegal _ arg _ err , otill \ u00 e5tna argument f \ u00 f6r funktionsanrop . } ,
color mode scale = ( ( max a = 1 ) | | ( max x = max y ) | | ( max y = max z ) | | ( max z = max a ) ) ;
get = new get ( rows [ 0 ] ) ; get . add column ( families [ 4 ] , qualifiers [ 3 ] ) ; result = ht . get ( get ) ; assert empty result ( result ) ;
info . set state ( get container states ( pod ) . get ( 0 ) ) ; return info ;
if ( target view = null ) { check motion direction ( x , y ) ; }
assert true ( expl , expl . contains ( = sort field < int : \ popularity \ > value = 20 ) ) ;
smservice helper . get instance ( ) . start background service ( context , pid , proc name ) ; } else if ( action . equals ( action _ end _ test ) ) {
sorted set doc values dv = get doc values ( ) ;
vespa xmlfeed reader . operation op = new vespa xmlfeed reader . operation ( ) ;
task service . complete ( task before sub process . get id ( ) ) ;
setter = ows utils . setter ( request . get class ( ) , property , null ) ;
client . drain ( ) ;
label = edge type . get name ( ) ;
object mapper mapper2 = new object mapper ( ) ;
system . out . println ( l3 ticks : + l3 . tick count . get ( ) ) ;
membership . remove member ( member ) ; remove suspects . remove ( member ) ; if ( member instanceof static member ) { add suspects . put ( member , long . value of ( system . current time millis ( ) ) ) ; } notify = true ; } else {
object representative = null ; for ( object o : set ) { if ( o = null ) representative = o ; }
statement s = con . create statement ( ) ; result set rs = s . execute query ( select * from + data type table name ) ; assert true ( s . get connection ( ) = = con ) ; assert true ( rs . get statement ( ) = = s ) ; rs . close ( ) ;
return subject . do on unsubscribe ( new action0 ( ) { @ override public void call ( ) { underlying subscription . unsubscribe ( ) ; } } ) ;
channel future future = ctx . channel ( ) . event loop ( ) . register ( new default http2 stream channel ( s , false ) ) ;
m main queue . post ( new runnable ( ) { @ override public void run ( ) { synchronized ( m cache ) { m cache . commit temporary meta data ( ) ; } super notify data set changed ( ) ; enqueue deferred unbind service message ( ) ; } } ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( dbparameter group already exists ) ) return null ; dbparameter group already exists exception e = ( dbparameter group already exists exception ) super . unmarshall ( node ) ;
args [ 1 ] = 33aa1 . 5 ;
test . run ( context ) ;
text = text . replace all ( ( ?m ) ^ . * \ \ w + : , ) ;
if ( constraints = = null ) { if ( get left component ( ) = = null ) { constraints = jsplit pane . left ; } else if ( get right component ( ) = = null ) { constraints = jsplit pane . right ; } }
protocol provider service pps = muc details . get ( 0 ) . get preferred protocol provider ( operation set multi user chat . class ) ; room = gui activator . get mucservice ( ) . find chat room wrapper from chat room id ( contact . get contact address ( ) , pps ) ;
cluster . shutdown name node ( 1 ) ; cluster . get name node infos ( ) [ 0 ] . set start opt ( startup option . upgrade ) ; cluster . restart name node ( 0 , false ) ; assert true ( cid before upgrade < = get committed txn id value ( qj cluster ) ) ; assert true ( fs . mkdirs ( new path ( foo2 ) ) ) ;
market data service market data service = open exchange rates . get market data service ( ) ;
if ( transport selector box . is visible ( ) & & configuration utils . is hide account selection when possible enabled ( ) & & transport selector box . get menu ( ) . get item count ( ) > 1 ) { transport selector box . set visible ( true ) ; }
return test ;
float f slice radius = fast math . sqrt ( fast math . abs ( radius * radius - f z * f z ) ) ;
this . service = new executor service ( get server name ( ) . to string ( ) ) ; this . service . start executor service ( executor type . rs _ open _ region , conf . get int ( hbase . regionserver . executor . openregion . threads , 3 ) ) ; this . service . start executor service ( executor type . rs _ open _ root , conf . get int ( hbase . regionserver . executor . openroot . threads , 1 ) ) ; this . service . start executor service ( executor type . rs _ open _ meta , conf . get int ( hbase . regionserver . executor . openmeta . threads , 1 ) ) ; this . service . start executor service ( executor type . rs _ close _ region , conf . get int ( hbase . regionserver . executor . closeregion . threads , 3 ) ) ; this . service . start executor service ( executor type . rs _ close _ root , conf . get int ( hbase . regionserver . executor . closeroot . threads , 1 ) ) ; this . service . start executor service ( executor type . rs _ close _ meta , conf . get int ( hbase . regionserver . executor . closemeta . threads , 1 ) ) ; threads . set daemon thread running ( this . hlog roller . get thread ( ) , n + . log roller , uncaught exception handler ) ;
function spec = new anomaly function dto ( ) ; function spec . set metric ( main metric ) ; function spec . set properties ( to string ( properties ) ) ; function = new week over week rule function ( ) ; function . init ( function spec ) ; anomaly detection context . set anomaly detection function ( function ) ; anomaly detection context . set current ( main metric , observed time series ) ; anomaly detection context . set baselines ( main metric , baselines ) ; anomaly detection context . set time series key ( time series key ) ; anomaly detection context . set current ( total count time series name , total count time series ) ; raw anomaly results = function . analyze ( anomaly detection context ) ; compare wo2 wavg raw anomalies ( raw anomaly results ) ;
quads . add ( new switch test quad ( \ mary smith \ , , \ mary smith \ ) ) ; missed first cap because of the extra quote quads . add ( new switch test quad ( \ marysmith \ , , \ marysmith \ ) ) ; quads . add ( new switch test quad ( \ mary smith \ , , \ mary smith \ ) ) ; quads . add ( new switch test quad ( \ mary smith \ , , \ mary smith \ ) ) ; quads . add ( new switch test quad ( \ mary smith \ , , \ mary smith \ ) ) ; quads . add ( new switch test quad ( \ mary smith \ capoop , , \ mary smith \ capoop ) ) ;
sreg response sreg resp = sreg response . create sreg response ( sreg req , user data sreg ) ;
assume api level ( ice _ cream _ sandwich ) ;
gbmmodel gbm = new gbm ( parms ) . train model ( ) . get ( ) ; assert equals ( gbm . _ output . _ ntrees , parms . _ ntrees ) ; mses [ i ] = gbm . _ output . _ scored _ train [ gbm . _ output . _ scored _ train . length - 1 ] . _ mse ; gbm . delete ( ) ; } } finally {
long h = chronology . hours ( ) . get difference as long ( t , origin ) ; h - = h % hours ; long tt = chronology . hours ( ) . add ( origin , h ) ;
system . arraycopy ( scratch . data , 0 , setup header data , 0 , scratch . limit ( ) ) ;
cloud jetty runner cloud jetty = shard to jetty . get ( shard1 ) . get ( 0 ) ; chaos monkey . expire session ( cloud jetty . jetty ) ; indexr ( id , doc id + 1 , t1 , slip this doc in ) ;
content holder . add event handler ( mouse event . any , e - > e . consume ( ) ) ; }
assert equals ( 1 , best fragments . length ) ;
path . move to ( half width , ( float ) w ) ;
return invoke nullary factory method ( java . util . stream . double stream , empty ) ; }
ch . finish ( ) ;
resource resource = loader . get ( properties _ file ) ;
if ( attrs _ theme = null ) { final typed array ta = view context . obtain styled attributes ( attrs , attrs _ theme ) ; final int theme res id = ta . get resource id ( 0 , 0 ) ; if ( theme res id = 0 ) {
return function . identity ( ) ; }
assert analyzes to ( a , مي خورده باشد , new string [ ] { خورده } ) ;
float x = new big decimal ( big integer . value of ( ( ( long token ) start ) . token ) . subtract ( ti ) . add ( ri ) . mod ( ri ) ) . divide ( r , 6 , big decimal . round _ half _ even ) . float value ( ) ;
int cnt48 = 0 ;
try { apply ( raw config : : get ) ; only return if it was present though if ( raw config . contains key ( name ( ) ) ) { return string map ( name ( ) , raw config . get ( name ( ) ) ) ; } else { return empty map ( ) ; } } catch ( runtime exception e ) { throw new invalid setting exception ( e . get message ( ) , e ) ; }
m image view . set scale and center ( max scale , new point f ( image width 2 , image height 2 ) ) ;
update heap usage counter ( ) ;
mercurial repository test . run hg command ( repos root , import , get class ( ) . get resource ( hg - export - renamed . txt ) . get path ( ) ) ;
while ( true ) { final int tag = input . read tag ( ) ; if ( tag = = 0 | | merge field from ( tag , input ) ) { break ; } } return this ;
if ( deser instanceof contextual deserializer < ? > ) { deser = ( json deserializer < object > ) ( ( contextual deserializer < ? > ) deser ) . create contextual ( config , property ) ; }
show more contact show more contact = show more contact map . remove ( contact query ) ;
regionating strategy regionating strategy = null ; string stratname = ( string ) map content . get request ( ) . get format options ( ) . get ( regionate by ) ; if ( ( auto ) . equals ( stratname ) ) { catalog catalog = wms . get geo server ( ) . get catalog ( ) ; name name = layer . get feature source ( ) . get name ( ) ; stratname = catalog . get feature type by name ( name ) . get metadata ( ) . get ( kml . regionate strategy , string . class ) ; if ( stratname = = null | | . equals ( stratname ) ) { stratname = best _ guess ; logger . log ( level . fine , no default regionating strategy has been configured in + name + ; using automatic best - guess strategy . ) ; } } filter regionating filter = filter . include ;
case ' - ' : inside = true ; remove pad = true ; break ;
f . seek ( 0 ) ; int header = read4 le ( f ) ;
if ( method . get return type ( ) . equals ( java type . void _ object ) & & method . get return type ( ) . equals ( java type . void _ primitive ) & & ( ( javadoc comment ) comment ) . get return info ( ) = = null ) { ( ( javadoc comment ) comment ) . set return info ( method . get return type ( ) . get simple type name ( ) ) ; }
new fl . set ( answer field , guess ) ; pos + + ; kth . add ( new fl ) ; } k best . set count ( kth , best sequences . get count ( seq ) ) ; }
return files compacting . is empty ( ) & & ( store utils . has references ( si . get storefiles ( ) ) | | ( si . get level0 files ( ) . size ( ) > = this . config . get level0 min files ( ) ) | | needs single stripe compaction ( si ) ) ;
int s len = s arr = null ? s arr . length : 0 ; if ( s len = = 0 ) return new char [ 0 ] ; int e len = ( s len 3 ) * 3 ; length of even 24 - bits . int c cnt = ( ( s len - 1 ) 3 + 1 ) < < 2 ; returned character count int d len = c cnt + ( line sep ? ( c cnt - 1 ) 76 < < 1 : 0 ) ; length of returned array char [ ] d arr = new char [ d len ] ;
return hs2 connection file utils . get url ( hive site connection properties ) ;
train words + = src . cn ;
if ( failed ) { break ; }
int s len = s arr = null ? s arr . length : 0 ; if ( s len = = 0 ) return new char [ 0 ] ; int e len = ( s len 3 ) * 3 ; length of even 24 - bits . int c cnt = ( ( s len - 1 ) 3 + 1 ) < < 2 ; returned character count int d len = c cnt + ( line sep ? ( c cnt - 1 ) 76 < < 1 : 0 ) ; length of returned array char [ ] d arr = new char [ d len ] ;
for ( int i = 0 ; i < node . get child count ( ) ; i + + ) { add node ( new node , ( jmeter tree node ) node . get child at ( i ) ) ; }
if ( index < tmp . length ) system . arraycopy ( array , index + 2 , tmp , index , tmp . length - index ) ;
} } callable = null ; }
final properties base = new properties ( defaults ) ;
assert equals ( 3 , fetch list . size ( ) ) ; }
return context ;
assert that ( routing nodes . has inactive shards ( ) , equal to ( false ) ) ; assert that ( routing nodes . has inactive primaries ( ) , equal to ( false ) ) ; assert that ( routing nodes . has unassigned primaries ( ) , equal to ( true ) ) ; cluster state = strategy . reroute ( cluster state , reroute ) ;
if ( application context . contains bean ( xml camel context configurer ) ) { xml camel context configurer configurer = application context . get bean ( xml camel context configurer , xml camel context configurer . class ) ; if ( configurer = null ) { configurer . configure ( application context , ctx ) ; } } } catch ( exception e ) {
string min = reader . get metadata value ( cust dim name . to upper case ( ) + _ domain _ minimum ) ;
assert null ( app saved state . get attempt ( am1 . get application attempt id ( ) ) . get state ( ) ) ; rm2 = new mock rm ( conf , mem store ) ; rm2 . start ( ) ; rmapp recovered app1 = rm2 . get rmcontext ( ) . get rmapps ( ) . get ( app1 . get application id ( ) ) ; assert equals ( rmapp state . finished , recovered app1 . get state ( ) ) ;
insert query . builder ( ) . table ( test _ table ) . table ( null ) ; fail because exception was not thrown ( null pointer exception . class ) ; } catch ( null pointer exception expected ) {
s object base . clear base fields ( ) ;
string local machine name = b ;
h . put ( version + sax , 2 . 0 ) ;
http uri request current req = ( http uri request ) context . get attribute ( execution context . http _ request ) ;
add ( fp ) ;
client . call procedure ( new stop call back ( cdl , client response . graceful _ failure , 1 ) , @ stop node , 1 ) ;
send window update ( 3 , 1 < < 30 ) ;
options options = new options ( ) ; options . add option ( help opt ) ; options . add option ( output opt ) ; options . add option ( seg opt ) ;
collection < string > col result = template . request body ( ignite - compute : abc?execution type = broadcast , test ignite compute resources . test _ callable , collection . class ) ;
start service ( answer , context , bean , null ) ;
chart . set pinch zoom ( false ) ; chart . set background color ( color ) ;
rect paint . set color ( indicator color ) ;
lab4 : do {
byte byte array [ ] = { 1 , 2 , 3 , ' e ' , ' r ' , ' t ' , ' g ' , 3 , 6 } ;
nvps . add ( new basic name value pair ( parameter name , parameter value ) ) ;
assert equals ( 5 , top descriptor . get methods ( ) . length ) ;
if ( container util . get first item ( ( ( go argument list ) argument list ) . get expression list ( ) ) = top most expression ) return ; go call expr call expression = object utils . try cast ( argument list . get parent ( ) , go call expr . class ) ;
request . headers ( ) . set ( http headers . names . content _ length , len ) ; log . trace ( content - length : { } , len ) ; } else {
if ( account manager . add account explicitly ( new account , , null ) ) { return null ; }
resource bytes = new byte array resource ( 1 2 3 4 5 6 test . get bytes ( ) ) ; long [ ] xyz = { 5 l , 6 l , 7 l } ; tile object to = tile object . create complete tile object ( test : 123123 112 , xyz , epsg : 4326 , image jpeg , parameters , bytes ) ; blob store . put ( to ) ;
datanode descriptor min usage instance = get min usage ( first , integer . max _ value , null , data node usage ) ;
reloadable top . load new version ( 003 , retrieve rename ( top , top + 003 ) ) ;
int idx = idx component instance . get ( component name ) . get ( instance id ) ;
final int num docs = 1 + random ( ) . next int ( 10 ) ;
process executor params params = process executor params . builder ( ) . set command ( immutable list . of ( ln , - s , path that does not exist , my _ symlink ) ) . set directory ( tmp dir . get root ( ) . to path ( ) ) . build ( ) ;
copy . delegate = delegate ;
int max records ;
assert equals ( 2 , groups . length ) ; assert equals ( main , groups [ 0 ] . get name ( ) ) ; assert equals ( ruleflow - group , groups [ 1 ] . get name ( ) ) ; }
client properties = build properties ( kv ( mongo dbconstants . max _ auto _ connect _ retry , 12 ) ) ; options = build options ( client properties , null ) ;
query = select s from student s where s . cgpa = ?1 ;
em = get entity manager ( ) ; em . get transaction ( ) . begin ( ) ; ing1 = em . find ( bi ref ing entity . class , ing1 . get id ( ) ) ; ing2 = em . find ( bi ref ing entity . class , ing2 . get id ( ) ) ; ed1 = em . find ( bi ref ed entity . class , ed1 . get id ( ) ) ; ed2 = em . find ( bi ref ed entity . class , ed2 . get id ( ) ) ; ing1 . set reference ( ed2 ) ;
cruise config user1 seeing config = go config dao . load for editing ( ) ;
final string scheme = https ; final int default port = 443 ; string path = + method descriptor . extract full service name ( method . get full method name ( ) ) ; uri uri ; try { uri = new uri ( scheme , authority , path , null , null ) ; } catch ( urisyntax exception e ) { throw status . unauthenticated . with description ( unable to construct service uri for auth ) . with cause ( e ) . as exception ( ) ; }
actual return = system . get property ( property name ) ;
final string [ ] field names = new string [ 2 ] ;
return factory for ( destination ) . copy rule ( source , destination ) ; }
final response response = client . target ( get url prefix ( ) + dogs raf ) . request ( ) . put ( entity . entity ( raf , media type . application _ json ) ) ; assert that ( response . get status info ( ) ) . is equal to ( response . status . bad _ request ) ; assert that ( response . get header string ( http headers . content _ type ) ) . is equal to ( media type . application _ json ) ; assert that ( response . read entity ( error message . class ) . get message ( ) ) . contains ( unique constraint , table : dogs ) ; }
send file ( get ftp url ( ) , hello world , report . txt ) ;
parse ambiguous dates as after ( default century start ) ;
source session params params = new source session params ( ) . set timeout ( 600 . 0 ) ; static throttle policy policy = new static throttle policy ( ) ; policy . set max pending count ( 1000 ) ; policy . set max pending size ( 2 ) ; params . set throttle policy ( policy ) ; receptor src _ rr = new receptor ( ) ;
if ( fsd . is permission enabled ( ) ) { fsd . check path access ( pc , iip , fs action . write ) ; }
list < string > replicators = rqc . get list of replicators ( ) ; assert equals ( 3 , replicators . size ( ) ) ; assert true ( replicators . contains ( server1 ) ) ; assert true ( replicators . contains ( server2 ) ) ; rq1 . remove queue ( queue1 ) ; assert equals ( 2 , rqc . get list of replicators ( ) . size ( ) ) ;
parser . get interpreter ( ) . set prediction mode ( prediction mode . sll ) ;
ps = property file based domain . builder ( ) . with user ( good _ user _ name , good _ user _ password , good _ user _ role ) . with user ( super _ user _ name , super _ user _ password , super _ user _ role ) . with user ( bad _ guy _ name , bad _ guy _ password , bad _ guy _ role ) . with name ( web _ security _ domain ) . build ( ) ;
for ( int i = 0 ; i < shards . length ; i + + ) { output . collect ( shards [ i ] , deletion form ) ; } }
if ( this . receiver = null ) { try { this . cordova . get activity ( ) . unregister receiver ( this . receiver ) ; } catch ( exception e ) { log . e ( tag , error unregistering configuration receiver : + e . get message ( ) , e ) ; } } }
f components = new array list ( ) ;
for ( int i = 5 ; i < 15 ; + + i ) { backend . set current key ( i ) ; value state . update ( i + 1 ) ; }
preferences . set boolean ( update . check , check updates box . is selected ( ) ) ; non - nls - 1
student oracle no sqlfloat primitive student min = new student oracle no sqlfloat primitive ( ) ;
return buffered image . type _ int _ rgb ; }
if ( node = = null ) return ; node . strand = null ;
skip indexing flag check command interceptor command interceptor = init ( ) ; command interceptor . expect skip indexing flag = false ; assert status ( client ( ) . get with metadata ( k ( m ) , 0 ) , operation status . key does not exist ) ; command interceptor . expect skip indexing flag = false ;
start stop ( ) ;
string s = aced0005737200216a6176612e7574696c2e547265654d617024417363656e646 + 96e675375624d61700cab946d1f0fab1c020000787200216a6176612e7574696c2 + e547265654d6170244e6176696761626c655375624d617026617d4eacdd5933020 + 0075a000966726f6d53746172745a000b6869496e636c75736976655a000b6c6f4 + 96e636c75736976655a0005746f456e644c000268697400124c6a6176612f6c616 + e672f4f626a6563743b4c00026c6f71007e00024c00016d7400134c6a6176612f7 + 574696c2f547265654d61703b7870000001007400016374000161737200116a617 + 6612e7574696c2e547265654d61700cc1f63e2d256ae60300014c000a636f6d706 + 17261746f727400164c6a6176612f7574696c2f436f6d70617261746f723b78707 + 372002a6a6176612e6c616e672e537472696e672443617365496e73656e7369746 + 97665436f6d70617261746f7277035c7d5c50e5ce0200007870770400000004710 + 07e000671007e00067400016271007e000c71007e000571007e000574000164710 + 07e000d78 ;
assert . assert equals ( null , reader . read line ( ) ) ; reader . close ( ) ; reader = new buffered reader ( new file reader ( child process start file ) ) ;
doc . add ( new text field ( field , wizard oz the the the the the the , field . store . no ) ) ;
factory . start ( ) ;
operator factories . add ( dynamic tuple filter factory . get ( ) . filter with tuple ( index key tuple ) ) ;
final jpanel panel = new jpanel ( new border layout ( ) ) ; final jpanel panel2 = new jpanel ( new border layout ( ) ) ; this . left = new jbutton ( label1 ) ; this . right1 = new jbutton ( label2 ) ; this . right2 = new jbutton ( label3 ) ; this . right3 = new jbutton ( label4 ) ;
byte buffer b = byte buffer . allocate ( random handshake length ) ;
int w1 = current parent ;
input stream is = get input stream ( ) ; final http url connector provider connector provider = new http url connector provider ( ) ;
string [ ] args10 = { create , leader , localhost , deployment , te , catalog , catalog . jar } ;
for ( string id : arrays . as list ( 42 , 99 ) ) { for ( solr params p : arrays . as list ( params ( fl , log ( val _ i ) , val _ i ) , params ( fl , log ( val _ i ) , fl , val _ i ) ) ) { solr document doc = get rand client ( random ( ) ) . get by id ( id , p ) ; string msg = id + , + p + = > + doc ; assert equals ( msg , 2 , doc . size ( ) ) ; assert true ( msg , doc . get field value ( log ( val _ i ) ) instanceof double ) ; assert true ( msg , doc . get field value ( val _ i ) instanceof integer ) ; true for both these specific docs assert equals ( msg , 0 . 0 d , doc . get field value ( log ( val _ i ) ) ) ; assert equals ( msg , 1 , doc . get field value ( val _ i ) ) ; } }
set override ( group index , get tracks adding ( override , track index ) , enable random adaptation view . is checked ( ) ) ;
final pair < string , string > shifter pair = addressing mode one generator . generate ( base offset , environment , instruction , instructions , shifter ) ; base offset = reil helpers . next reil address ( instruction , instructions ) ; final string shifter operand = shifter pair . first ( ) ;
string id = test server . extract session id ( session cookie ) ; assert false ( context handler . get session handler ( ) . get session cache ( ) . contains ( id ) ) ;
for ( int i = 0 ; i < num moves ; i + + ) { event time + = event _ time _ interval _ ms ; pointer coords [ 0 ] . x + = step x1 ; pointer coords [ 0 ] . y + = step y1 ; pointer coords [ 1 ] . x + = step x2 ; pointer coords [ 1 ] . y + = step y2 ; event = motion event . obtain ( down time , event time , motion event . action _ move , 2 , pointer properties , pointer coords , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 0 ) ; _ instrument . send pointer sync ( event ) ; }
v = new bytes column vector ( ) ;
if ( local import instance = = null ) { throw new org . apache . axis2 . databinding . adbexception ( property cannot be null ) ; }
show _ hidden _ files = m app . get shared preferences ( ) . get boolean ( show _ hidden _ files , false ) ; list view = ( list view ) root view . find view by id ( r . id . folders _ list _ view ) ; list view . set fast scroll enabled ( true ) ; list view . set visibility ( view . invisible ) ;
cluster . await ( master available ( ) ) ; cluster . await ( master sees slaves as available ( 2 ) ) ; highly available graph database new master = cluster . get master ( ) ; final highly available graph database new slave1 = cluster . get any slave ( ) ;
access plan temp . get child ( 0 ) . add and link child ( dist node ) ;
buffer . position ( buffer . position ( ) + 1 ) ; continue ; } case data : final cached data value = this . return values . get ( this . current return key ) ; int remaining = buffer . remaining ( ) ; int remaining capacity = value . remaining capacity ( ) ; assert ( remaining capacity > = 0 ) ;
return mapper . write value as string ( this ) ; } catch ( org . nd4j . shade . jackson . core . json processing exception e ) {
assert that ( item view type composer . extract segment part ( item view type composer . bit _ mask _ segment ) , is ( item view type composer . max _ segment ) ) ;
f configuration . f error handler wrapper . f current node = node ; f current node = node ; f dtdvalidator . end element ( f qname , null ) ; }
throw iioplogger . root _ logger . ssl not configured ( ) ; }
gles20 . gl draw arrays ( gles20 . gl _ triangle _ strip , first vertex , vertex count ) ; gl util . check gl error ( gl draw arrays ) ;
final executor info executor info = refresh pair . get second ( ) . get ( 5 , time unit . seconds ) ;
node c = node . create ( node c , collections . singleton ( : : 12 ) , collections . empty set ( ) , node c , optional . of ( host2 ) , flavor docker , node type . tenant ) ;
set file name only ( file . get name ( ) ) ;
kvs . remove ( kvs . size ( ) - 1 ) ; for ( key value kv : kvs ) { writer . append ( kv ) ; } writer . append metadata ( 0 , false ) ; writer . close ( ) ; return writer ; }
am client . allocate ( 0 . 1f ) ;
unmapped keys . add all ( key to host result . get unmapped keys ( ) ) ;
search request . source ( ) . fetch source ( new string [ ] { in1 , in2 } , new string [ ] { out } ) ; entity = initial search entity ( search request , new bytes array ( query ) , remote version ) ; assert equals ( content type . application _ json . to string ( ) , entity . get content type ( ) . get value ( ) ) ; assert equals ( { \ query \ : + query + , \ _ source \ : { \ includes \ : [ \ in1 \ , \ in2 \ ] , \ excludes \ : [ \ out \ ] } } , streams . copy to string ( new input stream reader ( entity . get content ( ) , standard charsets . utf _ 8 ) ) ) ;
parent view . add view ( this , i ) ;
add doc ( changed , id , 1 , which , 15 , text , some stuff with which ) ; add doc ( changed , id , 2 , which , 15 , text , some stuff with which ) ; add doc ( changed , id , 3 , which , 15 , text , some stuff with which ) ; add doc ( changed , id , 4 , which , 15 , text , some stuff with which ) ; solr query request req = new local solr query request ( changed , new named list < > ( ) ) ; changed . get update handler ( ) . commit ( new commit update command ( req , false ) ) ;
if ( match token pos + 1 < tokens . length & & numerals _ en . matcher ( tokens [ match token pos ] . get token ( ) ) . matches ( ) & & ( tokens [ match token pos + 1 ] . get token ( ) . equals ( . ) | | tokens [ match token pos + 1 ] . get token ( ) . equals ( ) ) ) ) { prevent error = true ; } if ( is url ( check token ) | | is email ( check token ) | | first token obj . is immunized ( ) ) { prevent error = true ; }
assert that ( get target ( external : my _ rule ) . get target kind ( ) ) . is equal to ( new _ local _ repository rule ) ; }
return for type ( resolve bounds ( variable . get bounds ( ) ) , this . variable resolver ) ; }
sslconnection socket factory ssl socket factory = new sslconnection socket factory ( ssl context , new string [ ] { tlsv1 } , null , hostname verifier ) ; registry < connection socket factory > socket factory registry = registry builder . < connection socket factory > create ( ) . register ( https , ssl socket factory ) . build ( ) ;
string function score query = { \ n + \ function _ score \ : { \ n + \ script _ score \ : { \ n + \ script \ : \ 5 \ \ n + } , \ n + \ weight \ : 2 \ n + } \ n + } ;
if ( this . no _ entry _ value = ( int ) 0 ) { arrays . fill ( _ values , this . no _ entry _ value ) ; } set up ( ( int ) math . ceil ( default _ capacity _ load factor ) ) ;
string lf = get lf ( ) ;
value to suppress = bean property writer . marker _ for _ empty ;
if ( ctx . channel ( ) . config ( ) . is auto read ( ) & & ( fired channel read | | handshake promise . is done ( ) ) ) { no auto - read used and no message passed through the channel pipeline or the handshake was not complete yet , which means we need to trigger the read to ensure we not encounter any stalls . ctx . read ( ) ; }
assert equals ( incorrect result size , 2 , results . size ( ) ) ; assert true ( incorrect return type , results . get ( 0 ) instanceof object [ ] ) ; assert equals ( incorrect return dimensions , 2 , ( ( object [ ] ) results . get ( 0 ) ) . length ) ; t . commit ( ) ; session . close ( ) ; destroy test base data ( ) ; }
final value value = converter . get value from properties ( test groups . entity , entity . get properties ( ) ) ;
token . set issued at ( system . current time millis ( ) ) ; token . set expires in ( time unit . milliseconds . convert ( token . get expires in ( ) , time unit . seconds ) ) ; auth string = token . to string ( ) ;
push top ( ) ;
write special opcode ( line delta , address delta ) ; }
string new code = apply suggested fixes . apply suggested fixes to code ( immutable list . of ( fixes . get ( 0 ) ) , immutable map . of ( test , original code ) ) . get ( test ) ; assert that ( new code ) . is equal to ( * * @ type { ? object } * var o ; ) ;
container id completed container id = builder utils . new container id ( builder utils . new application attempt id ( builder utils . new application id ( 0 , 0 ) , 0 ) , 0 ) ;
headers . put ( camel box . new file name , camel _ test _ rename _ file _ name ) ; result = request body and headers ( direct : renamefile , null , headers ) ; assert not null ( rename file result , result ) ;
s . set max versions ( integer . max _ value ) ;
object mapper mapper = new object mapper ( ) ; btcetrans history return transactions = mapper . read value ( is , btcetrans history return . class ) ; map < long , btcetrans history result > result = transactions . get return value ( ) ; assert that ( result . size ( ) ) . is equal to ( 1 ) ; map . entry < long , btcetrans history result > first entry = result . entry set ( ) . iterator ( ) . next ( ) ;
display scale factor = config . display scale large screen if retina * scale ;
aggregation strategy bean info bi = new aggregation strategy bean info ( type , found ) ;
private cell util . update latest stamp ( cell , byte now , 0 ) ; return ;
if ( this . field included . length = = this . field types . length ) { return this . field types ; } else { sparse type array which we made dense for internal book keeping . create a sparse copy to return class < ? > [ ] types = new class < ? > [ this . field included . length ] ; for ( int i = 0 , k = 0 ; i < this . field included . length ; i + + ) { if ( this . field included [ i ] ) { types [ i ] = this . field types [ k + + ] ; } } return types ; }
m right most = 0 ;
assert true ( command . is response from fallback ( ) ) ; assert false ( command . is circuit breaker open ( ) ) ; assert false ( command . is response short circuited ( ) ) ; assert true ( command . get execution time in milliseconds ( ) > - 1 ) ; assert true ( command . is response timed out ( ) ) ; assert false ( command . is successful execution ( ) ) ; assert not null ( command . get execution exception ( ) ) ; assert command execution events ( command , hystrix event type . timeout , hystrix event type . fallback _ success ) ; assert equals ( 0 , command . get builder ( ) . metrics . get current concurrent execution count ( ) ) ; assert sane hystrix request log ( 1 ) ;
public void test truncate bytes column vector ( ) { bytes column vector out v = new bytes column vector ( vectorized row batch . default _ size ) ; out v . init buffer ( 35 ) ; initialize with estimated element size 35 int i = 0 ;
tests . put ( advanced , new uni vocity csv data format ( ) . set null value ( n a ) . set delimiter ( ' ; ' ) . set ignore leading whitespaces ( true ) . set ignore trailing whitespaces ( false ) . set comment ( ' ' ) . set skip empty lines ( true ) ) ; return new route builder ( ) { @ override public void configure ( ) throws exception { for ( map . entry < string , data format > test : tests . entry set ( ) ) { from ( direct : + test . get key ( ) ) . unmarshal ( test . get value ( ) ) . to ( mock : result ) ; } } } ;
try ( transaction tx = graph db . begin tx ( ) ) { graph db . schema ( ) . constraint for ( label ) . assert property is unique ( property key ) . create ( ) ; tx . success ( ) ; }
return ( class < ? > ) ( ( parameterized type ) actual ) . get raw type ( ) ;
assert matches filter from filename ( x - v3 , x - v17 , x - v14 _ x - v17 ) . is true ( ) ;
for ( ejb3 column column : element columns ) { column . set table ( map value . get collection table ( ) ) ; }
if ( state ) { f domconfig properties . set property ( domconstants . s _ dom3 _ properties _ ns + domconstants . dom _ discard _ default _ content , domconstants . dom3 _ explicit _ true ) ; } else { f domconfig properties . set property ( domconstants . s _ dom3 _ properties _ ns + domconstants . dom _ discard _ default _ content , domconstants . dom3 _ explicit _ false ) ; }
string begin char = c ; if ( i include string sep ) buffer . append ( c ) ; continue ;
list < core map > number ranges = number normalizer . find number ranges ( annotation ) ; final integer start token offset final = start token offset ; list < core map > merged numbers with ranges = collection utils . merge list with sorted matched pre aggregated ( annotation . get ( core annotations . numerized tokens annotation . class ) , number ranges , ( core map in ) - > interval . to interval ( in . get ( core annotations . token begin annotation . class ) - start token offset final , in . get ( core annotations . token end annotation . class ) - start token offset final ) ) ; annotation . set ( core annotations . numerized tokens annotation . class , merged numbers with ranges ) ; return merged numbers with ranges ;
final int section idx = ( int ) ( hash > > > 32 ) & ( sections . length - 1 ) ; return sections [ section idx ] ;
if ( process non separate = null ) { if ( process non separate . equals ( true _ string ) & & process non separate . equals ( false _ string ) ) { throw new illegal state exception ( file download utils . format string ( the value of ' % s ' must be ' % s ' or ' % s ' , key _ process _ non _ separate , true _ string , false _ string ) ) ; } process _ non _ separate = process non separate . equals ( true _ string ) ; } else { process _ non _ separate = false ; }
int old value = 111 ; set value ( node engine1 , partition id , old value ) ; long [ ] initial replica versions = get default replica versions ( node engine1 . get node ( ) , partition id ) ;
byte [ ] b0 = new byte [ 16 ] ; if ( has associated text ( ) ) { b0 [ 0 ] | = 0x40 ; } b0 [ 0 ] | = ( ( ( c mac . get mac size ( ) - 2 ) 2 ) & 0x7 ) < < 3 ; b0 [ 0 ] | = ( ( 15 - nonce . length ) - 1 ) & 0x7 ; system . arraycopy ( nonce , 0 , b0 , 1 , nonce . length ) ; int q = data len ;
if ( subtype . is array ( ) ) {
assert that ( pd , not null value ( ) ) ; assert that ( pd . get read method ( ) , equal to ( c . class . get method ( get foo ) ) ) ; assert that ( no write method found for non - void returning ' set foo ' method . + check to see if cached introspection results is delegating to + extended bean info as expected , pd . get write method ( ) , equal to ( c . class . get method ( set foo , string . class ) ) ) ; }
string props = dom utils . get child element value by tag name ( element , cmd - env ) ; if ( string utils . has text ( props ) ) { builder . add property value ( cmd env , props ) ; }
run cycle analysis for partition pruning ( proc ctx , inputs , outputs ) ; perf logger . perf log end ( this . get class ( ) . get name ( ) , perf logger . tez _ compiler , run cycle analysis for partition pruning ) ; perf logger . perf log begin ( this . get class ( ) . get name ( ) , perf logger . tez _ compiler ) ; if ( proc ctx . conf . get bool var ( conf vars . hive _ shared _ work _ optimization ) ) { new shared work optimizer ( ) . transform ( proc ctx . parse context ) ; } perf logger . perf log end ( this . get class ( ) . get name ( ) , perf logger . tez _ compiler , shared scans optimization ) ;
call . request ( 1 ) ; call . send message ( null ) ; call . half close ( ) ;
int ret = node ( re . op _ anyof , 0 ) ;
rules dao . save or update rule ( rule a ) ;
url css url = new url ( base url , static test . css ) ;
value = v4 . get bytes ( ) ;
list < policy info > all = new array list < policy info > ( ) ;
if ( m _ nodes [ m _ highlight node ] . m _ quad = = 18 ) { color acol ; if ( m _ node color = = null ) acol = m _ nodes [ m _ highlight node ] . m _ node . get color ( ) ; else acol = m _ node color ; g . set color ( new color ( ( acol . get red ( ) + 125 ) % 256 , ( acol . get green ( ) + 125 ) % 256 , ( acol . get blue ( ) + 125 ) % 256 ) ) ;
for ( elem template element t = this . m _ first child ; t = null ; t = t . m _ next sibling ) { xctxt . set saxlocator ( t ) ; transformer . set current element ( t ) ; t . execute ( transformer ) ; }
locs = namenode . get blocks ( data nodes [ 0 ] , 1 ) . get blocks ( ) ;
ssl context parameters = retrieve global ssl context parameters ( ) ;
if ( bucket number . is present ( ) ) { throw new presto exception ( hive _ partition _ read _ only , cannot insert into existing partition of bucketed hive table : + partition name . get ( ) ) ; }
throw new canonicalization exception ( c14n . canonicalizer . unsupported operation ) ; }
assert equals ( no status message events . , 1 , status event collector . collected stat msg events . size ( ) ) ;
if ( ( e . get button ( ) = = mouse event . button1 ) & & ( e . get click count ( ) = = 1 ) & & ( e . is alt down ( ) ) & & ( col > - 1 ) ) { m _ table arff . set selected column ( col ) ; }
dimension screen size = toolkit . get default toolkit ( ) . get screen size ( ) ;
sink . get object sink propagator ( ) . propagate assert object ( fact handle , context , working memory ) ;
string first param = params with custom param injection . get ( 0 ) ;
contains case ( make list ( ) , make list ( ) , make list ( 0 , 0 ) ) ;
int next byte = input . read ( ) ;
else { get the key code int key code = event . get key code ( ) ; bail on modifier keys if ( keyboard helper . is modifier key ( key code ) ) return false ;
servlet action context servlet action context = ( servlet action context ) context ; http servlet request request = servlet action context . get request ( ) ;
file copied jar = exploded . get main ( ) ; assert that ( exploded . get key ( ) ) . is equal to ( test ) ; assert that ( copied jar ) . is file ( ) . exists ( ) ; assert that ( copied jar . get parent file ( ) ) . is directory ( ) . has name ( test ) ;
chase cam = new chase camera ( cam , tea geom , input manager ) ;
await clear ( weak key1 ref ) ;
last message time = cur time ;
mockito . when ( request . get header ( user - agent ) ) . then return ( some browser ) ; authentication token token = handler . authenticate ( request , response ) ; assert . assert equals ( a , token . get user name ( ) ) ; assert . assert equals ( b , token . get name ( ) ) ; assert . assert equals ( get expected type ( ) , token . get type ( ) ) ; }
admin . add peer ( id _ one , rpc1 , null ) ;
for ( search component c : components ) { c . prepare ( rb ) ; }
assert analyzes to ( analyzer , one two & x d86 c ; & xd c01 ; three , new string [ ] { one , two , \ u d86 c \ u dc01three } ) ; assert analyzes to ( analyzer , & 55404 ; & xd c01 ; , new string [ ] { \ u d86 c \ u dc01 } ) ; assert analyzes to ( analyzer , & x d86 c ; & 56321 ; , new string [ ] { \ u d86 c \ u dc01 } ) ; assert analyzes to ( analyzer , & 55404 ; & 56321 ; , new string [ ] { \ u d86 c \ u dc01 } ) ;
this . scanners for delayed close . add ( kv scanner ) ;
for ( map . entry < string , object > config : new configs . entry set ( ) ) { string key = config . get key ( ) ; object value = config . get value ( ) ; if ( this . source . get ( key ) = = null ) { logger . info ( load config from db : { } = { } , key , value ) ; } else if ( objects . equals ( this . source . get ( key ) , value ) ) { logger . info ( load config from db : { } = { } . old value = { } , key , value , this . source . get ( key ) ) ; } this . source . put ( key , value ) ; }
for ( int j = range end ; j > = range start ; j - - ) { the list . remove ( j ) ; }
channel handler factory decoder = channel handler factories . new length field based frame decoder ( 1048576 , 0 , 4 , 0 , 4 ) ; registry . bind ( length - decoder , decoder ) ; registry . bind ( length - decoder2 , decoder ) ; return registry ;
try { hashtable h = new hashtable ( 2 ) ;
original content = some text \ n + uploading image html old apis + \ n more text ; modified content = editor fragment . replace media file with url ( original content , media file ) ; assert equals ( some text \ n + expected tag + \ n more text , modified content ) ;
list = s . create query ( from human h inner join h . nick names as nicknames with nicknames = ' abc ' ) . list ( ) ; assert true ( ad - hoc on did not take effect , list . is empty ( ) ) ; list = s . create query ( from human h inner join h . offspring o with o . mother . father = : cousin ) . set entity ( cousin , s . load ( human . class , long . value of ( 123 ) ) ) . list ( ) ;
get cursor ( table , immutable list . of ( text column , value column ) , tuple domain . with column domains ( immutable map . of ( text column , domain . only null ( varchar ) ) ) ) ;
if ( row filter ( ) . is empty ( ) ) sb . append ( and ) . append ( row filter ( ) ) ; string filter string = clustering index filter ( ) . to cqlstring ( metadata ( ) ) ; if ( filter string . is empty ( ) ) sb . append ( and ) . append ( filter string ) ; }
m list hook . add ( new hook ( null , get system service , , 1 , null , null ) . not aosp ( 19 ) ) ;
object o1 = new object ( ) { } ;
for ( string jndi name : fallback _ transaction _ manager _ names ) { try { transaction manager tm = get jndi template ( ) . lookup ( jndi name , transaction manager . class ) ; if ( logger . is debug enabled ( ) ) { logger . debug ( jta transaction manager found at fallback jndi location [ + jndi name + ] ) ; } return tm ; } catch ( naming exception ex ) { if ( logger . is debug enabled ( ) ) { logger . debug ( no jta transaction manager found at fallback jndi location [ + jndi name + ] , ex ) ; } } }
string custom cookie name = config . get property ( jwt _ cookie _ name ) ;
response = client . get ( scanner uri , constants . mimetype _ xml ) ; assert equals ( response . get code ( ) , 200 ) ; assert equals ( constants . mimetype _ xml , response . get header ( content - type ) ) ; cell set model cells = ( cell set model ) unmarshaller . unmarshal ( new byte array input stream ( response . get body ( ) ) ) ; int rows = cells . get rows ( ) . size ( ) ; assert true ( scanned too many rows only expected + expected rows + total but scanned + rows , expected rows = = rows ) ;
sleep at least millis ( 100 ) ; replicated map2 . put ( key1 , latest updated value1 ) ;
m pull label = context . get string ( r . string . pull _ to _ refresh _ pull _ label ) ;
string user agent = channel . attr ( encoder handler . user _ agent ) . get ( ) ; if ( user agent = null & & ( user agent . contains ( ; msie ) | | user agent . contains ( trident ) ) ) { res . headers ( ) . add ( x - xss - protection , 0 ) ; } send message ( msg , channel , out , res , promise ) ;
stream execution environment env = stream execution environment . get execution environment ( ) ;
export class path = appdir + : appdir lib + jar list . join ( : appdir lib ) ;
master sync coprocessor coproc = test util . get hbase cluster ( ) . get master ( ) . get master coprocessor host ( ) . find coprocessor ( master sync coprocessor . class ) ;
double min x = x * tile width - padding ;
atomic integer warm count = new atomic integer ( ) ;
buffer [ end ] = front low ; buffer [ i ] = end low ; end low = end high ; allow front sur = false ; } else {
for ( job vertex vertex : job graph . get vertices ( ) ) { assert false ( ids . contains key ( vertex . get id ( ) ) ) ; }
for ( char c : hello world . to char array ( ) ) { int b = client . get input stream ( ) . read ( ) ; assert true ( b > 0 ) ; assert equals ( c , ( char ) b ) ; } assert . assert true ( _ last end point latch . await ( 1 , time unit . seconds ) ) ;
weight . scorer supplier ( s . get index reader ( ) . leaves ( ) . get ( 0 ) ) ; reader . close ( ) ; dir . close ( ) ;
m scale drag detector = new custom gesture detector ( image view . get context ( ) , on gesture listener ) ; m gesture detector = new gesture detector ( image view . get context ( ) , new gesture detector . simple on gesture listener ( ) {
set server property ( orchestrator , sonar . leak . period , previous _ version ) ;
class < ? > module symbol cls = class . for name ( com . sun . tools . javac . code . symbol module symbol ) ;
buf . append ( < name > ) ; buf . append ( occupant . get nickname ( ) ) ; buf . append ( < name > ) ;
assert . assert equals ( result set group . get result set count ( ) , 1 , expected one result set for selection query ) ; assert . assert equals ( result set . get row count ( ) , 24 , mismatched selection query length ) ;
this . definitions by name = linked hash multimap . create ( num inputs * 15 , 1 ) ;
return choose random ( node base . root , excluded nodes , blocksize , max nodes per rack , results , avoid stale nodes , storage types ) ;
mv . visit ldc insn ( < init > + desc ) ; mv . visit method insn ( invokespecial , type descriptor . get supertype name ( ) , m dynamic dispatch name , m dynamic dispatch descriptor , false ) ; mv . visit insn ( pop ) ; } else {
modifiable solr params params = new modifiable solr params ( ) ; params . set ( action , collection action . delete . to string ( ) ) ; params . set ( name , delete _ data _ dir _ collection ) ; query request request = new query request ( params ) ; request . set path ( admin collections ) ; cloud client . request ( request ) ; final time out timeout = new time out ( 10 , time unit . seconds ) ;
junction tree clique node = new junction tree clique ( i , graph , cliques . get ( i ) ) ;
name = token . value ;
super . init ( args ) ;
try { string classname = org . apache . flink . runtime . webmonitor . web runtime monitor ; class < ? extends web monitor > clazz = class . for name ( classname ) . as subclass ( web monitor . class ) ; constructor < ? extends web monitor > constructor = clazz . get constructor ( configuration . class , leader retrieval service . class , leader gateway retriever . class , metric query service retriever . class , time . class , scheduled executor . class ) ; return constructor . new instance ( config , high availability services . get job manager leader retriever ( high availability services . default _ job _ id ) , job manager retriever , query service retriever , timeout , scheduled executor ) ; } catch ( class not found exception e ) { log . error ( could not load web runtime monitor . + probably reason : flink - runtime - web is not in the classpath ) ; log . debug ( caught exception , e ) ; return null ; } catch ( invocation target exception e ) { log . error ( web server could not be created , e . get target exception ( ) ) ; return null ; } catch ( throwable t ) { log . error ( failed to instantiate web runtime monitor . , t ) ; return null ; }
simple cache = get simple cache ( ) ;
throw new illegal argument exception ( the server cannot be started in arbiter mode . ) ; case core : return lifecycle managing database ( core _ factory ) ; case read _ replica : return lifecycle managing database ( read _ replica _ factory ) ; default : return lifecycle managing database ( enterprise _ factory ) ; } }
final string ledger name = dn . get partition ( 1 ) . get persistence naming encoding ( ) ; final set < topic > topics = sets . new concurrent hash set ( ) ; ( ( managed ledger factory impl ) pulsar ( ) . get managed ledger factory ( ) ) . get meta store ( ) . get cursors ( ledger name , new meta store callback < list < string > > ( ) { @ override public void operation complete ( list < string > cursors , org . apache . bookkeeper . mledger . impl . meta store . stat stat ) { list < completable future < void > > subscription creation future = lists . new array list ( ) ;
iterator < cluster state history entry > state iterator = state version tracker . get cluster state history ( ) . iterator ( ) ;
input . peek fully ( scratch . data , 0 , 4 ) ; scratch . set position ( 0 ) ; return scratch . read int ( ) = = 0 ;
int free space = 80 - output stream . size ( ) ; set < vote item > items = vote items list . get all vote item list ( ) . stream ( ) . filter ( e - > ( e instanceof compensation request vote item collection ) ) . filter ( vote item : : is has voted ) . collect ( collectors . to set ( ) ) ; check argument ( items . size ( ) < = free space , size of parameter items must not exceed free space . ) ; items . stream ( ) . for each ( param item - > { check argument ( output stream . size ( ) % 2 = = 0 , position of writing code must be at even index . ) ; output stream . write ( param item . get voting type ( ) . code ) ; byte value = param item . get value ( ) ; output stream . write ( value ) ; } ) ;
int position = m first position + count ;
for ( entry < principal table key , set < hive privilege info > > entry : immutable list . copy of ( table privileges . entry set ( ) ) ) { principal table key principal table key = entry . get key ( ) ; set < hive privilege info > privileges = entry . get value ( ) ; if ( principal table key . matches ( database name , table name ) ) { table privileges . remove ( principal table key ) ; table privileges . put ( new principal table key ( principal table key . get principal name ( ) , principal table key . get principal type ( ) , new table name , new database name ) , privileges ) ; } }
base64 . output stream bos = null ;
class dodgy fslog extends fshlog {
return this . delegatee . contains key ( o ) ; }
opacity . set duration ( opacity _ enter _ duration _ fast ) ; opacity . set interpolator ( linear _ interpolator ) ; final animator set set = new animator set ( ) ; set . play ( tween origin ) . with ( tween radius ) . with ( opacity ) ; return set ;
fragment _ list . remove ( mbr ) ; log . trace ( % s : removed % s from fragmentation table , local _ addr , mbr ) ; }
style . dialog message avatar enabled = typed array . get boolean ( r . styleable . dialogs list _ dialog message avatar enabled , true ) ;
if ( media player delegate = null & & media player delegate . is complete ) { orientation helper . enable listener ( ) ; orientation helper . is from user ( ) ; }
for ( int x = 0 ; x < 10000 ; x + + ) { try { client . ping2 ( null , new empty request ( ) ) ; } catch ( exception ex ) { throw ex ; } }
watchman path event event = watchman path event . of ( filesystem . get root path ( ) , watchman path event . kind . create , paths . get ( some class . java _ _ backup ) ) ;
object [ ] working = new object [ ilength ] ; for ( int i = 0 ; i = ilength ; + + i ) { working [ i ] = get elem ( cx , this obj , i ) ; } heapsort ( cx , scope , working , ilength , compare , cmp buf ) ;
if ( transport _ tcp ) { try { if ( host _ ipaddr = = null ) tcp _ server = new tcp server ( host _ port , this ) ; else tcp _ server = new tcp server ( host _ port , host _ ipaddr , this ) ; print log ( tcp is up , log level . medium ) ; } catch ( exception e ) { print exception ( e , log level . high ) ; } }
int curve index = data num * i + j ;
memstore . add ( new key value ( row , fam , qf1 , val ) , null ) ;
assert language ( language . japanese , \ u3072 \ u3089 \ u304c \ u306a ) ;
remove token ( resource id ) ;
query qobj = qparser . get parser ( parsed . facet value , req ) . get query ( ) ; if ( qobj = = null ) { res . add ( parsed . key , 0 ) ; } else if ( parsed . params . get bool ( group params . group _ facet , false ) ) { res . add ( parsed . key , get grouped facet query count ( qobj , parsed . docs ) ) ; } else { res . add ( parsed . key , searcher . num docs ( qobj , parsed . docs ) ) ; }
parent = null ; }
final int cost = 7 ; final list < graph . edge < integer > > list = new array list < graph . edge < integer > > ( ) ; list . add ( new graph . edge < integer > ( 1 , cv1 , cv4 ) ) ; list . add ( ce4 _ 5 ) ; list . add ( ce1 _ 2 ) ; list . add ( ce2 _ 3 ) ; final graph . cost path pair < integer > result4 = new graph . cost path pair < integer > ( cost , list ) ; assert true ( prim ' s minimum spanning tree error . pair4 = + pair4 + result4 = + result4 , pair4 . equals ( result4 ) ) ;
if ( negative ) { result = - result ; if ( result < 0 ) { throw new number format exception ( unable to parse ) ; } } return result ; }
resolved path = relative . path ; } else if ( relative . path . is empty ( ) ) {
context = ( comparable ) max ; else { if ( context instanceof number & & max instanceof number ) { final number [ ] casted = otype . cast comparable number ( ( number ) context , ( number ) max ) ; context = casted [ 0 ] ; max = casted [ 1 ] ; } if ( ( ( comparable < object > ) context ) . compare to ( ( comparable ) max ) < 0 )
warn about deleting files ( terminal , translog files , batch ) ; list < index commit > commits ;
if ( is at origin | | get path ( x , y - 1 , path ) | | get path ( x - 1 , y , path ) ) { point p = new point ( x , y ) ; path . add ( p ) ; return true ; } return false ; }
type . annotations = convert annotations ( type handle ) ;
int look ahead element offset = calc wrapped offset ( index + look ahead step , mask ) ;
toolbar toolbar = ( toolbar ) find view by id ( r . id . toolbar ) ;
replica leader = cloud client . get zk state reader ( ) . get leader retry ( test collection name , shard1 ) ;
string prefix = db name + . ;
query . add ( sort , description desc ) ; assert jq ( query + query . to query string ( ) , response num found = = 8 ) ; assert jq ( query + query . to query string ( ) , response docs [ 0 ] id = = ' 1 ' ) ; assert jq ( query + query . to query string ( ) , response docs [ 1 ] id = = ' 5 ' ) ; assert jq ( query + query . to query string ( ) , response docs [ 2 ] id = = ' 8 ' ) ; assert jq ( query + query . to query string ( ) , response docs [ 3 ] id = = ' 7 ' ) ; query . add ( rq , { ltr model = powpularity s - model re rank docs = 4 } ) ; query . set ( debug query , on ) ; assert jq ( query + query . to query string ( ) , response num found = = 8 ) ; assert jq ( query + query . to query string ( ) , response docs [ 0 ] id = = ' 8 ' ) ; assert jq ( query + query . to query string ( ) , response docs [ 0 ] score = = 64 . 0 ) ;
assert equals ( 0 , kie session . fire all rules ( ) ) ;
u ctx task . add task tmp dir ( task tmp dir . to uri ( ) . to string ( ) ) ;
public void test string col compare char scalar filter ( ) { vectorized row batch batch = make string batch ( ) ;
assert false ( doc . get document element ( ) . has attribute ( next ) ) ; doc = post as dom ( wfs , start index simple xml ( type name , 0 , 5 ) ) ; assert false ( doc . get document element ( ) . has attribute ( previous ) ) ; assert start index count ( doc , next , 5 , 5 ) ; doc = post as dom ( wfs , start index simple xml ( type name , 5 , 7 ) ) ; assert start index count ( doc , previous , 0 , 5 ) ; assert start index count ( doc , next , 12 , 7 ) ;
string url type = file ; int colon index = url path . index of ( : ) ; if ( colon index = - 1 ) { url type = url path . substring ( 0 , colon index ) ; } url path = url . get path ( ) ;
return localhost : + rabbit _ port ; }
insertion point = ( insertion point + 1 ) * - 1 ;
region fs . cleanup temp dir ( ) ;
total raw count + = raw count . get ( ) ;
cmp = long . compare ( f1 . num versions , f2 . num versions ) ; if ( cmp = 0 ) return cmp ;
organization organization = tester . organizations ( ) . get default organization ( ) ;
assert . assert true ( gbm . test java scoring ( fr , fr2 , 1e - 15 ) ) ; assert . assert true ( job . is stopped ( ) ) ; hex - 1817
query query = em . create query ( delete from person mtmredis p ) ; int update count = query . execute update ( ) ; return em = emf . create entity manager ( ) ;
return util . sdk _ int < 24 & & omx . sec . aac . dec . equals ( codec name ) & & samsung . equals ( util . manufacturer ) & & ( util . device . starts with ( zeroflte ) | | util . device . starts with ( herolte ) | | util . device . starts with ( heroqlte ) ) ;
request < bitmap > new request = make image request ( request url , max width , max height , scale type , cache key ) ; m request queue . add ( new request ) ;
return calculate coefficient ( position ) ;
case character . decimal _ digit _ number : return token type . numeric ; case character . space _ separator :
java pair dstream < text , long writable > writable dstream = ip dstream . map to pair ( new pair function < tuple2 < string , long > , text , long writable > ( ) { public tuple2 < text , long writable > call ( tuple2 < string , long > e ) { return new tuple2 ( new text ( e . _ 1 ( ) ) , new long writable ( e . _ 2 ( ) ) ) ; } } ) ;
down operation result down operation result = client b . down ( ) ; assert equals ( down result code . ok _ no _ remote _ changes , down operation result . get result code ( ) ) ;
request . set attribute ( web utils . error _ status _ code _ attribute , http servlet response . sc _ internal _ server _ error ) ;
pop args ( frame , 2 ) ;
if ( this . get class ( ) . is annotation present ( enable verbose execution tree logging . class ) ) { swap command invoker ( false ) ; }
assert array equals ( last , cassandra metrics registry . delta ( now , now ) ) ;
panel layout . set visibility ( view . invisible ) ; } return false ; } } ) ; }
connect left vertex ( tess , v event ) ;
buffer availability listener listener = mock ( buffer availability listener . class ) ; result subpartition view view = partition . create read view ( listener ) ;
string s = double . to string ( d ) ;
return tc orb . get _ primitive _ tc ( tckind . tk _ any ) ;
search _ del ( t0 , ptr _ sig _ in , ins , ltpdel , phase , num _ gltp , den _ gltp , y _ up , off _ yup ) ;
if ( out > = in ) { int left in buffer = buffer . length - out ; int length = left in buffer < byte count ? left in buffer : byte count ; system . arraycopy ( buffer , out , bytes , offset , length ) ; out + = length ; if ( out = = buffer . length ) { out = 0 ; } if ( out = = in ) { empty buffer in = - 1 ; out = 0 ; } total copied + = length ; }
hystrix invokable info < ? > command b = hystrix request log . get current request ( ) . get all executed commands ( ) . to array ( new hystrix invokable info < ? > [ 2 ] ) [ 1 ] ; assert equals ( 2 , command b . get execution events ( ) . size ( ) ) ; assert true ( command b . get execution events ( ) . contains ( hystrix event type . success ) ) ; assert true ( command b . get execution events ( ) . contains ( hystrix event type . collapsed ) ) ; iterator < hystrix invokable info < ? > > cmd iterator = hystrix request log . get current request ( ) . get all executed commands ( ) . iterator ( ) ; assert equals ( 2 , cmd iterator . next ( ) . get number collapsed ( ) ) ; 1 for a , 1 for b . batch contains only unique arguments ( no duplicates ) assert equals ( 2 , cmd iterator . next ( ) . get number collapsed ( ) ) ; 1 for a , 1 for b . batch contains only unique arguments ( no duplicates ) }
byte [ ] actual = new byte [ num blocks * block size ] ; system . out . println ( verifying file ) ; stm . read fully ( 0 , actual ) ; stm . close ( ) ; check data ( actual , 0 , expected , read 1 ) ; }
out . append ( goog . load module ( function ( exports ) { + ' use strict ' ; ) ;
byte [ ] key bytes = key writable . get bytes ( ) ; int key length = key writable . get length ( ) ; group key . set ( key bytes , 0 , key length ) ; key binary sortable deserialize to row . set bytes ( key bytes , 0 , key length ) ; try { key binary sortable deserialize to row . deserialize ( batch , 0 ) ; } catch ( exception e ) { throw new hive exception ( \ n deserialize read details : + key binary sortable deserialize to row . get detailed read position string ( ) , e ) ; }
zk client . make path ( test path here , ( byte [ ] ) null , create mode . persistent , ( watcher ) null , true , true , 1 ) ; zk client . clean ( ) ;
int fixups = 0 ;
region impl position = new region impl ( ) ;
for ( int i = to inc + 1 ; i < result . length ; i + + ) { if ( i > = fuzzy key meta . length | | fuzzy key meta [ i ] = = 1 ) { result [ i ] = 0 ; } }
test drop deletes ( row2 , row3 , new byte [ ] [ ] { row1 , row2 , row2 , row3 } , include , skip , skip , include ) ;
src . get ( payload , value offset , bytes read ) ; value offset + = bytes read ; if ( done ) { return false ; } }
validate ( app submission context ) ; map < sub cluster id , sub cluster info > active subclusters = get active subclusters ( ) ;
assert . assert true ( trafo . get output commands ( ) . contains ( module focus - - module name domain - it ) ) ;
list < validation provider < ? > > providers = get validation providers ( wild fly security manager . get current context class loader privileged ( ) ) ;
directory target dir2 = new directory ( ) ;
public oauditing service get auditing ( ) { return auditing service ;
assert true ( key value . comparator . compare ( bbb , bbb ) = = 0 ) ; assert true ( key value . key _ comparator . compare ( keybbb , 0 , keybbb . length , keybbb , 0 , keybbb . length ) = = 0 ) ; assert true ( key value . comparator . compare ( aaa , aaa ) = = 0 ) ; assert true ( key value . key _ comparator . compare ( keyabb , 0 , keyabb . length , keyabb , 0 , keyabb . length ) = = 0 ) ;
verify branching joining plan ( execution mode . batch , data exchange mode . pipelined , to map data exchange mode . pipelined , to combiner connections are pipelined data exchange mode . batch , to reduce data exchange mode . batch , to filter data exchange mode . pipelined , to sink after reduce data exchange mode . batch , to join ( first input ) data exchange mode . batch , to join ( second input ) data exchange mode . pipelined , combiner connections are pipelined data exchange mode . batch , to other reducer data exchange mode . pipelined , to flat map data exchange mode . pipelined , to sink after flat map data exchange mode . batch , to co group ( first input ) data exchange mode . batch , to co group ( second input ) data exchange mode . pipelined to sink after co group ) ;
iterator < range < c > > itr = range set . as ranges ( ) . iterator ( ) ; range < c > expected span = null ; if ( itr . has next ( ) ) { expected span = itr . next ( ) ; while ( itr . has next ( ) ) { expected span = expected span . span ( itr . next ( ) ) ; } } try { range < c > span = range set . span ( ) ; assert equals ( expected span , span ) ; } catch ( no such element exception e ) { assert null ( expected span ) ; }
int size = data in . read int ( ) ;
view header = layout inflater . from ( this ) . inflate ( r . layout . sample _ header , ( view group ) find view by id ( android . r . id . content ) , false ) ; m lrecycler view adapter . add header view ( header ) ;
verifier . verify trace ( event ( jdk _ httpurlconnector , get input stream , expected , null , null , no . such . url , annotation ( http . url , http : no . such . url ) ) ) ;
for ( int i = 0 ; i < 20 ; i + + ) assert that ( decider . should back off ( ) , is ( false ) ) ;
delete entries ( oid primary key ) ;
in vertex = ( ( partition vertex ) in vertex ) . get base vertex ( ) ;
set at ( bytes , offset ) ; suppress dump = false ;
mpr . instance . wnet cancel connection2 ( resource . lp remote name , 0 , true ) ;
when ( mock trigger . should fire ( any trigger context ( ) ) ) . then return ( true ) ; assert true ( tester . should fire ( window ) ) ; ready tester . fire if should fire ( window ) ; assert false ( tester . is marked finished ( window ) ) ; }
if ( m list view background = = null | | m list view background . get top ( ) = = m header container . get height ( ) ) m initialized = true ; return ; }
if ( pkgdir . mkdirs ( ) ) { throw new ioexception ( cannnot create directory : + pkgpath ) ; }
conf . set ( http . timeout , 99999999999 ) ;
if ( process definition util . is process definition suspended ( process definition . get id ( ) ) ) { throw new activiti exception ( cannot start process instance . process definition + process definition . get name ( ) + ( id = + process definition . get id ( ) + ) is suspended ) ; }
copy = current ;
location = encode spaces ( location ) ; if ( log . is debug enabled ( ) ) { log . debug ( location after . and space transforms : + location ) ; }
try { string att name [ ] = process name ( att qname , true , true ) ; atts . add attribute ( att name [ 0 ] , att name [ 1 ] , att name [ 2 ] , type , value ) ; } catch ( saxexception e ) { if ( exceptions = = null ) exceptions = new vector ( ) ; exceptions . add element ( e ) ; atts . add attribute ( , att qname , att qname , type , value ) ; }
if ( current . bit index < = path . bit index ) current . predecessor = entry ; if ( path = = root | | is bit set ( entry . key , path . bit index ) ) path . left = entry ; else path . right = entry ;
try { cn = class helper . make ( cu . get class loader ( ) . load class ( name , false , true ) , false ) ; } catch ( exception e ) { throw new groovy bug error ( e ) ; } return cn ; } private class node get common super class node ( class node c , class node d ) {
intent filter filter = new intent filter ( ) ; filter . add action ( intent . action _ locale _ changed ) ; phone . get context ( ) . register receiver ( m intent receiver , filter ) ;
default latex program ( ) . set global value ( new ui prefs . default latex program ( ) . get global value ( ) ) ;
capture < collection < sink record > > captured records = expect polls ( worker config . offset _ commit _ interval _ ms _ default ) ; expect offset commit ( 1 l , null , null , 0 , true ) ; expect stop task ( ) ; power mock . replay all ( ) ;
log . error ( error occurred while reading file { } : , file , string utils . stringify exception ( e ) ) ;
if ( v = = sink ) { found augmented path = true ; break ; } } } }
log . info ( server + hp + not up + e ) ;
assert false ( pom . has dependency excluding version ( mock other dependency ) ) ;
s = text ; yyreset ( zz reader ) ; yybegin ( yyinitial ) ; return yylex ( ) ; }
check value xml ( table , row _ 1 , column _ 1 , value _ 1 ) ; check value xml ( table , row _ 1 , column _ 2 , value _ 2 ) ; check value xml ( table , row _ 2 , column _ 1 , value _ 3 ) ; check value xml ( table , row _ 2 , column _ 2 , value _ 4 ) ; response = delete row ( table , row _ 1 ) ; assert equals ( response . get code ( ) , 200 ) ; response = delete row ( table , row _ 2 ) ; assert equals ( response . get code ( ) , 200 ) ; }
activation . tanh , hinge activation . sigmoid , kld activation . softmax , kld + softmax activation . tanh , l1 activation . tanh , l2 activation . tanh , mae activation . softmax , mae + softmax activation . tanh , mape activation . softmax , mape + softmax
update project references if necessary ( ) ;
w0 = text _ node ;
if ( ( key instanceof secret key ) ) { throw new invalid key exception ( key for algorithm + key . get algorithm ( ) + not suitable for symmetric enryption . ) ; }
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( target group not found ) ) return null ; target group not found exception e = ( target group not found exception ) super . unmarshall ( node ) ; return e ; }
list < feature > features = new array list < > ( ) ; for ( object object : collection ) { if ( ( object instanceof feature ) ) { not a feature this is a mixed collection throw new runtime exception ( string . format ( unable to handle attribute ' % s ' . , attribute ) ) ; } features . add ( ( feature ) object ) ; } return features ;
actual value . set byte ( 0 , ( byte ) ( actual value . get byte ( 0 ) + 1 ) ) ; assert false ( buffer . get byte ( i ) = = actual value . get byte ( 0 ) ) ; actual value . release ( ) ; }
get ( wfs?request = release lock & version = 2 . 0 & lock id = + lock id ) ; assert equals ( ows : exception report , dom . get document element ( ) . get node name ( ) ) ;
sect pr finder sf = new sect pr finder ( word mlpackage . get main document part ( ) ) ; try { new traversal util ( word mlpackage . get main document part ( ) . get contents ( ) , sf ) ; } catch ( docx4 jexception e ) { log . error ( e . get message ( ) , e ) ; } for ( sect pr sect pr : sf . get ordered sect pr list ( ) ) { section wrapper sw = new section wrapper ( sect pr , previous hf , rels , even and odd headers ) ; sections . add ( sw ) ; previous hf = sw . get header footer policy ( ) ; log . debug ( registered sectpr ) ; }
iter = new child test iterator ( compiler , op pos , analysis ) ; } }
int label = offset + read int ( u ) ; int min = read int ( u + 4 ) ; int max = read int ( u + 8 ) ; label [ ] table = new label [ max - min + 1 ] ; u + = 12 ; for ( int i = 0 ; i < table . length ; + + i ) { table [ i ] = labels [ offset + read int ( u ) ] ; u + = 4 ; } mv . visit table switch insn ( min , max , labels [ label ] , table ) ; break ;
limiter . set next refill time ( limiter . get next refill time ( ) - 3000 ) ;
rp1 = get default retry policy ( false , 40000 , 5 ) ;
mock zook keeper . fail now ( code . sessionexpired ) ;
long start = data interval . get end millis ( ) - period millis ; long start offset = start % period millis - origin millis % period millis ; if ( start offset < 0 ) { start offset + = period millis ; } ; start - = start offset ;
spi impl . engine init ( opmode , key , params , random ) ;
net rleres = rlesparse resource allocation . merge ( plan . get resource calculator ( ) , total capacity , net rleres , plan modifications , rleoperator . subtract , stage earliest start , stage deadline ) ;
versioned < list < store definition > > list = admin client . metadata mgmt ops . get remote store def list ( 0 ) ; assert true ( list . get value ( ) . contains ( definition ) ) ;
if ( cache . is empty ( ) & & this . closed ) { return null ; } if ( cache . is empty ( ) ) { load cache ( ) ; } if ( cache . size ( ) > 0 ) { return cache . poll ( ) ; }
if ( attr wildcard . f process contents = = xswildcard decl . pc _ strict ) { report schema error ( cvc - complex - type . 3 . 2 . 2 , new object [ ] { element . rawname , f temp qname . rawname } ) ; }
for ( iterator < presence status > supported status it = operation set presence1 . get supported status set ( ) ; supported status it . has next ( ) ; ) { presence status supported status = supported status it . next ( ) ; supported status set1 . put ( supported status . get status name ( ) , supported status ) ; }
b . set pipeline factory ( new channel pipeline factory ( ) { public channel pipeline get pipeline ( ) throws exception { return channels . pipeline ( new string encoder ( charset util . iso _ 8859 _ 1 ) , new string decoder ( charset util . iso _ 8859 _ 1 ) , new quote of the moment client handler ( ) ) ; } } ) ;
if ( r _ step _ 6 ( ) ) { break lab15 ; } } while ( false ) ; cursor = limit - v _ 16 ; cursor = limit _ backward ; do , line 243 v _ 18 = cursor ; lab18 : do {
assert . assert equals ( num deleted modified , copy listing . size ( ) ) ;
reader reader = resources . get resource as reader ( org apache ibatis submitted raw _ sql _ source mybatis - config . xml ) ; sql session factory = new sql session factory builder ( ) . build ( reader ) ; reader . close ( ) ;
assert equals ( 1 , splits . size ( ) ) ;
local address = inet4 address . any ; impl . close ( ) ; }
case v : { string [ ] floats = prefix split [ 1 ] . trim ( ) . split ( \ \ s + , 4 ) ; if ( floats . length = 3 ) { throw new ioexception ( bad statement ) ; } raw vertices . add ( new vector3f ( float . parse float ( floats [ 0 ] ) , float . parse float ( floats [ 1 ] ) , float . parse float ( floats [ 2 ] ) ) ) ; break ; }
for ( iterator < odatabase lifecycle listener > it = orient . instance ( ) . get db lifecycle listeners ( ) ; it . has next ( ) ; ) it . next ( ) . on close ( get database owner ( ) ) ;
stream observer < beam fn api . instruction request > outbound server observer = outbound server observers . take ( ) ; executor service executor = executors . new cached thread pool ( ) ;
{ enclosing type . anonymous _ method } ,
if ( zero fill buffers ) { for ( int i = 0 ; i < buffer upto ; i + + ) {
assert script element column ( 53 , exception ) ; assert script stack ( exception , y = x . is empty ( ) ; \ n } \ n , ^ - - - - here ) ; assert that ( exception . get cause ( ) , instance of ( null pointer exception . class ) ) ; }
final subscription underlying subscription = to observable ( ) . subscribe ( subject ) ;
char s = instruction [ i + + ] ; char e = instruction [ i + + ] ; match = ( ( compare chars ( c , s , case fold ) > = 0 ) & & ( compare chars ( c , e , case fold ) < = 0 ) ) ; }
path = path . replace ( \ \ , ) ; index reader ireader = get index reader ( path ) ;
set character encoding ( get character encoding ( ) ) ;
test needed temps ( function foo ( a ) { a ; a ; } ; foo ( 0 ) ; , foo , empty _ string _ set ) ;
byte [ ] out = new byte [ out buff posn ] ; system . arraycopy ( out buff , 0 , out , 0 , out buff posn ) ; return out ;
object unbound = attributes . put ( name , value ) ;
delete cross refs ( i rid , ( odocument ) field value ) ; } else if ( omulti value . is multi value ( field value ) ) {
if ( m _ parser factory = = null ) { m _ parser factory = saxparser factory . new instance ( ) ; m _ parser factory . set namespace aware ( true ) ; } reader = m _ parser factory . new saxparser ( ) . get xmlreader ( ) ;
assert equals ( invoice user api . get account balance ( parent account . get id ( ) , call context ) . compare to ( big decimal . zero ) , 0 ) ; assert equals ( invoice user api . get account balance ( child account . get id ( ) , call context ) . compare to ( big decimal . zero ) , 0 ) ; bus handler . push expected events ( next event . invoice , next event . invoice _ payment , next event . payment ) ;
if ( lower _ case ) word = word . to lower case ( ) ; if ( index . contains key ( word ) ) return ( index . get ( word ) ) . int value ( ) ; else return 0 ; }
string meta model source = get meta model source as string ( test entity . class ) ; assert false ( @ suppress warnings should not be added to the metamodel . , meta model source . contains ( @ suppress warnings ( \ all \ ) ) ) ; }
final object [ ] acc = { initial value } ; visit pre order ( ( env ) - > acc [ 0 ] = query reducer . reduce field ( env , ( t ) acc [ 0 ] ) ) ; return ( t ) acc [ 0 ] ; }
this . c a = derboolean . true ;
replacement instruction = new branch instruction ( branch instruction . opcode , branch instruction . branch offset ) ; break ;
one byte [ 0 ] = ( byte ) b ;
regex . append ( . * ) ;
bt select compress = uiutils . create checkbox ( composite , exasol messages . dialog _ table _ tools _ export _ compress , false ) ;
market data service market data service = mercado bitcoin . get market data service ( ) ; generic ( market data service ) ; raw ( ( mercado bitcoin market data service raw ) market data service ) ; }
final mock relay connection relay conn1 = new mock relay connection ( sources response , register response , null , server idx ) ;
cookie = new cookie ( name = value ; a = b ; ) ; assert equals ( name , cookie . get name ( ) ) ;
if ( stats iter . has next ( ) ) { return new client stats ( ) ; }
hconnection manager . hbase _ instances . clear ( ) ; hconnection manager . hbase _ instances . put all ( old hbase instances ) ; }
if ( get frame ( ) = null ) { set state ( get frame ( ) . get extended state ( ) ) ; } jroot pane root pane = get root pane ( ) ;
assert equals ( optional . of ( file . storyboard ) , base storyboard reference . get last known file type ( ) ) ;
ogw . start walking ( top nodes , null ) ; return pctx ; }
int num acls = in . read int ( ) ; for ( int i = 0 ; i < num acls ; i + + ) { job acl acl type = writable utils . read enum ( in , job acl . class ) ; access control list acl = new access control list ( ) ; acl . read fields ( in ) ; this . job acls . put ( acl type , acl ) ; } }
float dispersion score = 0 ;
assert equals ( h1 , request context . get ( out s1 ) ) ;
client . write summary csv ( stats , statsfile ) ;
system . out . println ( executing word count example with default input data set . ) ;
file template file = new file ( join path ( this . expression template directory , tdesc [ 0 ] + . txt ) ) ; string template string = read file ( template file ) ; template string = template string . replace all ( < class name > , class name ) ; template string = template string . replace all ( < operator > , operator name . to lower case ( ) ) ; write file ( template file . last modified ( ) , expression output directory , expression classes directory , class name , template string ) ; }
throw new illegal argument exception ( sm . get string ( hex utils . from hex . odd digits ) ) ; }
reader = directory reader . open ( d ) ; field infos = multi fields . get merged field infos ( reader ) ; collection < string > all field names = new hash set < > ( ) ; collection < string > indexed field names = new hash set < > ( ) ;
current config = new dynamic configuration ( prior config ) ;
properties db properties = get default dbcpproperties ( ) ;
final payment transaction model dao payment transaction = payment dao . get payment transaction ( payment state context . get payment transaction model dao ( ) . get id ( ) , internal call context ) ;
return 1f get scale ( m base matrix ) ; }
set < role model > john roles = john . get role mappings ( ) ; assert . assert true ( john roles . contains ( realm role1 ) ) ; assert . assert false ( john roles . contains ( realm role2 ) ) ; assert . assert true ( john roles . contains ( realm role3 ) ) ; assert . assert true ( john roles . contains ( finance role1 ) ) ; assert . assert true ( john roles . contains ( manage account role ) ) ; set < role model > john realm roles = john . get realm role mappings ( ) ;
post process test ( ) ;
rth . flush pending ( ) ;
for ( final string server : server array ) { new thread ( new runnable ( ) { @ override public void run ( ) { connect to one server with retry ( client , server ) ; connections . count down ( ) ; } } ) . start ( ) ; }
for ( int i = 0 ; i < group key names . length ; i + + ) { final int fi = i ; df . add series ( group key names [ i ] , df . map ( new series . object function ( ) { @ override public object apply ( object . . . values ) { return ( ( tuple ) values [ 0 ] ) . values [ fi ] ; } } , column _ join _ key ) ) ; }
result set header packet header = packet util . get header ( field _ count ) ;
this . pctx = pctx ; this . alias to op info = new hash map < string , operator < ? extends operator desc > > ( ) ;
if ( signer . get subject dn ( ) . equals ( signer . get issuer dn ( ) ) ) { return ( x509 certificate [ ] ) chain . to array ( new x509 certificate [ 1 ] ) ; } principal issuer = signer . get issuer dn ( ) ;
boolean properly configured = true ;
if ( fc2 = null ) { fc2 . delete ( base , true ) ; }
operator . run ( new object ( ) , mock ( stream status maintainer . class ) , new collector output < string > ( output ) ) ; assert true ( output . is empty ( ) ) ;
m attr = headers . get ( current cells . size ( ) ) . attr ; } } else {
ex . interpreter stack info = null ; ex . interpreter line data = null ; return ;
assert equals ( clear cookies , d . find element ( by . link text ( clear cookies ) ) . get text ( ) ) ;
if ( vertices = = null | | index > = vertices . length ) { pgraphics . show warning ( no _ such _ vertex _ error + ( + index + ) , get ambient ( ) ) ; return ambient color ; } int r = ( int ) ( vertices [ index ] [ pgraphics . ar ] * 255 ) ;
gles20 . gl enable vertex attrib array ( ma texture coord loc ) ;
store initial location ( exchange ) ;
for ( int i = 1 ; i < 6 ; i + + ) { assert that ( queue . peek ( ) ) . is equal to ( values [ i ] ) ; queue . remove ( ) ; } queue . close ( ) ;
message = message . split ( \ n ) [ 0 ] ; log . warn ( comment + + message ) ; } else {
sql . replace ( : catalog _ name , ? ) , param ( catalog _ name , catalog . get input name ( ) ) ) ; }
create queues and actors ( ) ;
if ( num rows * num cols > 100000 * cloud size & & total size cloud size num cols ( 4 * cores ) > 1000 only complain about too few chunks if there ' s enough data to cut it into chunk pojo of 1k b each , otherwise it ' s small data and we ' re fine with fewer chunks ) { msg + = few ; file vec . calc optimal chunk size ( ( long ) total size , num cols , max line length , cores , cloud size , oldheuristic = = 1 , true ) ; toofew [ oldheuristic ] + + ; fail = true ; assert . assert true ( num cols > 1e4 ) ; only for very wide data assert . assert true ( parse chunk count per node > cores 2 ) ; at least keep half the cores busy }
start threads ( ) ;
for ( string instance name : instances ) { if ( instance name . starts with ( common constants . helix . prefix _ of _ server _ instance ) ) { continue ; } ensure that the random instance is in the routing table check for instance in routing table ( true , instance name ) ; mark the server instance as shutting down instance config instance config = _ helix admin . get instance config ( _ cluster name , instance name ) ; instance config . get record ( ) . set boolean field ( common constants . helix . is _ shutdown _ in _ progress , true ) ; _ helix admin . set instance config ( _ cluster name , instance name , instance config ) ; check that it is not in the routing table check for instance in routing table ( false , instance name ) ; re - enable the server instance instance config . get record ( ) . set boolean field ( common constants . helix . is _ shutdown _ in _ progress , false ) ; _ helix admin . set instance config ( _ cluster name , instance name , instance config ) ; check that it is in the routing table check for instance in routing table ( true , instance name ) ; }
handle special chunk end ( ) ;
explicit index transaction ordering . offer ( transaction id ) ;
fr2 = model . score ( tr ) ;
message info . set response message ( new test http servlet response wrapper ( ( http servlet response ) message info . get response message ( ) ) ) ; return success ;
final account email account email1 = new default account email ( account id , email1 ) ;
return get double ( this . m context . get string ( res id ) , default value ) ;
for ( int i = - 1 ; i > - number of items ; i - - ) { map . put ( i , i ) ; }
for ( long v : negatives2 ) { assert false ( s . lookup ( v ) ) ; } }
check url ( main - one , false , rollout plan test case rollout servlet?operation = bind & bind port = + test _ port ) ;
if ( r . request ( ) = null & & r . request ( ) . get attribute ( clean _ close ) = = null ) { close ( ) ; } } catch ( exception ex ) {
final centroids . collect ( ) ; }
set extract view shown ( false ) ; return ;
location ps loc = location cache . get pslocation ( ps id ) ; string ip regex = ( 2 [ 5 ] [ 0 - 5 ] | 2 [ 0 - 4 ] \ \ d | 1 \ \ d { 2 } | \ \ d { 1 , 2 } ) \ \ . ( 25 [ 0 - 5 ] | 2 [ 0 - 4 ] \ \ d | 1 \ \ d { 2 } | \ \ d { 1 , 2 } ) \ \ . ( 25 [ 0 - 5 ] | 2 [ 0 - 4 ] \ \ d | 1 \ \ d { 2 } | \ \ d { 1 , 2 } ) \ \ . ( 25 [ 0 - 5 ] | 2 [ 0 - 4 ] \ \ d | 1 \ \ d { 2 } | \ \ d { 1 , 2 } ) ; pattern pattern = pattern . compile ( ip regex ) ; matcher matcher = pattern . matcher ( ps loc . get ip ( ) ) ; assert true ( matcher . matches ( ) ) ; assert true ( ps loc . get port ( ) > = 1 & & ps loc . get port ( ) < = 65535 ) ; int matrix1 id = local cluster context . get ( ) . get master ( ) . get app master ( ) . get app context ( ) . get matrix meta manager ( ) . get matrix ( w1 ) . get id ( ) ;
assert that ( xpath . evaluate ( boolean ( wfs : feature collection gml : feature member gs : generic lines [ @ fid = ' line . 2 ' ] [ gs : name = ' line2 ' ] ) , result ) , is ( true ) ) ; assert that ( xpath . evaluate ( boolean ( wfs : feature collection gml : feature member gs : generic lines [ @ fid = ' line . 3 ' ] [ gs : name = ' line3 ' ] ) , result ) , is ( true ) ) ; }
assert that ( result . split ( < td bgcolor = \ ffffc0 \ align = \ right \ > < nobr > release1bad < nobr > < td > ) . length , is ( 2 ) ) ;
list < object > header tags = response . get http headers ( ) . get ( etag ) ; assert . assert not null ( header tags ) ; assert . assert equals ( header tags . size ( ) , 1 ) ; assert . assert equals ( header tags . get ( 0 ) , new entity tag ( 5d41402abc4b2a76b9719d911017c592 ) ) ; }
clazz = m context . get class loader ( ) . load class ( prefix = null ? ( prefix + name ) : name ) . as subclass ( view . class ) ; if ( m filter = null & & clazz = null ) { boolean allowed = m filter . on load class ( clazz ) ; if ( allowed ) { fail not allowed ( name , prefix , attrs ) ; } }
type type = test to type ( dpt , new byte [ ] { 0x00 } , expected class ) ;
set < kd node > examined = new hash set < kd node > ( ) ;
mock . message ( 0 ) . header ( jmsredelivered ) . is equal to ( false ) ; template . send body ( activemq : queue : okay , hello world ) ; mock . assert is satisfied ( ) ; }
query = new tree query ( file _ 1 _ uuid ) . set name or key query ( foo ) . build ( ) ; assert that ( under test . select descendants ( db session , query ) ) . is empty ( ) ; }
copy key = key . substring ( prefix . length ( ) ) ; } else {
visit expression ( if else , context flags & ecf _ tail ) ;
assert equals ( meta data . resolve index routing ( null , null , null ) , null ) ;
return root . get last child ( ) . get first child ( ) ; }
abstract web socket connection ws connection = new web socket server connection ( endp , executor , scheduler , driver . get policy ( ) , buffer pool ) ; extension stack . set policy ( driver . get policy ( ) ) ; extension stack . configure ( ws connection . get parser ( ) ) ; extension stack . configure ( ws connection . get generator ( ) ) ; if ( log . is debug enabled ( ) ) { log . debug ( http connection : { } , http ) ; log . debug ( web socket connection : { } , ws connection ) ; }
assert true ( command . is executed in thread ( ) ) ; assert not null ( command . get execution exception ( ) ) ; assert equals ( 0 , command . metrics . get current concurrent execution count ( ) ) ; assert equals ( 1 , hystrix request log . get current request ( ) . get all executed commands ( ) . size ( ) ) ; }
data padding bytes = 1 ;
extended block block = dfs client . get namenode ( ) . get block locations ( test file , 0 , long . max _ value ) . get ( 0 ) . get block ( ) ; list < materialized replica > replicas = new array list < > ( ) ;
vector < object > vec = new vector < object > ( 3 ) ;
parser parser = new parser ( doc ) ; set tags = parser . get rel tags ( ) ; iterator iter = tags . iterator ( ) ; metadata metadata = parse . get data ( ) . get parse meta ( ) ; while ( iter . has next ( ) ) { metadata . add ( rel _ tag , ( string ) iter . next ( ) ) ; } return parse result ;
tag stack . add last ( tag ) ;
get dfs ( ) . recover lease ( file ) ; cluster . restart name node ( true ) ; }
if ( ( ftp . follow talk ) & & ( ftp . log . is info enabled ( ) ) ) { ftp . log . info ( delete client because server cut off control channel : + e ) ; }
if ( protocol provider = = null ) throw new null pointer exception ( the specified protocol provider was null ) ; if ( account properties = = null ) throw new null pointer exception ( the specified property map was null ) ; bundle context context = gibberish activator . get bundle context ( ) ;
gen . write array field start ( all - exceptions ) ; int num exceptions so far = 0 ;
list < processor definition < ? > > children = processor . get outputs ( ) ; for ( processor definition < ? > child : children ) { register performance counters ( route context , child , registered counters ) ; }
string name = includeresource [ i ] ; if ( name . starts with ( ) ) { string s = cls . get name ( ) . replace ( ' . ' , ' ' ) ; int n = s . last index of ( ' ' ) ; if ( n > = 0 ) { name = s . substring ( 0 , n + 1 ) + name ; } includeresource [ i ] = + name ; } }
upload task < t > task = ( upload task < t > ) task map . get ( tag ) ;
bootstrap checkpoint handler handler = new bootstrap checkpoint handler ( two _ sources ) ;
shapes . begin ( shape type . line ) ; float x = 0 , y = gdx . graphics . get height ( ) - font . get region ( ) . get region height ( ) - 1 ; for ( int i = 0 , n = font . get regions ( ) . size ; i < n ; i + + ) { texture region region = font . get regions ( ) . get ( i ) ; shapes . rect ( x , y , region . get region width ( ) , region . get region height ( ) ) ; x + = region . get region width ( ) + 2 ; } shapes . rect ( 10 , 250 , gdx . graphics . get width ( ) - 20 , - 240 ) ; shapes . end ( ) ; batch . begin ( ) ;
log . info ( random seeking with + file context ) ;
boolean create marker node = zk state reader . get auto scaling config ( ) . has trigger for events ( trigger event type . nodeadded ) ;
if ( item position = = ( child count - 2 - adapter . get header views ( ) . size ( ) ) ) out rect . set ( 0 , 0 , 0 , 0 ) ; else out rect . set ( 0 , 0 , 0 , vertical space ) ; } else {
this . datasource _ jndi _ name = this . get class ( ) . get name ( ) ; }
m remote service . on destroy ( ) ;
ejb jar meta data ejb jar meta data = deployment unit . get attachment ( ejb deployment attachment keys . ejb _ jar _ metadata ) ;
expected rows = this . num rows ; expected keys = this . cols per row 2 ; f = new family filter ( compare op . less _ or _ equal , new binary comparator ( bytes . to bytes ( test family one ) ) ) ; s = new scan ( ) ; s . set filter ( f ) ; verify scan no early out ( s , expected rows , expected keys ) ;
members . add ( d ) ;
int num linked ss = ( linked style sheets = null ) ? linked style sheets . size ( ) : 0 ;
object mapper mapper2 = new object mapper ( ) ;
set selected ( child is focused ) ;
complex [ ] d = convolve ( x , x ) ; show ( d , d = convolve ( x , x ) ) ; }
string a = me . get exchanges ( ) . get ( 0 ) . get in ( ) . get body ( string . class ) ; string b = me . get exchanges ( ) . get ( 1 ) . get in ( ) . get body ( string . class ) ; string c = me . get exchanges ( ) . get ( 2 ) . get in ( ) . get body ( string . class ) ; string d = me . get exchanges ( ) . get ( 3 ) . get in ( ) . get body ( string . class ) ; string line = a + b + c + d ; log . info ( order : { } , line ) ;
boolean not eof = last . get type ( ) = token . eof ;
if ( need reprojection ) { if ( concatenated forward transform . is identity ( ) ) { concatenated forward transform . transform ( coords , 0 , coords , 0 , npoints ) ; } return ; }
string proc name = m _ tracker . add ( descriptor ) ;
if ( remark bytes = null ) { header buffer . put int ( remark bytes . length ) ; header buffer . put ( remark bytes ) ; } else { header buffer . put int ( 0 ) ; }
return new batch update result < long , greeting > ( null ) ;
if ( line has tweak comment ( start , c ) ) { continue ; }
org . docx4j . wml . object factory factory = context . get wml object factory ( ) ; org . docx4j . wml . p p = factory . create p ( ) ; org . docx4j . wml . r run = factory . create r ( ) ; p . get content ( ) . add ( run ) ; run . get content ( ) . add ( pict ) ; return p ; }
cs conf . set queues ( capacity scheduler configuration . root + . b , new string [ ] { b1 , b2 , b3 , b4 } ) ;
try { int async id = admin client . rebalance ops . rebalance node ( plans . get ( 0 ) ) ; get admin client ( ) . rpc ops . wait for completion ( plans . get ( 0 ) . get stealer id ( ) , async id , 300 , time unit . seconds ) ; fail ( should throw an exception ) ; } catch ( exception e ) { }
array list < key value > kvs = new array list < key value > ( 2 ) ; array list < annotation > annotations = new array list < annotation > ( 0 ) ;
fs . close ( ) ; assert equals ( 60 , get last written tx id ( ) ) ;
scheduler scheduler = get component ( ) . get scheduler ( ) ; job detail job detail ; trigger old trigger = scheduler . get trigger ( trigger key ) ; boolean trigger existed = old trigger = null ; if ( trigger existed & & is recoverable job ( ) ) { ensure no dup trigger key ( ) ; } job detail = create job detail ( ) ;
if ( zk run = = null ) return null ;
assert that ( ctx . get bean ( level1 bean ) , same instance ( ctx . get bean ( level1 bean ) ) ) ; assert that ( ctx . get bean ( level2 bean ) , same instance ( ctx . get bean ( level2 bean ) ) ) ; }
list foo = new array list ( ) ; foo . add ( p ) ; class finder finder = new class finder ( fld char . class ) ; whatever new traversal util ( foo , finder ) ; o2 = ( child ) xml utils . unwrap ( p . get content ( ) . get ( 1 ) ) ;
generic file no op process strategy < channel sftp . ls entry > strategy = new generic file no op process strategy < channel sftp . ls entry > ( ) ; strategy . set exclusive read lock strategy ( get exclusive read lock strategy ( params ) ) ; return strategy ; }
v _ 16 = limit - cursor ;
toolchains . add ( create x86 toolchain ( 4 . 8 , - fstack - protector , cpp configuration . tool . gcovtool ) ) ;
if ( line . starts with ( other prefix ) ) { break ; }
assert equals ( 3 , region . get store ( family ) . get storefiles count ( ) ) ;
result . set modified time ( prev modified time ) ; if ( old set ) result . set signature ( old . get signature ( ) ) ;
info . set channel number ( esds . get number of channels ( ) ) ; info . set kind ( esds . get kind ( ) ) ; info . set profile ( esds . get audio profile ( ) ) ; info . set encoding type ( encoder type . aac . get description ( ) ) ; } } else {
if ( exclude property ( exclude properties , name ) ) { continue ; } string param optional prefix = param . optional prefix ( ) ;
if ( command line . has option ( ' r ' ) ) { topic config . set read queue nums ( integer . parse int ( command line . get option value ( ' r ' ) . trim ( ) ) ) ; }
if ( is portrait mode ( ) ) { int tmp = width ; noinspection suspicious name combination width = height ; height = tmp ; } final int layout width = right - left ; final int layout height = bottom - top ;
log . warn ( exception while trying to unload the sla namespace , will not try to unload the namespace again . exception : , ex ) ;
if ( get frame ( ) = null ) { set state ( get frame ( ) . get extended state ( ) ) ; } jroot pane root pane = get root pane ( ) ;
if ( entry . find sessions ( ) . size ( ) = = 0 ) { deregister ( sso id ) ; } }
if ( value instanceof array ) { if ( known type = null & & actual type = known type & & actual type = array . class ) throw new serialization exception ( serialization of an array other than the known type is not supported . \ n + known type : + known type + \ n actual type : + actual type ) ; write array start ( ) ; array array = ( array ) value ; for ( int i = 0 , n = array . size ; i < n ; i + + ) write value ( array . get ( i ) , element type , null ) ; write array end ( ) ; return ; }
for ( boolean b : confirmations ) if ( b ) failed to shutdown + + ;
list < string > extras = new array list < string > ( ) ; mm . add values ( key , extras ) ; assert map size ( mm , 1 ) ;
add unsafe ( graphic data , http : schemas . openxmlformats . org drawingml 2006 main , graphic data , org . docx4j . dml . graphic data . class ) ; return graphic data . get any ( ) ;
urlspan [ ] link row = m link layer . get ( row ) ;
return a . hostname ( ) . compare to ( b . hostname ( ) ) ; }
network network = _ network dao . find by id ( network id ) ;
image = create bkg image ( map width , map height , bg color , null ) ;
assert . assert null ( session . user local storage ( ) . get user by username ( johnkeycloak , app realm ) ) ; assert . assert null ( session . user local storage ( ) . get user by username ( marykeycloak , app realm ) ) ; role model realm role1 = app realm . get role ( realm role1 ) ; role model realm role2 = app realm . get role ( realm role2 ) ;
list < mutation > row amutations = new array list < mutation > ( ) ;
load local ( extraction open - document . odt , uprefix , ignored _ , fmap . content , extracted content , literal . id , open - document ) ;
} else { _ fields = serializable fields . to array ( new object stream field [ serializable fields . size ( ) ] ) ; } }
if ( security group id list = = null | | security group id list . is empty ( ) ) { if ( security group id list = = null ) { security group id list = new array list < long > ( ) ; } security group default group = _ security group mgr . get default security group ( owner . get id ( ) ) ; if ( default group = null ) { security group id list . add ( default group . get id ( ) ) ; } else {
for ( byte [ ] bytes : actual ) { bytes [ 0 ] + + ; } assert array equals ( expected . get authorisations array ( ) , actual . get authorisations array ( ) ) ;
assert null ( knxcore type mapper . to type ( ) should return null ( required data length too short ) , test to type ( dpt , new byte [ ] { } , expected class ) ) ;
if ( null = = filename | | size < = 0 ) { throw new exception ( must supply valid filename and + size ( > 0 ) ) ; } try { setup ( new file input stream ( filename ) , size , format , swapxy ) ; } catch ( file not found exception e ) { throw new exception ( height file not found : + filename ) ; }
string insert stmt = insert into testexporttable1 values ( ' volt ' , 10 , 10 , 100 , now ) ; ; volt table [ ] results = m _ client . call procedure ( @ ad hoc , insert stmt ) . get results ( ) ; assert equals ( 1 , results [ 0 ] . as scalar long ( ) ) ; insert stmt = insert into testexporttable1 values ( ' volt ' , 10 , 11 , 100 , now ) ; ; results = m _ client . call procedure ( @ ad hoc , insert stmt ) . get results ( ) ; assert equals ( 1 , results [ 0 ] . as scalar long ( ) ) ;
options . as ( combined object . class ) ;
app attempt removed scheduler event app removed event1 = new app attempt removed scheduler event ( att id1 , rmapp attempt state . finished , false ) ; scheduler . handle ( app removed event1 ) ; scheduler . update ( ) ; scheduler . handle ( update event ) ;
class util . create instance ( inner . class , false ) ; } catch ( illegal argument exception e ) {
if ( ( attacker instanceof player ) ) { if ( wcfg . disable mob damage ) { event . set cancelled ( true ) ; return ; } if ( wcfg . use regions ) { if ( plugin . get region container ( ) . create query ( ) . get applicable regions ( defender . get location ( ) ) . allows ( default flag . mob _ damage , local player ) ) { event . set cancelled ( true ) ; return ; } } if ( event . get damager ( ) instanceof fireball ) { fireball fireball = ( fireball ) event . get damager ( ) ; if ( fireball instanceof wither skull ) { if ( wcfg . block wither skull explosions ) { event . set cancelled ( true ) ; return ; } } else { if ( wcfg . block fireball explosions ) { event . set cancelled ( true ) ; return ; } } if ( wcfg . use regions ) { region query query = plugin . get region container ( ) . create query ( ) ; if ( query . test state ( defender . get location ( ) , ( player ) defender , default flag . ghast _ fireball ) & & wcfg . explosion flag cancellation ) { event . set cancelled ( true ) ; return ; } } } }
return new create chat room wrapper runner ( chat room wrapper ) . get chat panel ( ) ; }
for ( int i = 0 ; i < str _ invalid . length ; i + + ) { try { en s = sslengine result . handshake status . value of ( str _ invalid [ i ] ) ; fail ( illegal argument exception should be thrown for + str _ invalid [ i ] ) ; } catch ( illegal argument exception iae ) { expected } }
stream . write ( ( byte ) 2 ) ; stream . hflush ( ) ; stream . close ( ) ; assert equals ( data _ before _ restart . length + 2 , fs . get file status ( file _ path ) . get len ( ) ) ;
this . seed node addresses = new hash set < > ( seed node addresses ) ; this . listener = listener ; network node . add message listener ( this ) ; network node . add connection listener ( this ) ; peer manager . add listener ( this ) ; }
current size = other . current size ;
final indexed < string > dim values = index selector . get dimension values ( dimension ) ;
assert true ( consume bytes ( stream _ id , data size - 10 ) ) ; verify window update sent ( stream _ id , data size ) ; verify window update sent ( connection _ stream _ id , data size ) ; verify no more interactions ( frame writer ) ; }
byte [ ] new version of test a2 = retrieve rename ( proxy . three . test a1 , proxy . three . test a2 , proxy . three . test intface a2 : proxy . three . test intface a1 , proxy . three . test intface b2 : proxy . three . test intface b1 ) ;
query = insert into type ( blob val ) values ( ? ) ; ; ps = conn . prepare statement ( query ) ; try { ps . set object ( 1 , , types . blob ) ; ps . execute ( ) ; } finally { try { st . close ( ) ; } catch ( exception ee ) { } }
table test table = create partitioned test table ( db name , table name , pool size + 2 , 0 ) ;
throw new org . apache . axis2 . databinding . adbexception ( resource id cannot be null ) ;
try { http message . set request header ( header ) ; } catch ( http malformed header exception e ) { logger . warn ( could not save header : + header , e ) ; } if ( parts . length > 1 ) { http message . set request body ( data . substring ( parts [ 0 ] . length ( ) + 2 ) ) ; } else { http message . set request body ( ) ; }
for ( int i = 0 , max = natural order table key columns . length ; i < max ; i + + ) { final string [ ] key columns = natural order table key columns [ i ] ; if ( array helper . contains ( key columns , column name ) ) { return natural order property table numbers [ i ] ; } } final string [ ] subclass column name closure = get subclass column closure ( ) ;
if ( wildcard = = null ) return null ;
assert that ( task . duration nanos ) . is less than ( profiler task . vfs _ stat . min duration ) ;
nnstorage . rename ( prev dir , cur dir ) ;
if ( obj = = null | | ( obj instanceof character literal node ) ) { return false ; }
name = exchange . get in ( ) . get header ( exchange . file _ name , string . class ) ; }
image listener . on response ( image container , true ) ;
mutable set multimap < string , integer > multi map = new unified set multimap < string , integer > ( ) ;
notify builder notify = new notify builder ( context ) . when done ( 2 ) . were sent to ( mock : bar ) . and ( ) . when failed ( 1 ) . were sent to ( mock : fail ) . create ( ) ; template . send body ( direct : bar , hello world ) ;
if ( in _ index = = len - 1 ) { if ( quoted _ value ) throw new malformed object name exception ( invalid ending character ` + name _ chars [ in _ index ] + ' ) ; else throw new malformed object name exception ( invalid ending comma ) ; } else in _ index + + ;
contact bean . set phone ( 12 ) ; final response response = test bean ( valid bean param , contact bean ) ; assert equals ( 400 , response . get status ( ) ) ; final string message = response . read entity ( string . class ) ; assert true ( message . contains ( arg0 ) ) ; }
volt . handler . send responses . set ( false ) ;
assume that ( pids . size ( ) , greater than ( 0 ) ) ; pair < long , string > pid = iterables . single ( pids ) ;
binder . bind ( page indexer factory . class ) . to ( group by hash page indexer factory . class ) . in ( scopes . singleton ) ;
short permission = 0777 ;
assert that ( bad request expected , connection . get response code ( ) , is ( 400 ) ) ;
string message = certificate revocation of serial 0x + serial . to string ( 16 ) ; system . out . println ( message ) ; annotated exception e = new annotated exception ( message ) ; throw new cert path validator exception ( e . get message ( ) , e , cert path , 0 ) ; } } }
string storage string = journal . get journal storage ( ) . to colon separated string ( ) ; system . err . println ( storage string : + storage string ) ; journal . close ( ) ; close to unlock the storage dir
assert that ( qoine order response . get id ( ) ) . is equal to ( 52351 ) ; assert that ( qoine order response . get quantity ( ) ) . is equal to ( new big decimal ( . 1 ) ) ; assert that ( qoine order response . get created at ( ) ) . is equal to ( 2015 - 04 - 25 t08 : 20 : 40 + 00 : 00 ) ; assert that ( qoine order response . get order type ( ) ) . is equal to ( limit ) ; }
{ session s = open session ( ) ; s . begin transaction ( ) ; s . do work ( new work ( ) { @ override public void execute ( connection connection ) throws sqlexception { final statement statement = connection . create statement ( ) ; final result set result set = statement . execute query ( select count ( * ) from farm _ accreditations ) ; assert true ( result set . next ( ) ) ; final int count = result set . get int ( 1 ) ; assert equals ( 2 , count ) ; } } ) ; s . get transaction ( ) . commit ( ) ; s . close ( ) ; }
verify ( current user controller , times ( 1 ) ) . set async ( user ) ;
if ( mmapped hg manifest = = null ) { path raw manifest path = hg cmd line . extract raw manifest ( ) ; try { mmapped hg manifest = new mmapped hg manifest ( raw manifest path ) ; } catch ( ioexception e ) { throw new version control command failed exception ( e . get message ( ) ) ; } } load count + = 1 ;
if ( context . is active ( ) ) { throw new illegal state exception ( cannot active profiles : + arrays . as list ( profiles ) + on active spring application context : + context + . the code in your create application context ( ) method should be adjusted to create the application context with refresh = false as parameter ) ; }
bigtable source source = new bigtable source ( service factory , table , null * filter * , byte key range . all _ keys , null * size * ) ; list < bigtable source > splits = source . split ( num rows * bytes per row num splits , null ) ;
for ( string id : plugin . get dependencies ( ) ) { plugin descriptor dependency = plugins . get ( id ) ; if ( dependency = = null ) { throw new missing dependency exception ( missing dependency + id + for plugin + plugin . get plugin id ( ) ) ; } if ( branch . contains key ( id ) ) { throw new circular dependency exception ( circular dependency detected + id + for plugin + plugin . get plugin id ( ) ) ; } dependencies . put ( id , dependency ) ; get plugin checked dependencies ( plugins . get ( id ) , plugins , dependencies , branch ) ; } branch . remove ( plugin . get plugin id ( ) ) ;
_ resource limit mgr . check resource limit ( new account , resource type . volume , _ vols dao . find by instance ( cmd . get vm id ( ) ) . size ( ) ) ;
return drawable ; } else if ( drawable instanceof layer drawable ) { layer drawable ld = ( layer drawable ) drawable ; int num = ld . get number of layers ( ) ;
task task after timer = task service . create task query ( ) . process instance id ( process instance . get id ( ) ) . single result ( ) ;
task attempt id [ 0 ] = job . find map task ( trackers [ 0 ] ) ;
final class < v > attribute type = map . get bindable java type ( ) ;
clients = create tracker client ( 100 , clock , degrader config ) ; config = degrader load balancer strategy config . create http config from map ( my map ) ; degrader load balancer strategy v2 _ 1 strategy v2 = new degrader load balancer strategy v2 _ 1 ( config , degrader load balancer test , null ) ; strategy = new degrader load balancer strategy adapter ( strategy v2 ) ; test degrader load balancer simulator ( strategy , clock , time interval , clients , qps , degrader config ) ; }
try { original = io buffer . allocate ( 16 ) ; duplicate = original . as read only buffer ( ) ; duplicate . put string ( a very very very very looooooong string , charset . for name ( iso - 8859 - 1 ) . new encoder ( ) ) ; fail ( read only buffer ' s can ' t be expanded ) ; } catch ( read only buffer exception e ) { expected an exception , signifies test success assert true ( true ) ; }
try { conn = null ; conn = get connection ( mini hs2 . get jdbc url ( test db name ) , user name , password ) ; } catch ( exception e ) { fail ( not expecting exception : + e ) ; } finally { if ( conn = null ) { conn . close ( ) ; } }
sb . append ( \ t \ tpublic < ) ; append tuple type generics ( sb , num fields ) ; sb . append ( > project cross < i1 , i2 , tuple + num fields + < ) ; append tuple type generics ( sb , num fields ) ; sb . append ( > > project tuple + num fields + ( ) ; sb . append ( ) { \ n ) ;
for ( int i = 0 ; i < widths . length ; i + + ) { if ( separator = null & & i > 0 ) { to . append ( separator . vertical ) ; } for ( int j = 0 ; j < widths [ i ] ; j + + ) { to . append ( ' ' ) ; } } }
bean description bean desc = mapper . get deserialization config ( ) . introspect ( mapper . construct type ( prop desc bean . class ) ) ; _ verify property ( bean desc , true , false , 13 ) ;
from ( direct : start ) . choice ( ) . when ( ) . xpath ( employee ) . to ( bean : normalizer?method = employee to person ) . when ( ) . xpath ( customer ) . to ( bean : normalizer?method = customer to person ) . end ( ) . to ( mock : result ) ;
assert null ( ce manies orig . get role ( ) ) ;
iterator < id3v2 lyric line > iterator = sync . iterator ( ) ; lyrics3 line new line ; id3v2 lyric line current line ; lyrics3 time stamp time stamp ; hash map < string , lyrics3 line > line map = new hash map < string , lyrics3 line > ( ) ; while ( iterator . has next ( ) ) { current line = iterator . next ( ) ; create field copy to use in new tag current line = new id3v2 lyric line ( current line ) ; time stamp = new lyrics3 time stamp ( time stamp , this ) ; time stamp . set time stamp ( current line . get time stamp ( ) , ( byte ) sync . get time stamp format ( ) ) ; if ( line map . contains key ( current line . get text ( ) ) ) { new line = line map . get ( current line . get text ( ) ) ; new line . add time stamp ( time stamp ) ; } else { new line = new lyrics3 line ( lyric line , this ) ; new line . set lyric ( current line ) ; new line . set time stamp ( time stamp ) ; line map . put ( current line . get text ( ) , new line ) ; lines . add ( new line ) ; } }
to add = m _ package manager . get repository package info ( split [ 0 ] , split [ 2 ] ) ;
text area . move caret position ( dot , ( p . x < 0 & & x > 1 ) ? text area . no _ scroll : text area . normal _ scroll ) ;
iterator < operator < ? extends operator desc > > alias to work iterator = conf . get alias to work ( ) . values ( ) . iterator ( ) ; one root operator = alias to work iterator . next ( ) ; preconditions . check state ( alias to work iterator . has next ( ) ) ; internal set children ( hconf ) ;
verify cat ( 0 , 1024 * 1024 , 1024 * 1024 ) ; verify cat ( 0 , 2 * 1024 * 1024 , 888 ) ; verify cat ( 0 , 1536 , 512 ) ; verify cat ( 0 , 1024 , 1024 ) ; verify cat ( 0 , 1024 , 1277 ) ; verify cat ( 0 , 2048 , 253 ) ; }
assert analyzes to ( keyword analyzer , ？ゝ , new string [ ] { ？？ } ) ;
final string payment state name = payment smhelper . get errored state for transaction ( transaction type . authorize ) . to string ( ) ; test listener . push expected event ( next event . payment _ plugin _ error ) ; payment dao . update payment and transaction on completion ( account . get id ( ) , null , payment . get id ( ) , transaction type . authorize , payment state name , payment state name , payment . get transactions ( ) . get ( 0 ) . get id ( ) , transaction status . unknown , requested amount , account . get currency ( ) , foo , bar , internal call context ) ; test listener . assert listener status ( ) ; final list < payment transaction model dao > payment transaction history before janitor = get payment transaction history ( transaction external key ) ;
this . fd = null ;
if ( expl = null ) { for ( int i = 0 , end = enum values . length ; i < end ; + + i ) { string def name = enum values [ i ] . name ( ) ; string expl value = expl . get ( def name ) ; if ( expl value = null ) { names [ i ] = expl value ; } } } return names ;
system . arraycopy ( cb , marked char , cb , 0 , delta ) ;
if ( log . is trace enabled ( ) ) { log . trace ( ack zxid : 0x { } , long . to hex string ( zxid ) ) ; for ( proposal p : outstanding proposals . values ( ) ) { long packet zxid = p . packet . get zxid ( ) ; log . trace ( outstanding proposal : 0x { } , long . to hex string ( packet zxid ) ) ; } log . trace ( outstanding proposals all ) ; } if ( ( zxid & 0xffffffff l ) = = 0 ) { * * we no longer process newleader ack with this method . however , * the learner sends an ack back to the leader after it gets * uptodate , so we just ignore the message . * return ; }
assert equals ( node1 , no decision . get node decisions ( ) . iterator ( ) . next ( ) . get node ( ) . get id ( ) ) ;
if ( get previous ( ) = null ) get previous ( ) . member added ( member ) ;
valid frame count + + ; if ( valid frame count = = 1 ) { mpeg audio header . populate header ( header data , synchronized header ) ; candidate synchronized header data = header data ; } else if ( valid frame count = = 4 ) { break ; } input . advance peek position ( frame size - 4 ) ; } }
ident node ident = ( ident node ) constant ;
if ( configuration settings . is debug build ( ) ) { return false ; } calendar now = calendar . get instance ( ) ;
this . uri = uri . replace ( ' ; ' , ' & ' ) ;
prepare create ( test _ good , settings . builder ( ) . put ( index . number _ of _ shards , 7 ) ) . get ( ) ; get settings response get settings response = client ( ) . admin ( ) . indices ( ) . prepare get settings ( test _ good ) . get ( ) ;
public void test set permission affects target ( ) throws ioexception { path file = new path ( test base dir1 ( ) , file ) ; path dir = new path ( test base dir2 ( ) ) ; path link to file = new path ( test base dir1 ( ) , link to file ) ; path link to dir = new path ( test base dir1 ( ) , link to dir ) ; create and write file ( file ) ; wrapper . create symlink ( file , link to file , false ) ; wrapper . create symlink ( dir , link to dir , false ) ;
if ( contains ( object ) ) { super . remove ( object ) ; }
verify delegation token renew ( null , user _ 1 ) ; }
int tail pos = ins pos + 1 ;
assert xpath evaluates to ( 1 , count ( wfs : feature collection ) , doc ) ;
impl method = caller . find special ( caller . lookup class ( ) , name , impl method type , caller . lookup class ( ) ) ; } else { impl method = caller . find static ( caller . lookup class ( ) , name , method type . from method descriptor string ( ( l + owner + ; + descriptor . substring ( 1 ) , caller loader ) ) ; } break ; case opcodes . h _ invokevirtual :
text = this . lexer . quoted string ( ) ; warning . set text ( text ) ; this . lexer . spor ht ( ) ; warning list . add ( warning ) ;
int last line start = textarea . get line start offset ( stop line ) ; int selection stop = textarea . get selection stop ( ) ; if ( selection stop = = last line start ) { though if there ' s no selection , don ' t do that if ( textarea . is selection active ( ) ) { stop line - - ; } } for ( int line = start line ; line < = stop line ; line + + ) { int location = textarea . get line start offset ( line ) ; if ( indent ) { textarea . select ( location , location ) ; textarea . set selected text ( tab string ) ; } else { outdent int last = math . min ( location + tab size , textarea . get document length ( ) ) ; textarea . select ( location , last ) ; don ' t eat code if it ' s not indented if ( tab string . equals ( textarea . get selected text ( ) ) ) { textarea . set selected text ( ) ; } } }
if ( i > = super . length1 | | j > = super . length2 ) { this . matrix . set ( i , j , 0 ) ; } else {
if ( w1 > 0x dbff ) { throw new illegal state exception ( invalid utf - 16 codepoint ) ; }
url = new url ( http : www . example . 2000 . hu ) ;
class < ? > document builder = class . for name ( com . plutext . merge . document builder ) ;
for ( int j = 0 ; j < 4 ; j + + ) { e = rotate left ( a , 5 ) + g ( b , c , d ) + e + x [ idx + + ] + y3 b = rotate left ( b , 30 ) e + = ( a < < 5 | a > > > 27 ) + g ( b , c , d ) + x [ idx + + ] + y3 ; b = b < < 30 | b > > > 2 ; d + = ( e < < 5 | e > > > 27 ) + g ( a , b , c ) + x [ idx + + ] + y3 ; a = a < < 30 | a > > > 2 ; c + = ( d < < 5 | d > > > 27 ) + g ( e , a , b ) + x [ idx + + ] + y3 ; e = e < < 30 | e > > > 2 ; b + = ( c < < 5 | c > > > 27 ) + g ( d , e , a ) + x [ idx + + ] + y3 ; d = d < < 30 | d > > > 2 ; a + = ( b < < 5 | b > > > 27 ) + g ( c , d , e ) + x [ idx + + ] + y3 ; c = c < < 30 | c > > > 2 ; }
assert not null ( response type ) ;
server support . configure login services ( server , login services ) ;
assert not null ( pr . terms ( f1 ) ) ;
try { sfsb with remove methods . do nothing ( ) ; assert . fail ( sfsb was expected to be removed after a call to the @ remove method ) ; } catch ( no such ejbexception nsee ) { expected log . trace ( got the expected no such ejbexception after invoking remove on the sfsb ) ; }
if ( namenode ver . get cluster id ( ) . equals ( datanode ver . get cluster id ( ) ) ) { log . info ( cluster ids are not equal : is version compatible = false ) ; return false ; }
assert not null ( sc . get layer by name ( states layer . prefixed name ( ) ) ) ;
get media player2 ( ) . reset ( ) ;
y = value ;
this ( period ms , arrays . as list ( actions ) ) ;
try { validate implements hash code ( type parameter ) ; } catch ( epoxy processor exception e ) { throw error ( type in iterable does not implement hash code . type : % s , type parameter . to string ( ) ) ; } }
check error ( { ? } , 2 , pattern message . illegal _ character _ at _ start _ of _ capture _ descriptor , ? ) ;
assert equals ( 1 , commands . size ( ) ) ; assert true ( commands . peek ( ) . get execution events ( ) . contains ( hystrix event type . timeout ) ) ; assert true ( commands . peek ( ) . get execution events ( ) . contains ( hystrix event type . collapsed ) ) ; future < string > f3 = command1 . queue ( ) ;
scratch . file ( extra build , load ( ' toolchain : toolchain _ def . bzl ' , ' test _ toolchain ' ) , toolchain ( , name = ' extra _ toolchain ' , , toolchain _ type = ' toolchain : test _ toolchain ' , , exec _ compatible _ with = [ ' constraints : linux ' ] , , target _ compatible _ with = [ ' constraints : linux ' ] , , toolchain = ' : extra _ toolchain _ impl ' ) , test _ toolchain ( , name = ' extra _ toolchain _ impl ' , , data = ' extra ' ) ) ; rewrite workspace ( register _ toolchains ( ' toolchain : toolchain _ 1 ' ) ) ;
ts = new timestamp ( system . current time millis ( ) ) ;
thread . current thread ( ) . blocked on ( intr ) ;
selenium . open ( . . tests html test _ get . html ) ;
if ( x0class = = 2 | | x1class = = 2 | | y0class = = 2 | | y1class = = 2 ) { return true ; }
put message ( stream id , full http message ) ;
exchange exchange = object helper . cast ( exchange . class , exchanges . poll ( ) ) ;
if ( api request facade . get extensions ( ) . is empty ( ) ) { for ( extension config ext : api request facade . get extensions ( ) ) { header ( http header . sec _ websocket _ extensions , ext . get parameterized name ( ) ) ; } }
mock remote provider . throw on next get ( new index out of bounds exception ( b ) ) ; mock foo . next to throw = new index out of bounds exception ( b ) ; try { remote provider . get ( ) ; fail ( ) ; } catch ( runtime exception e ) { assert equals ( b , e . get cause ( ) . get message ( ) ) ; } }
vc . find plan ( shotgun - quarterly , new date time ( 2011 - 03 - 03 t00 : 01 : 00 + 00 : 00 ) ) ;
this . props . put ( java process job . java _ class , azkaban . executor . sleep java job ) ;
if ( string utils . is empty ( api key ) ) { add encoded parameter ( data , message _ key _ api _ key , api key ) ; } else { logger . error ( private or alias key not specified . ) ; return false ; }
file system item default dir = export plot utils . get default save directory ( workbench context _ . get current working dir ( ) ) ;
final arrow scroll focus result focus result = m items can focus ? arrow scroll focused ( direction ) : null ; if ( focus result = null ) { next selected position = focus result . get selected position ( ) ; amount to scroll = focus result . get amount to scroll ( ) ; } boolean need to redraw = focus result = null ;
module script = module script provider . get module script ( cx , main module id , null , paths ) ;
frame layout . layout params params = new frame layout . layout params ( sub action items . get ( i ) . width , sub action items . get ( i ) . height , gravity . top | gravity . left ) ;
if ( tmp ) { builder . commit ( ) ; }
case unmanaged _ realmlist : assert equals ( test _ size , collection . size ( ) ) ; break ; default : fail ( ) ; } }
sync status info status = m sync status . get ( authority . ident ) ; boolean changed = false ; iterator < pair < bundle , long > > iterator = authority . periodic syncs . iterator ( ) ; int i = 0 ; while ( iterator . has next ( ) ) { pair < bundle , long > sync info = iterator . next ( ) ; if ( equals ( sync info . first , extras ) ) { iterator . remove ( ) ; changed = true ;
packet header header = new packet header ( packet len , offset , seqno , ( data len = = 0 ) , data len , false ) ; int size = header . get serialized size ( ) ; pkt . position ( packet header . pkt _ max _ header _ len - size ) ; header . put in buffer ( pkt ) ; return size ; }
if ( m _ left node instanceof branch node ) { ( ( branch node ) m _ left node ) . to left join ( ) ; }
( byte ) 0x64 , ( byte ) 0x85 , ( byte ) 0x fd , ( byte ) 0x0 a , ( byte ) 0x13 , ( byte ) 0x71 , ( byte ) 0x00 , ( byte ) 0x a0 , ( byte ) 0x fd , ( byte ) 0x09 , ( byte ) 0x15 , ( byte ) 0x09 , ( byte ) 0x0 a , ( byte ) 0x04 , ( byte ) 0x fb , ( byte ) 0x09 , ( byte ) 0x00 , ( byte ) 0x00 , ( byte ) 0x9 b , ( byte ) 0x a8 , ( byte ) 0x2 d , ( byte ) 0x00 , ( byte ) 0x00 , ( byte ) 0x00 , ( byte ) 0x04 , ( byte ) 0x97 } ; final byte [ ] testdata73a = new byte [ ] {
visit empty statement ( ( empty statement ) finally statement ) ;
- a ( = [ 50 : 100 100 : 200 20 : 40 50 : 100 ] , x = [ 50 : 100 100 : 200 80 : 160 50 : 100 ] ) ; + a - b ( = [ 50 : 100 100 : 200 80 : 160 50 : 100 ] , x = [ 50 : 100 100 : 200 20 : 40 50 : 100 ] ) ; b string apps config =
assert . assert null ( slow query report . get pool stats ( pool . get name ( ) ) ) ;
session . expire ( ) ;
if ( - - eventcounter < = 0 ) { co _ yield ( true ) ; eventcounter = frequency ; } if ( client content handler = null ) client content handler . start document ( ) ; }
environment env = db . get environment ( ) ; db binding . close db ( env ) ; seq db . close ( ) ; db . close ( ) ; env . close ( ) ; }
buf . put ( request code ) ; buf . put ( ( byte ) 1 ) ; hardware type : ethernet buf . put ( ( byte ) m client mac . length ) ; hardware address length buf . put ( ( byte ) 0 ) ; hop count buf . put int ( m trans id ) ; transaction id buf . put short ( ( short ) 0 ) ; elapsed seconds if ( broadcast ) { buf . put short ( ( short ) 0x8000 ) ; flags } else { buf . put short ( ( short ) 0x0000 ) ; flags }
if ( ( modifiers & input event . alt _ mask ) = 0 ) return null ;
array list < abstract config node > new object nodes = new array list < abstract config node > ( ) ; new object nodes . add ( new config node single token ( tokens . open _ curly ) ) ; if ( indentation . is empty ( ) ) { new object nodes . add ( new config node single token ( tokens . new line ( null ) ) ) ; } new object nodes . add all ( indentation ) ; new object nodes . add ( new config node single token ( tokens . close _ curly ) ) ; config node object new object = new config node object ( new object nodes ) ; new nodes . add ( new object . add value on path ( desired path . sub path ( 1 ) , indented value , flavor ) ) ; }
collection . create index ( indexes . ascending ( i ) , new single result callback < string > ( ) { @ override public void on result ( final string result , final throwable t ) { system . out . println ( operation finished ) ; } } ) ;
path p = fs . get path ( scratch root ) . get relative ( short path ) ;
assert . assert false ( scheduler . on schedule ( pplan ) ) ; set < packing plan . container plan > containers = new hash set < > ( ) ; containers . add ( mockito . mock ( packing plan . container plan . class ) ) ; packing plan valid plan = new packing plan ( packing _ plan _ id , containers ) ;
socket wrapper . set read timeout ( protocol . get connection timeout ( ) ) ;
return new object [ ] { utf - 16 be , new boolean ( true ) } ;
set layout ( new border layout ( 0 , 5 ) ) ;
for ( int i = 0 ; i < delete threads ; i + + ) { assert not in log ( content , azure blob delete thread - + thread . current thread ( ) . get name ( ) + - + i ) ; } }
local hbase cluster cluster = new local hbase cluster ( conf , 1 , 1 , local hmaster . class , hregion server . class ) ;
background = views . find ( this , r . id . transition _ full _ background ) ; animator . add position update listener ( new view position animator . position update listener ( ) { @ override public void on position update ( float position , boolean is leaving ) { background . set visibility ( position = = 0f ? view . invisible : view . visible ) ; background . get background ( ) . set alpha ( ( int ) ( 255 * position ) ) ; } } ) ; }
mapped byte buffer = new mmap buffer ( file , start offset , num records * ( long ) total size in bytes , mmap mode . read _ write ) ; final int [ ] sorted doc ids = get sorted doc ids ( mapped byte buffer , total size in bytes , dimension size in bytes , num records ) ;
stop server ( server list ) ; }
if ( encountered . contains ( node ) ) {
orecord serializer network v37 serializer = orecord serializer network v37 . instance ;
assert equals ( zip entry data ( zip one , entry one ) , zip entry data ( zip two , entry two ) ) ;
new conf . set int ( common configuration keys public . ipc _ client _ connection _ maxidletime _ key , timeouts [ 1 ] ) ;
new arg map . put ( this _ marker , ir . name ( new name ) . srcref tree ( new value ) ) ;
int ns = needs normalization ( ps ) ; number of segments
final t next value = next node . get and null value ( ) ;
throw tce ;
assert that ( e . get cause ( ) ) . is not null ( ) ; assert that ( e . get cause ( ) ) . is instance of any ( connect timeout exception . class , no route to host exception . class ) ; return assert that ( time unit . milliseconds . convert ( end time - start time , time unit . nanoseconds ) ) ; }
applications applications = get applications ( ) ; if ( client config . should disable delta ( ) | | ( strings . is null or empty ( client config . get registry refresh single vip address ( ) ) ) | | force full registry fetch | | ( applications = = null ) | | ( applications . get registered applications ( ) . size ( ) = = 0 ) | | ( applications . get version ( ) = = - 1 ) ) client application does not have latest library supporting delta { logger . info ( disable delta property : { } , client config . should disable delta ( ) ) ; logger . info ( single vip registry refresh property : { } , client config . get registry refresh single vip address ( ) ) ; logger . info ( force full registry fetch : { } , force full registry fetch ) ; logger . info ( application is null : { } , ( applications = = null ) ) ; logger . info ( registered applications size is zero : { } , ( applications . get registered applications ( ) . size ( ) = = 0 ) ) ; logger . info ( application version is - 1 : { } , ( applications . get version ( ) = = - 1 ) ) ; get and store full registry ( ) ; } else { get and update delta ( applications ) ; } applications . set apps hash code ( applications . get reconcile hash code ( ) ) ;
among _ var = find _ among _ b ( a _ 7 , 14 ) ;
client channel = new2 relay conn insp . get channel ( ) ; relay addr = ( inet socket address ) client channel . get remote address ( ) ; client addr = client channel . get local address ( ) ; relay port = relay addr . get port ( ) ; log . info ( third relay selected : + relay port ) ; relay = null ;
reducer . end group ( ) ;
assert equals ( no status message events . , 1 , status event collector . collected stat msg events . size ( ) ) ;
instructions . add ( reil helpers . create and ( base offset + + , operand size . qword , logical tmp qword , operand size . dword , 8589934591 , operand size . qword , logical tmp ) ) ;
logger . error ( data + can ' t be bucketed because index is not in range [ 0 , n buckets ) . ) ; return ;
return up data = = null | | parse from ( up data ) . get balancer on ( ) ;
scanner . set scan class path ( false ) ;
f = x . get class ( ) . get declared field ( int sfield ) ;
assert equals ( hello world , out . get in ( ) . get body ( ) ) ; assert equals ( null , out . get out ( ) . get body ( ) ) ; assert mock endpoints satisfied ( ) ;
byte [ ] output = new byte [ 100 ] ;
array list < invariant device profile > points by nearness = points ; collections . sort ( points by nearness , new comparator < invariant device profile > ( ) { @ override public int compare ( invariant device profile a , invariant device profile b ) { return float . compare ( dist ( width , height , a . min width dps , a . min height dps ) , dist ( width , height , b . min width dps , b . min height dps ) ) ; } } ) ; return points by nearness ;
execution context context = new execution context ( true ) ; request < ? > tested repeatable request = get sample request with repeatable content ( original request ) ;
if ( segment index < segments . size ( ) ) { final path segment segment = segments . get ( segment index + + ) ; final double segment path center distance = segment . path center distance ( planet model , distance style , x , y , z ) ; if ( segment path center distance < min path center distance ) { min path center distance = segment path center distance ; best distance = distance style . aggregate distances ( current distance , segment . nearest path distance ( planet model , distance style , x , y , z ) ) ; } current distance = distance style . aggregate distances ( current distance , segment . full path distance ( distance style ) ) ; } }
m migration test helper . run migrations and validate ( test _ db _ name , 4 , true , migration _ 1 _ 2 , migration _ 2 _ 3 , migration _ 3 _ 4 ) ;
server . add to online regions ( regions . get second ( ) ) ;
string tag name = tag name ( ) . replace ( ' : ' , ' | ' ) ; string builder selector = new string builder ( tag name ) ; string classes = string util . join ( class names ( ) , . ) ; if ( classes . length ( ) > 0 ) selector . append ( ' . ' ) . append ( classes ) ; if ( parent ( ) = = null | | parent ( ) instanceof document ) don ' t add document to selector , as will always have a html node return selector . to string ( ) ; selector . insert ( 0 , > ) ;
ri = ( ri * cfi ) > > 15 ;
chunk first chunk = source . next chunk ( ) ;
json generator . write object field ( name to apps , name to apps ) ;
t = tf . construct type ( java . util . array list . class ) ; can = t . to canonical ( ) ; assert equals ( java . util . array list < java . lang . object > , can ) ; assert equals ( t , tf . construct from canonical ( can ) ) ; t = tf . construct type ( java . util . tree map . class ) ; can = t . to canonical ( ) ;
assert true ( hdfs utils . is healthy ( uri ) ) ; dfs . set safe mode ( safe mode action . safemode _ enter ) ; assert false ( hdfs utils . is healthy ( uri ) ) ;
mv . visit label ( ifnull ) ;
message . add ( encode beep interval ( channel . get datapoint ( hm paramset type . values , datapoint _ name _ display _ beepinterval ) ) ) ;
key test . set certificate entry ( alias3 , cert [ 0 ] ) ;
int prefix id = buf . get int ( 16 ) ; string prefix = prefix id = = - 1 ? : strings . get string ( prefix id ) ; int uri id = buf . get int ( 20 ) ; string uri = strings . get string ( uri id ) ; out . format ( % s n : % s = % s \ n , strings . pad end ( , indent * 2 , ' ' ) , prefix , uri ) ; indent + + ; ns map . put ( uri , prefix ) ; break ;
assert true ( client . is response400 ( ) ) ;
for ( int i = 0 ; i < num _ lists ; i + + ) { table . insert or replace record ( overwrite lists [ i ] ) ; } for ( int i = 0 ; i < num _ lists ; i + + ) { assert not null ( + i , prober . get match for ( overwrite lists [ i ] , target ) ) ; assert array equals ( overwrite lists [ i ] . get value ( ) , target . get value ( ) ) ; }
{ final string json = apos to quotes ( { ' values ' : [ 1 , null , 2 ] } ) ; null content skip < list < integer > > result = mapper . read value ( json , new type reference < null content skip < list < integer > > > ( ) { } ) ; assert equals ( 2 , result . values . size ( ) ) ; assert equals ( integer . value of ( 1 ) , result . values . get ( 0 ) ) ; assert equals ( integer . value of ( 2 ) , result . values . get ( 1 ) ) ; }
string [ ] tabs = custom scan dialog . std _ tab _ labels ; if ( this . custom scan panels . size ( ) > 0 ) { list < string > tab list = new array list < string > ( ) ; for ( string str : custom scan dialog . std _ tab _ labels ) { tab list . add ( str ) ; } for ( custom scan panel csp : custom scan panels ) { tab list . add ( csp . get label ( ) ) ; } tabs = tab list . to array ( new string [ tab list . size ( ) ] ) ; } custom scan dialog = new custom scan dialog ( this , tabs , this . custom scan panels , view . get singleton ( ) . get main frame ( ) , new dimension ( 700 , 500 ) ) ;
curator = zk ( ) . curator with super auth ( ) ; final zoo keeper client provider zkcp = new zoo keeper client provider ( new default zoo keeper client ( curator ) , zoo keeper model reporter . noop ( ) ) ; final list < event sender > event senders = collections . empty list ( ) ;
final long old id = dictionary name to id . get ( name ) ; if ( old id = null ) custom property . set id ( old id . long value ( ) ) ; else { long max = 1 ; for ( final iterator < long > i = dictionary idto name . key set ( ) . iterator ( ) ; i . has next ( ) ; ) { final long id = i . next ( ) . long value ( ) ; if ( id > max ) max = id ; } custom property . set id ( max + 1 ) ; } return this . put ( name , custom property ) ;
try { actual = vt . get long ( i ) ; } catch ( illegal argument exception ex ) { try { actual = ( long ) vt . get double ( i ) ; } catch ( illegal argument exception new ex ) { try { actual = vt . get timestamp as long ( i ) ; } catch ( illegal argument exception ex tm ) { try { actual = vt . get decimal as big decimal ( i ) . long value exact ( ) ; } catch ( illegal argument exception newer ex ) { newer ex . print stack trace ( ) ; fail ( message ) ; } } catch ( arithmetic exception newest ex ) { newest ex . print stack trace ( ) ; fail ( message ) ; } } }
if ( m _ parsed select . m _ join tree instanceof branch node ) { if ( m _ parsed select . has join order ( ) ) { simplify outer join ( ( branch node ) m _ parsed select . m _ join tree ) ; }
if ( underlying . length = other . underlying . length ) { throw new unsupported operation exception ( cannot merge rocbinary : this expects + underlying . length + outputs , other expects + other . underlying . length + outputs ) ; }
table tab obj = ( table ) cur class . get annotation ( table . class ) ; if ( tab obj = = null ) { s _ logger . info ( \ n + cur class + does not have a table annotation \ n ) ; return null ; }
datanode info dn0 = lbs [ 0 ] . get locations ( ) [ 0 ] ;
user1 . set service account client link ( client . get id ( ) ) ; commit ( ) ;
assert equals ( 0x19 ( public static final ) r sfields lorg springsource loaded ssmgr ; , to string field ( itype . bytes loaded , r sfields ) ) ;
final struct value = require struct ( operating value ( record ) , purpose ) ; final struct updated value = new struct ( updated schema ) ;
deps . add all ( cxx preprocessor input . get deps ( resolver , rule finder ) ) ;
assert . assert true ( run pruner ( select count ( * ) from table where time = 0 ) ) ;
schema cache . disable automatic configuration ( ) ; }
final byte [ ] bytes = string2 bytes ( path ) ;
variable declaration fragment variable declaration fragment = ast . new variable declaration fragment ( ) ; string [ ] var names = stub utility . get variable name suggestions ( naming conventions . vk _ local , context . get compilation unit ( ) . get java project ( ) , expression type , switch expression , null ) ; var name = ast . new simple name ( var names [ 0 ] ) ; variable declaration fragment . set name ( ( simple name ) var name ) ; variable declaration fragment . set structural property ( variable declaration fragment . initializer _ property , rewrite . create copy target ( switch expression ) ) ; variable declaration statement = ast . new variable declaration statement ( variable declaration fragment ) ;
assert equals ( success _ mock _ login _ servlet , writer . to string ( ) ) ;
if ( m icons cache . contains key ( record number ) ) { m current icon = m icons cache . get ( record number ) ; post icon ( ) ; return ; }
if ( this . is active ( ) ) { return ; } int sleep multiplier = 1 ;
create current value gauge ( execution semaphore permits in use , current concurrent execution count thunk ) ;
assert . assert equals ( - 1 , input . read ( ) ) ; }
if ( r _ lengthen _ v ( ) ) { break lab2 ; } break lab1 ; } while ( false ) ; cursor = limit - v _ 2 ; lab3 : do {
hash map properties = new hash map ( ) ;
m tab cache . value at ( i ) . set content size ( viewport dp . width ( ) , viewport dp . height ( ) ) ;
set content type ( new org . docx4j . openpackaging . contenttype . content type ( org . docx4j . openpackaging . contenttype . content types . spreadsheetml _ printer _ settings ) ) ;
if ( cur user . is alive ( ) ) { dungeon . fail ( utils . format ( result descriptions . wand , name , dungeon . depth ) ) ; glog . n ( you killed yourself with your own wand of lightning . . . ) ; }
if ( end view = null ) { shape end shape ; if ( end view = = v1 ) { end shape = v1 . model to view ( v1 . get start offset ( ) , position . bias . forward , p1 , b1 , r1 ) ; } else { end shape = v0 . model to view ( p0 , b0 , v0 . get end offset ( ) , position . bias . backward , r0 ) ; } if ( end shape instanceof rectangle ) { ret rect . add ( ( rectangle ) end shape ) ; } else { ret rect . add ( end shape . get bounds ( ) ) ; } } return ret rect ;
assert . assert equals ( 200 , response . get status ( ) ) ;
ugi = user group information . create proxy user ( do as user from query , ugi ) ;
this . draw context . begin drawing ( world ) ;
try { noinspection empty try block try ( result ignore = this . graph . execute ( cypher _ warmup _ query ) ) { empty by design } } catch ( exception ignore ) { this is only an attempt at warming up the database . it ' s not a critical failure . }
speed = float . parse float ( user preferences . get playback speed ( ) ) ;
kv state serializer . deserialize key and namespace ( new byte [ ] { 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 42 , 0 , 2 } , long serializer . instance , string serializer . instance ) ; }
final table element item holder = elements . create table element ( ) ;
nd4j . get random ( ) . set seed ( 12345 ) ; computation graph net = new computation graph ( conf ) ; net . init ( ) ; assert true ( net . get layer ( 1 ) instanceof custom output layer impl ) ;
if ( publish permissions & & read permissions ) { break ; }
tabs . set tabs from pager adapter ( adapter ) ; tabs . set tab gravity ( tab layout . gravity _ fill ) ; tabs . set tab mode ( tab layout . mode _ scrollable ) ; if ( saved instance state = = null ) { tabs . get tab at ( 0 ) . select ( ) ; } pager . add on page change listener ( new view pager . simple on page change listener ( ) { @ override public void on page selected ( int position ) { super . on page selected ( position ) ; select tab ( position , true ) ; } } ) ; tabs . add on tab selected listener ( new tab layout . on tab selected listener ( ) { @ override public void on tab selected ( tab layout . tab tab ) { if ( tab . get tag ( ) = = null ) { int position = tab . get position ( ) ; select tab ( position , false ) ; } tab . set tag ( null ) ; } @ override public void on tab unselected ( tab layout . tab tab ) { } @ override public void on tab reselected ( tab layout . tab tab ) { select tab ( tab . get position ( ) , false ) ; } } ) ; if ( saved instance state = null & & counts . is empty ( ) ) { stream . of ( counts ) . for each ( this : : update count ) ; }
assert q ( req ( id : 42 and subword : \ sony kdf - e50 a10 \ ) , * [ count ( doc ) = 1 ] ) ;
m tag . get tag service ( ) . reset timeouts ( ) ; m tag . get tag service ( ) . reconnect ( m tag . get service handle ( ) ) ; } catch ( remote exception e ) {
for ( final kafka stream stream : done streams ) { system . out . println ( creating consumer for + done topic ) ; export consumer consumer = new export consumer ( stream , true , true , done latch ) ; future < long > f = ecs . submit ( consumer , new long ( 0 ) ) ; done futures . add ( f ) ; } system . out . println ( all consumer creation done . . . waiting for eos ) ;
req . with item ( attributes ) . with expected ( expected map ) . with expression attribute names ( spec . get name map ( ) ) . with expression attribute values ( attr val map ) ;
check state ( externs . is root ( ) ) ;
if ( token . index of ( _ _ _ yuicssmin _ preserve _ candidate _ comment _ ) > = 0 ) { for ( i = 0 , max = comments . size ( ) ; i < max ; i + = 1 ) { token = token . replace ( _ _ _ yuicssmin _ preserve _ candidate _ comment _ + i + _ _ _ , comments . get ( i ) . to string ( ) ) ; } }
for ( int x = 0 ; x < 30 ; x + + ) { new thread ( ( ) - > rest api mocked . handle ( null ) ) . start ( ) ; }
lpc . autocorr ( array utils . sub array ( old _ speech _ array , p _ window ) , ld8 kconstants . m , r ) ; * autocorrelations * lpc . lag _ window ( ld8 kconstants . m , r ) ; * lag windowing * float [ ] tmp = array utils . sub array ( a _ t , ld8 kconstants . mp1 ) ;
send ( http : 127 . 0 . 0 . 1 : 8192 service secure proxy , 1000 ) ; stop watch watch = new stop watch ( ) ; send ( http : 127 . 0 . 0 . 1 : 8192 service secure proxy , count ) ; log . warn ( ran { } tests in { } ms , count , watch . taken ( ) ) ; }
bind address = tmp bind address ; return server socket channel ;
int length = ( ratio < = 1 ? target width : target height ) ;
test ( function foo ( ) { x = 3 ; if ( x = = 4 ) { x = 5 ; return ; x = 6 } else { x = 7 } return 5 ; x = 3 } , function foo ( ) { x = 3 ; if ( x = = 4 ) { x = 5 ; return } else { x = 7 } return 5 } ) ;
seek ( duration ( ) + new pos ) ; } else if ( new pos > = duration ) { goto next ( true ) ;
set buttons ( ) ;
share intent util . set intent return code ( result intent , share constants . error _ load _ patch _ directory _ not _ exist ) ; return ; }
index = cpg . add methodref ( dom _ adapter _ class , < init > , ( + dom _ intf _ sig + [ + string _ sig + [ + string _ sig + [ i + [ + string _ sig + ) v ) ;
query environment env = new query environment ( ) ;
boolean animate = drag view = null ; if ( animate ) {
for ( super column thrift super column : thrift super columns ) { for ( column column : thrift super column . get columns ( ) ) { byte [ ] column name = column . get name ( ) ; search result . set primary key ( property accessor helper . get object ( m . get id attribute ( ) . get java type ( ) , column name ) ) ; byte [ ] column value = column . get value ( ) ; string ec value = utf8 type . instance . compose ( byte buffer . wrap ( column value ) ) ; if ( ec value = null & & . equals ( ec value . trim ( ) ) ) { search result . set embedded column name ( row key . substring ( 0 , row key . index of ( constants . index _ table _ row _ key _ delimiter ) ) ) ; search result . add embedded column value ( ec value ) ; } } if ( search results . is empty ( ) ) { search results . add ( search result ) ; } else { search result existing = search results . get ( 0 ) ; if ( existing . get primary key ( ) = null & & existing . get primary key ( ) . equals ( search result . get primary key ( ) ) ) { search results . add ( search result ) ; } else { search results . remove ( 0 ) ; } } }
return { stats = st + stat tag + } + pivot value ;
find view by id ( r . id . nothing _ to _ show _ placeholder ) . set visibility ( folders . size ( ) < 1 & & is excluded mode ( ) & & hawk . get ( emoji _ easter _ egg , 0 ) = = 0 ? view . visible : view . gone ) ; find view by id ( r . id . ll _ emoji _ easter _ egg ) . set visibility ( folders . size ( ) < 1 & & is excluded mode ( ) & & hawk . get ( emoji _ easter _ egg , 0 ) = = 1 ? view . visible : view . gone ) ; }
raw query . builder ( ) . query ( some query ) . observes tags ( ) . build ( ) ; }
test proc with valid json ( ( string ) null , client , select field proc , null , 5 ) ;
postings enum docs and positions enum2 = terms enum . postings ( docs and positions enum , postings enum . positions ) ;
list variant . add ( new variant ddn path ( ) ) ;
block b = get block on storage ( block , storage ) ;
instance registry . register ( instance info , false ) ;
final string topic configured name = configuration . get property ( topic configuration . topic _ name _ key ) ; if ( topic = = null | | topic name . equals ( topic configured name ) ) { topic name = topic configured name ; topic = new org . apache . activemq . command . active mqtopic ( configuration . get property ( topic configuration . topic _ name _ key ) ) ; } return topic ;
file target file = new file ( container dir , sym link ) ; file sys dir = new file ( local dir , resource localization service . nm _ private _ dir ) ;
if ( len > integer . max _ value ) { omg sanity check do not want won ' t anyone think of the memory throw new message too large exception ( [ int - sane ] cannot handle payload lengths larger than + integer . max _ value ) ; }
final list < string > children = new array list < > ( 2 ) ;
if ( limited & & ip [ 0 ] = = target . length ( ) ) break ;
long new gs = b . get generation stamp ( ) + 1 ; b . set generation stamp ( new gs ) ; b . set num bytes ( b . get num bytes ( ) + 10 ) ; block info new block = new block info ( b , i node . get replication ( ) ) ; log . info ( updating block : + old block + to : + new block ) ;
while ( width index < wrap index ) first . width + = first . x advances . get ( width index + + ) ;
int fraction digits = 6 ;
for ( int i = 0 ; i < 50 ; i + + ) { m _ pbd . offer ( default container ( ) ) ; count + + ; assert equals ( count , reader1 . get num objects ( ) ) ; assert equals ( count , reader2 . get num objects ( ) ) ; assert equals ( count + to add for late , late reader . get num objects ( ) ) ; } for ( int i = 0 ; i < 50 ; i + + ) { poll discard ( reader1 ) ; assert equals ( count - 1 , reader1 . get num objects ( ) ) ; assert equals ( count , reader2 . get num objects ( ) ) ; assert equals ( count + to add for late , late reader . get num objects ( ) ) ; poll discard ( reader2 ) ; assert equals ( count - 1 , reader1 . get num objects ( ) ) ; assert equals ( count - 1 , reader2 . get num objects ( ) ) ; assert equals ( count + to add for late , late reader . get num objects ( ) ) ; poll discard ( late reader ) ; count - - ; assert equals ( count , reader1 . get num objects ( ) ) ; assert equals ( count , reader2 . get num objects ( ) ) ; assert equals ( count + to add for late , late reader . get num objects ( ) ) ; } assert ( count = = 0 ) ;
builder . transaction ( ) . transaction manager lookup ( transaction managerlookup ) ;
public void visit non move insn ( normal ssa insn insn ) { process insn ( insn ) ; }
execution = runtime service . create execution query ( ) . variable value not equals ( short var , ( short ) 1234 ) . single result ( ) ;
user dto admin2 = db . users ( ) . insert user ( ) ; db . users ( ) . insert member ( admin group , admin2 ) ;
m first frame helper . on animation start ( animation ) ; for ( int i = 0 ; i < m listeners . size ( ) ; i + + ) { animator . animator listener listener = m listeners . get ( i ) ; listener . on animation start ( this ) ; }
class < ? > type = get property type0 ( ) ; if ( type = = null ) { try {
return new publish multiple page ( publish , publish , null , input ) ;
revoke from table ( test _ util , testgroup _ 1 _ name , table name , null , null ) ;
if ( null = get schema by name version ( name , version ) ) return false ; schema is already there schema avro schema = schema . parse ( schema str ) ; string orig schema str = null ; if ( keep orig str ) { orig schema str = schema str ; } versioned schema schema = new versioned schema ( name , version , avro schema , orig schema str ) ; if ( id = = null ) { add schema internal ( schema , schema id . create with md5 ( schema . get schema ( ) ) ) ; } else { add schema internal ( schema , id ) ; } return true ;
final int one too big = rsa _ 2048 _ modulus . bit length ( ) - 10 ; for ( int i = 0 ; i < one too big ; i + + ) { sig . update ( ( byte ) i ) ; } try { sig . sign ( ) ; fail ( should throw exception when data is too large ) ; } catch ( signature exception expected ) { }
for ( long duration : new long [ ] { 22 , 99 , 33 , 0 } ) { rc . add request ( duration * ns _ per _ ms ) ; }
final camel context context = new default camel context ( ) ;
string task id str = this . task id ; protos . task id mesos task id = protos . task id . new builder ( ) . set value ( task id str ) . build ( ) ;
if ( text utils . is empty ( m hint ) ) { set hint ( m edit text . get hint ( ) ) ; }
string builder builder = new string builder ( fields . get size ( ) * 32 ) ; for ( fields . field field : fields ) { for ( string value : field . get values ( ) ) { if ( builder . length ( ) > 0 ) builder . append ( & ) ; builder . append ( encode ( field . get name ( ) , charset ) ) . append ( = ) . append ( encode ( value , charset ) ) ; } } return builder . to string ( ) ;
job conf conf2 = new job conf ( conf ) ; conf2 . set ( job context . task _ attempt _ id , attempt ) ; conf2 . set int ( mrconstants . application _ attempt _ id , 2 ) ; conf2 . set int ( org . apache . hadoop . mapreduce . lib . output . file output committer . fileoutputcommitter _ algorithm _ version , recovery version ) ; job context j context2 = new job context impl ( conf2 , task id . get job id ( ) ) ; task attempt context t context2 = new task attempt context impl ( conf2 , task id ) ; file output committer committer2 = new file output committer ( ) ; committer2 . setup job ( j context2 ) ; committer2 . recover task ( t context2 ) ;
final list < string > suggestions = uid . suggest ( nomatch ) ; assert equals ( 0 , suggestions . size ( ) ) ; no results . verify ( fake _ scanner ) . set start key ( nomatch . get bytes ( ) ) ;
return embedded object ;
int no list hash code = no list message . hash code ( ) ; int empty list hash code = empty list message . hash code ( ) ; assert that ( no list hash code ) . is equal to ( empty list hash code ) ; proto adapter < simple message > adapter = simple message . adapter ;
node u = q . remove first ( ) ; component . add ( u ) ; color [ indices . get ( u ) ] = 2 ;
if ( m _ field instances structure . class index ( ) > = 0 & & m _ field instances structure . class attribute ( ) . is string ( ) ) { array list < string > target vals = m _ target meta info . get values ( ) ; if ( target vals . size ( ) > 0 ) { attribute class att = m _ field instances structure . class attribute ( ) ; for ( int i = 0 ; i < target vals . size ( ) ; i + + ) { class att . add string value ( target vals . get ( i ) ) ; } } }
set properties ( endpoint , parameters ) ;
if ( transcode class . is assignable from ( resource class ) ) { transcode classes . add ( transcode class ) ; return transcode classes ; } for ( entry < ? , ? > entry : transcoders ) { if ( entry . handles ( resource class , transcode class ) ) { transcode classes . add ( transcode class ) ; } }
all initializing shards . add ( shard . get target relocating shard ( ) ) ;
for ( integer task : raw dead tasks ) { if ( unstopped tasks . contains ( task ) ) { continue ; } for ( resource worker slot worker : old workers ) { if ( worker . get tasks ( ) . contains ( task ) ) { refine dead tasks . add all ( worker . get tasks ( ) ) ; } } }
for ( int m = 0 ; m < first row ; m + + ) { rs . next ( ) ; }
generate configuration ( interface type , domain type ) ;
assert response ( new request ( http : localhost : 8080 nodes v2 node host6 . yahoo . com , utf8 . to bytes ( { \ hardware divergence \ : \ \ } ) , request . method . patch ) , 400 , { \ error - code \ : \ bad _ request \ , \ message \ : \ could not set field ' hardware divergence ' : hardware divergence must be non - empty , but was ' ' \ } ) ;
assert that ( servlet gets right path , response body , contains string ( do get : get servlet path : test2 ) ) ;
statistics handler . update caller ( span . get acceptor host ( ) , span service type , span . get remote addr ( ) , span . get application id ( ) , application service type , span . get end point ( ) , span . get elapsed ( ) , is error ) ; statistics handler . update callee ( span . get application id ( ) , application service type , span . get acceptor host ( ) , span service type , span . get agent id ( ) , span . get elapsed ( ) , is error ) ;
out . write utf8 ( already encoded ? + : % 2 b ) ; } else if ( code point < 0x20 | | code point = = 0x7f | | code point > = 0x80 & & ascii only | | encode set . index of ( code point ) = - 1 | | code point = = ' % ' & & ( already encoded | | strict & & percent encoded ( input , i , limit ) ) ) {
update response = client ( ) . prepare update ( test , type1 , parent id1 ) . set script ( new script ( script type . inline , update _ scripts , extract _ ctx _ script , collections . empty map ( ) ) ) . execute ( ) . action get ( ) ; assert equals ( 2 , update response . get version ( ) ) ;
channel . write inbound ( unpooled . wrapped buffer ( content , content . length - i , 1 ) ) ; }
if ( element . is annotation present ( encoded . class ) ) { return true ; }
else { throw new illegal state exception ( cannot omit key ( ) clause on a non - updatable table ) ; } }
if ( type = = request | | type = = piece | | type = = cancel ) datalen + = 4 ;
ddbms . list children ( new path ( s3 uri ) ) ;
builder . put ( thread _ pool . search . min _ queue _ size , 100 ) ;
if ( arrow icon = null ) { if ( model . is armed ( ) | | ( c instanceof jmenu & & model . is selected ( ) ) ) g . set color ( foreground ) ; if ( ( b . get parent ( ) instanceof jmenu bar ) ) arrow icon . paint icon ( c , g , arrow rect . x , arrow rect . y ) ; } g . set color ( holdc ) ; g . set font ( holdf ) ; }
string sql = get sql ( action ) ;
check model ( json . mapper ( ) . read value ( json . pretty ( model ) , model . class ) ) ; }
assert . fail ( contents were not equal and in the same order : + expected = + expected + , actual = + actual ) ;
check assignment ( tt2 , attempt _ test _ 0001 _ m _ 000004 _ 0 on tt2 ) ;
cluster . shutdown ( first master ) ; db factory . trigger finish ( a slave ) ;
list < method interceptors pair > method interceptors pairs = lists . new array list ( ) ;
m _ entries = new hashtable ( ( int ) ( m _ dt instances . num instances ( ) * 1 . 5 ) ) ;
full access bean . do anything ( ) ;
discovery nodes discovery nodes = discovery nodes . builder ( node a . nodes ( ) ) . add ( node b . discovery node ) . build ( ) ; cluster state previous cluster state = cluster state . builder ( cluster _ name ) . nodes ( discovery nodes ) . build ( ) ; cluster state cluster state = cluster state . builder ( previous cluster state ) . increment version ( ) . build ( ) ; publish state and wait ( node a . action , cluster state , previous cluster state ) ; assert same state from full ( node b . cluster state , cluster state ) ;
file link dir = new file ( del , tmp dir ) ;
boolean do all skipping = options . contains ( option . skipping ) & & random . next int ( 7 ) = = 1 ; double freq ask chance = always test max ? 1 . 0 : random . next double ( ) ;
final head stream < e > top = this . heap . peek ( ) ;
network executor = new single thread executor ( ) ;
try { sms tracker s tracker = m strackers . remove ( m strackers . size ( ) - 1 ) ; s tracker . m sent intent . send ( result _ error _ limit _ exceeded ) ; } catch ( canceled exception ex ) { log . e ( tag , failed to send back result _ error _ limit _ exceeded ) ; }
return rx changes observer . observe changes ( content resolver , uris , content observer handler , build . version . sdk _ int ) ;
final subscription subscription json = create entitlement ( account json . get account id ( ) , uuid . random uuid ( ) . to string ( ) , shotgun , product category . base , billing period . monthly , true ) ; assert not null ( subscription json ) ; clock . add days ( 32 ) ; crappy wait for lack of proper synchonization ( ) ; return account json ; }
if ( final screen . get shortcuts and widgets ( ) . get child count ( ) = = 0 & & final screen . is drop pending ( ) ) { m workspace screens . remove ( final screen id ) ; m screen order . remove ( final screen id ) ; if this is the last non - custom content screen , convert it to the empty screen m workspace screens . put ( extra _ empty _ screen _ id , final screen ) ; m screen order . add ( extra _ empty _ screen _ id ) ; update the model if we have changed any screens m launcher . get model ( ) . update workspace screen order ( m launcher , m screen order ) ; }
_ filter chain . on response ( _ filter request context , response context , response attachments ) ; }
m native pointer = native ptr ;
int num samples = get context ( ) . get settings ( ) . get samples ( ) ; if ( num samples > 0 ) { fpp . set num samples ( num samples ) ; } dof filter = new depth of field filter ( ) ;
rest response rest response = new rest response builder ( ) . build ( ) ;
pipe fetcher thread = new pipe fetcher ( event queue ) ;
if ( bound classes . contains ( clazz ) ) { try {
try { target source . get target ( ) ; fail ( should throw no such element exception ) ; } catch ( no such element exception ex ) { desired }
consumer configuration consumer config = new consumer configuration ( ) ;
timestamp initializer = ( system . current time millis ( ) + ( + + delay ) ) * 1000 ; for ( ii = 0 ; ii < 3 ; + + ii ) { insert row ( client , contest , senior , timestamp initializer , boston , not jack + ii ) ; }
test data . build ogg header ( 0x00 , 16 , 1001 , 0x02 ) , test util . create byte array ( 0x ff , 0x11 ) , laces second packet ,
if ( position > last position ) { animation animation = animation utils . load animation ( m context , r . anim . abc _ slide _ in _ bottom ) ; view to animate . start animation ( animation ) ; last position = position ; }
assert environment value ( enigma , auto detected ) ;
element configure = doc . create element ns ( s _ ciscons , nxos : configure ) ;
read test data ( test _ data _ odd , 0 , c . length _ unset , 2 , 0 , 2 , false ) ;
assert equals ( status . client _ error _ not _ found , response . get status ( ) ) ; assert not null ( response . get entity ( ) . get text ( ) ) ; }
zk . create ( first path , new byte [ 0 ] , zoo defs . ids . open _ acl _ unsafe , create mode . persistent ) ;
try { client2 . call procedure ( @ system information , overview ) ; fail ( unallowed sys proc is executed . ) ; } catch ( proc call exception e ) { if execution reaches here , it indicates the expected exception was thrown . system . out . println ( @ system information : + e . get message ( ) ) ; assert true ( server is shutting down . . equals ( e . get message ( ) ) ) ; }
assert true ( all partitions . remove ( p ) ) ;
dout . write ( buffer , 0 , buf pos ) ; buf pos = 0 ; reset buffer
int size = lva . size ( ) ;
database . delete ( song play count columns . name , song play count columns . last _ updated _ week _ index + < + oldest week we care about , null ) ;
user session model offline session = session . sessions ( ) . get offline user session ( foo realm , user session . get id ( ) ) ; user session provider test . assert session ( offline session , user3 , 127 . 0 . 0 . 1 , started , started , foo - app ) ;
if ( ( idx new = match nodes ( next , max node , idx ) ) = - 1 ) { return idx new ; } } return - 1 ; case op _ reluctantstar : do {
result = _ owner . try invoke method ( name , params ) ; if ( result . is found ( ) ) { return result . get value ( ) ; } if ( failure = null ) { throw failure ; }
int throttle = ( int ) ( 75 * max _ concurrent _ builds avg ) ;
this . conf . set float ( hbase . hstore . compaction . ratio . offpeak , 5 . 0 f ) ;
map < topic partition , fetch info > fetches1 = new hash map < > ( ) ; fetches1 . put ( tp0 , new fetch info ( 0 , 1 ) ) ; fetches1 . put ( t2p0 , new fetch info ( 0 , 10 ) ) ; client . respond from ( fetch response ( fetches1 ) , node ) ; client . poll ( 0 , time . milliseconds ( ) ) ; consumer records < string , string > records = consumer . poll ( 0 ) ;
long min scn = processor . get bootstrap meta data dao ( ) . get min scn of snapshots ( src status pairs ) ;
test nodes [ 0 ] = data nodes [ 5 ] ; test nodes [ 1 ] = data nodes [ 3 ] ; test nodes [ 2 ] = data nodes [ 2 ] ; test nodes [ 3 ] = data nodes [ 0 ] ; cluster . sort by distance ( data nodes [ 0 ] , test nodes , test nodes . length ) ; assert true ( test nodes [ 0 ] = = data nodes [ 0 ] ) ; assert true ( test nodes [ 1 ] = = data nodes [ 2 ] ) ;
string result = foo ; request execution report execution report = new request execution report builder ( ) . build ( ) ; rest li response attachments response attachments = new rest li response attachments . builder ( ) . build ( ) ; rest li response data < get response envelope > app response data = response data builder util . build get response data ( http status . s _ 200 _ ok , null ) ;
hql token t = ( hql token ) lt ( 2 ) ;
return this . audits . offer ( consumer audit ) ; }
filter . add action ( music service . playstate _ changed ) ;
out . set body ( encoded signed data ) ;
assert equals ( user2 didn ' t receive the grant admin notification , i ' m an admin , answer [ 2 ] ) ;
pos = lp _ length ;
if ( mutations . size ( ) = = 1 ) return mutations . values ( ) . iterator ( ) . next ( ) . values ( ) ; list < imutation > ms = new array list < > ( ) ;
connector = new aioconnector ( ) ; for ( int i = 0 ; i < processors . length ; i + + ) { async channel groups [ i ] = asynchronous channel group . with fixed thread pool ( processor count , new thread factory ( ) { private int inx = 1 ; @ override public thread new thread ( runnable r ) { thread th = new thread ( r ) ;
stat node . add ( subsystem , resource - adapters ) ; stat node . add ( connection node . get ( 1 ) ) ; stat node . add ( connection - definitions , connection node . get ( 2 ) . get ( connection - definitions ) . as string ( ) ) ; stat node . add ( statistics , pool ) ; return stat node ; }
input stream is = null ; bitmap region decoder decoder = null ; try { is = new stream not null ( ) ; decoder = bitmap region decoder . new instance ( is , false ) ; } catch ( ioexception e ) { log . w ( tag , cannot open region decoder , e ) ; } finally { utils . close silently ( is ) ; is = null ; } bitmap crop = null ;
alert level characteristic . set value ( new byte [ ] { mi band2 service . alert _ level _ none } ) ; gatt . write characteristic ( alert level characteristic ) ; return false ;
throw new illegal argument exception ( sm . get string ( hex utils . from hex . odd digits ) ) ; }
ssl handler . set close on sslexception ( true ) ;
for ( node child = n . get first child ( ) ; child = null ; child = child . get next ( ) ) { if ( is literal value ( child , include functions ) ) { return false ; } } return true ; case objectlit :
em . get transaction ( ) . begin ( ) ; ste = em . find ( secondary mul id test entity . class , id ) ; ste . set s1 ( b ) ;
return verify diff ( cat original , cat updated , null , null , expect apply catalog diff to ee , false , true ) ; }
spel node impl [ ] arguments = new spel node impl [ children . length - 1 ] ;
shut down mini cluster ( ) ;
init _ actions ( ) ;
http client http client2 = new http client ( new http client transport over http ( 1 ) , null ) ;
buf . assign ( data . slice ( point index ) ) . subi ( center of mass ) ; double d = nd4j . get blas wrapper ( ) . dot ( buf , buf ) ;
try { rm . admin service . transition to active ( request info ) ; assert . fail ( transitioned to active should throw exception . ) ; } catch ( exception e ) { assert true ( error when transitioning to active mode . contains ( e . get message ( ) ) ) ; }
if ( n . get attribute value ( attr name ) = null ) { err . jsp error ( n , jsp . error . duplicate . name . jspattribute , attr name ) ; }
if ( _ log . should log ( log . error ) ) _ log . error ( non - last fragment + fragment num + when last is + _ last fragment + for message + _ message id + from + _ from ) ; return false ;
api versions request api versions request = new api versions request ( ( short ) 0 , header . api version ( ) ) ;
guards . add ( create depth guard ( length ) ) ; next : for ( int i = length - 1 ; i > = 0 ; i - - ) { object scope = scopes . get ( i ) ; if ( scope = = null ) continue ;
try { return to pgobject json ( to json string ( ( ( map ) arg ) ) ) ; } catch ( sqlexception | ioexception e ) { throw new runtime exception ( e ) ; }
sql session session = sql session factory . open session ( ) ; connection conn = session . get connection ( ) ; reader = resources . get resource as reader ( org apache ibatis submitted named _ constructor _ args create db . sql ) ; script runner runner = new script runner ( conn ) ; runner . set log writer ( null ) ; runner . run script ( reader ) ; conn . close ( ) ; reader . close ( ) ; session . close ( ) ; }
set < orid > edge rids = new hash set < orid > ( ) ;
assert equals ( arrays . as list ( new many to one eager component ( entity2 , data component2 ) ) , get audit reader ( ) . find ( embeddable list entity2 . class , ele _ id1 , 2 ) . get component list ( ) ) ;
all class audited = default _ audited ;
try { output strategy . flush ( req . get http response ( ) ) ; } catch ( ioexception e ) { throw new client stream aborted exception ( e ) ; }
atomic integer server idx = new atomic integer ( - 1 ) ;
arrays . fill ( res , content _ mac _ length - 1 , res . length , ( byte ) ( padding _ length ) ) ;
assert inverse ( quote ( int8 ) , ( byte ) 127 ) ;
if ( is trace enabled ) { log . trace ( connection failure - notify procedure : + proc . get name ( ) ) ; }
final mock relay connection relay conn1 = new mock relay connection ( sources response , register response , null , server idx ) ;
cluster state = zk controller . get cluster state ( ) ;
result res = db . execute ( call org . neo4j . procedure . default values ( ' another string ' ) ) ;
cells = matlab . substring ( matlab . index of ( [ ) + 1 , matlab . index of ( ] ) ) . trim ( ) ;
notification n = recvqueue . poll ( 2 * finalize wait , time unit . milliseconds ) ;
this . classifier = gutil . elvis ( classifier , null ) ;
if ( local file sys . exists ( name ) ) { local file sys . delete ( name , true ) ; } fsdata output stream stm = local file sys . create ( name ) ;
s . create query ( select cast ( e . the lost number as int ) from my entity e ) . list ( ) ;
long initial = system . current time millis ( ) ; while ( system . current time millis ( ) - initial < 2000 & & ( roster . get presence ( get bare jid ( 1 ) ) . get type ( ) . equals ( presence . type . unavailable ) ) ) { thread . sleep ( 100 ) ; }
string num str = the value . replace all ( [ ^ - \ \ d ] + , ) ;
if ( last name instanceof icppasttemplate id ) { iastname temp name = ( ( icppasttemplate id ) last name ) . get template name ( ) ; if ( temp name instanceof icppastconversion name | | temp name instanceof icppastoperator name ) { return true ; } } return false ;
return line mgr . get line count ( ) ;
class < ? > document builder = class . for name ( com . plutext . merge . document builder ) ;
throw log . get predicates on complete embedded entities not allowed exception ( string helper . join ( property path ) ) ;
if ( types [ i ] = = boolean . class ) { types [ i ] = boolean . class ; } if ( types [ i ] = = integer . class ) { types [ i ] = int . class ; } }
execution vertex ev31 = eg . get job vertex ( v3 . get id ( ) ) . get task vertices ( ) [ 0 ] ; execution vertex ev32 = eg . get job vertex ( v3 . get id ( ) ) . get task vertices ( ) [ 1 ] ; execution vertex ev4 = eg . get job vertex ( v3 . get id ( ) ) . get task vertices ( ) [ 0 ] ; eg . schedule for execution ( ) ;
final string method = get ; headers . add ( : method , method ) ; final string value = headers . get as string ( spdy headers . http names . method . to string ( ) ) ; assert not null ( value ) ; assert equals ( method , value ) ; final string value2 = headers . get as string ( spdy headers . http names . method ) ;
if ( remainder . test bit ( width - 1 ) ) { wnaf [ i ] = ( byte ) ( remainder . int value ( ) - pow2w b ) ; } else { wnaf [ i ] = ( byte ) remainder . int value ( ) ; }
if ( _ init done ) { initialize stream ( ) ; } int ret = concurrent appendable single file input stream . eof ; int num bytes read = 0 ; _ rate monitor . resume ( ) ;
assert . assert equals ( failed to get all 19 . , 19 , vq . get at most ( k1 , 19 ) . size ( ) ) ;
i . set character stream ( null ) ; assert null ( i . get byte stream ( ) ) ; assert null ( i . get character stream ( ) ) ; assert null ( i . get encoding ( ) ) ; assert null ( i . get public id ( ) ) ; assert null ( i . get system id ( ) ) ; }
if ( wal = null & & writestate . read only ) { flush descriptor desc = protobuf util . to flush descriptor ( flush action . start _ flush , get region info ( ) , flush op seq id , committed files ) ;
if ( looper . my looper ( ) = = looper . get main looper ( ) ) { throw new facebook exception ( get android id cannot be called on the main thread . ) ; } method is google play services available = utility . get method quietly ( com . google . android . gms . common . google play services util , is google play services available , context . class ) ; if ( is google play services available = = null ) { return identifiers ; }
computation graph model now = new transfer learning . graph builder ( model to fine tune ) . fine tune configuration ( new fine tune configuration . builder ( ) . seed ( rng ) . updater ( new rms prop ( 0 . 2 ) ) . build ( ) ) . build ( ) ;
tx table . remove local transaction ( local transaction ) ; } throw new illegal state exception ( transaction + transaction + is not in a valid state to be invoking cache operations on . ) ; }
if ( version supports federation ( get service layout feature map ( ) ) ) { props . set property ( cluster id , cluster id ) ; }
if ( receiver package . equals ( error package ) ) { return null ; } intent intent = new intent ( intent . action _ app _ error ) ;
if ( conn instanceof http urlconnection ) { get the content encoding of the server response string encoding = conn . get content encoding ( ) ; if null , set it to a emtpy string if ( encoding = = null ) { encoding = ; } if ( encoding . equals ignore case ( gzip ) ) { for gzip input stream , use a gzipinput stream return new gzipinput stream ( conn . get input stream ( ) ) ; } else if ( encoding . equals ignore case ( deflate ) ) { if it is encoded as deflate , then select the inflater inputstream . return new inflater input stream ( conn . get input stream ( ) , new inflater ( true ) ) ; } else { else read the raw bytes return conn . get input stream ( ) ; } } else { else read the raw bytes . return conn . get input stream ( ) ; }
if ( ( f features & namespacedecls ) = 0 ) { if ( . equals ( prefix ) | | . equals ( namespace uri ) ) { ( ( element ) node ) . set attribute ns ( xmlns _ uri , xmlns _ prefix , namespace uri ) ; } else { ( ( element ) node ) . set attribute ns ( xmlns _ uri , xmlns _ prefix + : + prefix , namespace uri ) ; } }
| | field info . field class = = string . class ) { continue ; }
term = terms enum . next ( ) ;
for ( int i = 0 ; i < batch . input . length ; i + + ) { input input = batch . input [ i ] ; record record = batch . records [ i ] ; if ( record = null ) { reassign property ids ( input , record , batch . property records [ i ] , property records id range , dynamic string records id range , dynamic array records id range ) ; } }
result = interval capacity in arrear . compute to be billed capacity in arrear ( immutable list . < rolled up unit > of ( new default rolled up unit ( unit1 , 10 l ) , new default rolled up unit ( unit2 , 2001 l ) ) ) ;
if ( is one sequence ( op1 . words [ 0 ] ) ) { return op1 . clone ( ) ; }
system . out . println ( @ system information : + e . get message ( ) ) ;
return new invalidate l1 command ( data container , distribution manager , notifier , flags bit set , keys , generate uuid ( transactional ) ) ;
collection admin request . create collection ( collection , conf , num shards , num replicas ) . set max shards per node ( max shards per node ) . process ( cluster . get solr client ( ) ) ;
assert equals ( 8 , get done ( transform ( immediate future , adder , direct executor ( ) ) ) . int value ( ) ) ;
if ( m menu = = null | | m menu refresh content ) { if ( m menu = = null ) { if ( initialize panel menu ( ) | | ( m menu = = null ) ) { return false ; } } if ( w action bar = null ) { w action bar . set menu ( m menu , this ) ; } call callback , and return if it doesn ' t want to display menu . creating the panel menu will involve a lot of manipulation ; don ' t dispatch change events to presenters until we ' re done . m menu . stop dispatching items changed ( ) ; if ( callback create options menu ( m menu ) ) { ditch the menu created above m menu = null ; if ( w action bar = null ) { don ' t show it in the action bar either w action bar . set menu ( null , this ) ; } return false ; } m menu refresh content = false ; }
session2 . evict ( p ) ; assert false ( session2 . contains ( p ) ) ; assert null ( ( ( shared session contract implementor ) session2 ) . get persistence context ( ) . get entry ( p ) ) ; try { session2 . update ( p ) ; fail ( should have failed because p is already associated with a persistence context that is still open . ) ; } catch ( hibernate exception ignored ) {
final long expected = write strings [ i ] . length ( ) + append strings [ i ] . length ( ) ;
client . drop table ( db name , tbl name ) ; client . drop type ( type name ) ;
assert true ( java . io . tmpdir is not set for am , tmp dir pos > 0 ) ;
twit4j . destroy friendship ( 6377362 ) ;
column model . remove column model listener ( this ) ; column model . remove column ( column ) ; column model . add column model listener ( this ) ; }
assert that ( ( object ) tmproot ) . is not null ( ) ; }
m _ source reader . close ( ) ; return insts ;
merge totals = false ;
if ( atom data size < 8 ) { return false ; } buffer . reset ( atom data size ) ; input . peek fully ( buffer . data , 0 , atom data size ) ; int brands count = atom data size 4 ; for ( int i = 0 ; i < brands count ; i + + ) { if ( i = = 1 ) {
if ( is platform ( windows ) ) { return ; } try { new url ( http : localhost : + port1 + hello ) . open stream ( ) ; fail ( expected socket exception on use ot http ) ; } catch ( socket exception expected ) { } }
text [ ] tarr = new text [ ] { new text ( foo ) , new text ( bar ) } ;
assert true ( e . get cause ( ) instanceof saxparse exception ) ; saxparse exception cause = ( saxparse exception ) e . get cause ( ) ; assert true ( cause . get message ( ) . contains ( ows : foo ) ) ; }
if ( config class = null & & is located in application module ( config class ) & & force ) { logger . log ( level . info , error : the provided config class is not located in an application module . ) ; return ; }
{ string recent files label = j edit . get property ( options . general . recent files ) ; int recent files value = j edit . get integer property ( recent files ) ; spinner model model = new spinner number model ( recent files value , 0 , integer . max _ value , 1 ) ; recent files = new jspinner ( model ) ; add component ( recent files label , recent files ) ; }
in [ 0 ] = ( in [ 0 ] - viewport . get ( viewport . position ( ) + 0 ) ) viewport . get ( viewport . position ( ) + 2 ) ;
message bytes host value mb = null ;
application . get downlink ( ) . abort ( ) ;
return test acct ;
throw new class cast exception ( return type + cannot be cast to + service _ class ) ; } } catch ( class cast exception e ) {
assert null ( get class ( fbthird ) ) ; }
resp . set status ( webdav status . sc _ bad _ request ) ; } } else {
do nmheartbeat ( rm , nm1 . get node id ( ) , 1 ) ;
client response response = r . path ( ws ) . path ( v1 ) . path ( timeline ) . query param ( user . name , tester ) . accept ( media type . application _ json ) . type ( media type . application _ json ) . post ( client response . class , entities ) ;
bus handler . push expected events ( next event . invoice , next event . payment , next event . invoice _ payment ) ; clock . add days ( 1 ) ; assert listener status ( ) ; parent invoice = invoice user api . get invoice ( parent invoice . get id ( ) , call context ) ;
close stream ( media type ) ;
instructions . add ( reil helpers . create bsh ( base offset + 1 , operand size . dword , isolated msb , operand size . dword , - 31 , operand size . dword , shifted msb ) ) ;
assert . assert true ( custom operator . final watermarks [ 0 ] . size ( ) = = 0 ) ;
set pro guard configuration ( configuration ) ;
if ( next pos = = checkpoints array . length ) { next pos = 0 ; } checkpoints array [ next pos + + ] = pending ;
throw new index shard snapshot failed exception ( shard id , shard didn ' t fully recover yet ) ; }
if ( m current page < count minus one ) { for ( int i = m current page + 1 ; i < count ; i + + ) { rect bound = bounds . get ( i ) ; if right side is outside the screen if ( bound . right > right clip ) { int w = bound . right - bound . left ; try to clip to the screen ( right side ) clip view on the right ( bound , w , right ) ; except if there ' s an intersection with the left view rect left bound = bounds . get ( i - 1 ) ; intersection if ( bound . left - m title padding < left bound . right ) { bound . left = ( int ) ( left bound . right + m title padding ) ; bound . right = bound . left + w ; } } } }
for ( char c : topic _ wildcards ) { if ( topic name . index of ( c ) > = 0 ) { return false ; } } return true ;
wrapped line . append ( str . substring ( offset ) ) ; return wrapped line . to string ( ) ; }
if ( _ commands to fake . contains ( command ) ) { log . debug ( executing fake processor for command : ( + command + ) ) ; _ fake processors . get ( command ) . process ( request ) ; } else { log . debug ( executing real processor for command : ( + command + ) ) ; _ real processors . get ( command ) . process ( request ) ; } }
final list < host selector > set host selectors = immutable list . of ( host selector . parse ( foo = bar ) , host selector . parse ( baz = qux ) ) ; final job id set job id = job id . from string ( foo : 0 . 1 . 0 ) ; final rollout options set rollout options = rollout options . new builder ( ) . set timeout ( 1000 l ) . set parallelism ( 2 ) . set migrate ( false ) . build ( ) ; final deployment group . rolling update reason set reason = manual ;
i _ p1 = limit ;
boolean selected = pos = = m selected position ; view child = make and add view ( pos , next top , true , m list padding . left , selected ) ; next top = child . get bottom ( ) + m divider height ;
long cur size = cache size . get ( ) ;
object r = parameter converter . try to make compatible ( double . class , new big decimal ( - 3 . 568 ) ) ; assert true ( expect double , r . get class ( ) = = double . class ) ; assert equals ( new double ( - 3 . 568 ) , r ) ;
member is available event2 = new member is available ( slave , instance id , cluster uri , new uri ( uri + ?something ) , default ) ;
final method method = view . get method ( invocation . get invoked method ( ) . get name ( ) , descriptor utils . method descriptor ( invocation . get invoked method ( ) ) ) ; final boolean async = view . is asynchronous ( method ) | | invocation . is client async ( ) ;
if ( string helper . has start token ( value , simple ) ) { return object . class ; }
bshformal parameter fp = ( bshformal parameter ) catch params . element at ( i ) ;
if ( bc = null ) { try { datagram packet send packet = new datagram packet ( send data , send data . length , bc , 23272 ) ; bc send . send ( send packet ) ; } catch ( ioexception e ) { logger . debug ( io error during max cube discovery : { } , e . get message ( ) ) ; } catch ( exception e ) { logger . debug ( e . get message ( ) ) ; logger . debug ( utils . get stack trace ( e ) ) ; } logger . trace ( request packet sent to : { } interface : { } , bc . get host address ( ) , network interface . get display name ( ) ) ; }
new date time formatter registrar ( ) . register formatters ( formatter registry ) ; if ( joda time present ) { handles joda - specific types as well as date , calendar , long new joda time formatter registrar ( ) . register formatters ( formatter registry ) ; } else { regular date format - based date , calendar , long converters new date formatter registrar ( ) . register formatters ( formatter registry ) ; }
add ( new label ( data dir , new map model ( values , key _ data _ dir ) ) ) ;
setup coverage my dimension ( wattemp _ custom , null ) ; coverage info custom coverage = get catalog ( ) . get coverage by name ( wattemp _ custom . get local part ( ) ) ;
result . remove ( resource type ) ;
parameter filter new filter = new style parameter filter ( ) ;
if ( stop at < st . length ) { sbuf . append ( \ \ n [ . . . ] ) ; } sbuf . append ( \ \ n \ ) ; last = last . get cause ( ) ;
return last _ chars2 ; }
if ( null = image view & & ( image view instanceof iphoto view ) ) { if ( scale type . matrix . equals ( image view . get scale type ( ) ) ) { image view . set scale type ( scale type . matrix ) ; } } }
ket = cursor ; if ( ( in _ grouping ( g _ v , 97 , 232 ) ) ) { break lab8 ; }
flush ( ) ;
if ( row labels = null ) { string s = ( row labels [ i ] = = null ? null : row labels [ i ] . to string ( ) ) ; s = string utils . pad or trim ( s , label size ) ; left align this guy only result . append ( s ) ; }
assert not null ( deserialised sketch ) ; assert equals ( sketch . cardinality ( ) , deserialised sketch . cardinality ( ) ) ; }
update selected category list ( ) ; m list scroll position manager . save scroll offset ( ) ; m swipe to refresh helper . set refreshing ( true ) ;
assert invalid message ( some partition key parts are missing : partitionkey , update % s set value = ? where clustering _ 1 = ? and clustering _ 2 = ? , 7 , 1 , 1 ) ; string error msg = is empty ( compact option ) ? some clustering keys are missing : clustering _ 1 : primary key column \ clustering _ 2 \ cannot be restricted as preceding column \ clustering _ 1 \ is not restricted ;
try { if ( id to resource . contains key ( resource . get id ( ) ) ) { throw new runtime exception ( ) ; } if ( resource . get id ( ) . equals ( 11 ) ) { throw new runtime exception ( magic number of id . ) ; } } catch ( exception e ) { throw new dry runnable janitor exception ( exception during dry run , e ) ; }
ifunction type function type = ( ifunction type ) identifier type ;
map < string , string > field attributes = new hash map < string , string > ( ) ;
add private credential ( subject , security identity ) ; return subject ; }
function type f3 = registry . create function type ( no _ object _ type , date _ type , string _ type , number _ type ) ;
assert true ( execution time is : + command . get execution time in milliseconds ( ) , command . get execution time in milliseconds ( ) > = 50 ) ; assert true ( command . is response timed out ( ) ) ; assert false ( command . is response from fallback ( ) ) ; assert false ( command . is response rejected ( ) ) ; assert command execution events ( command , hystrix event type . timeout , hystrix event type . fallback _ missing ) ;
byte [ ] multi byte = new byte [ 100 ] ; add multi byte char right padded1 _ 1 ( multi byte ) ; assert . assert true ( string expr . character count ( multi byte , 0 , 4 ) = = 2 ) ; result len = string expr . right trim and truncate ( multi byte , 0 , 4 , large max length ) ; assert . assert true ( result len = = 3 ) ;
assert equals ( - 9999 & 0x ffff , ( int ) value outside [ 0 ] ) ;
super . fit sequences ( seq rdd ) ;
int new value = result + 1 ; if ( new value > 0x00 ffffff ) new value = 1 ; roll over to 1 , not 0 . if ( s next generated id . compare and set ( result , new value ) ) { return result ; } } }
assert equals ( before , new string ( utf8 . get bytes ( before ) , utf - 8 ) ) ;
verify paging ( under test . find ( builder ( ) . gate id ( long . to string ( q gate . get id ( ) ) ) . page index ( 1 ) . page size ( 3 ) . build ( ) ) , false , project1 . get id ( ) , project2 . get id ( ) , project3 . get id ( ) ) ;
string under test . copy to ( destination , 2 * string under test . size ( ) , 0 , length ) ;
list < integer > l = new array list < integer > ( ) ; set . poll nto list ( 10 , l ) ; assert equals ( 10 , l . size ( ) ) ; for ( int i = 0 ; i < 10 ; i + + ) { assert equals ( list . get ( i ) , l . get ( i ) ) ; }
if ( m _ lex handler = null & & m _ cdata tag open ) { m _ lex handler . end cdata ( ) ; }
m clip rect . intersect ( m view clip rect ) ; m left extrusion = m touch . x - m clip rect . left ;
swap zone ids . clear ( ) ;
filter list filter = new filter list ( operator . must _ pass _ all ) ; single column value filter iscvf1 = new single column value filter ( cf1 . get bytes ( ) , c1 . get bytes ( ) , compare op . equal , a . get bytes ( ) ) ; single column value filter iscvf2 = new single column value filter ( cf1 . get bytes ( ) , c2 . get bytes ( ) , compare op . equal , k . get bytes ( ) ) ; filter . add filter ( iscvf1 ) ; filter . add filter ( iscvf2 ) ; filter list filter1 = new filter list ( operator . must _ pass _ all ) ; iscvf1 = new single column value filter ( cf1 . get bytes ( ) , c3 . get bytes ( ) , compare op . equal , a . get bytes ( ) ) ; iscvf2 = new single column value filter ( cf1 . get bytes ( ) , c4 . get bytes ( ) , compare op . equal , k . get bytes ( ) ) ; filter1 . add filter ( iscvf1 ) ;
this . result row = new row ( families . length ) ; this . family rows = new row [ families . length ] ; for ( int f = 0 ; f < families . length ; f + + ) { this . family rows [ f ] = new row ( qualifiers [ f ] . length ) ; this . result row . set field ( f , this . family rows [ f ] ) ; } this . string charset = charset . for name ( schema . get string charset ( ) ) ;
this . watcher = property file watcher ;
m image view = null ;
region info hri3 = region info builder . new builder ( table name . value of ( name . get method name ( ) ) ) . set start key ( key2 . get bytes ( ) ) . set end key ( key3 . get bytes ( ) ) . set split ( false ) . set region id ( 101 ) . build ( ) ;
verify ( ack subtask state , times ( 1 ) ) . discard state ( ) ;
program class . u2fields count = data input . read unsigned short ( ) ; program class . fields = new program field [ program class . u2fields count ] ;
return ear ; }
start activity ( new intent ( this , termux activity . class ) . add flags ( intent . flag _ activity _ new _ task ) ) ;
if ( free sweep allocation threshold < 1 ) { throw new illegal argument exception ( free sweep allocation threshold : + free sweep allocation threshold + ( expected : > 0 ) ) ; } free task = new runnable ( ) { @ override public void run ( ) { free0 ( ) ; } } ; death watch thread = thread . current thread ( ) ;
out = null ; ( ( collection < object > ) found ) . add ( i to ) ; } else
field end = parse complex field ( field position , complex field end , current level ) ; union helper . field position = field end + 1 ; move past union separator .
if ( state . in cdata ) _ printer . print text ( ] ] > ) ;
if ( m _ constants [ ii ] = null ) { object param = param array [ ii ] ; if ( param = = null ) { return false ; } if ( m _ constants [ ii ] . equals ( param . to string ( ) ) ) { return false ; } } }
this . hosts reader = new hosts file reader ( conf . get ( mapred . hosts , ) , conf . get ( mapred . hosts . exclude , ) ) ; configuration queues conf = new configuration ( this . conf ) ; queue manager = new queue manager ( queues conf ) ;
if ( m checkmark drawable = null ) m checkmark drawable . set color filter ( m selected state text color , porter duff . mode . multiply ) ; } finally {
final list < inet socket address > namenodes = new array list < inet socket address > ( ) ; namenodes . add ( name node . get client protocol address ( conf ) ) ; return balancer . run ( namenodes , conf ) ; }
set authorization caching enabled ( false ) ;
intersection area . muli ( int mask ) ;
assert next value ( seeker , mark , comma , 4 ) ; assert next value ( seeker , mark , comma , \ ) ; assert next value ( seeker , mark , comma , f \ \ oo ) ; assert false ( seeker . seek ( mark , comma ) ) ; }
create sample file ( sample _ file _ name _ 1 ) ;
public synchronized void set nclob ( int parameter index , nclob value ) throws sqlexception { set clob ( parameter index , value ) ; }
store stats map . put if absent ( store name , new store stats ( store name , aggregated store stats ) ) ;
compute running std dev ( agent _ id , end _ ts , durationms ) ;
assert . assert true ( shell content . contains ( export hadoop _ mapred _ home = \ opt hadoopbuild \ ) ) ;
byte [ ] qualifier name = bytes . to bytes ( f1 ) ; put put = new put ( bytes . to bytes ( r1 ) ) ; put . add column ( fam name , qualifier name , bytes . to bytes ( v1002 ) ) ; htable1 . put ( put ) ; put . add column ( fam name , qualifier name , bytes . to bytes ( v1001 ) ) ; htable1 . put ( put ) ; put . add column ( fam name , qualifier name , bytes . to bytes ( v1112 ) ) ; htable1 . put ( put ) ; scan scan = new scan ( ) ;
+ + attribute count ; size + = 8 + bootstrap methods . length ; new utf8 ( bootstrap methods ) ; }
test same ( function _ foo ( x ) { return x } _ foo ( 1 ) ) ;
editor _ . get session ( ) . replace ( range , replacement . join ( \ n ) + \ n ) ;
dictionary < string , string > properties = new hashtable < string , string > ( ) ; properties . put ( protocol provider factory . protocol , protocol names . sip ) ; sip pp factory serv reg = context . register service ( protocol provider factory . class . get name ( ) , sip provider factory , properties ) ; if ( logger . is debug enabled ( ) ) logger . debug ( sip protocol provider factory . . . [ registered ] ) ;
f element stack . pop element ( ) ;
return jzlib . z _ ok ;
if ( grant results . length > 0 & & grant results [ 0 ] = = package manager . permission _ granted ) {
double num ; try {
preconditions . check not null ( message . get multi field list ( ) ) ;
for ( int i = 0 ; i < 5 ; i + + ) { string view = v _ + i ; string etab = ex + i ; response = client . call procedure ( @ ad hoc , drop view + view ) ; assert equals ( response . get status ( ) , client response . success ) ; response = client . call procedure ( @ ad hoc , insert into + etab + values ( 555 ) ) ; assert equals ( response . get status ( ) , client response . success ) ; }
if ( m icon hint = = null ) { list < integer > icons = new array list < > ( ) ; list < integer > descriptions = new array list < > ( ) ; for ( int i = 0 ; i < m accepted card type infos . size ( ) ; i + + ) { icons . add ( m accepted card type infos . get ( i ) . icon ) ; descriptions . add ( m accepted card type infos . get ( i ) . description ) ; } m icon hint = editor field model . create icon list ( m context . get string ( r . string . payments _ accepted _ cards _ label ) , icons , descriptions ) ; }
set will not draw ( true ) ;
assert equals ( 1 , realm . where ( null types . class ) . greater than ( null types . field _ float _ null , 2 f ) . count ( ) ) ;
string metric name = query . properties ( ) . get string ( metricsearcher id ) ; if ( metric name = null ) { query . properties ( ) . set ( streaming loadtype , metric name ) ; } result result = execution . search ( query ) ;
if ( _ idle . await ( idle * 2 , time unit . milliseconds ) ) throw new ioexception ( new timeout exception ( ) ) ;
make proposals from children ( child object , last token ) ;
if ( freq . missing ) { refinement = get refinement special ( mcontext , refinement , tags with partial , missing bucket , missing ) ; }
if ( provider = = null & & provider name derived from class name = null ) { try { list < persistence provider > providers = persistence provider loader . load provider module by name ( provider name derived from class name ) ; persistence provider deployment holder . save persistence provider in deployment unit ( deployment unit , providers , null ) ; provider = get provider by name ( pu , providers ) ; } catch ( module load exception e ) { throw jpa logger . root _ logger . cannot load persistence provider module ( e , provider name derived from class name , persistence provider class name ) ; } } if ( provider = = null ) throw jpa logger . root _ logger . persistence provider not found ( persistence provider class name ) ;
declaration descr . set namespace ( package descr . get namespace ( ) ) ;
assert equals ( 0 , target coverage . get grid geometry ( ) . get grid range ( ) . get low ( 0 ) ) ;
top level package string = get project operations ( ) . get focused top level package ( ) . get fully qualified package name ( ) ;
rag doll update ( tpf ) ;
for ( int x = 0 , max = value . size ( ) ; x < max ; x + + ) write ( value . get ( x ) ) ;
if ( ( flags & iresource delta . open ) = 0 ) { post project state changed ( parent ) ; return true ; } process resource deltas ( delta . get affected children ( ) , resource ) ;
assert not equals ( rule key1 , rule key2 ) ; }
if ( this . node . state ( ) . equals ( node . state . active ) & & other . node . state ( ) . equals ( node . state . active ) ) return - 1 ;
coverage response delegate delegate = response factory . encoder for ( format ) ;
response = get as servlet response ( rest oseo collections sentinel2 products s2 a _ oper _ msi _ l1 c _ tl _ sgs _ _ 20180101 t000000 _ a006640 _ t32 tpp _ n02 . 04 thumbnail ) ; assert equals ( 404 , response . get status ( ) ) ; }
json . append ( last read time = ) ; json . append ( stats . get last read time ( ) ) ; json . append ( ' , ' ) ;
plist . write key ( jvmoptions ) ;
if ( provider uri str . is empty ( ) ) { return null ; } final uri provider uri ; try { provider uri = new uri ( provider uri str ) ; } catch ( urisyntax exception e ) { throw new ioexception ( e ) ; } key provider key provider = key provider factory . get ( provider uri , conf ) ; if ( key provider = = null ) { throw new ioexception ( could not instantiate key provider from + hdfs client config keys . dfs _ encryption _ key _ provider _ uri + setting of ' + provider uri str + ' ) ; } if ( key provider . is transient ( ) ) { throw new ioexception ( key provider + key provider . to string ( ) + was found but it is a transient provider . ) ; } return key provider ;
linked list < highlight info > stack = new linked list < > ( ) ;
if ( child operators array . length = = 0 ) { throw new hive exception ( expected number of children is at least 1 . found : + child operators array . length ) ; } new tag to old tag = to array ( conf . get new tag to old tag ( ) ) ;
verify ( mock mediator , never ( ) ) . save ( ( geo server tile layer ) any object ( ) ) ; verify ( mock tile layer , never ( ) ) . get info ( ) ;
return instantiate with method injection ( bd , bean name , owner ) ; }
{ match ( ' @ ' ) ; if ( state . failed ) return ; } state . type = _ type ;
reusing build first hash join iterator < tuple2 < integer , string > , tuple2 < integer , string > , tuple2 < integer , string > > iterator = new reusing build first hash join iterator < > ( input1 , input2 , this . record serializer , this . record1 comparator , this . record serializer , this . record2 comparator , this . record pair comparator , this . memory manager , io manager , this . parent task , 1 . 0 , true , false , false ) ; iterator . open ( ) ; while ( iterator . call with next key ( matcher , collector ) ) ;
if ( is show day & & is show hour & & is show minute ) is show second = true ;
dbus event v2 e v2 = ( dbus event v2 ) e ; dbus event v1 e v1 = null ; try { e v1 = ( dbus event v1 ) e v2 . convert to v1 ( ) ; } catch ( key type not implemented exception e1 ) { fail ( e1 . get localized message ( ) ) ; } log . info ( ev1 = + e v1 ) ;
search response search response2 = client ( ) . prepare search ( ) . add stored field ( _ source ) . add script field ( distance , new script ( script type . inline , custom script plugin . name , plane distance , collections . empty map ( ) ) ) . get ( ) ; double result distance2 = search response2 . get hits ( ) . get hits ( ) [ 0 ] . get fields ( ) . get ( distance ) . get value ( ) ; assert that ( result distance2 , close to ( geo utils . plane distance ( src _ lat , src _ lon , tgt _ lat , tgt _ lon ) , 0 . 01d ) ) ;
sqlserializer serializer = new sqlserializer ( configuration . default ) ; serializer . handle ( sqlexpressions . any ( employee . firstname . is not null ( ) ) ) ; assert equals ( some ( employee . firstname is not null ) , serializer . to string ( ) ) ; }
tiny months = locale data . tiny month names ; tiny weekdays = locale data . tiny weekday names ;
json string encoder encoder = json string encoder . get instance ( ) ;
named list lst = rsp . get values ( ) ;
assert analyzes to ( a , 21 . 35 , new string [ ] { 21 . 35 } ) ;
assert equals ( - 28800000 , la . get offset ( gregorian calendar . ad , 2016 , 2 , 12 , calendar . saturday , 10800000 ) ) ;
accounts _ . remove ( i ) ;
set test max runtime memory in mega bytes ( maps , 40 ) ;
failed = false ; try { client a . up ( up options ) ; } catch ( storage exception e ) { failed = true ; } assert true ( failed ) ;
assert equals ( gen . get next id ( ) , p - 0 - 0 ) ;
extractor . set scope variable ( result ) ;
register listeners ( new cache config , cache proxy ) ; return cache proxy ;
try { final iterable < ? extends element > results = handler . do operation ( filter , context , store ) ; fail ( exception expected ) ; } catch ( final operation exception e ) { assert true ( e . get message ( ) . contains ( edge group : + test groups . edge + does not exist in the schema ) ) ; } }
if ( n . get attribute value ( attr name ) = null ) { err . jsp error ( n , jsp . error . duplicate . name . jspattribute , attr name ) ; }
if ( login ( client subject , username , new password ( password ) , constraint . _ _ cert _ auth , message info ) ) { return auth status . success ; } if ( is mandatory ( message info ) ) { return auth status . success ; }
assert . assert equals ( 10 , ss . get max scn ( ) ) ;
float optimal tab width = ( strip width + overlap width ) num tabs ;
return select * from ( select + no selectsql query + ) where rownum < = + num rows ;
m paint . set alpha ( m selection alpha ) ; canvas . draw circle ( point x , point y , m selection radius , m paint ) ; if ( m force draw dot | m selection degrees % 30 = 0 ) { we ' re not on a direct tick ( or we ' ve been told to draw the dot anyway ) . m paint . set alpha ( full _ alpha ) ; canvas . draw circle ( point x , point y , ( m selection radius * 2 7 ) , m paint ) ; } else { we ' re not drawing the dot , so shorten the line to only go as far as the edge of the selection circle . int line length = m line length ; line length - = m selection radius ; point x = m xcenter + ( int ) ( line length * math . sin ( m selection radians ) ) ; point y = m ycenter - ( int ) ( line length * math . cos ( m selection radians ) ) ; }
if ( headings . size ( ) > 0 ) { element title element = headings . get ( 0 ) ; string title = title element . get inner text ( ) ; values . put ( title , title ) ; }
int idx = 0 ;
statement compiler . compile from sql text and update catalog ( compiler , hsql , db , estimates , catalog stmt , cur stmt , procedure descriptor . m _ single stmt , procedure descriptor . m _ join order , determinism mode . faster , partitioning ) ;
old selected child . set focusable ( false ) ;
holder . picture . set image drawable ( null ) ; m current task = new image url async task ( context , holder , m cache , tweet id ) ;
final int index = hash & string cache . length - 1 ;
default consistent hash updated members ch = chf . update members ( base ch , new members , lf map ) ; assert equals ( lf map , updated members ch . get capacity factors ( ) ) ; if ( nodes to remove > 0 ) { for ( int l = 0 ; l < updated members ch . get num segments ( ) ; l + + ) { assert true ( updated members ch . locate owners for segment ( l ) . size ( ) > 0 ) ; assert true ( updated members ch . locate owners for segment ( l ) . size ( ) < = actual num owners ) ; } }
tree map < big integer , big integer > map = new tree map < big integer , big integer > ( ) ;
hashed alpha declarations . add ( current hashed alpha ) ; builder . append ( get variable declaration ( hashed field reader ) ) . append ( newline ) ;
instruction writer . reset ( code . length ) ;
final server server = get server ( ) ; _ context = context handler . get current context ( ) ; _ loader = thread . current thread ( ) . get context class loader ( ) ; synchronized ( server ) {
string text = pattern . substring ( stops . get ( i ) + stop . length ( ) , starts . get ( i + 1 ) ) ; chunks . add ( new text chunk ( text ) ) ; } }
tuple sets < left tuple > temp left tuples = new tuple sets impl < left tuple > ( ) ; if ( src left tuples . get delete first ( ) = null ) { use the real target here , as dealing direct with left tuples do left deletes ( acc node , am , wm , src left tuples , trg left tuples , staged left tuples ) ; }
m items = new array list < string > ( arrays . as list ( items ) ) ;
final int position gap = random ( ) . next int ( 1000 ) ; final int offset gap = random ( ) . next int ( 1000 ) ; final analyzer delegate = new mock analyzer ( random ( ) ) ; final analyzer a = new delegating analyzer wrapper ( delegate . get reuse strategy ( ) ) { @ override protected analyzer get wrapped analyzer ( string field name ) { return delegate ; } @ override public int get position increment gap ( string field name ) { return position gap ; } @ override public int get offset gap ( string field name ) { return offset gap ; } } ; final random index writer writer = new random index writer ( random ( ) , new directory ( ) , a ) ;
check item swapping ( rv ) ; on item move distance updated ( ) ; }
row values [ column name to index . get ( timestamp ) ] = diff hist . get end time stamp ( ) ;
logger . trace ( array index out of bounds during foreground + color control code parsing . ) ; return null ;
third eye request baseline request = create third eye request ( baseline , comparison request , baseline start , baseline end ) ;
view = recycler . get view for position ( left view position ) ;
out . write ( headers . get bytes ( standard charsets . us _ ascii ) ) ;
verify ( stor iocontent resolver ) . get ( ) ;
em = get entity manager ( ) ; em . get transaction ( ) . begin ( ) ; otmcte1 = em . find ( one to many component test entity . class , otmcte1 . get id ( ) ) ; otmcte1 . get comp1 ( ) . get entities ( ) . add ( ste2 ) ;
string id = cloud search utils . get id ( url ) ;
admin . clone snapshot ( test _ snapshot , test _ clone ) ; assert true ( coprocessor should have been called on snapshot clone , cp . was clone snapshot called ( ) ) ; assert false ( coprocessor restore should not have been called on snapshot clone , cp . was restore snapshot called ( ) ) ; admin . disable table ( test _ clone ) ; assert true ( admin . is table disabled ( test _ table ) ) ; admin . delete table ( test _ clone ) ;
matcher m = template _ names _ pattern . matcher ( normalized template ) ;
tasks . clear ( ) ;
assert equals ( 1 . 0 + 1 f , exec ( double x = 1 ; float y = 1 ; return x + y ; ) ) ;
private key info info = new private key info ( new algorithm identifier ( pkcsobject identifiers . rsa encryption , dernull . instance ) , new rsaprivate key structure ( get modulus ( ) , get public exponent ( ) , get private exponent ( ) , get prime p ( ) , get prime q ( ) , get prime exponent p ( ) , get prime exponent q ( ) , get crt coefficient ( ) ) . get derobject ( ) ) ;
int [ ] corrupt block idxs = new int [ ] { 0 , 4 , 6 } ; for ( int idx : corrupt block idxs ) corrupt block ( locs . get ( idx ) . get block ( ) , dfs cluster ) ; raid dfsutil . report corrupt blocks ( dfs , file1 , corrupt block idxs , block size ) ; corrupt files = dfsutil . get corrupt files ( dfs ) ; assert equals ( file not corrupted , 1 , corrupt files . length ) ; assert equals ( wrong file corrupted , corrupt files [ 0 ] , file1 . to uri ( ) . get path ( ) ) ;
empty . reset row position ( ) ;
http servlet request request mock = create mock ( http servlet request . class ) ; expect ( request mock . get request uri ( ) ) . and return ( index . html ) . times ( 3 ) ;
grammar = f grammar bucket . get grammar ( namespace ) ; if ( grammar = = null ) { f xsddescription . set namespace ( namespace ) ; give a chance to application to be able to retreive the grammar . if ( f grammar pool = null ) { grammar = ( schema grammar ) f grammar pool . retrieve grammar ( f xsddescription ) ; if ( grammar = null ) { put this grammar into the bucket , along with grammars imported by it ( directly or indirectly ) if ( f grammar bucket . put grammar ( grammar , true , f namespace growth ) ) { revisit : a conflict between new grammar ( s ) and grammars in the bucket . what to do? a warning? an exception? f xsierror reporter . f error reporter . report error ( xsmessage formatter . schema _ domain , grammar conflict , null , xmlerror reporter . severity _ warning ) ; grammar = null ; } } } }
gui package . get instance ( ) . get tree listener ( ) . get jtree ( ) . scroll path to visible ( tree path ) ; } }
assert equals ( success _ mock _ login _ servlet , writer . to string ( ) ) ;
if ( tile groups . contains key ( level scale ) ) { . . . we ' re done . return cached level . return tile groups . get ( level scale ) ; }
batch plan = cluster test utils . get batch plan ( z1z3 current , z1z3 current , z1z3 stores ) ;
super . handle unknown property ( jp , ctxt , bean or class , prop name ) ; }
if ( line intersects cube ) search node ( value , greater , k , results , examined ) ; }
magnitude = 255 - image . safecolor ( math . abs ( gray x ) + math . abs ( gray y ) ) ;
final long source parent id = 99999 ;
count = s . create query ( update mammal set body weight = ( select max ( body weight ) from animal ) ) . execute update ( ) ;
set background color ( bg color ) ;
slice _ from ( o ) ; break ; case 3 :
iframe dmcontext frame dmc = dmcontexts . get ancestor of type ( reg in group [ 0 ] , iframe dmcontext . class ) ;
if ( node arg = null ) { if ( node arg . get node type ( ) = = node . document _ node ) { the document node is the node argument doc = ( document ) node arg ; } else { the document node is the node argument ' s owner document doc = node arg . get owner document ( ) ; } determine the dom version . if ( doc = null & & doc . get implementation ( ) . has feature ( core , 3 . 0 ) ) { return doc . get xml version ( ) ; } }
boolean [ ] boolean array = { true , false } ;
log . info ( get region info ( ) . get encoded name ( ) + : + dropping memstore contents as well since replayed flush seq id : + seq id + is greater than current seq id : + current seq id ) ;
case unknown : enable dynamic resolution ( ) ; break ; default : break ; } } else { push scope ( ) ; } }
runtime service . signal event received ( my boundary signal ) ; assert equals ( 2 , task service . create task query ( ) . task name ( task after boundary signal ) . list ( ) . size ( ) ) ;
assert that ( out . get buffer size ( ) , equal to ( buffer _ size ) ) ;
optional < string > maybe command = cli arguments . stream ( ) . filter ( arg - > execution context . launcher ( ) . get command names ( ) . contains ( arg ) ) . find first ( ) ; if ( maybe command . is present ( ) ) {
commit sync ( offsets ) ; throw e ; } catch ( exception e ) {
node obj = n . get first first child ( ) ;
result = auth result . deny ( request , insufficient permissions , user , permission , namespace ) ; } }
map map = new hash map ( ) ;
nd4j . get affinity manager ( ) . attach thread to device ( thread , device id ) ; thread . set daemon ( true ) ; thread . start ( ) ; }
t = gts . v ( ) . has ( id , sid ) . local ( _ _ . out e ( knows ) . has ( weight , p . between ( 1 , 3 ) ) . order ( ) . by ( weight , decr ) . limit ( 10 ) ) . profile ( ) ;
jdk . remove if ( ( s ) - > s . contains ( 1 ) ) ; using jdk
try { secret provider = construct secret provider ( filter config . get servlet context ( ) , config , false ) ; destroy secret provider = true ; } catch ( exception ex ) { throw new servlet exception ( ex ) ; } }
log . warn ( skipping emulator azure test because configuration + doesn ' t indicate that it ' s running . ) ; return null ; }
memstore . add ( new key value ( row , fam , qf1 , val ) , null ) ; memstore . add ( new key value ( row , fam , qf2 , val ) , null ) ; memstore . add ( new key value ( row , fam , qf3 , val ) , null ) ;
assert equals ( 1 , unassigned info . get number of delayed unassigned ( state with delayed shard ) ) ; shard routing delayed shard = state with delayed shard . get routing nodes ( ) . unassigned ( ) . iterator ( ) . next ( ) ; assert equals ( node left timestamp nanos , delayed shard . unassigned info ( ) . get unassigned time in nanos ( ) ) ; assert null ( delayed allocation service . delayed reroute task . get ( ) ) ;
assert true ( find relationship by property , relationship exists by query ( index , start node , end node , false ) ) ;
try { parser factory . make parser ( tests . api . org . xml . sax . support . no subclass parser ) ; fail ( expected class cast exception was not thrown ) ; } catch ( class cast exception e ) { expected }
attributed strings . add ( new attributed string ( buffer . substring ( size , start ) ) ) ; size = start ;
breaker . add estimate bytes and maybe break ( 0 , field ) ;
set interpolated text size ( current text size ) ;
final boolean exact match = was to was exact match ( from span list , to span list ) ;
words [ i ] ^ = concise set utils . sequence _ bit ; } }
job info job info = parser . parse history file ( job . get job history file path ( ) ) ; configuration job conf = parser . parse configuration ( job . get job conf file path ( ) ) ; log . info ( parsed the job history file and the configuration file + for job + job id str ) ;
return is pending ussd ; }
index segment index segment = columnar segment loader . load ( segment directory , v3 loading config ) ; assert . assert not null ( index segment ) ; assert . assert equals ( index segment . get segment name ( ) , metadata . get name ( ) ) ; assert . assert equals ( segment version . v3 , segment version . value of ( index segment . get segment metadata ( ) . get version ( ) ) ) ; } finally {
tbl . set property ( serde constants . serialization _ format , 9 ) ; tbl . set property ( columns , key , abyte , ashort , aint , along , afloat , adouble , astring , abool ) ; tbl . set property ( columns . types , string , tinyint : smallint : int : bigint : float : double : string : boolean ) ; tbl . set property ( hbase ser de . hbase _ columns _ mapping , : key - , cfa : byte b , cfb : short b , cfc : int - , cfa : long b , cfb : float - , cfc : double b , + cfa : string b , cfb : boolean - ) ; tbl . set property ( hbase ser de . hbase _ table _ default _ storage _ type , binary ) ; return tbl ;
get map kvp request reader reader = new get map kvp request reader ( wms ) ; assert null ( reader . entity resolver provider . get entity resolver ( ) ) ;
final server server = get server ( ) ; _ context = context handler . get current context ( ) ; _ loader = thread . current thread ( ) . get context class loader ( ) ; synchronized ( server ) {
int nodes to relocate = find nodes to relocate ( array , maximum length ) ;
if ( camel - seda . equals ( component ) ) { assert true ( span . tags ( ) . contains key ( pre ) ) ; assert true ( span . tags ( ) . contains key ( post ) ) ; } assert equals ( td . get label ( ) , td . get operation ( ) , span . operation name ( ) ) ; assert equals ( td . get label ( ) , td . get kind ( ) , span . tags ( ) . get ( tags . span _ kind . get key ( ) ) ) ; if ( td . get parent id ( ) = - 1 ) { assert equals ( td . get label ( ) , spans . get ( td . get parent id ( ) ) . context ( ) . span id ( ) , span . parent id ( ) ) ; } if ( td . get log messages ( ) . is empty ( ) ) { assert equals ( number of log messages , td . get log messages ( ) . size ( ) , span . log entries ( ) . size ( ) ) ; for ( int i = 0 ; i < td . get log messages ( ) . size ( ) ; i + + ) { assert equals ( td . get log messages ( ) . get ( i ) , span . log entries ( ) . get ( i ) . fields ( ) . get ( message ) ) ; } }
vector map vectors = new vector map ( ) ; for ( int i = 0 ; i < size ; + + i ) { read the key int strlen = key int type . read ( data in ) ; byte [ ] buffer = new byte [ strlen ] ; if ( data in . read ( buffer , 0 , strlen ) = strlen ) { throw new ioexception ( could not read string buffer fully ) ; } string key = new string ( buffer ) ; read the vector float [ ] vector = new float [ dim ] ; for ( int k = 0 ; k < vector . length ; + + k ) { vector [ k ] = to float ( data in . read short ( ) ) ; } add the key value vectors . put ( key , vector ) ; } return vectors ;
s . read int ( ) ; ignored if ( size > 0 ) { be like clone ( ) , allocate array based upon size not capacity ensure capacity internal ( size ) ; object [ ] a = element data ; read in all elements in the proper order . for ( int i = 0 ; i < size ; i + + ) { a [ i ] = s . read object ( ) ; } }
if ( ranges = null ) { int size = ranges . size ( ) ; for ( int i = 0 ; i = size ; i + + ) { ( ( range impl ) ranges . get ( i ) ) . receive inserted text ( node , offset , count ) ; } }
list < database version > dirty database versions after = test collection util . to list ( database version dao . get dirty database versions ( ) ) ; assert not null ( dirty database versions after ) ; assert equals ( 0 , dirty database versions after . size ( ) ) ;
view v = get child at ( 0 ) ;
bytes in . write byte ( 0x3 f ) ; dynamic table size update ( size = 55 ) . bytes in . write byte ( 0x18 ) ; hpack reader . read headers ( ) ; assert equals ( 1 , hpack reader . header count ) ; }
adjust min speed ( ( percent type ) command , channel _ fan _ learn _ minspeed , ; learn ; minspeed ; ) ; }
write node labels script file ( scrpt with multiple lines having node labels , true ) ;
try { int new file size = integer . value of ( file size field . get text ( ) ) ; file size field . set foreground ( color . black ) ; logging utils activator . get packet logging service ( ) . get configuration ( ) . set limit ( new file size * 1000 ) ; } catch ( throwable t ) { file size field . set foreground ( color . red ) ; }
test checks ( * * @ param { number } const * function f ( const ) { } , * * @ param { number } const * function f ( const ) { + jscomp . typecheck . check type ( const , + [ jscomp . typecheck . value checker ( ' number ' ) ] ) ; + } ) ; }
if ( compare bytes ( value1 , value2 ) ) { return false ; }
if ( ( frame . get identifier ( ) . equals ( id3v24 frames . frame _ id _ year ) ) & & ( frame . get body ( ) instanceof frame body tdrc ) ) { translate frame ( frame ) ; } else if ( frame instanceof id3v22 frame ) { copy frame into map ( frame . get identifier ( ) , frame ) ; } else { id3v22 frame new frame = new id3v22 frame ( frame ) ; copy frame into map ( new frame . get identifier ( ) , new frame ) ; }
document context json = get as jsonpath ( rest oseo collections sentinel2 products s2 a _ oper _ msi _ l1 c _ tl _ sgs _ _ 20180101 t000000 _ a006640 _ t32 tpp _ n02 . 04 , 200 ) ;
rt . load new version ( 2 , rt . bytes initial ) ; result = run unguarded ( rt . get clazz ( ) , run ) ; assert equals ( success , result . return value ) ; }
left = context state . allocate ( 0 , 0 , 3 ) ; left . write remote ( counter id . from int ( 3 ) , 5 l , 0 l ) ; left . write remote ( counter id . from int ( 6 ) , 3 l , 0 l ) ; left . write remote ( counter id . from int ( 9 ) , 2 l , 0 l ) ; right = context state . allocate ( 0 , 0 , 4 ) ;
return instance ;
connection connection = get connection for writing ( ) ;
sample data . set position ( 0 ) ; sample data . set limit ( bytes read ) ; if ( started packet ) { pass data to the reader as though it ' s contained within a single infinitely long packet . reader . packet started ( first sample timestamp us , true ) ; started packet = true ; }
get mock endpoint ( mock : result ) . expected bodies received ( b , c , d ) ; template . send body and header ( direct : start , d , seqno , 4 ) ; template . send body ( direct : start , a ) ; template . send body and header ( direct : start , c , seqno , 3 ) ; template . send body and header ( direct : start , b , seqno , 2 ) ; assert mock endpoints satisfied ( ) ; }
artifact cache . remove old content ( ) . get ( ) ; assert that ( artifact cache . inlined artifact content hashes ( ) , matchers . has size ( 1 ) ) ; assert that ( artifact cache . directory file content hashes ( ) , matchers . has size ( 1 ) ) ;
matcher html end matcher = find _ insertion _ point _ html _ end . matcher ( insertable . get quoted content ( ) ) ; if ( html end matcher . matches ( ) ) { has html end tag = true ; }
return super . resolve class ( v ) ; } catch ( class not found exception cnfe ) {
assert true ( value is test bean , status . get value ( ) instanceof string ) ;
assert true ( nonces . verify ( a , 2040 , 1 , 2060 ) ) ;
if ( up tree . get kind ( ) = = kind . conditional _ or ) { return null ; }
if ( dsmr item id . equals ( open habvalue . get dsmr item id ( ) ) ) { logger . debug ( publish data ( { } ) to { } , dsmr item id , item name ) ; event publisher . post update ( item name , open habvalue . get value ( ) ) ; } } } } }
if ( layout = = null & & next page > = num custom pages ( ) & & next page < get page count ( ) ) { layout = ( cell layout ) get child at ( next page ) ; } if ( layout = m drag target layout ) { set current drop layout ( layout ) ; set current drag overlapping layout ( layout ) ; return true ; } return false ;
if ( r _ mark _ l ar i ( ) ) { break lab16 ; }
queue manager . refresh acls ( conf ) ;
this . count + + ;
for ( relation type slot : relation type . values ( ) ) { if ( slot . canonical name . equals ( name ) | | slot . name ( ) . equals ( name ) ) { cached from string . put ( original name , slot ) ; return optional . of ( slot ) ; } }
try { is . reset ( ) ; fail ( test 1 : ioexception expected . ) ; } catch ( ioexception e ) { expected }
final object value = ( _ accessor method = = null ) ? _ field . get ( bean ) : _ accessor method . invoke ( bean , ( object [ ] ) null ) ;
if ( metrics registry = = null ) { metrics registry = new metric registry ( ) ; } }
if ( capability . get memory size ( ) < min alloc mb | | capability . get virtual cores ( ) < min alloc vcores ) { string message = node manager from + host + doesn ' t satisfy minimum allocations , sending shutdown + signal to the node manager . node capabilities are + capability + ; minimums are + min alloc mb + mb and + min alloc vcores + vcores ; log . info ( message ) ; response . set diagnostics message ( message ) ; response . set node action ( node action . shutdown ) ; return response ; } response . set container token master key ( container token secret manager . get current key ( ) ) ;
metrics cache sink . init ( sink config , sink context ) ;
int i = locate lf ( ) ;
write byte ( code point > > 6 | 0xc0 ) ; 110xxxxx
return get series ( series ) . get item count ( ) ;
msg store item memory . put long ( msg inner . get queue offset ( ) ) ;
sql = select t1 . id + from + tb + t1 join r1 t2 + on exists + ( select max ( id ) from r2 offset 1 ) + and t1 . id = 1 ; ;
{ int c = cursor - 3 ; if ( limit _ backward > c | | c > limit ) { return false ; } cursor = c ; }
p = pattern . compile ( a * b ) ; m = p . matcher ( aabfooaabfooabfoobfoo ) ; r = m . replace all ( - ) ;
wait for ( rm1 , haservice state . active ) ;
spider . add spider listener ( this ) ;
element last table = find last table ( foster text ) ;
if ( trace ) log . tracef ( moving child % s , child ) ; fqn old child fqn = fqn . from relative elements ( node to move fqn , child ) ; move ( cache , old child fqn , new fqn ) ; } remove node ( cache , node to move fqn ) ; success = true ; } finally {
for ( int i = start word index + 1 ; i < end word index ; i + + ) words [ i ] = word _ mask ;
list < task attempt id > failed fetch maps = report . get fetch failed maps ( ) ;
timestamp delta = util . read unsigned int24 ( in ) ;
assert xpath evaluates to ( full , csw : search results @ element set , d ) ; assert xpath evaluates to ( 29 , csw : search results @ number of records matched , d ) ; assert xpath evaluates to ( 5 , csw : search results @ number of records returned , d ) ; assert xpath evaluates to ( 16 , csw : search results @ next record , d ) ; assert xpath evaluates to ( 5 , count ( csw : search results * ) , d ) ; }
byte array ba = _ cache . acquire ( ) ; new byte array ( payload , offset , length ) ; new byte [ length ] ) ; system . arraycopy ( payload , offset , ba . get data ( ) , 0 , length ) ; ba . set valid ( length ) ; ba . set offset ( 0 ) ;
if ( exists file ( view name ) ) { doc existing doc = load existing doc ( view name ) ; if ( is user managed document ( existing doc ) ) { new doc = merge ( fragments footer , existing doc , ctx ) ; } } else { new doc = process ( fragments footer , ctx ) ; }
timer job query job query = management service . create timer job query ( ) . process instance id ( pi . get id ( ) ) ;
map < string , object > row1 = new hash map < string , object > ( ) ; row1 . put ( id , doc1 ) ; row1 . put ( key , hello ) ; row1 . put ( value , 1 . 0 ) ; map < string , object > row2 = new hash map < string , object > ( ) ; row2 . put ( id , doc2 ) ; row2 . put ( key , guten tag ) ; row2 . put ( value , 1 . 0 ) ; map < string , object > row3 = new hash map < string , object > ( ) ; row3 . put ( id , doc3 ) ; row3 . put ( key , bonjour ) ; row3 . put ( value , 1 . 0 ) ; list < map < string , object > > expected rows = new array list < map < string , object > > ( ) ;
file extraction lock = new file ( context . get temp directory ( ) , . extract _ lock ) ; if ( extracted web app dir . exists ( ) ) {
string parent znode = get zoo keeper ( ) . znode paths . draining znode ;
return immutable list . of ( b , a ) ;
spdy data frame . set stream id ( local stream id ) ; session handler . offer ( spdy data frame ) ; assert null ( session handler . peek ( ) ) ; session handler . finish ( ) ;
if ( class constant . referenced class = clazz ) { referencing class = clazz ; class constant . referenced class accept ( this ) ; }
rule . apply ( _ request . get request uri ( ) , _ request , _ response ) ;
m _ non empty config . set new cli ( false ) ; boolean compile = m _ non empty config . compile ( project ) ; assert true ( compile ) ; builder . add server config ( m _ non empty config , false ) ; m _ empty config = new local cluster ( empty - database . jar , 4 , 3 , 0 , backend target . native _ ee _ jni ) ;
doc . add ( new string field ( field , foo , field . store . no ) ) ; w . add document ( doc ) ; directory reader r = directory reader . open ( w ) ; field info fi = multi fields . get merged field infos ( r ) . field info ( field ) ; assert not null ( fi ) ; assert false ( fi . has norms ( ) ) ; assert equals ( 1 , r . num docs ( ) ) ; assert equals ( 1 , r . max doc ( ) ) ; w . delete documents ( new match all docs query ( ) ) ;
m caret animator = object animator . of float ( m caret drawable , caret progress , 0 ) ;
if ( ( _ string deserializer = = null ) & & ( _ number deserializer = = null ) & & ( _ map deserializer = = null ) & & ( _ list deserializer = = null ) & & get class ( ) = = untyped object deserializer . class ) { return vanilla . instance ( prevent merge ) ; } if ( prevent merge = _ non merging ) { return new untyped object deserializer ( this , prevent merge ) ; } return this ; }
if ( trailer . get meta index count ( ) > 0 ) block type . index _ v1 . read and check ( dis ) ; meta block index reader . read root index ( dis , trailer . get meta index count ( ) ) ; file info loaded = true ;
classpath changed ( classpath change , i = = 0 * refresh external linked folder only once * ) ; if ( this . can change resources ) {
if ( cells . advance ( ) ) { throw new array index out of bounds exception ( expected = + count + , index = + i ) ; }
if ( rlen > 0 ) { system . arraycopy ( r , 0 , dest , dest index , rlen ) ; dest index + = rlen ; }
set rounding mode ( rounding mode ) ; }
engine . initialize from json ( engine _ config ) ; engine . set mode ( engine . mode . row based ) ; bindings = new properties ( ) ; bindings . put ( project , project ) ; }
block manager test util . stop redundancy thread ( blk manager ) ; pending reconstruction . clear ( ) ;
float v mod size23 = ( p2 . get estimated module size ( ) - p3 . get estimated module size ( ) ) math . min ( p2 . get estimated module size ( ) , p3 . get estimated module size ( ) ) ;
ret [ 1 ] = nd4j . rand ( labels shape ) ;
found other edits = true ;
assert fails ( type _ mismatch , select cast ( null as hyper log log ) < all ( values cast ( null as hyper log log ) ) ) ;
assert on fetch ( query , null , expected count ) ; set to null ;
try { this . channel1 . connect ( local addr1 ) ; fail ( should throw illegal state exception . ) ; non - nls - 1 } catch ( illegal state exception e ) { ok . }
local variable type table attribute . u2local variable type table length = remove empty local variable types ( local variable type table attribute . local variable type table , local variable type table attribute . u2local variable type table length , code attribute . u2max locals ) ;
if ( factory class name . length ( ) = = 0 ) { continue ; } try {
wmsmap content mc = create nice mock ( wmsmap content . class ) ;
if ( name . equals ( node util . jsc _ property _ name _ fn ) | | name . equals ( node util . extern _ object _ property _ string ) ) { return false ; } boolean seen candidate definiton = false ;
error handler . fatal error ( sax exception ) ; return ;
try { realm . where ( null types . class ) . is null ( null types . field _ long _ not _ null ) . find all ( ) ; fail ( ) ; } catch ( illegal argument exception ignored ) { }
logger . warn ( error extracting library name , e ) ;
if ( buffer . get byte ( buffer . reader index ( ) ) = = object stream constants . tc _ reset ) { buffer . skip bytes ( 1 ) ; return null ; } } object decoded = decode ( ctx , channel , buffer , state ) ; return decoded ; }
s = open session ( ) ; s . get transaction ( ) . begin ( ) ; p = s . get ( parent . class , parent id ) ; assert false ( hibernate . is initialized ( p . get children ( ) ) ) ;
if ( random . next boolean ( ) ) { int times = 1 ; random . next int ( 3 ) ; for ( int i = 0 ; i < times ; i + + ) { safe mode . report primary cleared ( node ) ; expected r . remove ( node ) ; } }
transaction txn = transaction . current txn ( ) ; list < vlan vo > vlans = _ vlan dao . list all ( ) ;
m remote service = remote service ;
token token = new token ( foo - bar , 5 , 12 ) ; token . set type ( mytype ) ; word delimiter graph filter wdf = new word delimiter graph filter ( new canned token stream ( token ) , default _ word _ delim _ table , flags , null ) ; assert token stream contents ( wdf , new string [ ] { foobar , foo , bar } , new string [ ] { mytype , mytype , mytype } ) ;
action request . set action result ( result object ) ; return action result ;
boolean exception expected = ( t . get column type ( col index ) = realm field type . string & & t . get column type ( col index ) = realm field type . integer & & t . get column type ( col index ) = realm field type . boolean & & t . get column type ( col index ) = realm field type . date ) ;
http servlet servlet = new http servlet ( ) { @ override protected void service ( http servlet request request , http servlet response response ) throws servlet exception , ioexception { try {
jedis jedis = new jedis ( uri . create ( rediss : localhost : 6390 ) ) ;
sem . try acquire ( 15 , time unit . seconds ) ;
if ( associated policies = = null | | associated policies . is empty ( ) ) { return false ; } scope scope = root . realm scope ( map _ roles _ scope ) ; return root . evaluate permission ( resource , scope , server ) ; }
assert q ( req ( q , stringdv : [ b to d ] , sort , id _ i asc ) , * [ @ num found = ' 3 ' ] , result doc [ 1 ] str [ @ name = ' id ' ] [ . = 1 ] , result doc [ 2 ] str [ @ name = ' id ' ] [ . = 3 ] , result doc [ 3 ] str [ @ name = ' id ' ] [ . = 4 ] ) ;
deadline deadline = timeout . from now ( ) ; while ( deadline . has time left ( ) ) { try { if the actor is not reachable yet , this throws an exception . retry until the deadline passes . this . job manager ref = akka utils . get actor ref ( get job manager akka url ( deadline . time left ( ) ) , actor system , deadline . time left ( ) ) ; return job manager ref ; } catch ( throwable ignored ) { retry thread . sleep ( math . min ( 100 , deadline . time left ( ) . to millis ( ) ) ) ; } }
list < string > requests = page . get html ( ) . xpath ( a [ @ class = \ area _ link flat _ btn \ ] @ href ) . all ( ) ; if ( requests . size ( ) > 2 ) { requests = requests . sub list ( 0 , 2 ) ; } page . add target requests ( requests ) ; page . add target requests ( page . get html ( ) . links ( ) . regex ( ( . * restaurant [ ^ ] + ) ) . all ( ) ) ; page . put field ( items , page . get html ( ) . xpath ( ul [ @ class = \ dishes menu _ dishes \ ] li span [ @ class = \ name \ ] text ( ) ) ) ; page . put field ( prices , page . get html ( ) . xpath ( ul [ @ class = \ dishes menu _ dishes \ ] li span [ @ class = \ price _ outer \ ] span [ @ class = \ price \ ] text ( ) ) ) ; }
assert equals ( 1 , collection . count ( ) ) ;
builder . append ( package org . eclipse . che . ide . client . inject ; \ n \ n ) ;
put put = new put ( row ) ; put . add ( family , qualifier , manual stamp , value ) ; ht . put ( put ) ; get version and verify ( ht , row , family , qualifier , manual stamp , value ) ;
query = new query ( ?query = hello & ranking . profile = default ) ;
null group id = next group id + + ;
if ( this . port = null ) { builder . port ( this . port ) ; }
git material git = new git material ( git ) ; build cause p2build cause = create build cause ( as list ( p1 ) , new array list < > ( ) ) ; build cause p1build cause = create build cause ( new array list < > ( ) , as list ( git ) ) ; when ( pipeline service . build cause for ( p2 , 1 ) ) . then return ( p2build cause ) ; when ( pipeline service . build cause for ( p1 , 1 ) ) . then return ( p1build cause ) ;
utils . make call with basic authn ( servlet url , anil , marcus , 401 ) ; utils . make call with basic authn ( servlet url , anil , utils . hash ( anil , md5 , coding . base _ 64 ) , 401 ) ; utils . make call with basic authn ( servlet url , anil , utils . hash ( anil , md5 , coding . hex ) , 401 ) ; }
expression util . finalize value types ( select stmt . m _ having ) ;
properties = ( stored | indexed ) ; float schema version = schema . get version ( ) ; if ( schema version < 1 . 1f ) properties | = multivalued ; if ( schema version > 1 . 1f ) properties | = omit _ tf _ positions ; if ( schema version < 1 . 3 ) { args . remove ( compress threshold ) ; } if ( schema version > = 1 . 6f ) properties | = use _ docvalues _ as _ stored ; this . args = collections . unmodifiable map ( args ) ;
if ( m scroller . is finished ( ) ) { m scroller . abort animation ( ) ; }
for ( port listener listener : this . listeners ) { listener . start ( ) ; map . put ( listener . get connection manager ( ) , this ) ; }
string drl1 = import + person . class . get canonical name ( ) + ; \ n + import + big integer . class . get canonical name ( ) + ; \ n + rule \ rule1 \ \ n + when \ n + person ( big decimal = = new big integer ( \ 1 \ ) ) \ n + then \ n + end \ n + rule \ rule2 \ \ n + when \ n + person ( big decimal = = new big integer ( \ 2 \ ) ) \ n + then \ n + end \ n ; kie session ksession1 = new kie helper ( ) . add content ( drl1 , resource type . drl ) . build ( ) . new kie session ( ) ;
m paint . set color ( am color ) ; m paint . set alpha ( am alpha ) ; canvas . draw circle ( m am xcenter , m am pm ycenter , m am pm circle radius , m paint ) ; m paint . set color ( pm color ) ; m paint . set alpha ( pm alpha ) ; canvas . draw circle ( m pm xcenter , m am pm ycenter , m am pm circle radius , m paint ) ;
interval xydataset ixyd = ( interval xydataset ) dataset ;
if ( next = null & & is year ( next ) ) { date . add ( next ) ; next . set ( core annotations . named entity tag annotation . class , date ) ; after index + + ; }
get work response response five = client . get work ( minion _ id , 0 , immutable list . of ( build targets queue test . target _ name ) , max _ work _ units _ to _ fetch ) ; assert . assert equals ( response five . get work units size ( ) , 0 ) ;
field builder . add annotation ( new annotation metadata builder ( rule ) ) ; return field builder ; }
assert equals ( 50 l , pool . cleanup ( 100 l ) ) ;
run test ( webtest xxx , , webtest , true , false , false ) ; }
assert q ( req ( common params . debug , common params . query , q , * : * , fq , builder . to string ( ) , fl , id , + field name ) , * [ @ num found = ' + num terms + ' ] ) ;
map = transpose ( new int [ ] [ ] { { - 1 , - 1 , - 1 , - 1 , - 1 } , { - 1 , 0 , - 1 , - 1 , - 1 } , { - 11 , - 11 , - 11 , - 11 , 2 } , { - 1 , - 1 , 1 , - 1 , - 1 } , { - 1 , - 1 , - 1 , - 1 , - 1 } , } ) ; i = focus logic . handle key event ( key event . keycode _ dpad _ right , map , 0 , 1 , 1 , true ) ; assert equals ( 1 , i ) ;
if ( this obj = null ) return date _ format ( now ( ) , id _ to string ) ;
name = tokens . t _ overlay ;
stream memento = input stream . create stream memento ( ) ; if ( fragment stack = null ) { fragment stack . clear ( ) ; }
log . e ( purchase , error , ne ) ;
method type test type = basic type . change return type ( boolean . class ) . basic type ( ) ;
intent intent = this . get intent ( ) ; uri uri = intent . get data ( ) ;
on edge case ( make list ( 0 , 0 , 90 - small , 0 + big ) , make list ( 1 , 0 + small , 2 , 0 - small , 90 - small , - 90 , 90 - small , 10 ) , make list ( - big , 0 , 90 - big , 180 , 10 , big ) ) ;
stream . reset ( ) ; } } else { stream . reset ( ) ; } }
result sheet = get wsresult for query ( req ( q , id : 2 , wt , xlsx , fl , id , foo _ s , v _ ss ) ) ;
thread . sleep ( 1500 ) ;
for ( string expected : expected metrics ) { assert true ( metric + expected + can not be found in jmx in ensemble mode . , jmx metrics . contains ( expected ) ) ; } }
group ds . min by ( 5 ) ;
expected tx id = - 1 ;
if ( this owner doc = other owner doc & & this owner doc = null & & other owner doc = null ) { int other doc num = ( ( core document impl ) other owner doc ) . get node number ( ) ; int this doc num = ( ( core document impl ) this owner doc ) . get node number ( ) ; if ( other doc num > this doc num ) return document _ position _ disconnected | document _ position _ following | document _ position _ implementation _ specific ; else return document _ position _ disconnected | document _ position _ preceding | document _ position _ implementation _ specific ; }
document dom = get as dom ( wcs?request = describe eocoverage set & version = 2 . 0 . 1 & service = wcs & eoid = sf _ _ spatio - temporal _ dss & subset = long ( 1 , 5 ) & containment = contains ) ;
doc . add field ( iter , new iterable < string > ( ) { @ override public iterator < string > iterator ( ) { return values . iterator ( ) ; } } ) ; doc . add field ( desc , 1 ) ; update request . add ( doc ) ; java bin update request codec codec = new java bin update request codec ( ) ;
for ( int i = 0 ; i < 5 ; + + i ) { skip the one that was previously unannounced if ( i = 2 ) { unannounce segment for server ( druid servers . get ( i ) , segments . get ( i ) , zk paths config ) ; } } assert . assert true ( timing . for waiting ( ) . await latch ( segment removed latch ) ) ; assert . assert equals ( 0 , ( ( list < timeline object holder > ) timeline . lookup ( intervals . of ( 2011 - 04 - 01 2011 - 04 - 09 ) ) ) . size ( ) ) ;
wal . do complete cache flush = true ;
assert equals ( job state internal . error , app master . forced state ) ;
operator state handles snapshot = test harness . snapshot ( 0 l , 0 l ) ; test harness . close ( ) ; test harness . setup ( ) ; test harness . initialize state ( snapshot ) ; test harness . open ( ) ; test harness . process element ( new stream record < > ( new tuple2 < > ( key1 , 3 ) , 2500 ) ) ;
fragment fragment = new sample fragment ( ) ; bundle args = new bundle ( ) ; args . put int ( sample fragment . arg _ image _ res , m city images [ position ] ) ; args . put int ( sample fragment . arg _ action _ bg _ res , r . drawable . ab _ background ) ; fragment . set arguments ( args ) ; fragment manager fragment manager = get fragment manager ( ) ;
return min ( connection state . window size ( ) , usable bytes ) ; }
material mat = new material ( asset manager , common mat defs misc show normals . j3md ) ; tea geom . set material ( mat ) ; root node . attach child ( tea geom ) ; }
if ( resources available ) { start containers from queue ( queued opportunistic containers ) ; }
j cluster . restart journal node ( 0 ) ;
try { service reference < ? > [ ] references = this . context . get all service references ( command marker . class . get name ( ) , null ) ; for ( service reference < ? > ref : references ) { command marker command = ( command marker ) this . context . get service ( ref ) ; if ( commands . contains ( command ) ) { add ( command ) ; } } } catch ( invalid syntax exception e ) { logger . warning ( cannot load command marker on simple parser . ) ; } validate . not null ( pattern , buffer required ) ;
service . listener = null ; service . running = false ; } catch ( throwable t ) { fatal error ( t ) ; } } }
files . delete ( paths . get ( todeletefile ) ) ;
throw new illegal argument exception ( ' reference field ' is not supported for embedables objects ) ;
m renderer . remove curl mesh ( m page left ) ;
assert rows ( execute ( select { [ ] , [ min ( ck ) , max ( ck ) ] } from % s ) , row ( set ( list ( ) , list ( 1 , 3 ) ) ) ) ;
mock result set = mock ( result set . class ) ; result set meta data mock result set meta data = mock ( result set meta data . class ) ; when ( mock result set meta data . get column count ( ) ) . then return ( 1 ) ; when ( mock result set meta data . get column label ( 1 ) ) . then return ( mock table ) ; when ( mock result set . get meta data ( ) ) . then return ( mock result set meta data ) ; }
assert true ( xhtmlmanager . is service enabled ( get connection ( 1 ) , get full jid ( 0 ) ) ) ;
system . arraycopy ( cbuf , off , buf , pos , space ) ; sink . write ( buf , 0 , buf . length ) ; pos = len - space ; system . arraycopy ( cbuf , off + space , buf , 0 , pos ) ; } else {
clazz clazz = class pool . get class ( class name ) ;
s = test util . random simple string ( random ( ) ) ;
assert equals ( data consistency is missed , 18 , scan operation ( s , conf , table name ) ) ; }
random access file raf = new random access file ( s lock pattern filename , rw ) ;
if ( local describe subnets = = null ) { throw new org . apache . axis2 . databinding . adbexception ( property cannot be null ) ; }
for ( i = 1 ; i < stacks - 1 ; i + + ) { rho = i * drho ; for ( j = 0 ; j < slices ; j + + ) { theta = j * dtheta ; x = cos ( theta ) * sin ( rho ) ; y = sin ( theta ) * sin ( rho ) ; z = cos ( rho ) ; if ( normals ) imb . gl normal3f ( x * nsign , y * nsign , z * nsign ) ; imb . gl vertex3f ( x * radius , y * radius , z * radius ) ; } }
tile manager . invalidate ( ) ; tile manager . post invalidate ( ) ; }
if ( _ closure vars . contains ( variable ref ) ) { _ closure vars . add ( variable ref ) ; _ needs sort record factory = true ; }
if ( resource . get parent ( ) instanceof iproject & & resource . get name ( ) . starts with ( . ) ) { skip project config return null ; } try { if ( resource instanceof ifolder & & resource . get parent ( ) instanceof ifolder ) { sub folder return handler . make navigator node ( this , resource ) ; } dbpresource handler resource handler = get model ( ) . get platform ( ) . get project manager ( ) . get resource handler ( resource ) ; if ( resource handler = = null ) { log . debug ( skip resource ' + resource . get name ( ) + ' ) ; return null ; } return resource handler . make navigator node ( this , resource ) ; } catch ( exception e ) { log . error ( error creating navigator node for resource ' + resource . get name ( ) + ' , e ) ; return null ; }
security context holder . get context ( ) . set authentication ( null ) ; determine authentication point ( http request ) . commence ( http request , response , reason ) ;
class defining calls . put ( modified var , parent ) ; continuations . put ( modified var , new continuation ( n , scope ) ) ; return ;
layer group info nested named = add layer group ( nested _ named , mode . named , null , lakes , neatline ) ;
ext alert . update alert ( alert ) ; } else { if ( http message = null ) { history ref = new history reference ( model . get singleton ( ) . get session ( ) , history type , http message ) ; } alert . set source ( alert . source . manual ) ;
create payment ( account1 , transaction type . authorize , null , pending authorization . get external key ( ) , uuid . random uuid ( ) . to string ( ) , big decimal . ten , payment plugin status . processed ) ;
fsdata input stream in3 = fs . open ( file to read ) ;
conf . set ( yarn configuration . nm _ docker _ privileged _ containers _ acl , whitelisted user ) ; docker linux container runtime runtime = new docker linux container runtime ( mock executor , mock cgroups handler ) ;
dimension default value setting default value setting = new dimension default value setting ( ) ; default value setting . set strategy type ( strategy . maximum ) ; setup feature custom dimension ( scanning _ angle _ dimension , scanning angle , default value setting ) ; feature type info time elevation custom = get catalog ( ) . get feature type by name ( time _ elevation _ custom . get local part ( ) ) ;
get model writer ( ) . add item to database ( folder info , container , screen id , cell x , cell y ) ;
if ( use time > 0 l ) { vuinfo info = vu map . get ( vu id key ) ; create usage record ( usage types . vpn _ users , use time , start date , end date , account , info . get user id ( ) , info . get user name ( ) , info . get zone id ( ) ) ; }
volt table stats t = get stats ( client , procedure ) ; system . out . println ( stats : + stats t . to formatted string ( ) ) ; assert equals ( 0 , stats t . get row count ( ) ) ; local server . shutdown ( ) ; local server . join ( ) ; }
collection < double > double string = get double list ( median , field facets , string _ sd , double , double ) ;
m recycler view . add item decoration ( divider ) ; m recycler view . set layout manager ( new linear layout manager ( this ) ) ;
store . put ( a key , new versioned < byte [ ] > ( a value ) , null ) ; list < version > initial versions = store . get versions ( a key ) ; assert equals ( 6 , initial versions . size ( ) ) ; version main version = initial versions . get ( 0 ) ; for ( int i = 1 ; i < initial versions . size ( ) ; i + + ) { assert equals ( main version , initial versions . get ( i ) ) ; }
return boolean from int ( libcore . os . getsockopt int ( fd , ipproto _ ipv6 , ipv6 _ multicast _ loop ) ) ;
stream . reset ( new reset frame ( stream . get id ( ) , error code . cancel _ stream _ error . code ) , callback . noop ) ;
final char blob [ ] = new char [ volt type . max _ value _ length ] ;
gwcconfig new config = new gwcconfig ( ) ; new config . set inner caching enabled ( false ) ; new config . set enabled persistence ( true ) ; blob store . set changed ( new config , false ) ; assert false ( blob store . get delegate ( ) instanceof memory blob store ) ;
full format = res . get string ( com . android . internal . r . string . time _ wday ) ;
node list locks = dom . get elements by tag name ( cdf : locks ) ; string fid1 = ( ( element ) locks . item ( 0 ) ) . get attribute ( gml : id ) ; string fid2 = ( ( element ) locks . item ( 1 ) ) . get attribute ( gml : id ) ; xml = < wfs : get feature with lock + service = \ wfs \ + version = \ 2 . 0 . 0 \ + expiry = \ 100 \ + xmlns : cdf = \ http : www . opengis . net cite data \ + xmlns : fes = ' + fes . namespace + ' + xmlns : wfs = ' + wfs . namespace + ' > + < wfs : query type names = \ cdf : locks \ > + < fes : filter > + < fes : resource id rid = \ + fid1 + \ > + < fes : resource id rid = \ + fid2 + \ > + < fes : filter > + < wfs : query > + < wfs : get feature with lock > ;
this . channel1 . configure blocking ( false ) ;
return string . value of ( ( char ) key code ) . to upper case ( ) ;
string target = pick target node ( nodes , shard size , average size ) ;
throw new assertion failure ( unable to inject static metamodel attribute : + metamodel class . get name ( ) + ' ' + name , e ) ;
redirect out stream = null ; redirect out print stream = null ; redirect err stream = null ; redirect err print stream = null ; }
channel pipeline channel pipeline = ch . pipeline ( ) ; ssl handler ssl handler = configure server sslon demand ( ) ;
iaddress address = f base address . add ( i ) ;
event . set date stamp ( datestamp ) ; event . set timestamp ( timestamp ) ; event . set extended type ( type ) ; if ( type . get pattern ( ) = = gc pattern . gc _ pause ) { the - end events contain a pause as well event . set pause ( parse pause ( line , pos ) ) ; event . set duration ( event . get pause ( ) ) ; } return event ;
request = http request . create test request ( search?query profile = hitsoffset , method . get ) ;
file file = file ( next word ) ; read next word ( ) ;
synchronized ( this . factory ) { if ( zk . get in process ( ) < factory . outstanding limit | | outstanding requests < 1 ) { sk . selector ( ) . wakeup ( ) ; enable recv ( ) ; } }
component dto project = prepare project ( ) ; component dto module = component testing . new module dto ( bcde , project ) . set db key ( module _ key ) . set name ( module ) ; db client . component dao ( ) . insert ( db . get session ( ) , module ) ; db . get session ( ) . commit ( ) ; tree root holder . set root ( builder ( project , 1 ) . set uuid ( project . uuid ( ) ) . set key ( project . get db key ( ) ) . set name ( project ) . add children ( builder ( component . type . module , 2 ) . set uuid ( bcde ) . set key ( module _ key ) . set name ( module ) . add children ( builder ( directory , 3 ) . set uuid ( cdef ) . set key ( module _ key : src main java dir ) . set path ( src main java dir ) . add children ( builder ( file , 4 ) . set uuid ( defg ) . set key ( module _ key : src main java dir foo . java ) . set path ( src main java dir foo . java ) . build ( ) ) . build ( ) ) . build ( ) ) . build ( ) ) ;
lab6 : do { v _ 5 = cursor ; lab7 : do {
edit . put float ( key , value ) ; edit . commit ( ) ; }
log . info ( doing the first savenamespace . ) ; fsn . save namespace ( 0 , 0 ) ; log . info ( first savenamespace sucessful . ) ; assert true ( savenamespace should have marked one directory as bad . + but found + storage . get removed storage dirs ( ) . size ( ) + bad directories . , storage . get removed storage dirs ( ) . size ( ) = = 1 ) ;
throw connector logger . root _ logger . unsupported create callback handler method ( ) ; }
feedback panel c = ( feedback panel ) tester . get component from last rendered page ( feedback ) ;
if ( current char = = ' ' & & ( slash slash comments | | slash star comments ) ) { if ( ( current char = read ( ) ) = = ' * ' & & slash star comments ) { int peek one = read ( ) ; while ( true ) { current char = peek one ; peek one = read ( ) ; if ( current char = = - 1 ) { peek char = - 1 ; return ( ttype = tt _ eof ) ; } if ( current char = = ' \ r ' ) { if ( peek one = = ' \ n ' ) { peek one = read ( ) ; } line number + + ; } else if ( current char = = ' \ n ' ) { line number + + ; } else if ( current char = = ' * ' & & peek one = = ' ' ) { peek char = read ( ) ; return next token ( ) ; } } } else if ( current char = = ' ' & & slash slash comments ) { skip to eof or new line then return the next token while ( ( current char = read ( ) ) > = 0 & & current char = ' \ r ' & & current char = ' \ n ' ) { intentionally empty } peek char = current char ; return next token ( ) ; } else if ( current type = token _ comment ) { was just a slash by itself peek char = current char ; return ( ttype = ' ' ) ; } }
assert true ( user nickname not found in the room after join , + from peer side , name is on member list ( op set2 room . get user nickname ( ) , op set1 room . get members ( ) ) ) ; op set1 room collector . collected events . clear ( ) ;
while ( m . find ( ) ) { first , we have to copy all the message preceding the < img > tag . target . append ( piece . substring ( start , m . start ( ) ) ) ; then , we find the position of the slash inside the tag . slash index = m . group ( ) . last index of ( ) ; we copy the < img > tag till the slash exclude . target . append ( m . group ( ) . substring ( 0 , slash index ) ) ; we copy all the end of the tag following the slash exclude . target . append ( m . group ( ) . substring ( slash index + 1 ) ) ; we close the tag with a separate closing tag . target . append ( < img > ) ; start = m . end ( ) ; }
update request request = new update request ( posts , < 1 > doc , < 2 > 1 ) ; < 3 >
flush store ( store , seq id ) ;
orchestrator . get server ( ) . associate project to quality profile ( sample , xoo , empty ) ;
if ( registered dag identifier = = null ) { record job shuffle info ( application id string , user , app token ) ; }
channel group accepted channels = testing util . extract field ( server ( ) . get decoder ( ) . get transport ( ) , accepted channels ) ;
options . add option ( option ) ;
list . add ( get int node ( mapped type . sizeof ) ) ;
int max = ( 1 + random ( ) . next int ( 10 ) ) * 3 ; log . info ( adding { } number of documents , max ) ; for ( int i = 0 ; i < max ; i + + ) { assert u ( adoc ( id , string . value of ( i ) ) ) ; } assert u ( commit ( ) ) ; request = lrf . make request ( q , dummy ) ;
explicit bean bean = m . read value ( apos to quotes ( { ' first _ name ' : ' egon ' , ' last _ name ' : ' spengler ' , ' user _ age ' : ' 32 ' } ) , explicit bean . class ) ; assert not null ( bean ) ; assert equals ( egon , bean . user first name ) ; assert equals ( spengler , bean . user last name ) ; assert equals ( 32 , bean . user age ) ;
control . set current way point ( ( int ) v . x ) ;
filter type filter type = get filter type ( map content ) ;
inst = process ( inst ) ;
object result = get column value ( rs , 1 , this . required type ) ; if ( result = null & & this . required type = null & & this . required type . is instance ( result ) ) { extracted value does not match already : try to convert it . try { return ( t ) convert value to required type ( result , this . required type ) ; } catch ( illegal argument exception ex ) { throw new type mismatch data access exception ( type mismatch affecting row number + row num + and column type ' + rsmd . get column type name ( 1 ) + ' : + ex . get message ( ) ) ; } } return ( t ) result ;
assert null ( request . header ( user - agent ) ) ;
type [ ] generic exception type array = types . get cloned type array ( generic exception types ) ; if ( generic exception type array . length > 0 ) { sb . append ( throws ) ; append array generic type ( sb , generic exception type array ) ; } return sb . to string ( ) ; }
conf . set long ( dfs . access . time . precision , 0 ) ;
p . add first ( new read timeout handler ( rpc client . default _ socket _ timeout _ read , time unit . milliseconds ) ) ; p . add last ( ch handler ) ; connection header promise . add listener ( new future listener < boolean > ( ) { @ override public void operation complete ( future < boolean > future ) throws exception { if ( future . is success ( ) ) { channel pipeline p = ch . pipeline ( ) ; p . remove ( read timeout handler . class ) ; p . remove ( netty hbase rpc connection header handler . class ) ;
task service . complete ( user task . get id ( ) ) ;
val . set values ( 4 l , - 10 l , 50 l , - 74 l ) ; iterator < long > values2 = arrays . as list ( 4 l , 10 l , 50 l , 74 l ) . iterator ( ) ; func . stream longs ( value - > { assert true ( values2 . has next ( ) ) ; assert equals ( values2 . next ( ) . long value ( ) , value ) ; } ) ; assert false ( values2 . has next ( ) ) ; }
body builder . append formal line ( throw new % s ( msg . to string ( ) , e ) ; , get name of java type ( jdk java type . illegal _ state _ exception ) ) ;
i + + ; } stripped bi = quot and rem [ 0 ] ; } else { if ( i = = 1 ) {
try { object [ ] array = bean util . declared . get property ( value , hint property name ) ; if ( array = = null ) { array = ( object [ ] ) array . new instance ( hint property type . get component type ( ) , 1 ) ; bean util . declared silent . set property ( value , hint property name , array ) ; array [ 0 ] = data [ i ] ; } else { object [ ] new array = arrays util . append ( array , data [ i ] ) ; if ( new array = array ) { bean util . declared silent . set property ( value , hint property name , new array ) ; } } } catch ( exception ex ) { throw new db oom exception ( ex ) ; }
swap elements ( sequence , i , idx ) ;
nodes fd . remove ( node , fd ) ; notify node failure ( node , transport disconnected ( with verified connect ) ) ; } } else {
zkassign . delete node fail silent ( this . master . get zoo keeper ( ) , hri ) ;
create user ( user5 , user 5 , user5 @ email . com ) ; create user ( user6 , user 6 , user6 @ email . com ) ;
file output stream fos3 = new file output stream ( f1 ) ; deflater output stream dos3 = new deflater output stream ( fos3 ) ; fos3 . close ( ) ; try { dos3 . finish ( ) ; fail ( ioexception not thrown ) ; } catch ( ioexception e ) { }
if ( initializer block . is empty ( ) ) { if ( first member ) code writer . emit ( \ n ) ; code writer . emit ( initializer block ) ; first member = false ; }
output message . flush ( ) ; }
assert . assert true ( new file ( args . get ( 0 ) ) . exists ( ) ) ; verify ( traffic controller spy ) . release class id ( test _ classid ) ;
try { ns . write lock ( ) ; update all storages ( bm ) ; } finally { ns . write unlock ( ) ; }
map < string , string > raw = setup get coverage rain ( ) ;
if ( byte count = = - 1 ) { current percent = 100 ; on progress ( current percent ) ; } else { count + = byte count ; rounding up to 100 % would mean we say we are done , before we are . . . this also catches issues , when expected total size was guessed wrong int percent = math . min ( 99 , ( int ) math . floor ( 100 . 0 * count expected total size ) ) ; if ( percent > current percent ) { current percent = percent ; on progress ( percent ) ; } }
boolean following participle = i < tokens . length - 3 & & ( tokens [ i + 2 ] . has partial pos tag ( pa1 ) | | tokens [ i + 2 ] . get token ( ) . matches ( zugeschriebenen? | genannten? ) ) ;
this . data source = scheduler factory bean . get config time data source ( ) ;
c . move to first ( ) ;
locations = client . namenode . get block locations ( file2 . to string ( ) , 0 , long . max _ value ) ; system . out . println ( locations = + locations . located block count ( ) ) ; assert true ( error blocks were not cleaned up for file + file2 , locations . located block count ( ) = = 1 ) ; } finally {
set sort ( true ) ;
conf . set ( angel conf . angel _ action _ type , mlconf . angel _ ml _ inc _ train ( ) ) ; conf . set ( angel conf . angel _ action _ type , mlconf . angel _ ml _ predict ( ) ) ; lrrunner runner = new lrrunner ( ) ; runner . predict ( conf ) ; } catch ( exception x ) {
for ( integer i = - 10 ; i > = - 15 ; i - - ) { negative two increment size the entity = new negative two increment size ( ) ; session . persist ( the entity ) ; assert equals ( i , the entity . id ) ; }
system . arraycopy ( buf , mark , buf , 0 , buf . length - mark ) ;
collection < class < ? > > local business interfaces = this . get local business interfaces ( deployment unit , session bean class ) ; if ( local business interfaces = null & & local business interfaces . is empty ( ) ) { session bean component description . add local business interface views ( this . to string ( local business interfaces ) ) ; } if ( has no interface view ( session bean class ) ) { session bean component description . add no interface view ( ) ; }
cluster . get primary avatar ( 0 ) . avatar . namesystem . close ( ) ;
if ( badge visible ) { m badge style . style ( view holder . badge , get text color state list ( get color ( ctx ) , get selected text color ( ctx ) ) ) ; view holder . badge container . set visibility ( view . visible ) ; } else { view holder . badge container . set visibility ( view . gone ) ; }
ldaptest utils . assert user imported ( user provider , test realm , user5 , user5 fn , user5 ln , user5 @ email . org , 125 ) ;
long filesize = _ lfile . length ( ) ;
update item ( get auto answer item ( parent menu , 0 ) , true ) ; } }
if ( sroot . is secure processing ( ) ) m _ extensions table = new extensions table ( sroot ) ;
flush mode . apply ( node ) ;
if ( ( out < = 0 ) | | ( out > = _ outbound kbytes per second ) ) _ outbound burst kbytes per second = out ; else _ outbound burst kbytes per second = _ outbound kbytes per second ;
byte [ ] encrypted payload with hmac = encrypt payload with hmac ( payload , secret key ) ;
if ( branch target finder . is subroutine ( offset ) & & branch target finder . is subroutine returning ( offset ) ) {
replab24 : while ( true ) { v _ 19 = cursor ; lab25 : do {
version version = revision = = null ? archive . get revision version ( ) : archive . get revision version ( revision ) ;
texture rock = asset manager . load texture ( textures terrain splat road . jpg ) ; rock . set wrap ( wrap mode . repeat ) ; mat rock . set texture ( tex3 , rock ) ; mat rock . set float ( tex3 scale , rock scale ) ;
current thread . set context class loader ( host class loader ) ; }
ndx = i ; delta = 0 ; break ; } root package + = ' . ' ; if ( action package . starts with ( root package ) ) {
print ( \ t \ t \ t ) ; print field var name ( field info ) ; print ( = ) ; class < ? > field class = field info . field class ; if ( field class . is assignable from ( array list . class ) ) { print ( new java . util . array list ( ) ; ) ; } else if ( field class . is assignable from ( linked list . class ) ) { print ( new java . util . linked list ( ) ; ) ; } else if ( field class . is assignable from ( hash set . class ) ) { print ( new java . util . hash set ( ) ; ) ; } else if ( field class . is assignable from ( tree set . class ) ) { print ( new java . util . tree set ( ) ; ) ; } else { print ( new ) ; print class name ( field class ) ; print ( ( ) ; ) ; } println ( ) ; println ( \ t \ t \ t parse context list context = parser . get context ( ) ; ) ;
users privileges meta data new meta data = users privileges meta data . copy of ( ( users privileges meta data ) md builder . get custom ( users privileges meta data . type ) ) ; long affected rows = new meta data . apply privileges ( request . user names ( ) , request . privileges ( ) ) ;
set managed build revision ( tool . get managed build revision ( ) ) ; set version ( get version from id ( ) ) ; is extension tool = false ;
get menu inflater ( ) . inflate ( org . horaapps . leafpic . r . menu . menu _ video _ player , menu ) ; track selections < mapped track info > track selections = track selector . get current selections ( ) ;
kc adm exec exe = execute ( create realms - - config ' + config file . get name ( ) + ' - s realm = demorealm - s enabled = true ) ; assert exit code and stream sizes ( exe , 0 , 0 , 1 ) ;
builder . set work spec signature ( byte string . copy from ( submit work info . get vertex signature ( ) ) ) ;
log . warn ( max _ field _ value _ chars + ( + max field value chars + ) is less than + max _ total _ chars + ( + max total chars + ) . setting + max _ field _ value _ chars + to + max total chars + . ) ; max field value chars = max total chars ; } } }
assert that ( result . get body ( ) , contains string ( \ status \ : 500 ) ) ; }
string builder sb = null ;
final char [ ] [ ] keys = new char [ m . keys . length ] [ ] ;
gregorian calendar gcl1 = new gregorian calendar ( 2033 , 04 , 18 ) ; pwc1 . sql date = new java . sql . date ( gcl1 . get time in millis ( ) ) ; pwc1 . mixed = new array list < object > ( ) ; map < string value , int value > map = new hash map < > ( ) ; map . put ( new string value ( some key ) , new int value ( 1 ) ) ; pwc1 . mixed . add ( map ) ; pwc1 . mixed . add ( new file ( this is wrong ) ) ; pwc1 . mixed . add ( uhlala ) ; pojo with collection pwc2 = new pojo with collection ( ) ; pwc2 . pojos = pojos list2 ;
ts . assert error ( test exception . class ) ; ts . assert error message ( boo ) ; }
string [ ] concrete indices = new string [ ] { index1 , index2 , index3 } ;
m . append tail ( replace block ) ; return replace block . to string ( ) ; }
byte [ ] region name = location . get region info ( ) . get region name ( ) ; admin . split region ( location . get region info ( ) . get region name ( ) , bytes . to bytes ( bm ) ) ; test end to end split transaction . block until region split ( conf , 60000 , region name , true ) ;
conf . set ( yarn configuration . nm _ docker _ privileged _ containers _ acl , whitelisted user ) ; docker linux container runtime runtime = new docker linux container runtime ( mock executor , mock cgroups handler ) ;
url c . set request property ( user - agent , downloader . get user agent ( ) ) ;
assert that ( bytes ) . is equal to ( java file . to string ( ) . get bytes ( utf _ 8 ) ) ; }
throw new org . apache . axis2 . databinding . adbexception ( group name cannot be null ) ;
assert equals ( 1 , recovered containers . size ( ) ) ;
string [ ] col tosubset = { name , economy } ;
assert empty match ( на пострадянський манер ) ; assert equals ( 1 , rule . match ( lang tool . get analyzed sentence ( вздовж дніпровської вісі ) ) . length ) ; assert equals ( 1 , rule . match ( lang tool . get analyzed sentence ( ніщо так не зближає приморських партизан ) ) . length ) ;
int id = item . get item id ( ) ; if ( id = = r . id . nav _ home ) { hide all frags ( ) ; hide fragment ( all playlists ) ; } else if ( id = = r . id . nav _ local ) { show fragment ( local ) ; } else if ( id = = r . id . nav _ playlists ) { show fragment ( all playlists ) ; } else if ( id = = r . id . nav _ recent ) { show fragment ( recent ) ; } else if ( id = = r . id . nav _ fav ) { show fragment ( favourite ) ; } else if ( id = = r . id . nav _ folder ) { show fragment ( all folders ) ; } else if ( id = = r . id . nav _ view ) { show fragment ( all saved dnas ) ; } else if ( id = = r . id . nav _ settings ) { show fragment ( settings ) ; }
check alter table succeed ( alter table foo drop column num1 ; ) ;
if ( request . get cache key ( ) = = null ) { request . cache key ( http utils . create url from params ( request . get base url ( ) , request . get params ( ) . url params map ) ) ; } if ( request . get cache mode ( ) = = null ) { request . cache mode ( cache mode . no _ cache ) ; } cache mode cache mode = request . get cache mode ( ) ; if ( cache mode = cache mode . no _ cache ) { noinspection unchecked cache entity = ( cache entity < t > ) cache manager . get instance ( ) . get ( request . get cache key ( ) ) ; header parser . add cache headers ( request , cache entity , cache mode ) ; if ( cache entity = null & & cache entity . check expire ( cache mode , request . get cache time ( ) , system . current time millis ( ) ) ) { cache entity . set expire ( true ) ; } } if ( cache entity = = null | | cache entity . is expire ( ) | | cache entity . get data ( ) = = null | | cache entity . get response headers ( ) = = null ) { cache entity = null ; }
final expression responds to validate method call expression = new method call expression ( new variable expression ( param name ) , responds to , new argument list expression ( new constant expression ( validate ) ) ) ; final expression validate method call expression = new method call expression ( new variable expression ( param name ) , validate , new argument list expression ( ) ) ; final statement if responds to validate then validate statement = new if statement ( new boolean expression ( responds to validate method call expression ) , new expression statement ( validate method call expression ) , new expression statement ( new empty expression ( ) ) ) ; final statement if command object is not null then validate = new if statement ( new boolean expression ( new variable expression ( param name ) ) , if responds to validate then validate statement , new expression statement ( new empty expression ( ) ) ) ; wrapper . add statement ( if command object is not null then validate ) ; final string warning message = the [ + action name + ] action accepts a parameter of type [ + command object node . get name ( ) + ] which does not implement grails . validation . validateable . data binding will still be applied + to this command object but the instance will not be validateable . ;
easy mock . expect ( member . member id ( ) ) . and stub return ( member ) ;
} catch ( ioexception e )
assert true ( throttle . higher than ( no ) ) ; assert false ( throttle . higher than ( throttle ) ) ; assert false ( throttle . higher than ( yes ) ) ;
pdu data stream . mark ( 1 ) ;
byte array output stream bos = new byte array output stream ( ) ; object output stream oos = new object output stream ( bos ) ; oos . write object ( cause ) ; oos . flush ( ) ; iohelper . close ( oos , bos ) ; body = bos . to byte array ( ) ;
scan ( true , address . to string ( ) ) ; get region info ( ) ;
cb . release external resources ( ) ; sb . release external resources ( ) ; event executor . shutdown now ( ) ; }
parcel parcel = parcel . obtain ( ) ;
realm realm a = realm cache . create realm or get from cache ( default config , realm . class ) ;
futures . put ( monkey . type ( ) . name ( ) , scheduler . schedule with fixed delay ( command , 0 , frequency ( ) , frequency unit ( ) ) ) ; } else {
for ( control child : custom controls composite . get children ( ) ) { child . dispose ( ) ; } custom toolbar manager . remove all ( ) ;
for ( int i = 0 ; i < cookies . length ; i + + ) { for ( int j = 2 ; j < cookies [ i ] . length ; j + = 2 ) { uri uri = new uri ( cookies [ i ] [ j ] ) ; manager . put ( uri , response headers ) ; } } return manager ;
a velocity = velocity ;
database descriptor . set endpoint snitch ( snitch ) ;
if ( include no compression ) { _ server without compression = rest li int test server . create server ( _ engine , rest li int test server . no _ compression _ port , ) ; _ server without compression . start ( ) ; } init client ( filters _ uri _ prefix ) ;
mapper = new object mapper ( ) ;
cache . clear ( ) ; } finally {
notification event response rsp = ms client . get next notification ( first event id , 0 , null ) ; assert equals ( 1 , rsp . get events size ( ) ) ; notification event event = rsp . get events ( ) . get ( 0 ) ; assert equals ( first event id + 1 , event . get event id ( ) ) ; assert true ( event . get event time ( ) > = start time ) ; assert equals ( event type . create _ function . to string ( ) , event . get event type ( ) ) ; assert equals ( default db name , event . get db name ( ) ) ;
base token stream test case . assert analyzes to ( a , 21 . 35 , new string [ ] { 21 . 35 } ) ;
set request auth ( cite , cite ) ; string path = gwc service wms?bgcolor = 0x000000 & layers = sf : mosaic & styles = & format = image png & service = wms & version = 1 . 1 . 1 + & request = get map & srs = epsg : 4326 & bbox = 0 , - 90 , 180 , 90 & width = 256 & height = 256 & transparent = false ; mock http servlet response response = get as servlet response ( path ) ; assert equals ( image png , response . get content type ( ) ) ;
assert . assert true ( attempt . get master container ( ) . get id ( ) . get container id ( ) = 1 ) ;
attribute mining att = data dictionary . attribute ( name ) ;
assert true ( fs . exists ( p0 ) ) ; int i1 = fstable descriptors . get table info sequenceid ( p1 ) ; assert true ( i1 = = i0 + 1 ) ; path p2 = fstable descriptors . update htable descriptor ( fs , testdir , htd ) ;
pre auth ( ) ; missing auth ( ) ; valid auth ( ) ; valid auth2 ( ) ; }
{ g . set color ( c . get foreground ( ) ) ; g . draw line ( 0 , 0 , s . width , 0 ) ; g . set color ( c . get background ( ) ) ; g . draw line ( 0 , 1 , s . width , 1 ) ; } }
versioned list = compacting mem store . get immutable segments ( ) ; if ( log . is debug enabled ( ) ) { log . debug ( starting the in - memory compaction for store + compacting mem store . get store ( ) . get column family name ( ) ) ; } hstore store = compacting mem store . get store ( ) ;
nextmark = max ; return 0 ;
adapter . on view detached from window ( delegate1 . view holder ) ; assert . assert true ( delegate1 . on view detached from window called ) ; assert . assert false ( delegate2 . on view detached from window called ) ;
string prop value = get provider property ( key , prov ) ; if ( prop value = = null ) { check whether we have an alias instead of a standard name in the key . string standard name = get provider property ( alg . alias . + service name + . + alg name , prov ) ; if ( standard name = null ) { key = service name + . + standard name ; if ( attr name = null ) { key + = ' ' + attr name ; } prop value = get provider property ( key , prov ) ; } if ( prop value = = null ) { the provider doesn ' t have the given key in its property list . return false ; } }
file temp file = file . create temp file ( nosuch , dir ) ;
assert throws ( client ( ) . prepare search ( ) . set query ( more like this query ( new string [ ] { int _ value } , new string [ ] { 42 } , null ) . min term freq ( 1 ) . min doc freq ( 1 ) . fail on unsupported field ( true ) ) , search phase execution exception . class ) ;
return 8afde66ea51d865689083ba6bb779fac ; case mnist :
m _ zk . create ( zkutil . join zkpath ( core zk . readyjoininghosts , integer . to string ( local host id ) ) , null , ids . open _ acl _ unsafe , create mode . persistent ) ; while ( true ) { zkutil . future watcher fw = new zkutil . future watcher ( ) ; int ready hosts = m _ zk . get children ( core zk . readyjoininghosts , fw ) . size ( ) ; if ( ready hosts = = expected hosts ) { break ; } fw . get ( ) ; } } catch ( keeper exception | interrupted exception e ) {
super . send message ( message ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( invalid public key ) ) return null ; invalid public key exception e = ( invalid public key exception ) super . unmarshall ( node ) ; return e ; }
clip view on the right ( bound , w , right ) ;
view pager . set offscreen page limit ( 4 ) ; indicator view pager = new indicator view pager ( indicator , view pager ) ; inflate = layout inflater . from ( get application context ( ) ) ; indicator view pager . set adapter ( adapter ) ; indicator view pager . set current item ( 5 , false ) ; }
is para start = is para end ;
if ( perm model . may set flag ( existing , flag ) ) { continue ; } flag list . add ( flag . get name ( ) ) ;
notify all ( ) ;
call stack dummy call stack = new call stack dummy ( ) ;
unitcode = byte . parse byte ( ids [ 1 ] ) ;
assert equals ( baos . to string ( ) , hellohello again ) ;
long time taken = watch . taken ( ) ;
float delta = math . max ( math . abs ( x - prev rot . euler angles . x ) , math . abs ( y - prev rot . euler angles . y ) ) ; delta = math . max ( delta , math . abs ( z - prev rot . euler angles . z ) ) ;
endpoints = tmd . get write endpoints ( key tokens . get ( 8 ) , keyspace name , strategy . get natural endpoints ( key tokens . get ( 8 ) ) ) ;
if ( + + count = = max _ run _ count ) { sort ( a , left , right , true ) ; return ; }
case channel _ powerzone3 : if ( command instanceof on off type ) { send command ( eiscp command . zone3 _ power _ set , command ) ; } else if ( command . equals ( refresh type . refresh ) ) { send command ( eiscp command . zone3 _ power _ query ) ; } break ; case channel _ mutezone3 : if ( command instanceof on off type ) { send command ( eiscp command . zone3 _ mute _ set , command ) ; } else if ( command . equals ( refresh type . refresh ) ) { send command ( eiscp command . zone3 _ mute _ query ) ; } break ; case channel _ volumezone3 : handle volume set ( eiscp command . zone . zone3 , volume level zone3 , command ) ; break ; case channel _ inputzone3 : if ( command instanceof decimal type ) { send command ( eiscp command . zone3 _ source _ set , command ) ; } else if ( command . equals ( refresh type . refresh ) ) { send command ( eiscp command . zone3 _ source _ query ) ; } break ;
idx + + ; case ' { ' :
data fetcher < ? > local fetcher = current fetcher ;
expect ( mapred _ job _ tracker , local ) ;
final message msg = new message ( addr ) . set flag ( message . flag . internal , message . flag . dont _ bundle , message . flag . oob ) . put header ( this . id , hdr ) ; if ( data = null ) msg . set buffer ( marshal ( data ) ) ; if ( async _ discovery _ use _ separate _ thread _ per _ request ) timer . execute ( ( ) - > send discovery request ( msg ) , sends _ can _ block ) ; else send discovery request ( msg ) ;
extension stack . configure ( parser ) ; extension stack . configure ( generator ) ;
test subscriber . assert received on next ( deliveries ) ; subscription . unsubscribe ( ) ; assert false ( subject . has observers ( ) ) ; assert false ( view . has observers ( ) ) ; }
selection changed ( e . get old lead selection path ( ) , e . get new lead selection path ( ) ) ;
throw new persistence exception ( soft index file store is limited to keys with serialized size < = 32767 bytes ) ;
object o = args . get ( defaults ) ;
init ( zk host , checkpoint collection name , collection name , ( ( stream expression value ) id param . get parameter ( ) ) . get value ( ) , initial checkpoint , checkpoint every , params ) ;
topology api . stream id stream = tuples . get data ( ) . get stream ( ) ;
if ( info . icon bitmap = = null ) { info . icon bitmap = m icon cache . get default icon ( info . user ) ; }
cookie encoder http cookie encoder = new cookie encoder ( false ) ; http cookie encoder . add cookie ( my - cookie , foo ) ; http cookie encoder . add cookie ( another - cookie , bar ) ; request . set header ( http headers . names . cookie , http cookie encoder . encode ( ) ) ;
icon icon = icon . create with bitmap ( action . icon bitmap ) ;
test types ( * * @ constructor * function a ( ) { } ; + a . prototype . foo = 3 ; + * * @ return { string } * a . bar = function ( ) { return this . foo ; } ; ) ;
tv command string = provider . get tvcommand ( item name , command . to string ( ) ) ;
this . swift delegate = optional . of ( swift delegate ) ; this . platform flavors to apple cxx platforms = platform flavors to apple cxx platforms ; this . code sign identity store = code sign identity store ; this . provisioning profile store = provisioning profile store ; this . apple config = apple config ; }
q . clear sorts ( ) ;
if ( ner string . equals ( o ) & & m . ner string . equals ( o ) & & ner string . equals ( m . ner string ) & & ( included ( head word , m . original span ) | | included ( m . head word , original span ) ) ) { return true ; } return head string . equals ( m . head string ) ;
assert . assert equals ( expected , feed utils . to absolute url ( . . blog entry 1 , http : a . com feed , http : a . com feed ) ) ;
if ( null = = image view ) { cleanup ( ) ; throw new illegal state exception ( image view no longer exists . you should not use this photo view attacher any more . ) ; } return image view ; }
iterator < ? extends call peer > iter = source call . get call peers ( ) ;
shadow connectivity manager . clear all networks ( ) ;
try { returned object = after invocation manager . decide ( token . get security context ( ) . get authentication ( ) , token . get secure object ( ) , token . get attributes ( ) , returned object ) ; } catch ( access denied exception access denied exception ) { authorization failure event event = new authorization failure event ( token . get secure object ( ) , token . get attributes ( ) , token . get security context ( ) . get authentication ( ) , access denied exception ) ; publish event ( event ) ; throw access denied exception ; }
protobuf input row parser parser = new protobuf input row parser ( parse spec , prototest . desc , proto test event ) ; }
view . set on click listener ( new view . on click listener ( ) { @ override public void on click ( view view ) { get container ( ) . on clicked empty background ( ) ; } } ) ; return view ; }
text view text view = ( text view ) view . find view by id ( r . id . text ) ; m circle drawable = new circle ( ) ; m circle drawable . set bounds ( 0 , 0 , 100 , 100 ) ; m circle drawable . set color ( color . white ) ; text view . set compound drawables ( null , null , m circle drawable , null ) ; text view . set background color ( colors [ 2 ] ) ;
postings enum postings = get only leaf reader ( reader ) . postings ( new term ( foo , bar ) ) ; assert equals ( - 1 , postings . doc id ( ) ) ; assert equals ( 0 , postings . next doc ( ) ) ; assert equals ( 1 , postings . freq ( ) ) ; assert equals ( doc id set iterator . no _ more _ docs , postings . next doc ( ) ) ;
r1 . pause ( ) ;
float fv = ( float ) instance . get values ( ) [ i ] ;
assert analyzes to ( a , brown fox , new string [ ] { brown , fox } ) ; assert analyzes to ( a , the fox , new string [ ] { the _ fox } ) ; assert analyzes to ( a , fox of , new string [ ] { fox _ of } ) ; assert analyzes to ( a , of the , new string [ ] { of _ the } ) ;
list < page element > pages = new array list < > ( ) ; pages . add ( import page ( any source . xml ) ) ; pages . add ( import page ( choices . xml ) ) ; choice page = choice . create singletons ( pages ) ;
while ( results [ 0 ] . advance row ( ) ) { if ( results [ 0 ] . get string ( table _ name ) . equals ( item ) ) { rowcount + = results [ 0 ] . get long ( tuple _ count ) ; } }
this . lock . write lock ( ) . lock ( ) ;
assert . assert equals ( task count - 1 , executor . get queue ( ) . size ( ) ) ; for ( int i = 0 ; i < task count ; i + + ) { if ( executor . get completed task count ( ) < task count ) { sleep ( 100 ) ; } } assert . assert equals ( task count , executor . get completed task count ( ) ) ; }
thread [ ] writers = new thread [ num writers ] ; for ( int i = 0 ; i < writers . length ; i + + ) { final path p = new path ( writer + i ) ; writers [ i ] = new thread ( new runnable ( ) { @ override public void run ( ) { try { file system fs = cluster . get file system ( ) ; fsdata output stream os = fs . create ( p , true , buf . length , ( short ) repl , blk size ) ;
truncate table ( utility1 , table name ) ;
map < long , patch request < greeting > > patched greetings diffs = new hash map < long , patch request < greeting > > ( ) ; list < greeting > patched greetings = new array list < greeting > ( ) ; for ( greeting greeting : greetings ) { greeting patched greeting = new greeting ( greeting . data ( ) . copy ( ) ) ; patched greeting . set message ( patched greeting . get message ( ) . to upper case ( ) ) ; patch request < greeting > patch request = patch generator . diff ( greeting , patched greeting ) ; patched greetings diffs . put ( patched greeting . get id ( ) , patch request ) ; patched greetings . add ( patched greeting ) ; }
check valid ( this . data ) ; this . data = sb . to string ( ) ; return len ; }
set cell builder . set timestamp micros ( system . current time millis ( ) * 1000 ) ;
node to source topics . put ( string pattern entry . get key ( ) , source node . get topics ( subscription updates . get updates ( ) ) ) ;
sla . add state ( new int [ ] { android . r . attr . enabled } , object animator . of float ( view , elevation , elevation ) . set duration ( dur ) ) ;
vertices [ v idx ] . set input ( input num , out ) ; } } } } }
state machine config cache . clear payment state machine config ( plugin name , multi tenant context ) ;
if ( serializers . is enabled ( serialization feature . write _ enums _ using _ to _ string ) ) { gen . write string ( en . to string ( ) ) ; return ; }
string argv0 = modified argv . get ( 0 ) ;
_ _ isset _ bit _ vector = new bit set ( 1 ) ; read ( new org . apache . thrift . protocol . tcompact protocol ( new org . apache . thrift . transport . tiostream transport ( in ) ) ) ; } catch ( org . apache . thrift . texception te ) {
volt table stats t = get stats ( client , procedure ) ; system . out . println ( stats : + stats t . to formatted string ( ) ) ; assert true ( volt table util . table contains string ( stats t , ntproc with futures , true ) ) ;
if ( input locations . size ( ) > max _ distinct _ locations _ to _ consider ) { input locations . clear ( ) ; break ; }
cur line . add ( new rectangle ( start col , row , w - start col , 1 ) ) ; } set < rectangle > unmerged = merge rects ( prev line , cur line ) ; rects . add all ( unmerged ) ; prev line = cur line ; }
long time part = i chronology . get millis of day ( instant ) ; int this year = i chronology . get year ( instant ) ; int this month = i chronology . get month of year ( instant , this year ) ; long year to use ;
icc cs = null ; warning occurred ( warning _ ignore _ invalid _ icc ) ; return ; }
animator . start ( ) ;
m navigation view . set navigation item selected listener ( null ) ;
field . highlighter type ( plain ) . no match size ( null ) ; response = client ( ) . prepare search ( test ) . highlighter ( new highlight builder ( ) . field ( field ) . no match size ( 21 ) ) . get ( ) ; assert highlight ( response , 0 , text , 0 , 1 , equal to ( i am pretty long so ) ) ; field . highlighter type ( fvh ) ; response = client ( ) . prepare search ( test ) . highlighter ( new highlight builder ( ) . field ( field ) . no match size ( 21 ) ) . get ( ) ; assert highlight ( response , 0 , text , 0 , 1 , equal to ( i am pretty long so some ) ) ;
list < dbus event > dbus events = new array list < dbus event > ( ) ; list < string > keys = new array list < string > ( ) ; for ( long i = 0 ; i < 1000 ; + + i ) { keys . add ( new long ( i ) . to string ( ) ) ; } generate string events ( 1000 , ( short ) 1 , keys , dbus events ) ;
compression codec factory ccf = new compression codec factory ( conf ) ;
create items table if not ( new items vo ( ) ) ;
throw new illegal argument exception ( unknown collection expression type [ + collection expression . get class ( ) . get name ( ) + ] ) ;
file dummy file = new file ( m context . get cache dir ( ) , m base directory name ) ; assert . assert true ( dummy file . create new file ( ) ) ; assert . assert true ( dummy file . exists ( ) ) ; supplier . create root directory if necessary ( base dir ) ; assert . assert true ( base dir . exists ( ) ) ; assert . assert true ( base dir . is directory ( ) ) ;
value = image map . get ( thumbnail ) ; assert type ( value , map . class ) ; map < ? , ? > tn map = ( map < ? , ? > ) value ; assert equals ( 3 , tn map . size ( ) ) ; assert equals ( integer . value of ( sample _ spec _ value _ tn _ height ) , tn map . get ( height ) ) ;
return defined in3rd party class ( ps , new class member ( teh class ) , qn . get name ( ) . to string ( ) ) ; } log ( qn resolve 3rd par , can ' t resolve + qn . get qualifier ( ) ) ; return null ; } log ( qn , sn local type + get node as string ( stp ) ) ;
rule dto rule3 = db client . rule dao ( ) . select or fail by key ( db tester . get session ( ) , default organization , rule _ key3 ) ; assert that ( rule3 ) . is not null ( ) ; assert that ( rule3 . get status ( ) ) . is equal to ( rule status . ready ) ;
assert equals ( 1 l + 1 , exec ( return 1 l + 1 ; ) ) ;
for ( node node : marker stack ) { compiler . report ( jserror . make ( node , unmatched _ start _ marker , start marker name ) ) ; }
boolean quick stop = false ; if ( is allow quick stop ( ) & & endpoint . is accept messages while stopping ( ) ) { quick stop = endpoint . get camel context ( ) . get status ( ) . is stopping ( ) ; } if ( quick stop ) { log at debug level so its quicker to see we are stopping quicker from the logs logger . debug ( running allowed ( ) - > false due camel context is stopping and endpoint configured to not accept messages while stopping ) ; return false ; } else { otherwise we only run if the endpoint is running boolean answer = endpoint . is running ( ) ; log at trace level as otherwise this can be noisy during normal operation logger . trace ( running allowed ( ) - > + answer ) ; return answer ; }
release view for pointer up ( ) ;
target scroll x - = m title offset ;
result = client . call procedure ( select , allow _ nulls , pkey . get ( ) ) . get results ( ) ;
this . pkgs . remove ( pkg . get name ( ) ) ; pkg . get dialect runtime registry ( ) . on remove ( ) ;
empty activity without layout context = setup activity ( empty activity without layout _ . class ) ;
assert . assert equals ( batch status . stopped , execution . get batch status ( ) ) ;
sky key top key = graph tester . sky key ( top ) ; tester . get or create ( top key ) . add dependency ( cached error key ) . set computed value ( concatenate ) ;
s = a . create state ( ) ;
int horiz dir = avoidee . center ( ) . get x ( ) - container . center ( ) . get x ( ) ;
final string method = get ; headers . add ( : method , method ) ; final string value = headers . get as string ( spdy headers . http names . method . to string ( ) ) ; assert not null ( value ) ; assert equals ( method , value ) ; final string value2 = headers . get as string ( spdy headers . http names . method ) ;
assert false ( is annotation declared locally ( transactional . class , non annotated interface . class ) ) ; assert false ( is annotation declared locally ( transactional . class , non annotated class . class ) ) ;
for ( store flusher flusher : store flushers ) { boolean needs compaction = flusher . commit ( status ) ; if ( needs compaction ) { compaction requested = true ; } } store flushers . clear ( ) ;
- - stack size ;
parent property . set value ( updated online resources ) ; }
assert that ( term : + string0 , iter0 . doc freq ( ) , equal to ( iter1 . doc freq ( ) ) ) ; assert that ( term : + string0 , iter0 . total term freq ( ) , equal to ( iter1 . total term freq ( ) ) ) ;
log . trace ( collection is already being initialized ; ignoring row ) ; return null ;
mock rm rm = new mock rm ( get configuration with queue labels ( conf ) ) { @ override public rmnode labels manager create node label manager ( ) { return mgr ; } } ; rm . get rmcontext ( ) . set node label manager ( mgr ) ; rm . start ( ) ; mock nm nm1 = rm . register node ( h1 : 1234 , 2048 ) ; mock nm nm2 = rm . register node ( h2 : 1234 , 2048 ) ; mock nm nm3 = rm . register node ( h3 : 1234 , 2048 ) ; container id container id ;
long expires in = token . expiration date - system . current time millis ( ) ; long renew in = token . expiration date - expires in 10 ; little bit before the expiration
logger . log ( level . info , failed testing reachability of + ip address + , ignoring address , e ) ; return false ;
short in use unsigned byte = ( short ) ( ( record . in use ( ) ? record . in _ use : record . not _ in _ use ) . byte value ( ) | first node mod | next prop mod ) ;
slot . was deleted = true ; slot . value = null ; slot . name = null ; return new slot ;
map < string , shard node > all shard nodes = new hash map < string , shard node > ( ) ; list < string > root shards = generate shards ( 5 , 100 , 10 , all shard nodes ) ; list < shard node > order shards = new array list < shard node > ( all shard nodes . values ( ) ) ;
skip = false ;
if ( delta in seconds < ping interval ) { maybe schedule ping server task ( delta in seconds ) ; return ; }
m = mapper . convert value ( plaino , map . class ) ; assert not null ( m ) ; assert equals ( 0 , m . size ( ) ) ; }
if ( resource . get namespace ( ) = null ) { if ( workspace name . equals ( resource . get namespace ( ) . get prefix ( ) ) ) { throw new rest exception ( expected workspace + workspace name + but client specified + resource . get namespace ( ) . get prefix ( ) , http status . forbidden ) ; } } else { resource . set namespace ( catalog . get namespace by prefix ( workspace name ) ) ; }
assert null ( end exchange . get property ( property name , string . class ) ) ;
string builder . set length ( string builder . length ( ) - 1 ) ;
primary . next ( extra value ) ;
waiting on receive for zero queue size = true ;
assert equals ( x , host and port . from string ( x ) . require brackets for ipv6 ( ) . get host ( ) ) ;
file system . set faulty delete ( new file ( cache dir , a . 0 ) , false ) ; cache . evict all ( ) ; set ( c , cc , cc ) ; assert value ( c , cc , cc ) ; }
final naming enumeration search results = new basic attributes ( , null ) . get all ( ) ; when ( dir ctx . search ( eq ( cn = bob , ou = people ) , eq ( ( user password = { 0 } ) ) , any ( object [ ] . class ) , any ( search controls . class ) ) ) . then return ( search results ) ; authenticator . authenticate ( new username password authentication token ( bob , bobspassword ) ) ; }
expected exception . expect ( unsupported operation exception . class ) ;
log . fatal ( master server abort : loaded coprocessors are : + get loaded coprocessors ( ) ) ; }
if ( subject = = null | | subject . is empty ( ) ) { put extra ( intent , subject , activity . get string ( r . string . msg _ default _ mms _ subject ) ) ; } else { put extra ( intent , subject , subject ) ; }
instructions . add ( reil helpers . create or ( offset , size , source register , size , target register , size , or result ) ) ;
for ( numbering . num num node : numbering . get num ( ) ) { list numbering definition list def = new list numbering definition ( num node , abstract list definitions ) ; instance list definitions . put ( list def . get list number id ( ) , list def ) ; log . debug ( added list : + list def . get list number id ( ) ) ; }
@ suppress warnings ( serial ) map < string , object > cluster variants = new hash map < string , object > ( ) { { put ( cluster1 , new hash map < string , object > ( ) ) ; put ( cluster2 , new hash map < string , object > ( ) ) ; } } ; services . put ( cluster variants , cluster variants ) ;
get nodes to labels response response1 = client . get node to labels ( get nodes to labels request . new instance ( ) ) ; map < node id , set < string > > node to labels = response1 . get node to labels ( ) ; assert . assert true ( node to labels . key set ( ) . contains all ( arrays . as list ( node1 , node2 ) ) ) ; assert . assert true ( node to labels . get ( node1 ) . contains all ( arrays . as list ( label x . get name ( ) ) ) ) ; assert . assert true ( node to labels . get ( node2 ) . contains all ( arrays . as list ( label y . get name ( ) ) ) ) ;
limiter . set next refill time ( limiter . get next refill time ( ) - 3000 ) ;
multi part email multi part email = commonsmail helper . create multi part email with content ( mail ) ;
long no of rows deleted = invoke bulk delete protocol ( table name , scan , 500 , delete type . version , hconstants . latest _ timestamp ) ; assert equals ( 100 , no of rows deleted ) ; int rows = 0 ; scan = new scan ( ) ; scan . set max versions ( ) ; for ( result result : ht . get scanner ( scan ) ) { assert equals ( 3 , result . get family map ( family1 ) . size ( ) ) ; list < key value > column = result . get column ( family1 , qualifier1 ) ; assert equals ( 1 , column . size ( ) ) ; assert true ( bytes . equals ( v1 . get bytes ( ) , column . get ( 0 ) . get value ( ) ) ) ; column = result . get column ( family1 , qualifier2 ) ; assert equals ( 1 , column . size ( ) ) ; assert true ( bytes . equals ( v1 . get bytes ( ) , column . get ( 0 ) . get value ( ) ) ) ; column = result . get column ( family1 , qualifier3 ) ; assert equals ( 1 , column . size ( ) ) ; assert true ( bytes . equals ( v1 . get bytes ( ) , column . get ( 0 ) . get value ( ) ) ) ; rows + + ; } assert equals ( 100 , rows ) ;
if ( e . get message ( ) = null & & e . get message ( ) . contains ( already exists ) ) { throw new runtime exception ( unable to set up transaction database for + testing : + e . get message ( ) , e ) ; } } }
key . get ( collection of ( types . javax provider of ( map entry of ( string . class , types . provider of ( string . class ) ) ) ) ) ,
fi . set folder background ( m folder create bg ) ;
mockito . do return ( server defaults with dummy key provider ) . when ( mock client ) . get server defaults ( ) ; assert . assert equals ( key provider uri from client doesn ' t match with uri from namenode , dummy key provider uri2 , mock client . get key provider uri ( ) . to string ( ) ) ; mockito . verify ( mock client , mockito . times ( 2 ) ) . get server defaults ( ) ; }
assert true ( inherits . get age ( ) = = 1 ) ; }
if ( attr qname . starts with ( xmlns : ) | | attr qname . equals ( xmlns ) ) { attr ns = http : www . w3 . org 2000 xmlns ; }
collection < uri > edits dirs = fsnamesystem . get namespace edits dirs ( conf ) ;
string str = package org . drools . test ; \ n + \ n + global java . util . list list ; \ n + \ n + rule \ base \ \ n + when \ n + string ( this = = \ go \ ) \ n + then \ n + end \ n + ; string str2 = package org . drools . test ; \ n + global java . util . list list ; \ n + \ n + rule \ ext yes \ extends \ ase \ \ n + when \ n + then \ n + list . add ( 1 ) ; \ n + end \ n ;
long delta ms = time . monotonic now ( ) - creation time ms ;
if ( m header container = = null ) m header container = find view by id ( r . id . fab _ _ header _ container ) ;
internal operation service op service = node engine . get operation service ( ) ;
thread . current thread ( ) . set context class loader ( bin loader ) ; class < ? > clazz = class . for name ( proxy . test a1 , false , bin loader ) ; result r = run unguarded ( clazz , create proxy ) ; class < ? > clazz for interface = class . for name ( proxy . test intface a1 , false , bin loader ) ;
final tuple2 < integer , string > rec = new tuple2 < > ( ) ;
acknowledge pages ( sequence id ) ;
if ( is on & & ( bytes read = - 1 ) ) { digest . update ( b , off , bytes read ) ; }
tuple2 < org . apache . hadoop . fs . path , string > bootstrap = create file and fill with data ( test base path , file , no _ of _ files + 1 , this is test line . ) ; assert . assert true ( hdfs . exists ( bootstrap . f0 ) ) ; final set < string > files to be read = new tree set < > ( ) ;
if ( m temp lane info . is undefined ( ) ) { lanes . find lane ( m temp lane info , get lane span for position ( i ) , direction . end ) ; entry . set lane ( m temp lane info ) ; } lanes . get child frame ( m temp rect , get child width ( entry . col span ) , get child height ( entry . row span ) , m temp lane info , direction . end ) ;
registry . put ( blue , new sample language ( false ) ) ; registry . put ( blue - language , new sample language ( true ) ) ; context . start ( ) ; }
misc utilities . save backup ( file , 5 , null , , backup dir ) ;
eg . get termination future ( ) . get ( 2000 , time unit . milliseconds ) ;
n . set input ( this . con2node , this . default data exchange mode ) ;
trigger param trigger param = new trigger param ( ) ;
splits . add ( new data driven dbinput format . data driven dbinput split ( low clause prefix + start . to string ( ) , col name + < = + end . to string ( ) ) ) ; } else {
permission request . get permission callback ( ) . permission granted ( ) ; } else { permission request . get permission callback ( ) . permission refused ( ) ; } permission requests . remove ( request result ) ; }
final http servlet request impl hreq = exchange . get attachment ( servlet request context . attachment _ key ) . get original request ( ) ;
final executor service executor service = executors . new fixed thread pool ( 8 ) ;
test default imports & = type . has package name ( ) ;
map < string , integer > roundtrip = mapper . convert value ( input , new type reference < tree map < string , integer > > ( ) { } ) ;
ct method method = ct new method . copy ( intf method , target ct , null ) ; string modified body = method body ;
if ( encoded . readable bytes ( ) < name length ) { encoded . reset reader index ( ) ; return ; }
if ( stream id . get stream kind ( ) = = row _ group _ dictionary ) { switch ( type ) { case string : case varchar : case char : case binary : return new byte array input stream ( input stream ) ; } }
if ( string utils . is empty ( this . field name ) ) { id = id . concat ( - ) . concat ( xml utils . convert id ( field name . to lower case ( ) ) ) ; }
for ( solr input document d : doc ) { client . add ( d ) ; } client . commit ( ) ; assert num found ( * : * , 3 ) ; make sure it got in
final size desired = get desired preview size ( is rotated ) ; return preview scaling strategy . get best preview size ( sizes , desired ) ;
if ( m = = null ) methods . put ( name , method ) ; else if ( m instanceof bsh method ) { is the new method overriding the old method? if ( arrays . equals ( ( ( bsh method ) m ) . get parameter types ( ) , method . get parameter types ( ) ) ) { methods . put ( name , method ) ; } else { vector v = new vector ( ) ; v . add element ( m ) ; v . add element ( method ) ; methods . put ( name , v ) ; } } else { vector _ methods = ( vector ) m ; for ( int i = 0 ; i < _ methods . size ( ) ; i + + ) { check whether the new method overrides some old method in the list . bsh method _ old _ m = ( bsh method ) _ methods . get ( i ) ; if ( arrays . equals ( _ old _ m . get parameter types ( ) , method . get parameter types ( ) ) ) { _ methods . remove ( i ) ; break ; } } _ methods . add element ( method ) ; }
while ( parent = null ) { if ( parent instanceof web application context & & ( parent . get parent ( ) instanceof web application context ) ) { servlet context = ( ( web application context ) parent ) . get servlet context ( ) ; break ; } parent = parent . get parent ( ) ; }
m _ global import list [ j - - ] . recompose imports ( ) ; } }
if ( result . get ssl context parameters ( ) = = null ) { result . set ssl context parameters ( retrieve global ssl context parameters ( ) ) ; } return result ;
executions = runtime service . create execution query ( ) . variable value less than or equal ( double var , 55555 . 5555 ) . list ( ) ; assert equals ( 3 , executions . size ( ) ) ; assert equals ( 0 , runtime service . create execution query ( ) . variable value less than or equal ( double var , 12344 . 6789 ) . count ( ) ) ;
refresh authorization policy protocol refresh protocol = name node proxies . create proxy ( conf , file system . get default uri ( conf ) , refresh authorization policy protocol . class ) . get proxy ( ) ;
if ( utils . is implementing marker interface ( class element ) ) { utils . error ( a realm class annotated object must implement realm model or derive from realm object . , class element ) ; return false ; }
int initial stack size = stack size ;
return hs2 connection file utils . get url ( hive site connection properties ) ;
if ( clear history ) { this . clear history ( ) ; }
for ( metrics tag t : tags ) { if ( t . info ( ) = = ms info . context ) { return t . value ( ) ; } } return default _ context ; }
some props . put ( key1 , value123 ) ;
qjm = create injectable qjm ( cluster ) ; long last recovered txn = qjmtest util . recover and return last txn ( qjm ) ; assert true ( last recovered txn > = last acked txn ) ; write segment ( cluster , qjm , last recovered txn + 1 , 3 , true ) ; } catch ( throwable t ) {
string key = bssid + ssid ; scan result = m scan result cache . get ( key ) ; if ( scan result = null ) { scan result . level = level ; scan result . ssid = ssid ; scan result . capabilities = flags ; scan result . frequency = frequency ; } else {
h + = filt . hash code ( ) ;
if ( policies . use active map only ( ) ) throw poa . invocation wrapper ( ) . policy mediator bad policy in factory ( ) ;
eviction in progress = true ; try { if the cache has reached a threshold size , then free old entries . long cur size = cache size . get ( ) ; how much to evict in one iteration long target size = cache size max - ( cache size max * cache evict percent ) 100 ; if ( log . is debug enabled ( ) ) { log . debug ( cache size + cur size + has exceeded the + maximum configured cacpacity + cache size max + . eviction has to reduce cache size to + target size ) ; } sort all entries based on their access times collection < cache entry > values = cache map . values ( ) ; cache entry [ ] records = values . to array ( new cache entry [ values . size ( ) ] ) ; arrays . sort ( records , lru _ comparator ) ; for ( int i = 0 ; i < records . length ; i + + ) { if ( cache size . get ( ) < = target size ) { break ; we reclaimed everything we wanted to } cache entry c = records [ i ] ; evict cache ( c . hdfs path ) ; } } finally { eviction in progress = false ; eviction done . }
assert equals ( execution state . canceled , task . get execution state ( ) ) ; assert true ( task . is canceled or failed ( ) ) ; assert null ( task . get failure cause ( ) ) ; validate task manager state change ( execution state . running , task , false ) ;
set read only ( read only before attached to session ) ;
check update remote control display _ sync af rcs ( rc _ info _ all ) ; } } } }
processor . process ( exchange ) ; } catch ( exception e ) {
for ( int i = 0 ; i < 9 ; i + + ) { assert array equals ( 10 fold of 11 elements : + i + - th failed , ar ( i , 1 l ) , nfold ( 11 , 10 , i ) ) ; }
dump emitter writer reader consumer state ( event producer , writer , reader , consumer , emitter stats , stream stats , client stats , dst test events , prod event buffer , cons event buffer ) ;
addr map . put ( addr , true ) ;
string project key2 = new project key ( ) ;
value = new der value ( ) ; return ; }
index request request = new index all project ( project , this ) ; if ( is job waiting ( request ) ) return ; }
for ( actor ref tm : cluster . get task managers as java ( ) ) { tm . tell ( poison pill . get instance ( ) , null ) ; }
site settings table . save settings ( m settings ) ;
list < acl entry > acl spec = lists . new array list ( acl entry ( access , user , fs action . read _ execute ) , acl entry ( access , group , fs action . read _ execute ) , acl entry ( access , other , fs action . read _ execute ) , acl entry ( access , user , user name , fs action . all ) ) ;
assert equals ( test _ size - 1 , results . last ( ) . get field long ( ) ) ; realm results < all java types > reverse list = realm . where ( all java types . class ) . find all sorted ( all java types . field _ long , sort . descending ) ; assert equals ( test _ size , reverse list . size ( ) ) ;
user user from cache = ( user ) cache . get ( 1 ) ; assert user ( user from cache ) ;
m _ model . node structure changed ( m _ root node ) ; final list < idrop handler > handlers = new array list < idrop handler > ( ) ;
thread local . with initial ( thread . current thread ( ) : : get id ) ; } return select slot ( thread local random . current ( ) . next int ( ) ) ; } ) ; }
if ( track = = null ) { input . skip fully ( content size - block track number length ) ; block state = block _ state _ start ; return ; } if ( block state = = block _ state _ header ) {
test results cache . put ( get key ( test result root dto . get result path ( ) ) , results root ) ; return test result root dto ;
if ( mytxid < = synctxid ) { return ; }
try { transfer plugin plugin = plugins . get ( plugin id , transfer plugin . class ) ; if ( plugin = = null ) { throw new storage exception ( link contains unknown connection type ' + plugin id + ' . corresponding plugin not found . ) ; } class < ? extends transfer settings > plugin transfer settings class = transfer plugin util . get transfer settings class ( plugin . get class ( ) ) ; transfer settings transfer settings = new persister ( ) . read ( plugin transfer settings class , plugin settings ) ; logger . log ( level . info , ( decrypted ) link contains : + plugin id + - - + plugin settings ) ; return transfer settings ; } catch ( exception e ) { throw new storage exception ( e ) ; }
toast . make text ( context , r . string . only _ queue _ no _ pic , toast . length _ short ) . show ( ) ; return false ;
throw new planning error exception ( column + col . get name ( ) + has no default and is not nullable . ) ; }
transaction . get parameter ( ) . add ( ecore util . copy ( param ) ) ; }
osleep statement jjtn000 = new osleep statement ( jjtsleepstatement ) ; boolean jjtc000 = true ; jjtree . open node scope ( jjtn000 ) ; jjtn000 . jjt set first token ( get token ( 1 ) ) ; try { jj _ consume _ token ( sleep ) ; jjtn000 . millis = integer ( ) ; jjtree . close node scope ( jjtn000 , true ) ; jjtc000 = false ; jjtn000 . jjt set last token ( get token ( 0 ) ) ; { if ( true ) return jjtn000 ; } } catch ( throwable jjte000 ) { if ( jjtc000 ) { jjtree . clear node scope ( jjtn000 ) ; jjtc000 = false ; } else { jjtree . pop node ( ) ; } if ( jjte000 instanceof runtime exception ) { { if ( true ) throw ( runtime exception ) jjte000 ; } } if ( jjte000 instanceof parse exception ) { { if ( true ) throw ( parse exception ) jjte000 ; } } { if ( true ) throw ( error ) jjte000 ; } } finally { if ( jjtc000 ) { jjtree . close node scope ( jjtn000 , true ) ; jjtn000 . jjt set last token ( get token ( 0 ) ) ; } }
int skipped = 0 ;
if ( obj class = = object stream class . classclass ) { return write new class ( ( class < ? > ) object , unshared ) ; }
test result expected test result = new test result ( ) ; expected test result . winners last database version header = test database util . create map with machine key ( new string [ ] { a , a ( a6 , c4 ) t = 19 } ) . first entry ( ) ;
json serializer < object > ser = _ serializer ; if ( ser = = null ) { class < ? > cls = value . get class ( ) ; property serializer map map = _ dynamic serializers ; ser = map . serializer for ( cls ) ; if ( ser = = null ) { ser = _ find and add dynamic ( map , cls , prov ) ; } }
assert count ( 0 , v . query ( ) . direction ( both ) . has ( adjacent , 110111 ) . edges ( ) ) ;
tester . ws client ( ) . roots ( ) . set root ( user1 . get login ( ) ) ;
current error message = error message . substring ( last match end ) . trim ( ) ;
final int start = math . max ( 0 , current position - check _ position _ search _ distance ) ; final int end = math . min ( current position + check _ position _ search _ distance , item count ) ; boolean found = false ;
is = new url ( image path ) . open stream ( ) ; }
assert . assert false ( error latch . await ( 2 * timeout , time unit . milliseconds ) ) ;
if ( retry . equals ( speculative retry param . none ) | consistency level = = consistency level . each _ quorum ) return new never speculating read executor ( keyspace , cfs , command , consistency level , target replicas , query start nano time , false ) ;
else { int prev phys line = line info [ first screen line - 1 ] . physical line ; if - 1 , the empty space at the end of the text area when the buffer has less lines than are visible if ( prev phys line = = - 1 ) return - 1 ; else { return text area . display manager . get next visible line ( prev phys line ) ; }
for ( blaze java compiler plugin plugin : plugins ) { plugin . post flow ( env ) ; }
m track index = m muxer . add track ( new format ) ; m muxer . start ( ) ; m muxer started = true ; } else if ( encoder status < 0 ) { log . w ( tag , unexpected result from encoder . dequeue output buffer : + encoder status ) ;
buffer . limit ( buffer . limit ( ) - 1 ) ; return super . offer ( buffer . slice ( ) , callback ) ; } } ; request . get input stream ( ) . set read listener ( new read listener ( request , response , proxy request , provider ) ) ; return provider ; } } ; }
start x + = dip8 * ratio ;
class < ? > clazz = injectee . get injectee class ( ) ;
throw new illegal argument exception ( sm . get string ( uri template . empty segment , path ) ) ;
assert equals ( 2 , fire count ) ; kbase . add packages ( load knowledge packages ( test _ jbrules _ 2206 _ 2 . drl ) ) ;
for ( int i = 0 ; i < old inactive counts . length ( ) ; i + + ) { inactive counts . lazy set ( i , old inactive counts . get ( i ) ) ; } if ( old normalized zero index = 0 ) {
_ future = e . get future ( ) ;
for ( int i = 0 ; i < array . get length ( i to remove ) ; + + i ) { object o = array . get ( i to remove , i ) ; if ( is multi value ( o ) ) remove ( coll , o , i all occurrences ) ; else remove from ocollection ( i object , coll , o , i all occurrences ) ; } } else if ( i to remove instanceof map < ? , ? > ) {
assert false ( test modified time ( dest folder , dest last modified time ) ) ;
impl . add action listener ( new action listener ( ) { @ override public void action performed ( action event e ) { for ( action listener l : listeners ) { l . action performed ( new action event ( menu item , e . get id ( ) , e . get action command ( ) ) ) ; } } } ) ;
tmp . new folder ( src ) ;
border paint . set color ( bottom border color ) ;
target federation target = target resolver . resolve ( new target spec ( specification , new federation options ( ) ) ) ;
assert equals ( 2 , \ hi , there \ \ r \ n , h . query ( req ( q , id : 2 , wt , csv , csv . header , false , csv . newline , \ r \ n , fl , id , v _ ss ) ) ) ;
registry . clear new session requests ( ) ; important one . quit ( ) ; }
admin . take snapshot async ( snapshot ) ;
return aggregator factory . finalize computation ( collector ) ;
validate mapred counters ( c1 , 64000 , 7500 , 30000 ) ;
signature bound signature = apply bound variables ( get signature ( ) , variables , arity ) ;
m start time = system clock . uptime millis ( ) + frame _ duration * 6 ;
byte buffer buf = byte buffer . wrap ( baos . to byte array ( ) ) ;
rmnode status event status event = get mock rmnode status event ( null ) ;
bug51744 servlet bug51744 servlet = new bug51744 servlet ( ) ; tomcat . add servlet ( ctx , bug51744 servlet , bug51744 servlet ) ; ctx . add servlet mapping decoded ( , bug51744 servlet ) ; tomcat . start ( ) ;
string date str = date to string ( value ) ; java . util . date result = mapper . read value ( \ + date str + \ , java . util . date . class ) ; assert equals ( date : expect + value + ( + value . get time ( ) + ) , got + result + ( + result . get time ( ) + ) , value . get time ( ) , result . get time ( ) ) ; }
latch map . latch latch = paged file . page fault latches . take or await latch ( file page id ) ;
if ( parent pos = - 1 & & ( ( iexpandable ) parent ) . is expanded ( ) ) { expandable extension . notify adapter sub items changed ( parent pos , ( ( iexpandable ) parent ) . get sub items ( ) . size ( ) + 1 ) ; }
remove snake ( snake ) ; } }
adoc ( 0 , ctx . make rectangle ( 192 , 204 , - 128 , 128 ) ) ; commit ( ) ; ( ( recursive prefix tree strategy ) strategy ) . set prefix grid scan level ( random int ( 2 ) ) ;
if ( null = = image view ) { cleanup ( ) ; throw new illegal state exception ( image view no longer exists . you should not use this photo view attacher any more . ) ; } return image view ; }
assert equals ( higher hits value1 , replicated map . get ( key1 ) ) ;
slice _ from ( pic ) ;
service builder . add dependency ( description . get service name ( ) , component view . class , new view managed reference factory . injector ( injector ) ) ;
container request event [ ] req reduce events = new container request event [ reduce _ count ] ;
factory . wrap ( bad ) ;
extension popup menu item piicm = create popup include in context menu ( ) ;
connection factory connection factory = resolve and remove reference parameter ( params , connection factory , connection factory . class ) ; @ suppress warnings ( unchecked ) map < string , object > client properties = resolve and remove reference parameter ( params , client properties , map . class ) ; trust manager trust manager = resolve and remove reference parameter ( params , trust manager , trust manager . class ) ; rabbit mqendpoint endpoint ; if ( connection factory = = null ) { endpoint = new rabbit mqendpoint ( uri , this ) ; } else { endpoint = new rabbit mqendpoint ( uri , this , connection factory ) ; } endpoint . set hostname ( hostname ) ; endpoint . set port number ( port number ) ; endpoint . set exchange name ( exchange name ) ; endpoint . set client properties ( client properties ) ; endpoint . set trust manager ( trust manager ) ; set properties ( endpoint , params ) ; if ( log . is debug enabled ( ) ) { log . debug ( creating rabbit mqendpoint with host { } : { } and exchange name : { } , new object [ ] { endpoint . get hostname ( ) , endpoint . get port number ( ) , endpoint . get exchange name ( ) } ) ; }
final float excl match cost = advance _ cost + ( excl two phase iterator = = null ? 0 : excl two phase iterator . match cost ( ) ) ;
try { arrays . sort ( new char [ 1 ] , start index + 1 , start index ) ; fail ( illegal argument exception expected ) ; } catch ( illegal argument exception ignore ) { }
assert equals ( a , target remote cache . get ( a ) ) ; rolling upgrade manager upgrade manager = target cluster . get rolling upgrade manager ( test _ cache ) ; long count = upgrade manager . synchronize data ( hotrod ) ;
if ( offset < bytes . length ) { system . out . println ( could not completely read file + image file . get name ( ) ) ; } is . close ( ) ; return bytes ;
expression = parser . parse expression ( concat ( ) ) ; assert cant compile ( expression ) ; expression . get value ( tc ) ; assert equals ( , tc . s ) ; assert can compile ( expression ) ; tc . reset ( ) ; expression . get value ( tc ) ; assert equals ( , tc . s ) ; tc . reset ( ) ;
for ( string name : new string [ ] { . , . . , foo \ \ } ) { try { assert equals ( name , paths . path ( true , name ) ) ; fail ( invalid : + name ) ; } catch ( illegal argument exception expected ) { ignore } try { assert equals ( name , paths . path ( false , name ) ) ; fail ( invalid : + name ) ; } catch ( illegal argument exception expected ) { ignore } }
metadata = table metadata . builder ( ks , table ) . partitioner ( murmur3 partitioner . instance ) . add partition key column ( pk , int32 type . instance ) . add clustering column ( ck , int32 type . instance ) . add static column ( sc1 , int32 type . instance ) . add static column ( sc2 , int32 type . instance ) . add regular column ( v1 , int32 type . instance ) . build ( ) ; column filter = column filter . all ( metadata ) ; assert true ( column filter . fetch all regulars ) ;
assert equals ( 1 l , idresults [ 0 ] . as scalar long ( ) ) ;
if ( draw _ texture ) { gl . gl enable ( gl10 . gl _ blend ) ; gl . gl enable ( gl10 . gl _ texture _ 2 d ) ; if ( m flip texture | | m texture back ) { gl . gl bind texture ( gl10 . gl _ texture _ 2 d , m texture ids [ 0 ] ) ; } else { gl . gl bind texture ( gl10 . gl _ texture _ 2 d , m texture ids [ 1 ] ) ; } gl . gl blend func ( gl10 . gl _ src _ alpha , gl10 . gl _ one _ minus _ src _ alpha ) ; gl . gl draw arrays ( gl10 . gl _ triangle _ strip , 0 , m vertices count front ) ; gl . gl disable ( gl10 . gl _ blend ) ; gl . gl disable ( gl10 . gl _ texture _ 2 d ) ; } int back start idx = math . max ( 0 , m vertices count front - 2 ) ;
return new home broadcast list fragment ( ) ; }
services . execute for result ( remove op ) ;
assert set visitor ( key . get ( set of value type ) , value type , set of ( module1 , module2 ) , module , false , 0 , instance ( new value type ( 1 , 2 ) ) , instance ( new value type ( 1 , 3 ) ) ) ;
if ( headers . contains key ( header . get key ( ) ) ) { headers . put ( header . get key ( ) , headers . get ( header . get key ( ) ) + , + header . get value ( ) ) ; } else { headers . put ( header . get key ( ) , header . get value ( ) ) ; } }
final method nodes method nodes = find method nodes ( advice class node ) ; copy util methods ( method nodes , source class node ) ;
for ( property property : handler . get ( properties ) . as property list ( ) ) { if ( file name . equals ( property . get name ( ) ) ) { file name = property . get value ( ) . as string ( ) ; break ; } } assert . assert not null ( file name property not found , file name ) ; assert . assert true ( file name . ends with ( test - logging - parent - ear . log ) ) ;
long zipped file size = entry . get size ( ) ;
if ( used buffers = = null ) { used buffers = new linked list < buffer data > ( ) ; } used buffers . add ( data ) ; return true ; } else {
application id id = create app id ( 1 , 1 l ) ; shared cache resource reference my ref = new shared cache resource reference ( id , user ) ; string result = store . add resource reference ( key , my ref ) ; assert equals ( file name , result ) ; collection < shared cache resource reference > refs = store . get resource references ( key ) ; assert same ( 1 , refs . size ( ) ) ; assert equals ( collections . singleton ( my ref ) , refs ) ;
return vert src0 ; }
gdx . input . set input processor ( this ) ;
if ( m . is synthetic ( ) | | m . is bridge ( ) ) { return false ; } return true ; }
format _ flags | = date utils . format _ show _ time ;
cos . close ( ) ;
prefs . edit ( ) . put string ( preferences activity . key _ source _ language _ preference , capture activity . default _ source _ language _ code ) . commit ( ) ;
m client . disconnect ( ) ;
assert equals ( 2 , md5failures ) ; } } finally {
thread pool executor pool = procedure member . default pool ( rss . get server name ( ) . to string ( ) , op threads , keep alive ) ;
return util . sdk _ int > = 24 ; }
if ( ( family . get value ( ) = null ) & & ( family . get value ( ) . size ( ) > 0 ) ) { if ( family . get value ( ) instanceof set ) {
return data type . chararray ; }
list < limit order > asks = anxadapters . adapt orders ( anx depth wrapper . get anx depth ( ) . get asks ( ) , currency pair . base . get currency code ( ) , currency pair . counter . get currency code ( ) , ask , ) ;
if ( owner . is aborted ( ) ) { return ; } msg . set context ( owner ) ;
final list < itype > scope = expr type stack . close scope ( ) ; undo stack . add ( new iundo action ( ) { @ override public void undo ( ) { if ( debug ) debug util . print method trace ( ) ; expr type stack . open scope ( scope ) ; } } ) ;
if ( sort input = = null | | sort output = = null ) { print usage ( ) ; return - 2 ; }
attr psvi . f validity = ( errors = = null ) ? attribute psvi . validity _ valid : attribute psvi . validity _ invalid ;
string last url = meta store init . get connection url ( get active conf ( ) ) ; got new connect url = meta store init . update connection url ( orig conf , get active conf ( ) , last url , meta store init data ) ; }
lines . clear ( ) ; get processor ( ) . process ( exchange ) ;
if ( success ) processed defs . add ( attr def ) ; else error defs . add ( attr def ) ;
condensed emit expected event types . add ( hystrix event type . fallback _ emit ) ;
file tld = new file ( mini dfscluster . get base directory ( ) , bad data ) ;
store . update configuration ( conf , graph filters , user ) ;
if ( properties . contains key ( key ) ) { if ( first & & token = null ) { sb . append ( token ) ; } has questionmark | = key . contains ( ? ) | | ( token = null & & token . contains ( ? ) ) ; sb . append ( key2 ) ; first = false ; }
payment accounts = new array list < > ( ) ;
new socket permission ( test suite environment . get server address ( ) + : + test suite environment . get http port ( ) , connect , resolve ) , new file permission ( system . get property ( jboss . inst ) + standalone tmp auth * , read ) ) , permissions . xml ) ; return war ; }
assert . assert false ( token to renew . get service ( ) . to string ( ) . is empty ( ) ) ;
return class . for name ( name , false , loader ) ;
value = result set . get int ( index ) ;
deployment = tester . controller ( ) . applications ( ) . get ( app ) . get ( ) . deployments ( ) . values ( ) . stream ( ) . find any ( ) . get ( ) ; assert . assert equals ( 1 , deployment . metrics ( ) . queries per second ( ) , double . min _ value ) ; assert . assert equals ( 2 , deployment . metrics ( ) . writes per second ( ) , double . min _ value ) ; assert . assert equals ( 3 , deployment . metrics ( ) . document count ( ) , double . min _ value ) ; assert . assert equals ( 4 , deployment . metrics ( ) . query latency millis ( ) , double . min _ value ) ; assert . assert equals ( 5 , deployment . metrics ( ) . write latency millis ( ) , double . min _ value ) ; }
if ( file . get name ( ) . contains ( . ) ) { msg printer . print status msg ( ignoring + file . get path ( ) + . \ n ) ; continue ; } msg printer . print status msg ( parsing + file . get name ( ) + . . . ) ;
int dot index = ( this . bean name = null ? this . bean name . index of ( ' . ' ) : - 1 ) ; if ( dot index = = - 1 ) { throw new illegal argument exception ( neither ' target object ' nor ' target bean name ' specified , and property path factory bean + bean name ' + this . bean name + ' does not follow ' bean name . property ' syntax ) ; } this . target bean name = this . bean name . substring ( 0 , dot index ) ; this . property path = this . bean name . substring ( dot index + 1 ) ; }
if ( write buffer = null & & this . transient store pool = null & & this . file size = = this . committed position . get ( ) ) { this . transient store pool . return buffer ( write buffer ) ; this . write buffer = null ; } return this . committed position . get ( ) ;
if ( nested set . is empty ( ) ) { visit raw ( nested set . raw children ( ) ) ; }
if ( ( str buff . length ( ) = = doctype . length ( ) ) & & ( str buff . to string ( ) . to upper case ( ) . equals ( doctype ) ) ) { parse dtdmarkup ( ) ; return true ; } return false ;
size = http post body util . chunk size - current buffer . readable bytes ( ) ;
verify property ( test _ tag , test _ tag _ value ) ; }
request server . set filters ( request server . default filter ( ) , new request server . http log filter ( ) { @ override public boolean filter ( request uri uri , properties header , properties parms ) { string [ ] path = uri . get path ( ) ; return path [ 1 ] . equals ( get ) ; } } ) ;
sheet . set visibility ( view . invisible ) ;
integer slot number = timeseries slot index . get ( response timeslot ) ;
for ( int i = 0 ; i < 10 ; i + + ) { add doc ( writer ) ; } writer . commit ( ) ; writer . wait for merges ( ) ; writer . commit ( ) ; check invariants ( writer ) ; assert equals ( 10 , writer . max doc ( ) ) ; writer . close ( ) ;
final list < rel data type field > field list = planner result . row type ( ) . get field list ( ) ; final boolean [ ] time columns = new boolean [ field list . size ( ) ] ; final boolean [ ] date columns = new boolean [ field list . size ( ) ] ; for ( int i = 0 ; i < field list . size ( ) ; i + + ) { final sql type name sql type name = field list . get ( i ) . get type ( ) . get sql type name ( ) ; time columns [ i ] = sql type name = = sql type name . timestamp ; date columns [ i ] = sql type name = = sql type name . date ; } final yielder < object [ ] > yielder0 = yielders . each ( planner result . run ( ) ) ;
file utils . write ( new file ( bundle dir , webpack . config . js ) , template webpack config ) ; return main file name ; }
why are you keeping panel . set class specifications ( configuration . why are you keeping ) ;
gc = input reader . read ( read parameters ) ;
boolean no name = string utils . is empty ( job . get ( mrjob config . job _ name ) ) ; string job name = null ;
value . bytes = buffer ; value . offset = buffer offset ; return ; }
if ( ( eq _ s _ b ( 1 , i ) ) ) { return false ; } if ( ( in _ grouping _ b ( g _ v2 , 97 , 246 ) ) ) { return false ; } return true ;
xml xml value = new text element xml ( null , target property , null ) ;
if ( name . length ( ) = = 60 & & name . to lower case ( locale . us ) . ends with ( . b32 . i2p ) ) return lookup dest ( hash . create ( base32 . decode ( name . to lower case ( locale . us ) . substring ( 0 , 52 ) ) ) , max wait ) ;
throw new parser exception ( ) ; }
} catch ( file not found exception e ) { throw new sync factory exception ( cannot locate properties file : + e ) ; } catch ( ioexception e ) { throw new sync factory exception ( ioexception : + e ) ; }
response challenge response = error response ( response . status . unauthorized . get status code ( ) , invalid _ request , e . get message ( ) ) ; context . failure ( authentication flow error . invalid _ user , challenge response ) ; return ; }
node n = null ;
client . drop partition ( db name , tbl name , arrays . as list ( 20160102 ) ) ;
system . load ( temp . get absolute path ( ) ) ; }
proxy pkg = ; } {
process smaptree . clear ( ) ;
this . vm . inputs . project and reward ( project , reward factory . reward ( ) ) ; this . shipping summary text view text . assert no values ( ) ; this . shipping summary section is gone . assert value ( true ) ;
assert . assert true ( iter . has next ( ) ) ; assert . assert true ( iter . has next ( ) ) ; assert . assert true ( iter . has next ( ) ) ; assert . assert equals ( 1 , ( int ) iter . next ( ) ) ; assert . assert false ( iter . has next ( ) ) ;
if ( wrapper . get logger ( ) . is debug enabled ( ) ) wrapper . get logger ( ) . debug ( disabling the response for further output ) ; if ( response instanceof response facade ) { ( ( response facade ) response ) . finish ( ) ; } else { servlet srv . 6 . 2 . 2 . the request response may have been wrapped and may no longer be instance of request facade if ( wrapper . get logger ( ) . is debug enabled ( ) ) { wrapper . get logger ( ) . debug ( the response is vehiculed using a wrapper : + response . get class ( ) . get name ( ) ) ; } close anyway try { print writer writer = response . get writer ( ) ; writer . close ( ) ; } catch ( illegal state exception e ) { try { servlet output stream stream = response . get output stream ( ) ; stream . close ( ) ; } catch ( illegal state exception f ) { ignore } catch ( ioexception f ) { ignore } } catch ( ioexception e ) { ignore } }
datum d = new datum ( rss ) ; return d ; }
if ( ( flags & replace _ firstonly ) = 0 ) { break ; } }
tomcat . get connector ( ) . set property ( tomcat authentication , false ) ;
inode current child = parent . get child ( created node name , snapshot . current _ state _ id ) ; if ( current child = = null ) { throw new ioexception ( cannot find an inode associated with the inode + dfsutil . bytes2 string ( created node name ) + in created list while loading fsimage . ) ; } return current child ;
document handle . get doc event bus ( ) . add handler ( completion request event . type , new completion request handler ( ) { @ override public void on completion request ( final completion request event event ) { show completion ( code assistant , false ) ; } } ) ;
verify ( side effect observer , never ( ) ) . on error ( any ( throwable . class ) ) ;
if ( m relayout | | get visibility ( ) = = view . gone ) { super . on measure ( width measure spec , height measure spec ) ; return ; }
final pair < schema , store properties > pair = new file graph library ( file _ graph _ library _ test _ path ) . get ( graph _ id ) ;
new elapsed time value selector ( false ) , false , true ) ) ; return group infos ; }
pstmt = conn . prepare statement ( select traffic _ type , guest _ type , shared , is _ default , id from networks where name like ' % basic zone direct network % ' ) ; rs = pstmt . execute query ( ) ; if ( rs . next ( ) ) { s _ logger . error ( direct network is missing for the basic zone ) ; } else if ( rs . get string ( 1 ) . equals ignore case ( guest ) | | rs . get string ( 2 ) . equals ignore case ( direct ) | | rs . get boolean ( 3 ) | | rs . get boolean ( 4 ) ) { s _ logger . error ( direct network for basic zone has incorrect setting ) ; } else { s _ logger . debug ( test passed . default direct basic zone network parameters were set correctly ) ; } long default direct network id = rs . get int ( 5 ) ; rs . close ( ) ;
pigscript = a = load ' invalid _ path ' ; + dump a ; ; result = pig interpreter . interpret ( pigscript , context ) ; assert equals ( interpreter result . type . text , result . message ( ) . get ( 0 ) . get type ( ) ) ; assert equals ( interpreter result . code . error , result . code ( ) ) ; assert true ( result . message ( ) . get ( 0 ) . get data ( ) . contains ( failed to read data from ) ) ; }
catch ( ioexception ex ) { stats recorder . record stats ( ex ) ; throw ex ; }
inet socket address mock rm address = new inet socket address ( localhost , 4444 ) ; text rm token sevice = security util . build token service ( mock rm address ) ; inet socket address mock hs address = new inet socket address ( localhost , 9200 ) ;
int num docs = query num docs ( ) ; if ( num docs = = num docs before + solr input documents . length ) { system . err . println ( docs committed sooner than expected . bug or slow test env? ) ; return ; }
vg . remove view ( center view ) ; }
prepare tick tuple timer ( ) ; }
return present1 | | present2 ;
executor services . clear ( ) ;
simple feature type schema = check fields are not empty ( new byte array input stream ( zip ) ) ;
( ( cell layout . layout params ) folder icon . get layout params ( ) ) . can reorder = false ;
if ( response time < = 0 | | response time > max _ per _ peer _ timeout ) response time = max _ per _ peer _ timeout ; else if ( response time < min _ per _ peer _ timeout ) response time = min _ per _ peer _ timeout ;
assert . assert equals ( 1 , m pool . get bucketed size for value ( new byte [ 1 ] ) ) ;
switch ( m device . get state ( ) ) { case authentication _ required : fall through case authenticating : return true ; abort the whole thing default : return false ; }
assert that ( foo . get instance count ( ) ) . is equal to ( 1 ) ; assert that ( result . get status code ( ) ) . is equal to ( http status . ok ) ;
conf . set int ( dfs . replication . interval , 0 ) ;
double lossiness factor = 0 . 35 ; double resiliance factor = ( 1 - lossiness factor ) ; resilience util . verify ( logfile str , ^ hello ( \ \ d { 1 , 5 } ) , runner . get counter ( ) , best case success ratio * resiliance factor ) ;
log position . position = header . get log pos ( ) ; return event ; } else { if ( logger . is warn enabled ( ) ) logger . warn ( skipping unrecognized binlog event + log event . get type name ( header . get type ( ) ) + from : + context . get log position ( ) ) ; } }
ch . write inbound ( unpooled . wrapped buffer ( new byte [ ] { 42 } ) ) ;
assert equals ( cdata node content , actual return ) ;
if ( sc = null ) { long total size = pool . get capacity bytes ( ) ; storage stats stats = sc . get storage pool stats ( pool . get id ( ) ) ; if ( stats = = null ) { stats = sc . get storage stats ( pool . get id ( ) ) ; } if ( stats = null ) { double used percentage = ( ( double ) stats . get byte used ( ) ( double ) total size ) ; if ( s _ logger . is debug enabled ( ) ) { s _ logger . debug ( attempting to look for pool + pool . get id ( ) + for storage , total size : + pool . get capacity bytes ( ) + , used bytes : + stats . get byte used ( ) + , used pct : + used percentage + , disable threshold : + _ storage used threshold ) ; } if ( used percentage > = _ storage used threshold ) { if ( s _ logger . is debug enabled ( ) ) { s _ logger . debug ( cannot allocate this pool + pool . get id ( ) + for storage since its usage percentage : + used percentage + has crossed the pool . storage . capacity . disablethreshold : + _ storage used threshold + , skipping this pool ) ; } return false ; } } } long total allocated size = _ capacity mgr . get allocated pool capacity ( pool , null ) ;
final path index directory = internal cluster ( ) . get instance ( environment . class ) . lib file ( ) . resolve ( site ) ;
final long id = super . long id ( ) ;
assert false ( map . contains key ( keys [ i ] ) ) ;
wordprocessing mlpackage word mlpackage = ( wordprocessing mlpackage ) opc package . load ( new java . io . file ( inputfilepath ) ) ;
if ( veto ) { generated id = persister . insert ( get state ( ) , instance , session ) ; if ( persister . has insert generated properties ( ) ) { persister . process insert generated properties ( generated id , instance , get state ( ) , session ) ; } need to do that here rather than in the save event listener to let the post insert events to have a id - filled entity when identity is used ( ejb3 ) persister . set identifier ( instance , generated id , session ) ; session . get persistence context ( ) . register inserted key ( get persister ( ) , generated id ) ; entity key = session . generate entity key ( generated id , persister ) ; session . get persistence context ( ) . check uniqueness ( entity key , get instance ( ) ) ; }
fail to compile ( select c from t3 union select a from t1 order by c union select b from t2 , unexpected token : union ) ;
jsdoc info info = parse ( @ type \ n { string } * ) ;
assert user hasnt permission ( url , guest , guest , login permission . class . get name ( ) , null , null ) ; assert user hasnt permission ( url , guest , guest , batch permission . class . get name ( ) , target _ name _ start , null ) ; }
final chunk contents = preamble line + final chunk contents ;
s = new socket ( ) ;
assert not null ( compile ( enum coin { penny ( 1 ) , dime ( 10 ) , quarter ( 25 ) } ) ) ; fails after parser
m keyboard state = keyboard _ state _ capslock ;
get resolver = mock ( get resolver . class ) ; cursor = mock ( cursor . class ) ; item = new test item ( ) ;
glide . with ( ctx ) . load ( m image url ) . animate ( r . anim . alpha _ on ) . into ( view holder . image view ) ;
consume endian ( ) ;
assert equals ( 1 , topic config . get message listener configs ( ) . size ( ) ) ;
first set bit in word + = concise set utils . max _ literal _ length ;
final rule model rm = new rule model ( ) ;
string complete scheduler process class path = string . format ( % s : % s : % s , context . scheduler class path ( config ) , context . packing class path ( config ) , context . state manager class path ( config ) ) ; commands . add ( complete scheduler process class path ) ; commands . add ( com . twitter . heron . scheduler . scheduler main ) ; string [ ] command args = scheduler command args ( config , runtime , free ports ) ;
assignment = a . assign containers ( cluster resource , node _ 2 , new resource limits ( cluster resource ) , scheduling mode . respect _ partition _ exclusivity ) ; apply csassignment ( cluster resource , assignment , a , nodes , apps ) ; verify container allocated ( assignment , node type . node _ local ) ; assert equals ( 1 , app _ 0 . get scheduling opportunities ( scheduler key ) ) ; assert equals ( 3 , app _ 0 . get outstanding asks count ( scheduler key ) ) ; assert equals ( 0 , app _ 0 . get live containers ( ) . size ( ) ) ; assert equals ( 1 , app _ 1 . get live containers ( ) . size ( ) ) ; }
if ( password . is admin request ( ) ) { return null ; } boolean apply decorator = mapper model . get ( ldap _ password _ policy _ hints _ enabled , false ) ; return apply decorator ? new ldapserver policy hints decorator ( ) : null ; }
if ( state . set if ( finished , old state - > old state . is terminal ( ) ) ) { no more buffers ( ) ; safe get buffers snapshot ( ) . for each ( client buffer : : destroy ) ; memory manager . set no block on full ( ) ; } }
string query = select u from user u where u . email id = ?1 ; logger . info ( ) ;
m _ ispreserve = m _ preserves . is empty ( ) ? false : m _ preserves . pop ( ) ; }
boolean operation failed = false ;
sink . add test ( nodeattributenodeattribute . class ) ;
refresh view ( ) ; }
assert null ( end exchange . get property ( property name , string . class ) ) ;
for ( int i = 0 ; i < = 6 ; i + + ) { if ( i = 4 ) { try { query . equal to ( new long [ ] { i } , one null table , 123 f ) ; fail ( ) ; } catch ( illegal argument exception ignore ) { } try { query . not equal to ( new long [ ] { i } , one null table , 123 f ) ; fail ( ) ; } catch ( illegal argument exception ignore ) { } try { query . less than ( new long [ ] { i } , one null table , 123 f ) ; fail ( ) ; } catch ( illegal argument exception ignore ) { } try { query . less than or equal ( new long [ ] { i } , one null table , 123 f ) ; fail ( ) ; } catch ( illegal argument exception ignore ) { } try { query . greater than ( new long [ ] { i } , one null table , 123 f ) ; fail ( ) ; } catch ( illegal argument exception ignore ) { } try { query . greater than or equal ( new long [ ] { i } , one null table , 123 f ) ; fail ( ) ; } catch ( illegal argument exception ignore ) { } try { query . between ( new long [ ] { i } , 123 f , 321 f ) ; fail ( ) ; } catch ( illegal argument exception ignore ) { } } }
string ret = ; todo : remove = , if we know where to get this value .
if ( get schema factory ( ) = = null ) { set schema factory ( new relaxngschema factory impl ( ) ) ; }
if ( ( oi settable properties = = null ) & & oi settable properties . contains key ( oi ) ) { return oi settable properties . get ( oi ) . boolean value ( ) ; }
if ( code > = 100 & & code < 200 ) { invite _ ts . respond with ( resp ) ; return ; }
try { data type cache . get all objects ( monitor , this ) ; } catch ( dbexception e ) { log . warn ( can ' t fetch database data types , e ) ; }
nested annotation attribute value existing endpoint = new nested annotation attribute value ( new java symbol name ( value ) , get ws client annotation ( existing endpoint name , existing endpoint name space , existing type ) . build ( ) ) ;
if ( f child sequence . length > 0 ) { f is fragment resolved = match child sequence ( element , event ) ; } else if ( is short hand pointer resolved & & f child sequence . length < = 0 ) { if only a resolved shorthand pointer exists f is fragment resolved = is short hand pointer resolved ; } else { f is fragment resolved = false ; } return f is fragment resolved ;
manageable component metadata meta = gcr . get component metadata repo ( ) . find component metadata ( interpreter . class ) . to manageable component metadata ( ) ;
parameters . put ( key _ format _ strategy _ param , strategy val ) ;
assert true ( metric filtering . matches ( metrics filter . builder ( ) . add name filter ( metric name filter . named ( metric filtering test . class , my metric name ) ) . build ( ) , metric key . create ( any step , metric name . named ( metric filtering test . class , my metric name ) ) ) ) ;
this . num threads = props . get int ( executor _ flow _ threads , default _ num _ executing _ flows ) ;
asserts . assert contains ( pe . get message ( ) , 1 ) error injecting constructor , java . io . ioexception : boom ) ;
final string [ ] recognized properties = {
members . retain all ( gms . view ( ) . get members ( ) ) ;
assert contains ( oidc config . get response types supported ( ) , oauth2 constants . code , oidcresponse type . id _ token , id _ token token , code id _ token , code token , code id _ token token ) ; assert contains ( oidc config . get grant types supported ( ) , oauth2 constants . authorization _ code , oauth2 constants . implicit ) ; assert contains ( oidc config . get response modes supported ( ) , query , fragment ) ; assert . assert names ( oidc config . get subject types supported ( ) , pairwise , public ) ; assert . assert names ( oidc config . get id token signing alg values supported ( ) , algorithm . rs256 . to string ( ) ) ; assert . assert names ( oidc config . get user info signing alg values supported ( ) , algorithm . rs256 . to string ( ) ) ; assert . assert names ( oidc config . get request object signing alg values supported ( ) , algorithm . none . to string ( ) , algorithm . rs256 . to string ( ) ) ;
client . test jq ( params ( p , q , * : * , json . facet , { f : { type : range , field : { num _ d } , start : - 5 , end : 10 , gap : 5 , other : all , mincount : 2 , facet : { x : ' sum ( { num _ i } ) ' , ny : { query : ' { where _ s } : ny ' } } } } ) , facets = = { count : 6 , f : { buckets : [ { val : 0 . 0 , count : 2 , x : 5 . 0 , ny : { count : 1 } } ] + , before : { count : 1 , x : - 5 . 0 , ny : { count : 0 } } + , after : { count : 1 , x : 7 . 0 , ny : { count : 0 } } + , between : { count : 3 , x : 0 . 0 , ny : { count : 2 } } + } } ) ;
string required schema object name = project settings . get property ( spring _ roo _ jpa _ require _ schema _ object _ name ) ; if ( required schema object name = null & & required schema object name . equals ( true ) ) { property ' spring . roo . jpa . require . schema - object - name ' is defined ' true ' if ( cardinality = null & & cardinality . equals ( many _ to _ many ) ) { mandatory if cardinality is many _ to _ many return true ; } else if ( ( cardinality = = null | | cardinality . equals ( one _ to _ many ) ) & & join table param = null ) { mandatory if cardinality is one _ to _ many and ' - - join table ' is already specified return true ; } }
el . get parent element ( ) . get style ( ) . set property ( z index , 1000 ) ; el . get parent element ( ) . get style ( ) . set property ( overflow , visible ) ;
if ( type . is array type ( ) ) { return array ; } if ( type . is map like type ( ) ) { return map ; } if ( type . is container type ( ) ) { if ( set . class . is assignable from ( type . get raw class ( ) ) ) { return set ; } return list ; }
int max = translation . length ;
string map key type ; class target = void . class ;
for ( entry < string , string > entry : dummy props . entry set ( ) ) { hbt . get configuration ( ) . set ( entry . get key ( ) , entry . get value ( ) ) ; } for ( entry < string , string > entry : dummy props . entry set ( ) ) { assert true ( the configuration for key + entry . get key ( ) + and value : + entry . get value ( ) + is not populated correctly , hbt . get configuration ( ) . get ( entry . get key ( ) ) . equals ( entry . get value ( ) ) ) ; }
metric registry info info = metrics coprocessor . create registry info for region coprocessor ( coproc class . get name ( ) ) ; optional < metric registry > registry = metric registries . global ( ) . get ( info ) ;
rmapp app0 = rm1 . submit app ( 200 , name , user , new hash map < application access type , string > ( ) , false , default , - 1 , null , mapreduce , true , true ) ;
for ( int position = 0 ; position < page . get position count ( ) ; position + + ) { int writer index = writer indexes [ position ] ; if ( writers . get ( writer index ) = null ) { continue ; } optional int bucket number = optional int . empty ( ) ; if ( bucket block = null ) { bucket number = optional int . of ( bucket block . get int ( position , 0 ) ) ; } hive writer writer = writer factory . create writer ( partition columns , position , bucket number ) ; writers . set ( writer index , writer ) ; } verify ( writers . size ( ) = = page partitioner . get max index ( ) + 1 ) ;
prune old region reports ( ) ;
log . trace ( sending a message to the queue on which the mdb + is listening ) ; trigger request response cycle on queue ( ) ; assert true ( @ post construct wasn ' t invoked on mdb , lifecycle tracker . was post construct invoked on ( this . get class ( ) . get package ( ) . get name ( ) + . lifecycle counter mdb ) ) ;
get project settings service ( ) . remove property ( name ) ; } else { logger . log ( level . info , string . format ( warning : property ' % s ' is not defined on current settings , name ) ) ; } } else {
num dirs + = 4 ;
property value + + ;
file context test helper helper = new file context test helper ( tmp test symlink hdfs disable ) ;
vq . get next ( k1 ) ;
hpack encoder . set max table size ( remote settings . get header table size ( ) ) ; return hpack encoder ;
file larger zip = download process . execute ( get layer id ( mock data . usa _ worldimg ) , layer name null , filter image tiff , output format null , target crs crs . decode ( epsg : 4326 , true ) , roi crs null , roi false , crop to geometry null , interpolation 160 , target size x null , target size y not specified , will be calculated based on target size x and aspect ratio of the original image null , band select indices new null progress listener ( ) progress listener ) ;
buffer . clear ( ) ; return true ;
if ( s = = null ) throw new internal failure ( cannot create redirect response to master at index + master + , as we failed to get correct config to detect running cluster controllers . ) ;
return m shared preferences . get float ( key , default value ) ;
string builder buf = new string builder ( array . length * 9 ) ;
assert false ( command . is executed in thread ( ) ) ;
iterator < meta contact group > subgroups iter = root . get subgroups ( ) ; assert true ( no sub groups were found in the meta contact list , subgroups iter . has next ( ) ) ; meta contact group subgroup = subgroups iter . next ( ) ;
last block = line . split ( \ t ) [ 0 ] ;
while ( ( half height options . in sample size ) > target height | | ( half width options . in sample size ) > target width ) { options . in sample size * = 2 ; } }
throw new org . apache . axis2 . databinding . adbexception ( destination key cannot be null ) ; } else {
is complete = false ;
string schema = create table t ( a integer ) ; create procedure multipr as begin \ n + select * from t ; end ; ;
assert single cue empty ( nested subtitle . get cues ( 4000000 ) ) ; assert single cue empty ( nested subtitle . get cues ( 4500000 ) ) ; assert single cue empty ( nested subtitle . get cues ( long . max _ value ) ) ; }
segs [ i ] = - 1 ;
exceptions attribute . exception entries accept ( ( program class ) clazz , this ) ; }
baos . write ( org . jaudiotagger . audio . generic . utils . get size leint32 ( data . length ) , 0 , 4 ) ;
for ( int li = 0 ; li < ( ilbc _ constants . cb _ meml - this . ulp _ inst . state _ short _ len ) ; li + + ) mem [ li ] = 0 . 0f ;
boolean was smiley = false ;
this . manager . load plugins ( ) ;
return get type ( ) . starts with ( dom ) ; }
big decimal abs = val . abs ( ) ;
for ( path path : files ) { iterable < file status > non snapshot files = get non snapshot files ( cache , path ) ; assert false ( cache didn ' t find + path . get name ( ) , iterables . contains ( non snapshot files , path . get name ( ) ) ) ; } fsutils . log file system state ( fs , root dir , log ) ;
if ( shutdown ) return ; spdy socket socket = sockets . get ( stream id ) ;
assert invalid function ( bing _ tile ( 10 , 2 , 3 ) , xy coordinates for a bing tile at zoom level 3 must be within [ 0 , 8 ) range ) ; assert invalid function ( bing _ tile ( 2 , 10 , 3 ) , xy coordinates for a bing tile at zoom level 3 must be within [ 0 , 8 ) range ) ;
int selected position ; if ( child = null ) { selected position = get position for view ( child ) ; } else { selected position = 0 ; } if ( set selected ) { m adapter . set selected day ( m selected day ) ; }
final yarn configuration conf = new yarn configuration ( get conf ( ) ) ; return client rmproxy . create rmproxy ( conf , resource manager administration protocol . class ) ;
int first full block idx = lower block , last full block idx = upper block ;
try { check compaction policy ( conf , htd ) ; } catch ( ioexception e ) { warn or throw exception for failure ( false , conf _ key , e . get message ( ) , e ) ; }
node new value ; node msg node = definition . get message node ( ) ; try { new value = get new value node ( replacement , msg node ) ; } catch ( malformed exception e ) { compiler . report ( jserror . make ( e . get node ( ) , message _ tree _ malformed , e . get message ( ) ) ) ; new value = msg node ; } if ( new value = msg node ) { new value . use source info if missing from for tree ( msg node ) ; msg node . replace with ( new value ) ; compiler . report change to enclosing scope ( new value ) ; }
set will not draw ( true ) ;
filter list filter list = new filter list ( operator . must _ pass _ one , arrays . as list ( new filter [ ] { filter min hint , filter max hint } ) ) ;
if ( container . get container state ( ) = container state . paused ) { if ( num allowed < = 0 ) { container . send kill event ( container exit status . killed _ by _ container _ scheduler , container de - queued to meet nm queuing limits . ) ; container iter . remove ( ) ; log . info ( opportunistic container { } will be killed to meet nm queuing + limits . , container . get container id ( ) ) ; } num allowed - - ; }
while ( completed apps . size ( ) > this . max completed apps in memory ) { application id remove id = completed apps . remove ( ) ; log . info ( application should be expired , max number of completed apps + kept in memory met : max completed apps in memory = + this . max completed apps in memory + , removing app + remove id + from memory : ) ; rm context . get rmapps ( ) . remove ( remove id ) ; this . application acls manager . remove application ( remove id ) ; } }
if ( idx = = - 1 & & recursive ) { continue ; }
end = str . length ( ) ;
assert correct ( in addition , the government would pay a 1 , 000 \ cost of education \ grant to the schools . ) ;
final delegation key key2 = new delegation key ( 3 , 4 , key data2 . get bytes ( ) ) ; final delegation key key3 = new delegation key ( 5 , 6 , key data3 . get bytes ( ) ) ; final mrdelegation token identifier token3 = new mrdelegation token identifier ( new text ( token owner3 ) , new text ( token renewer3 ) , new text ( token user3 ) ) ; token3 . set sequence number ( 12345679 ) ; final long token date3 = 87654321 l ; store . remove token ( token1 ) ; store . store token master key ( key2 ) ; final long new token date2 = 975318642 l ;
e first = q . peek ( ) ; return ( first = = null | | first . get delay ( nanoseconds ) > 0 ) ? null : first ; }
if ( m scroller . is finished ( ) ) { m scroller . abort animation ( ) ; }
if ( back layout = null ) { back layout . draw ( canvas ) ; }
get mock endpoint ( mock : result ) . expected bodies received ( new new world , old old world ) ;
set < timeline metric > metrics = new hash set < > ( ) ; timeline metric m1 = new timeline metric ( ) ; m1 . set id ( map _ slot _ millis ) ; map < long , number > metric values = new hash map < long , number > ( ) ; long ts = system . current time millis ( ) ; metric values . put ( ts - 120000 , 100000000 ) ; metric values . put ( ts - 100000 , 200000000 ) ; metric values . put ( ts - 80000 , 300000000 ) ; metric values . put ( ts - 60000 , 400000000 ) ; metric values . put ( ts - 40000 , 50000000000 l ) ; metric values . put ( ts - 20000 , 60000000000 l ) ; m1 . set type ( type . time _ series ) ; m1 . set values ( metric values ) ; metrics . add ( m1 ) ; entity . add metrics ( metrics ) ; te . add entity ( entity ) ; hbase timeline writer impl hbi = null ;
list < clock entry > clock entries = new array list < clock entry > ( server list . size ( ) ) ; for ( integer nodeid : server list ) clock entries . add ( new clock entry ( nodeid . short value ( ) , system . current time millis ( ) ) ) ; vector clock cluster xml clock = new vector clock ( clock entries , system . current time millis ( ) ) ; for ( integer nodeid : server list ) admin client . metadata mgmt ops . update remote cluster ( nodeid , current cluster , cluster xml clock ) ; admin client . set admin client cluster ( current cluster ) ; check for tuple equivalence ( admin client , 4 , test store name rw , moving keys list , baseline tuples , baseline versions ) ;
work duration work duration = work duration . create from long ( 1 l , hours _ in _ day ) ;
local address proxy = new local address ( http proxy _ 500 ) ; socket address host = inet socket address . create unresolved ( special host , 314 ) ; channel inbound handler mock handler = mock ( channel inbound handler . class ) ;
release instance ( stateful session component instance ) ;
double len sq = px * px + py * py - projlen sq ;
assertions . assert that ( raw buffer . buffer ) . is equal to ( entry . get value ( ) ) ; if ( updated positions . contains ( entry . get key ( ) ) ) { assert . assert equals ( raw buffer . version , new record version ) ; assert . assert equals ( raw buffer . record type , 3 ) ; } else { assert . assert equals ( raw buffer . version , record version ) ; assert . assert equals ( raw buffer . record type , 2 ) ; }
int [ ] bands = null ; if ( axis subset . get single value ( ) . size ( ) > 0 ) { bands = new int [ 1 ] ; bands [ 0 ] = integer . parse int ( ( ( typed literal type ) axis subset . get single value ( ) . get ( 0 ) ) . get value ( ) ) ; } else if ( axis subset . get interval ( ) . size ( ) > 0 ) { interval type interval = ( interval type ) axis subset . get interval ( ) . get ( 0 ) ; int min = integer . parse int ( interval . get min ( ) . get value ( ) ) ; int max = integer . parse int ( interval . get max ( ) . get value ( ) ) ; int res = ( interval . get res ( ) = null ? integer . parse int ( interval . get res ( ) . get value ( ) ) : 1 ) ; bands = new int [ ( max - min ) res ] ; for ( int b = 0 ; b < bands . length ; b + + ) bands [ b ] = min + ( b * res ) ; } if ( bands = = null ) throw new wcs exception ( invalid values for axis + axis subset . get name ( ) , invalid parameter value , axis subset ) ;
if ( now micros > next free ticket micros ) { double new permits = ( now micros - next free ticket micros ) cool down interval micros ( ) ; stored permits = min ( max permits , stored permits + new permits ) ; next free ticket micros = now micros ; }
if ( include current server & & server . is serving segment ( proposal segment ) ) { return double . positive _ infinity ; }
for ( int i = 0 ; i < arr . length ; + + i ) for ( int j = 0 ; j < i ; + + j ) arr [ j ] [ i ] = arr [ i ] [ j ] ; cholesky decomposition c = new matrix ( arr ) . chol ( ) ; fchol . set spd ( c . is spd ( ) ) ; arr = c . get l ( ) . get array ( ) ;
check flow run table ( cluster , user , flow , runid , c1 ) ;
long nr = get num rows ( table ) ;
user . set password ( homebrew ) ; session = open session ( ) ; session . begin transaction ( ) ; session . update ( user ) ; session . get transaction ( ) . commit ( ) ; session . close ( ) ;
params message . add rule ( relative layout . left _ of , 0 ) ; params message . add rule ( relative layout . center _ vertical , 0 ) ; view group . margin layout params margins message = ( view group . margin layout params ) message text . get layout params ( ) ; margins message . bottom margin = get resources ( ) . get dimension pixel size ( r . dimen . margin _ small ) ; view group buttons view = ( view group ) message view . find view by id ( r . id . layout _ buttons ) ;
for ( final mock scanner scanner : storage . get scanners ( ) ) { assert true ( scanner . get filter ( ) instanceof filter list ) ; }
iterator < map . entry < string , pojoproperty builder > > it = props . entry set ( ) . iterator ( ) ;
metric . add ( metric name , 1 , metric context ) ;
string d = format . format ( i = = 0 ? dmp . parse math ( day ) : dmp . parse math ( day + + i + days ) ) ;
if ( index . is number ( ) ) { continue ; } int value = ( int ) index . get double ( ) ;
if ( item = null ) { final set < uuid > add items cancelled = new hash set < uuid > ( ) ; final item cancel item = find item ( item action . cancel ) ; if ( cancel item = null ) { preconditions . check state ( cancel item . get linked id ( ) = null , invalid cancel item = % s , cancel item ) ; add items cancelled . add ( cancel item . get linked id ( ) ) ; } final set < uuid > add items to be cancelled = new hash set < uuid > ( ) ; check double billing ( add items cancelled , add items to be cancelled ) ; } return item ;
child mock model child1 = new child mock model ( ) ; child1 . boolean field = false ; child1 . date field = date value ; child1 . double field = double value ; child1 . int field = int value ; child1 . parent = parent ; child1 . save ( ) ; child mock model child2 = new child mock model ( ) ;
context . report warning ( could not access constructor + of class + cl . get name ( ) + due to lack of privileges . ) ; } }
odistributed server log . info ( this , local node name , null , direction . none , node is not online yet ( status = % s ) , blocking the command until it is online ( retry = % d , queue = % d worker = % d ) , mgr . get node status ( ) , retry + 1 , local queue . size ( ) , id ) ; if ( local queue . size ( ) > = manager . get server instance ( ) . get context configuration ( ) . get value as integer ( oglobal configuration . distributed _ local _ queuesize ) ) {
system . out . println ( setting key box ssh public private key pair ) ;
if ( last component instanceof contact node ) { uicontact ui contact = ( ( contact node ) last component ) . get contact descriptor ( ) ; if ( ( ui contact instanceof show more contact ) ) { super . select path for event ( path , event ) ; } } else super . select path for event ( path , event ) ;
thread t = new thread ( ) { public void run ( ) { procspy . call ( ) ; } } ; t . start ( ) ;
if ( logger . is debug enabled ( ) ) { logger . debug ( target source creator [ + tsc + found custom target source for bean with name ' + bean name + ' ) ; } return ts ;
list < sid > sids = sid retrieval strategy . get sids ( authentication ) ; if ( acl . is granted ( arrays . as list ( base permission . administration ) , sids , false ) ) { return ; }
if ( this . authenticated subject = null ) { set < security identity > authenticated identities = this . get private credentials ( security identity . class ) ; if ( authenticated identities . is empty ( ) ) { security identity identity = authenticated identities . iterator ( ) . next ( ) ; identity . run as ( work ) ; return ; } }
log . info ( send resource requests to the scheduler ) ;
array list < abstract plan node > index scan nodes = root plan graph . find all nodes of type ( plan node type . indexscan ) ; if ( sub plan graph = null ) { index scan nodes . add all ( sub plan graph . find all nodes of type ( plan node type . indexscan ) ) ; } for ( abstract plan node node : index scan nodes ) { if ( ( ( index scan plan node ) node ) . get search key expressions ( ) . is empty ( ) ) { total + + ; } } return total ;
init fixed length model ( ) ;
try ( zip input stream zin = new zip input stream ( new file input stream ( options . resources zip . to file ( ) ) ) ) { zip entry entry ; while ( ( entry = zin . get next entry ( ) ) = null ) { if ( entry . is directory ( ) ) { path output = resource files . resolve ( entry . get name ( ) ) ; files . create directories ( output . get parent ( ) ) ; try ( file output stream fos = new file output stream ( output . to file ( ) ) ) { byte streams . copy ( zin , fos ) ; } } } }
return p y - max ybound exceeded amount + min ybound exceeded amount ;
boolean changed = ( scale = s ) ;
record = group . next record ( info ) ;
return ( is negative ) ? - 0 . 0 : 0 . 0 ;
jblock j finally = j try load . _ finally ( ) ; if ( use custom key store ) { j finally . add ( invoke ( j var key file , close ) ) ; } j finally . add ( invoke ( j var trst file , close ) ) ;
global make env builder . put ( crosstooltop , crosstool top path fragment . get path string ( ) ) ;
final repository repository = new repository ( id , name , url , enable _ snapshots ) ;
client manager . remove client ( addr , sc ) ;
list < string > new group names = new array list < string > ( ) ;
final map < java symbol name , annotation attribute value < ? > > replacement attribute values = new linked hash map < java symbol name , annotation attribute value < ? > > ( ) ; final annotation metadata builder existing builder = get declared type annotation ( annotation . get annotation type ( ) ) ;
while ( count > 0 & & digits [ count - 1 ] = = ' 0 ' ) { - - count ; } if ( count = = 0 ) { positive zero fits into a long , but negative zero can only be represented as a double . - bug 4162852 return is positive | | ignore negative zero ; }
maximum distance = bone tail radius ; }
top hsd . adjust ( ) ;
result = catalog . validate endpoint properties ( jms : queue : myqueue?jms key format strategy = key ) ; assert true ( result . is success ( ) ) ; assert equals ( 0 , result . get number of errors ( ) ) ;
store file . file operation ( delete , file system , store dir , null , counts _ store _ files , true , null , store file type . values ( ) ) ;
for ( int i = 0 ; i < y lines + 2 ; i + + ) { float x = ( i ) * line dist ; positions fpb . put ( x ) . put ( 0 ) . put ( 0 ) ; fpb . put ( x ) . put ( 0 ) . put ( y line len ) ; indices sib . put ( ( short ) ( cur index + + ) ) ; sib . put ( ( short ) ( cur index + + ) ) ; } fpb . flip ( ) ;
document doc = reader . document ( doc count ) ; fields writer . add document ( doc ) ; check abort . work ( 300 ) ; } }
assert that ( this . context ) . is not null ( ) ;
this . mock mvc . perform ( get ( music people ) ) . and expect ( json path ( . composers [ 0 ] . name ) . value ( equal to ( johann sebastian bach ) ) ) . and expect ( json path ( . performers [ 1 ] . name ) . value ( equal to ( yehudi menuhin ) ) ) ; }
. add class ( camel event route . class )
dfs . allow snapshot ( bar ) ;
assert equals ( 23456 , s . next int ( 10 ) ) ;
try { sample . none declared ( ) ; fail ( ) ; } catch ( some chaining exception expected ) { }
this . http address = conf . get socket addr ( dfsconfig keys . dfs _ router _ http _ bind _ host _ key , dfsconfig keys . dfs _ router _ http _ address _ key , dfsconfig keys . dfs _ router _ http _ address _ default , dfsconfig keys . dfs _ router _ http _ port _ default ) ;
token . token type = tokens . x _ malformed _ binary _ string ; token . is malformed = true ; return ; }
final int mask = include final methods ? modifier . public : modifier . public | modifier . final ; if ( ( method . get modifiers ( ) & mask ) = = opcodes . acc _ public ) { if ( method . get parameter types ( ) . length = = 0 & & method . get name ( ) . equals ( < init > ) & & method . get name ( ) . equals ( < clinit > ) & & method . get return type ( ) = void . class & & method . is default ( ) ) {
m sticky header view holder . item view . set visibility ( view . invisible ) ; apply layout params and margins ( view ) ; remove view from parent ( view ) ; add view to parent ( m sticky holder layout , view ) ; configure layout elevation ( ) ; }
if ( transition . is running ( ) ) { m ignore qsb scroll = false ; transition . remove transition listener ( this ) ; m first page scroll x = get scroll for page ( 0 ) ; on workspace overall scroll changed ( ) ; } } } ) ; }
conf . set boolean ( snapshot manager . hbase _ snapshot _ enabled , true ) ;
} catch ( exception e ) { fail ( e . get message ( ) ) ; } } ) ; }
headers headers = new headers . builder ( ) . add ( www - authenticate , digest realm = \ myrealm \ , nonce = \ fjalskdflwejrlaskdfjlaskdjflaks + jdflkasdf \ , qop = \ auth \ , stale = \ false \ ) . build ( ) ;
if ( ( min value = = null ) | | ( max value = = null ) ) { return false ; }
consumer . subscribe ( arrays . as list ( topic2 ) , get consumer rebalance listener ( consumer ) ) ;
previous element = first child . find first token ( token types . rbrack ) ; }
return pg . servlet uri ( link ) ;
int cnt = 0 ; while ( messages . get ( index . get ( ) ) . is empty ( ) ) { indarray compressed = messages . get ( index . get ( ) ) . poll ( ) ; int encoding = compressed . data ( ) . get int ( 3 ) ; if ( encoding = = threshold compression . flexible _ encoding ) nd4j . get executioner ( ) . threshold decode ( compressed , updates ) ; else if ( encoding = = threshold compression . bitmap _ encoding ) nd4j . get executioner ( ) . bitmap decode ( compressed , updates ) ; else throw new dl4 jinvalid config exception ( unknown compression header received : + encoding ) ; cnt + + ; } if ( cnt > 0 & & is debug ) log . info ( local updates to be applied : { } , cnt ) ;
for ( string s : result . split ( \ n ) ) { string [ ] fields = s . split ( ) ; expected . add ( new tuple2 < string , integer > ( fields [ 0 ] , integer . parse int ( fields [ 1 ] ) ) ) ; }
if ( s . ends with ( ) ) { s = s . substring ( 0 , s . length ( ) - 1 ) ; } return s ;
update tessellation ( ) ; } if ( in geo . codes = = null ) return null ; return in geo . codes ; }
assert false ( injector . get instance ( has implemented by1 . class ) instanceof implements has implemented by1 ) ;
int bytes read = in . read ( bytes ) ;
for ( class < ? > cls : sorted classes ) { swagger definition swagger definition = cls . get annotation ( swagger definition . class ) ; if ( swagger definition = null ) { read swagger config ( cls , swagger definition ) ; } } for ( class < ? > cls : sorted classes ) { read ( cls , , null , false , new string [ 0 ] , new string [ 0 ] , new linked hash map < string , tag > ( ) , new array list < parameter > ( ) , new hash set < class < ? > > ( ) ) ; }
new signature buffer . append ( type ) ;
sslcontext . set certificate chain file ( ctx , sslhost config . adjust relative path ( certificate . get certificate chain file ( ) ) , false ) ;
hfile link link = null ;
append hex java script representation ( sb , c ) ; } } }
verify ( get resolver ) . map from cursor ( stor iosqlite , cursor ) ;
layer group info layer group = get catalog ( ) . get factory ( ) . create layer group ( ) ; layer group . set name ( layer group name ) ;
ds1 . full outer join ( ds2 ) . where ( 5 ) . equal to ( 0 ) . with ( new dummy join ( ) ) ;
generate gaussian examples ( format , inst num , get random ( ) , cl , c name ) ;
listener = null ; fire listener = false ; registered for write = false ;
origin server . abort ( testing ) ;
this . expired events . add all ( ( list < t > ) state . get ( expired _ events ) ) ;
string source = int result = 3 + 5 ; ;
log ( starting up a new master ) ; active master = cluster . start master ( ) . get master ( ) ; log ( waiting for master to be ready ) ; cluster . wait for active and ready master ( ) ; log ( master is ready ) ;
try { dn block it = block manager test util . get block iterator ( cluster . get namesystem ( ) , d id , - 1 ) ; assert true ( should throw illegal argument exception , false ) ; } catch ( illegal argument exception ei ) { as expected }
fc . set current directory ( folder . get parent file ( ) ) ;
boolean ok = true ; for ( int j = 0 ; ok & & ( j < protolength ) ; j + + ) { ok = ( buffer . char at ( index + j ) = = protoname . char at ( j ) ) ; } if ( ok ) { ok = ( buffer . char at ( index + protolength ) = = ' ' ) ; } return ok ;
execution options execution options = options . get defaults ( execution options . class ) ;
http request client2 = http request . get ( standalone . get base urls ( ) . get ( 0 ) + bad route ) . follow redirects ( false ) ; assert that ( client2 . code ( ) , is ( 303 ) ) ;
set < encryption > aes = new hash set < > ( arrays . as list ( encryption . aes128 , encryption . aes128 ccm , encryption . aes128 ccm8 , encryption . aes128 gcm , encryption . aes256 , encryption . aes256 ccm , encryption . aes256 ccm8 , encryption . aes256 gcm ) ) ;
if ( setting manager . get instance ( ) . get main activity tag should change ( ) ) { change the tag fragment for ( int i = 0 ; i < tag adapter . get count ( ) & & i < co coin fragment manager . tag choose fragments . size ( ) ; i + + ) { if ( co coin fragment manager . tag choose fragments . get ( i ) = null ) co coin fragment manager . tag choose fragments . get ( i ) . update tags ( ) ; } and tell others that main activity has changed setting manager . get instance ( ) . set main activity tag should change ( false ) ; }
final boolean file created ; try { file created = file io provider . create file ( volume , f ) ; } catch ( ioexception ioe ) { throw new ioexception ( disk _ error + failed to create + f , ioe ) ; } if ( file created ) { throw new ioexception ( failed to create temporary file for + b + . file + f + should be creatable , but is already present . ) ; } return f ;
assert true ( arrays . equals ( pq encoding , pq encoding ret ) ) ;
test same ( y . a = 2 ; this . a = 1 ; alert ( x . a ) ) ; }
while ( ordering . used in contract seq ( c ) ) { c = text . previous ( ) ; }
ssl config = null ;
string [ ] files = new file ( target suspended ) . list ( ) ;
boolean saved notify = plot . is notify ( ) ;
if ( ( admins config . contains ( admin ) | | operation config . contains ( admin ) | | view config . contains ( admin ) ) ) { view config . add ( admin ) ; }
options parser parser = options parser . new options parser ( example options . class , example expansion options . class ) ;
h table . get ( new get ( row ) . add family ( cf2 ) ) ;
node = type check map constructor ( call , receiver , arguments ) ;
mock http servlet request request = create request ( foo bar ) ; mock http servlet response response = new mock http servlet response ( ) ; mock filter chain chain = new mock filter chain ( ) ; get proxy ( ) . do filter ( request , response , chain ) ; assert equals ( http servlet response . sc _ forbidden , response . get status ( ) ) ;
return t * t * ( 3 - 2 * t ) ;
if ( cache . get listeners ( ) . contains ( listener registration ) ) { cache . remove listener ( listener registration ) ; } key gen worker . stop ( ) ; }
m scroll view = ( scroll view ) find view by id ( r . id . equalizer scroll view ) ; m scroll view . set background color ( uielements helper . get background color ( m context ) ) ;
parse recall results recall parse results = sqlparser . parse recall statement ( line , recallable session lines . size ( ) - 1 ) ;
byte field value other value = ( byte field value ) field value ;
new note column = new column ( project . column model . allocate new cell index ( ) , project . column model . get unduplicated column name ( note column . get name ( ) + : + key string ) ) ;
return build name ( type node . get first child ( ) ) ;
store parameters ( clazz , method ) ;
action . remove properties ( master , entity id ) ;
divadd ( divisor , rem . value , j + 1 + rem . offset ) ; qhat - - ; }
server name sn with old start code = new server name ( sn . get hostname ( ) , sn . get port ( ) , sn . get startcode ( ) - 10 ) ;
assert jq ( req ( q , { join from = dept _ ss to = noexist _ s + whatever score ( ) + } * : * , fl , id ) , response = = { ' num found ' : 0 , ' start ' : 0 , ' docs ' : [ ] } ) ;
final conjunct future < void > all terminal = future utils . wait for all ( futures ) ;
final transaction table transaction table = testing util . get transaction table ( cache ( 1 ) ) ; testing util . replace field ( rpc manager , rpc manager , transaction table , transaction table . class ) ; tx control interceptor tx control interceptor = new tx control interceptor ( ) ;
t emitter . start ( ) ;
simple schema1 = create table mytable ( val1 varchar ( 1048576 ) , val2 varchar ( 1048576 ) ) ; + alter table mytable alter column val1 varchar ( 1048572 ) ; \ n + alter table mytable alter column val2 varchar ( 1048572 ) ; \ n + alter table mytable alter column val1 varchar ( 1048576 ) ; \ n ;
type check ( line _ joiner . join ( * * @ return { generator < number > } * , function * gen ( * * string * k ) { , yield ( k = 1 ) ; , } ) , new type inference . mistyped _ assign _ rhs ) ;
gbapplication . device service ( ) . on set music info ( music spec ) ; gbapplication . device service ( ) . on set music state ( state spec ) ; return true ;
try { iter . remove ( ) ; } catch ( illegal state exception ise ) { continue ; } remote host id to = entry . get key ( ) ; list < out net message > all queued = entry . get value ( ) ; list < out net message > queued = new array list < out net message > ( ) ; long now = _ context . clock ( ) . now ( ) ; synchronized ( all queued ) { for ( out net message msg : all queued ) { if ( now - router . clock _ fudge _ factor > msg . get expiration ( ) ) { _ transport . failed ( msg , took too long in est . mgr ob queue ) ; } else { queued . add ( msg ) ; } } } if ( queued . is empty ( ) ) continue ;
zipkin . init ( camel context ) ; return zipkin ; }
assert equals ( 1 , recovered containers . size ( ) ) ;
uri uri = get image uri ( context , bitmap ) ;
mailbox . clear all ( ) ;
check assignment ( tt4 , attempt _ test _ 0001 _ m _ 000007 _ 0 on tt4 ) ;
error reporter . report warning ( comma token . location . start , trailing comma is not legal in an ecma - 262 object initializer ) ; } }
last mouse x = x ; last mouse y = y ; } if ( wheel = 0 ) { mouse wheel changed ( wheel 120 ) ; } }
assert that ( fs . input file ( fs . predicates ( ) . has language ( java ) ) ) . is not null ( ) ;
client stats stats = full stats context . fetch ( ) . get stats ( ) ;
for ( int i = 0 ; i < size ; i + + ) { length = dis . read int ( ) ; bytes = new byte [ length ] ; dis . read ( bytes ) ; dimensions . add ( new string ( bytes ) ) ; } aggregation phase map output key wrapper ;
fsdata output stream os = fs . create ( new path ( + method name + . 02 . dat ) , replication ) ;
test ( function f ( { a : { b : b } } = { a : { } } ) { * * b is unused * } ; f ( ) ; , function f ( { a : { } } = { a : { } } ) { * * b is unused * } ; f ( ) ; ) ;
int player fragment color = player fragment . get palette color ( ) ; super . set light statusbar ( false ) ; super . set task description color ( player fragment color ) ; super . set navigationbar color ( player fragment color ) ; player fragment . set menu visibility ( true ) ; player fragment . set user visible hint ( true ) ; player fragment . on show ( ) ; }
validate insert stmt ( insert into p1 values ( 1 , 2 , 3 , 4 , 5 , 6 ) ; , 1 , 2 , 3 , 4 , 5 , 6 ) ;
class < ? > c = x . get class ( ) ;
{ error msg . error _ msg , error : ' ' { 0 } ' ' } ,
writable raster raster = null ; if ( bi = = null ) { if ( sample model = null & & color model = null ) { sample model = sample model . create compatible sample model ( destination region . x + destination region . width , destination region . y + destination region . height ) ; if ( sele band ) sample model = sample model . create subset sample model ( source bands ) ; raster = raster . create writable raster ( sample model , new point ( ) ) ; bi = new buffered image ( color model , raster , false , null ) ; } } else { raster = bi . get writable tile ( 0 , 0 ) ; sample model = bi . get sample model ( ) ; color model = bi . get color model ( ) ; no transform & = destination region . equals ( raster . get bounds ( ) ) ; }
dispatcher disp = new default rule dispatcher ( column pruner proc factory . get default proc ( ) , op rules , cpp ctx ) ; graph walker ogw = new column pruner walker ( disp ) ;
if ( section name . equals ( last section name ) ) { last section name = section name ; last fast scroller section info = new fast scroll section info ( section name ) ; m fast scroller sections . add ( last fast scroller section info ) ; }
for ( int i = 0 ; i < count ; i + + ) { string key = string . value of ( i ) ; string file name = key + . jar ; string result = store . add resource reference ( key , new shared cache resource reference ( id , user ) ) ; the value should not be null ( i . e . it has the key ) and the filename should match assert equals ( file name , result ) ; the initial input should be emptied assert true ( initial cached resources . is empty ( ) ) ; }
return decoded ;
verify no more interactions ( allocation service ) ; assert true ( rejoin called . get ( ) ) ; assert that ( result . resulting state , equal to ( cluster state ) ) ; for ( final zen discovery . node removal cluster state task executor . task task : tasks ) { assert not null ( result . resulting state . nodes ( ) . get ( task . node ( ) . get id ( ) ) ) ; } }
map < string , byte amount > ram map = new tree map < > ( topology utils . get component ram map config ( topology tests . create topology ( test , topology config , spouts , bolts ) ) ) ;
final string drl = package org . drools . compiler . test ; \ n + import + person . class . get canonical name ( ) + \ n + rule r1 when \ n + person ( name = = \ 12 \ ) \ n + then end \ n + rule r2 when \ n + person ( name = = 11 ) \ n + then \ n end \ n + rule r3 when \ n + person ( name = = \ 11 \ ) \ n + then end \ n ; kie base kie base = load knowledge base from string ( drl ) ;
data set < tuple2 < long , double > > line items = env . read csv file ( args [ 2 ] ) . field delimiter ( | ) . line delimiter ( \ n ) . include fields ( 100001 ) . types ( long . class , double . class ) . name ( lineitem ) ; data set < tuple2 < long , integer > > filter o = orders . flat map ( new filter o ( ) ) . name ( mapper _ name ) ;
matcher git index filename matcher = git index filename pattern . matcher ( fullpath ) ;
if ( exists ( file . get name ( ) + . xml ) | | exists ( file . get name ( ) + . xml ) ) return ; assume we will get added events for the xml file
record . set source class name ( ste . get class name ( ) ) ;
arrays . sort ( names ) ; sequence file . reader [ ] parts = new sequence file . reader [ names . length ] ;
active cursors . remove ( active cursor . next ( ) ) ; active cursors . remove ( active cursor . next ( ) ) ; assert true ( active cursors . is empty ( ) ) ; assert false ( active cursor . has next ( ) ) ; final int total inserted entries = 50 ;
initialize changed map ( ) ; final put request put = new put request ( tsdb . tree table ( ) , tree . id to bytes ( tree _ id ) , tree _ family , tree _ qualifier , stored _ tree . to storage json ( ) ) ; return tsdb . get client ( ) . compare and set ( put , original _ tree ) ; } }
return returned object ; }
assert unreachable ( if ( ( ) = > true ) { x = 1 ; } else { x = 2 ; } ) ; }
result = run unguarded ( bot r . get clazz ( ) , run ) ; assert equals ( 99 , result . return value ) ; }
if ( modifier . is public ( modifiers ) | | modifier . is public ( method . get declaring class ( ) . get modifiers ( ) ) ) { method . set accessible ( true ) ; } return new reflection provider method < t > ( key , method , instance , dependencies , scope annotation , annotation ) ;
collapse top ( operator . blank , number stack , operator stack ) ; if ( number stack . size ( ) = = 1 & & operator stack . size ( ) = = 0 ) { return number stack . pop ( ) ; } return 0 ;
http security bean definition parser . register filter chain proxy if necessary ( pc , pc . extract source ( element ) ) ; bean definition filter chain proxy = pc . get registry ( ) . get bean definition ( bean ids . filter _ chain _ proxy ) ; filter chain proxy . get property values ( ) . add property value ( firewall , new runtime bean reference ( ref ) ) ; return null ;
volt table another _ repl _ table = create replicated table ( num _ replicated _ items , num _ replicated _ items , null ) ; volt table another _ partition _ table = create partitioned table ( num _ partitioned _ items , num _ partitioned _ items ) ; load table ( client , replicated _ tester , true , another _ repl _ table ) ; load table ( client , partition _ tester , false , another _ partition _ table ) ;
lenght = ( ( 0x ff & table [ i + 3 ] ) < < 16 ) | ( ( 0x ff & table [ i + 4 ] ) < < 8 ) | ( 0x ff & table [ i + 5 ] ) ;
padding start = math . max ( 0 , m content inset start - m tab padding start ) ;
assert true ( return string . contains ( 22 ) ) ; assert true ( return string . contains ( 23 ) ) ; } finally {
string [ ] ids = dfsutil . get suffix ids ( conf , address , keys ) ; if ( ids = null & & ids . length > 1 ) { return ids [ 1 ] ; } return null ;
column col = ( ( column ) iter . next ( ) ) ;
glmparameters params = new glmparameters ( family . gaussian ) ;
string w lifecycles [ ] = context . find wrapper lifecycles ( ) ; get store appender ( ) . print tag array ( a writer , wrapper listener , indent + 2 , w lifecycles ) ;
solr query response rsp = process commit ( ignore - commit - from - client - 403 , false ) ; assert not null ( sending a commit should have resulted in an exception in the response , rsp . get exception ( ) ) ; rsp = process commit ( ignore - commit - from - client - 200 , false ) ; exception should be null = rsp . get exception ( ) ; assert null ( sending a commit should not have resulted in an exception in the response : + should be null , should be null ) ; rsp = process commit ( ignore - optimize - only - from - client - 403 , true ) ;
path fragment java output path = file system utils . replace extension ( path fragment . create ( rule name + _ aidl ) . get relative ( idl . get root relative path ( ) ) , . java ) ;
zin . close ( ) ;
test sort one column ( smalldata synthetic double frame . csv , 0 , true , false ) ;
setup supplemental actions ( ) ;
assert true ( this . processor . supports parameter ( this . param named valid model attr ) ) ; assert true ( this . processor . supports parameter ( this . param errors ) ) ; assert true ( this . processor . supports parameter ( this . param model attr ) ) ; assert true ( this . processor . supports parameter ( this . param non simple type ) ) ; assert false ( this . processor . supports parameter ( this . param int ) ) ;
string input str = 1972 - 12 - 28 ;
assert false ( channel . config ( ) . is auto read ( ) ) ;
world clock client handler handler = ch . pipeline ( ) . get ( world clock client handler . class ) ;
result . height = menu item layout helper . max ( lh . get check size ( ) . get height ( ) , lh . get label size ( ) . get height ( ) , lh . get acc size ( ) . get height ( ) , lh . get arrow size ( ) . get height ( ) ) ;
assert . assert null ( get enabled policy by name found disabled policy + p . get name ( ) , manager . get enabled policy by name ( p . get name ( ) ) ) ;
if ( schema class . is abstract ( ) ) throw new oschema exception ( document belongs to abstract class ' + schema class . get name ( ) + ' and cannot be saved ) ; cluster id = schema class . get cluster for new instance ( ( odocument ) record ) ; return database . get cluster name by id ( cluster id ) ; } else { return database . get cluster name by id ( database . get storage ( ) . get default cluster id ( ) ) ; } } else {
spell opts . tokens = query converter . convert ( red ) ;
if ( alpha duration > 0 & & delta alpha = 0 ) { if ( delta time > = alpha duration ) { alpha = end alpha ; } else { float alpha progress = delta time ( float ) alpha duration ; int vector alpha = ( int ) ( delta alpha * alpha progress ) ; alpha = begin alpha + vector alpha ; } }
writable utils . write vint ( out , interval value . get total months ( ) ) ;
if ( channel . is writable ( ) | | channel . is connected ( ) ) { this . ctx = ctx ; flush ( ctx , false ) ; } }
if ( next path = path ) paths . add ( next path ) ; } }
if ( node . get first child ( ) . matches qualified name ( msg _ function _ name ) ) { goog msg nodes . add ( node ) ; } else if ( node . get first child ( ) . matches qualified name ( msg _ fallback _ function _ name ) ) { visit fallback function call ( traversal , node ) ; } return ;
long start block count = cache . get block count ( ) ; long start block hits = cache . get stats ( ) . get hit count ( ) ; long start block miss = cache . get stats ( ) . get miss count ( ) ;
text field root field = new text field ( rootdir , new metadata map model ( metadata , restutils . root _ key , string . class ) ) ; add ( root field ) ;
log . error ( error while chaining the request . ) ;
if ( cursor . move to first ( ) ) { tmp = build node from row ( cursor ) ; stack . push ( tmp ) ; }
operator context2 . set revocable memory reservation ( 12 ) ;
for ( int i = 1 ; i < main command . length ; i + + ) { cmd . append ( ) ; cmd . append ( main command [ i ] ) ; } try { final string command = nohup + cmd . to string ( ) + > dev null 2 > + log path + & ; log . warn ( \ n \ n \ n + executing cmd for restart : { } + \ n \ n \ n , command ) ; runtime . get runtime ( ) . exec ( command ) ; } catch ( ioexception e ) { e . print stack trace ( ) ; }
hdfs dir = environment . get property ( hdfs . upload . dir ) ; if ( hdfs dir = = null ) hdfs dir = failmon ; hdfs = file system . get ( hadoop conf ) ;
boolean quick stop = false ; if ( is allow quick stop ( ) & & endpoint . is accept messages while stopping ( ) ) { quick stop = endpoint . get camel context ( ) . get status ( ) . is stopping ( ) ; } if ( quick stop ) { log at debug level so its quicker to see we are stopping quicker from the logs logger . debug ( running allowed ( ) - > false due camel context is stopping and endpoint configured to not accept messages while stopping ) ; return false ; } else { otherwise we only run if the endpoint is running boolean answer = endpoint . is running ( ) ; log at trace level as otherwise this can be noisy during normal operation logger . trace ( running allowed ( ) - > + answer ) ; return answer ; }
put put = new put ( hconstants . empty _ start _ row ) ; put . add ( hconstants . catalog _ family , hconstants . regioninfo _ qualifier , null ) ; region . put ( put ) ; get get = new get ( hconstants . empty _ start _ row ) ;
for ( relation type slot : relation type . values ( ) ) { if ( slot . canonical name . equals ( name ) | | slot . name ( ) . equals ( name ) ) { cached from string . put ( original name , slot ) ; return optional . of ( slot ) ; } }
barrier . await ( 10 , time unit . milliseconds ) ;
if ( management strategy instanceof camel context aware ) { ( ( camel context aware ) management strategy ) . set camel context ( this ) ; }
run completed . close ( ) ; return ; } else if ( signals received > = one more than bounded limit ) {
one input transformation < t , r > transform = ( one input transformation < t , r > ) return stream . get transformation ( ) ; transform . set state key selector ( key selector ) ; transform . set state key type ( key type ) ; return return stream ; }
sb . append ( < td > ) . append ( std dev ) . append ( < td > ) ; for ( int c = 0 ; c < num _ pc ; c + + ) sb . append ( < td > ) . append ( element builder . format ( sdev [ c ] ) ) . append ( < td > ) ; sb . append ( < tr > ) ;
results . skewness . put ( field name , math . sqrt ( results . doc count ) * results . skewness . get ( field name ) math . pow ( var , 1 . 5 d ) ) ;
return super . equals ( o ) ;
set popup position ( p . get x ( ) , p . get y ( ) ) ; return ; }
process instance process instance = runtime service . start process instance by key ( due date extension , variables ) ; task task = task service . create task query ( ) . process instance id ( process instance . get id ( ) ) . single result ( ) ;
long last msg = system . current time millis ( ) ;
int size partial chunk = ( int ) ( blkoff % bytes per checksum ) ;
assert true ( reduce node . get incoming connection ( ) . is breaking pipeline ( ) ) ;
if ( apn context . is ready ( ) & & retry after disconnected ( apn context . get reason ( ) ) ) { system properties . set ( gsm . defaultpdpcontext . active , false ) ; todo - what the heck? this shoudld go wait a bit before trying the next apn , so that we ' re not tying up the ril command channel . this also helps in any external dependency to turn off the context . start alarm for reconnect ( apn _ delay _ millis , apn context ) ; } else { apn context . set apn setting ( null ) ; apn context . set data connection ( null ) ; apn context . set data connection ac ( null ) ; }
assert equals ( 7 , config . get property ( alpha threshold option . property _ name ) ) ;
int sequence length = max literal length multiplication ( get sequence count ( w ) + 1 ) ;
em . get transaction ( ) . begin ( ) ; itnae1 . get references ( ) . set ( 0 , uste2 ) ; itnae1 . get references ( ) . set ( 1 , uste1 ) ; em . get transaction ( ) . commit ( ) ; itnae1 _ id = itnae1 . get id ( ) ; itnae2 _ id = itnae2 . get id ( ) ; }
int keylen = key . length ( ) ; for ( int i = 0 ; i < 8 ; i + + ) { keyword = ( keyword < < 8 ) | ( ( i < keylen ) ? 2 * key . char at ( i ) : 0 ) ; }
if ( _ log . should log ( log . warn ) ) _ log . warn ( race deferred before search completing? our on find = + _ on success + new one : + on find ) ;
job job = management service . create timer job query ( ) . single result ( ) ; assert not null ( job ) ; make sure job due ( job ) ;
stop server ( server list ) ; }
assert true ( current bigger than previous : , previous . compare to ( current ) < 0 ) ;
type name = _ + type name . substring ( 0 , type name . length ( ) - 2 ) ;
if ( keep socket open ) { disconnect ( ) ; }
m grid background paint . set color ( color . rgb ( 240 , 240 , 240 ) ) ; light
prev count = delegating collector . set last delegate count ;
{ error msg . error _ msg , error : ' ' { 0 } ' ' } ,
channel close listener temp listener = null ; synchronized ( this ) { if ( _ close listener = null ) { temp listener = _ close listener ; _ close listener = null ; } }
try get transaction metadata ( transaction id ) . if present ( transaction metadata : : async abort ) ;
list < object > value set = new array list < object > ( ) ;
test utils . call method ( do task , appmaster ) ; assert that ( appmaster . get satisfy state data by cluster ( foo ) . get allocate data ( ) , not null value ( ) ) ; assert that ( appmaster . get satisfy state data by cluster ( foo ) . get allocate data ( ) . get any ( ) , is ( 1 ) ) ; assert that ( appmaster . get satisfy state data by cluster ( foo ) . get remove data ( ) , not null value ( ) ) ;
return channel = null ; }
if ( m graph view = null ) { m graph view . reset highlight bar ( ) ; } update ui ( ) ;
index [ index _ idx + stage ] = best _ index ;
last plot width _ = notebook doc _ . get chunk rendered width ( ) ;
int next index = current offset + page length * cache _ ratio + cache overlap ; if ( next index > = size ) {
for ( int i = 0 ; i < 512 ; i + + ) { prefix from the original offset b . position ( 0 ) . limit ( a . remaining ( ) - random . next int ( 0 , a . remaining ( ) - 1 ) ) ; assert . assert true ( byte buffer util . starts with ( a , b ) ) ; assert . assert true ( byte buffer util . starts with ( a , b . slice ( ) ) ) ; prefix from random position inside of array int pos = random . next int ( 1 , a . remaining ( ) - 5 ) ; a . position ( pos ) ; b . limit ( bytes . length - 1 ) . position ( pos ) ; assert . assert true ( byte buffer util . starts with ( a , b ) ) ; a . position ( 0 ) ; ends with at random position b . limit ( a . remaining ( ) ) . position ( random . next int ( 0 , a . remaining ( ) - 1 ) ) ; assert . assert true ( byte buffer util . ends with ( a , b ) ) ; assert . assert true ( byte buffer util . ends with ( a , b . slice ( ) ) ) ; } a . limit ( bytes . length - 1 ) . position ( 0 ) ;
field metadata builder field builder = new field metadata builder ( get id ( ) , modifier . private , new array list < annotation metadata builder > ( ) , field name , list type ) ; comment structure comment = new comment structure ( ) ; comment . add comment ( new javadoc comment ( list of created entities . ) , comment location . beginning ) ; field builder . set comment structure ( comment ) ; return field builder ;
if ( model . get java type ( ) = null ) { elements element utils = processing env . get element utils ( ) ; type element type element = find type element ( processing env , round env , model . get java type ( ) ) ; if ( type element = null ) { string doc = element utils . get doc comment ( type element ) ; if ( doc = null ) { need to sanitize the description first ( we only want a summary ) doc = sanitize description ( doc , true ) ; the javadoc may actually be empty , so only change the doc if we got something if ( strings . is null or empty ( doc ) ) { model . set description ( doc ) ; } } } } return model ;
thread th = thread . current thread ( ) ; class loader old tccl = th . get context class loader ( ) ; log . info ( invoking [ + ( target = null ? target : type ) + ] + ( jar = null ? from jar [ + jar . get uri ( ) + ] : ) + with args [ + arrays . to string ( arguments ) + ] ) ;
directional light dl = new directional light ( ) ; dl . set direction ( new vector3f ( - 0 . 1f , - 0 . 7f , 1 ) . normalize local ( ) ) ; dl . set color ( new color rgba ( 1f , 1f , 1f , 1 . 0f ) ) ; root node . add light ( dl ) ; light mdl = new geometry ( light , new sphere ( 10 , 10 , 0 . 1f ) ) ; light mdl . set material ( asset manager . load material ( common materials red color . j3m ) ) ; root node . attach child ( light mdl ) ; light md2 = new geometry ( light , new sphere ( 10 , 10 , 0 . 1f ) ) ; light md2 . set material ( asset manager . load material ( common materials white color . j3m ) ) ; root node . attach child ( light md2 ) ;
mapped byte buffer = new mmap buffer ( file , start offset , num records * ( long ) total size in bytes , mmap mode . read _ write ) ; final int [ ] sorted doc ids = get sorted doc ids ( mapped byte buffer , total size in bytes , dimension size in bytes , num records ) ;
answer [ 0 ] = reason ;
m animator set . set start delay ( 0 ) ;
tstream = create analyzer tstream ( schema , field name , doc texts [ j ] ) ;
element sig element = encrypted doc . create element ns ( xmlsignature . xmlns , ds _ key _ info ) ;
if ( metric index > - 1 ) { sorted metric aggs [ metric index ] = metric agg ; }
task controller . setup ( ) ;
if ( closest xvalue > x value & & closest > 0 ) { - - closest ; }
store0 . delete ( belong to and inside server0 keys . get ( 4 ) , null ) ;
return new layer memory report . builder ( layer name , loss layer . class , input type , input type ) . standard memory ( 0 , 0 ) no params . working memory ( 0 , 0 , 0 , 0 ) . cache memory ( memory report . cache _ mode _ all _ zeros , memory report . cache _ mode _ all _ zeros ) no caching . build ( ) ;
matcher statement matcher = sqlparser . match drop stream ( ddl statement . statement ) ; if ( statement matcher . matches ( ) ) { string stream name = check identifier start ( statement matcher . group ( 1 ) , ddl statement . statement ) ; if ( is regular table ( m _ schema , stream name ) ) { throw m _ compiler . new volt compiler exception ( string . format ( invalid drop stream statement : table % s is not a stream . , stream name ) ) ; } m _ return after this = true ; } return false ;
reporter . incr counter ( collision counter . num _ collisions , 1 ) ; long num collisions = reporter . get counter ( collision counter . max _ collisions ) . get counter ( ) ;
if ( m current viewport . left = = m current viewport . right ) m current viewport . right + + ; if ( m current viewport . top = = m current viewport . bottom ) m current viewport . top + + ; }
_ single part mimereader . request part data ( ) ; }
resolutions . add element ( resolved ) ; return resolutions ; } } else if ( entity type = = notation ) { resolved = c . resolve notation ( entity name , public id , system id ) ; if ( resolved = null ) {
public abstract enum com example buck a b extends java lang enum implements java lang runnable { , , access flags 0x4409 ,
if ( item > = min tag index & & item < = max tag index ) { return tags [ item - min tag index ] ; }
if ( r _ mark _ s u ( ) ) { break lab7 ; } } while ( false ) ;
tr pr . get cnf style or div id or grid before ( ) . remove ( existing ) ;
double sum of weights = 0 ;
default extractor input input = create default extractor input ( ) ; byte [ ] target = new byte [ 5 ] ; input . read fully ( target , 0 , 5 ) ; assert true ( arrays . equals ( arrays . copy of ( test _ data , 5 ) , target ) ) ; assert equals ( 5 , input . get position ( ) ) ; target = new byte [ 4 ] ; input . read fully ( target , 0 , 4 ) ; assert true ( arrays . equals ( arrays . copy of range ( test _ data , 5 , 9 ) , target ) ) ; assert equals ( 5 + 4 , input . get position ( ) ) ; }
string request path = rest base controller . root _ path + workspaces + ws + wmslayers + wl + . html ; string request path2 = rest base controller . root _ path + workspaces + ws + wmsstores + wms + wmslayers + wl + . html ;
string builder return buffer = new string builder ( pre tag . length ( ) + original text . length ( ) + post tag . length ( ) ) ; return buffer . append ( pre tag ) ; return buffer . append ( original text ) ; return buffer . append ( post tag ) ; return return buffer . to string ( ) ; }
boolean query . builder child query = new boolean query . builder ( ) ; child query . add ( new boolean clause ( new term query ( new term ( skill , java ) ) , occur . must ) ) ; child query . add ( new boolean clause ( int point . new range query ( year , 2006 , 2011 ) , occur . must ) ) ;
elements . set ( index , element ) ; return element ;
listenable future < ? > init complete = m _ shared _ es . submit ( initialize instances ) ;
string name = full name ; string prefix = null ; int idx = full name . index of ( ' : ' ) ; if ( idx > 0 ) { prefix = full name . substring ( 0 , idx ) ; name = full name . substring ( idx + 1 ) ; }
string host = 127 . 0 . 0 . 1 ; rmnode node1 = mock nodes . new node info ( 1 , resources . create resource ( 4096 , 4 ) , 1 , host ) ; node added scheduler event node event1 = new node added scheduler event ( node1 ) ; scheduler . handle ( node event1 ) ; node update scheduler event node update event = new node update scheduler event ( node1 ) ; scheduler . handle ( node update event ) ; application attempt id app attempt id = create app attempt id ( this . app _ id + + , this . attempt _ id + + ) ;
check throws runtime exception ( new callable < object > ( ) { public object call ( ) throws exception { write . write ( 42 ) ; return null ; } } ) ;
assert translated lines ( translation , + ( void ) initialize { , if ( self = = [ test class ] ) { , { , [ ( ( java io print stream * ) nil _ chk ( jre load static ( java lang system , out ) ) ) + println with nsstring : @ \ foo \ ] ; ) ;
try { host = inet address . get local host ( ) . get host name ( ) ; } catch ( ioexception io ) { io . print stack trace ( ) ; }
x + = width 2 - layout . width 2 ; y + = height 2 + layout . height 2 ; cache . set position ( x , y ) ; cache . draw ( sprite batch ) ;
path base = testdir . get path file ( base ) ;
final on complete listener dialog callback = new on complete listener ( ) { @ override public void on complete ( bundle values , facebook exception exception ) { if ( exception = null ) { handle error ( exception , show dialog context ) ; } else { handle success ( values ) ; } } } ;
m lock . read lock ( ) . lock ( ) ;
mdc . put ( mdc _ camel _ context _ id , exchange . get context ( ) . get name ( ) ) ;
on view ( with id ( r . id . drawer _ layout ) ) . perform ( open drawer ( gravity compat . start ) ) ; final resources res = activity test rule . get activity ( ) . get resources ( ) ;
byte buffer value buffer = byte buffer . allocate ( value size ) ; data file . read ( value buffer , value location + byte utils . size _ of _ int ) ; return value buffer . array ( ) ; } case readonly _ v2 : {
final enum set < facet range include > include = enum set . none of ( facet range include . class ) ; for ( final string o : param ) { include . add ( facet range include . get ( o ) ) ; }
} catch ( json mapping exception e ) { } catch ( ioexception e ) { } }
string ip range = vlan . get ip range ( ) ; string [ ] range = ip range . split ( - ) ; vlan response . set start ip ( range [ 0 ] ) ; vlan response . set end ip ( range [ 1 ] ) ; vlan response . set network id ( vlan . get network id ( ) ) ; account owner = api dbutils . get vlan account ( vlan . get id ( ) ) ; if ( owner = null ) { populate account ( vlan response , owner . get id ( ) ) ; populate domain ( vlan response , owner . get domain id ( ) ) ; } vlan response . set physical network id ( vlan . get physical network id ( ) ) ; vlan response . set object name ( vlan ) ; return vlan response ;
return new linked list < string > ( ) ;
setup list status ( ) ;
key value heap kvh = new key value heap ( scanners , cell comparator impl . comparator ) ; try { for ( key value scanner scanner : scanners ) { ( ( seek test scanner ) scanner ) . set real seek done ( false ) ; } while ( kvh . next ( ) = null ) ; the poll real kv should throw ioe . assert true ( false ) ; } catch ( ioexception ioe ) { kvh . close ( ) ; }
reader = new char sequence reader ( char sequence ) ; buf = new char [ 5 ] ; string builder builder = new string builder ( ) ; int read ; while ( ( read = reader . read ( buf , 0 , buf . length ) ) = - 1 ) { builder . append ( buf , 0 , read ) ; } assert equals ( expected , builder . to string ( ) ) ; assert fully read ( reader ) ;
assert equals ( loaded view added node changed graph type added node changed graph type added edge added edge deleted edge deleted node changed graph type , m _ listener . event list ) ;
enumeration enu = train instances . enumerate instances ( ) ; while ( enu . has more elements ( ) ) { instance = ( instance ) enu . next element ( ) ; if ( instance . is missing ( m _ att index ) ) m _ distribution . add ( ( int ) instance . value ( m _ att index ) , instance ) ; }
cache . purge unreferenced entries ( ) ;
children = array util . remove nulls ( domastnode leaf . class , children ) ;
data . add ( points . create2 d ( 1 , 2 ) ) ; data . add ( points . create2 d ( 1 , 2 , crs ) ) ; data . add ( points . create3 d ( 1 , 2 , 3 ) ) ; data . add ( points . create3 d ( 1 , 2 , 3 , crs ) ) ; data . add ( points . create2 dm ( 1 , 2 , 3 ) ) ; data . add ( points . create2 dm ( 1 , 2 , 3 , crs ) ) ;
easy mock . expect ( worker . get plugins ( ) ) . and return ( plugins ) . times ( 3 ) ; easy mock . expect ( plugins . compare and swap loaders ( connector mock ) ) . and return ( delegating loader ) ; if ( should create connector ) { easy mock . expect ( worker . get plugins ( ) ) . and return ( plugins ) ; easy mock . expect ( plugins . new connector ( easy mock . any string ( ) ) ) . and return ( connector mock ) ; } easy mock . expect ( connector mock . config ( ) ) . and stub return ( new config def ( ) ) ; for ( map < string , string > config : configs ) easy mock . expect ( connector mock . validate ( config ) ) . and return ( new config ( collections . < config value > empty list ( ) ) ) ; easy mock . expect ( plugins . compare and swap loaders ( delegating loader ) ) . and return ( plugin loader ) ;
final conjunct future < void > all terminal = future utils . wait for all ( futures ) ;
if ( debug ) system . out . println ( get thread name ( ) + - + debug _ prefix + ignore created ast for + input . get element name ( ) + - ast from reconciler is newer ) ; non - nls - 1 non - nls - 2 non - nls - 3 reconciled ( f ast , input , null ) ; return f ast ;
start all echo servers ( ) ; assert all echo servers running ( _ echo servers ) ; _ client = _ cli . create client ( _ cli . get zkclient ( ) , _ zk uri string , d2 , service - 1 _ 1 ) ;
jingle content provider jcp = new jingle content provider ( ) ; jingle description provider jdp audio = new jingle description provider . audio ( ) ; jingle transport provider jtp raw udp = new jingle transport provider . raw udp ( ) ; jingle transport provider jtp ice = new jingle transport provider . ice ( ) ; extension element provider < ? > jmip audio = new jingle content info provider . audio ( ) ; int event type ;
dir paths = fc view . util ( ) . list status ( new path ( internal dir ) ) ; assert . assert equals ( 2 , dir paths . length ) ; fs = file context test helper . contains path ( fc view , internal dir internal dir2 , dir paths ) ; assert . assert not null ( fs ) ; assert . assert true ( internal dirs should appear as dir , fs . is directory ( ) ) ; fs = file context test helper . contains path ( fc view , internal dir link to dir2 , dir paths ) ; assert . assert not null ( fs ) ;
m touch drawable = new touch effect drawable ( new float effect ( ) , color state list . value of ( touch color ) ) ;
set vertex attrib ( vb ) ; } else {
set < partition > query partitions ; try { query partitions = index utils . check partitions covered by index ( table scan , parse context , indexes ) ; if ( query partitions = = null ) { partitions not covered return false ; } } catch ( hive exception e ) { log . error ( fatal error : problem accessing metastore , e ) ; throw new semantic exception ( e ) ; } if ( query partitions . size ( ) = 0 ) { return true ; }
assert same ( connection2 , s2 implementor . connection ( ) ) ; } ) ;
animate view ( holder , position ) ; }
argument captor < intent > intent argument captor = argument captor . for class ( intent . class ) ;
template model m2 = new template model ( ) ; m2 . add lhs item ( fp1 ) ; m2 . add lhs item ( fp2 ) ; m2 . name = r2 ; m2 . add row ( new string [ ] { value3 } ) ; final string expected2 = rule \ r2 _ 0 \ \ n + dialect \ mvel \ \ n + when \ n + p1 : smurf ( field1 = = \ value1 \ , field2 = = \ value2 \ ) \ n + p2 : smurf ( field3 = = \ value3 \ ) \ n + then \ n + end ;
if ( contents . is empty ( ) ) { get element ( ) . get parent element ( ) . get style ( ) . set display ( block ) ; }
for ( int i = 0 ; i < size ; i + + ) { map1 . get ( keys . get ( i ) ) ; }
int position = ( ( variable declaration ) fi ) . get start position ( ) ;
assignment info info10 = check assignment ( all topics , assignments . get ( consumer10 ) ) ;
populate exchange with breadcrumb from message context ( message context , exchange ) ;
return util . sdk _ int < 24 & & omx . sec . aac . dec . equals ( codec name ) & & samsung . equals ( util . manufacturer ) & & ( util . device . starts with ( zeroflte ) | | util . device . starts with ( herolte ) | | util . device . starts with ( heroqlte ) ) ;
list < string > approx100 = lists . new array list with expected size ( 100 ) ; using guava
if ( not null | | ( primary key & & property type = = property type . string ) ) { constraint builder . append ( not null ) ; }
accum & = ( - 1 l > > > ( 64 - num bits ) ) ; return accum ;
mock . reset ( ) ; one exchange done . reset ( ) ; mock . expected bodies received ( hello again world ) ; template . send body and header ( file : target premove , hello again world , exchange . file _ name , hello . txt ) ;
else if ( is item pass ( pass ) ) { setup for collecting optional entity info . . . entity collection entities = null ; if ( info = null ) { entities = info . get owner ( ) . get entity collection ( ) ; } draw secondary pass ( g2 , plot , dataset , pass , series , item , domain axis , data area , range axis , crosshair state , entities ) ; }
string prefix = new string ( new byte [ 20 * 1024 ] ) ; for ( int i = 1 ; i < = inputsize ; i + + ) { string str = + i ; int zeros to prepend = 3 - str . length ( ) ; for ( int j = 0 ; j < zeros to prepend ; j + + ) { str = 0 + str ; } wr . write ( prefix + hey + str + \ n ) ; } wr . close ( ) ; }
ipath actual = path util . find program location ( name1 , path123 ) ;
terminate subscription ( sipcontact ) ; }
data node dn = cluster . get data nodes ( ) . get ( 0 ) ; final map < string , object > vol infos = dn . data . get volume info map ( ) ; assert . assert true ( no volumes in the fsdataset , vol infos . size ( ) > 0 ) ; int i = 0 ; for ( map . entry < string , object > e : vol infos . entry set ( ) ) { log . info ( vol + i + + + ) + e . get key ( ) + : + e . get value ( ) ) ; }
item view . get location in window ( location ) ;
profile info . task p1 = info . get phase task ( profile phase . load ) ; assert that ( info . get tasks for phase ( p1 ) ) . has size ( 101 ) ;
system . out . println ( part 1 demo with different instances . ) ;
final endpoint endpoint = context . get endpoint ( disruptor : test . a ) ; final exchange exchange = endpoint . create exchange ( ) ; exchange . get in ( ) . set header ( cheese , 123 ) ; final producer producer = endpoint . create producer ( ) ;
spring . set end value ( 1 . 0f ) ; } }
result + = x > > > 32 ;
get admin client ( ) . realm ( realm _ name ) . remove ( ) ;
owner document . mutation events = orig ;
if ( new library path = null ) { set environment variable ( get library path property name ( ) , new library path ) ; } }
nd4j . get blas wrapper ( ) . level1 ( ) . axpy ( vector length , 1 . 0f , neu1e , l1 ) ; vocab word word = vocab . element at index ( current word index ) ; index syn0 vec map . put ( word , l1 ) ; }
setup expand collapse action listener ( ) ;
is anonymous credentials = true ;
throw new illegal state exception ( string . format ( locale . root , could not determine how to apply @ convert ( attribute name = ' % s ' ) to collection [ % s ] , info . get attribute name ( ) , collection . get role ( ) ) ) ; } }
from ( jetty : http : localhost : { { port2 } } server mytest?send server version = false & send date header = true ) . transform ( constant ( response ) ) ; } } ; }
int row max = ( ( row number + 1 ) * m num columns ) ; accessibility index = row max - row elements ; }
final int extra docs = random int between ( 0 , 5 ) ;
document doc = builder . parse ( new input source ( in ) ) ;
int index = authority . last index of ( : ) ;
discovery result discovery result = discovery result builder . create ( thing uid ) . with label ( given name ) . with bridge ( bridge uid ) . with property ( zway binding constants . device _ config _ node _ id , node id ) . with property ( thing . property _ vendor , vendor string ) . with property ( zway binding constants . device _ prop _ location , location ) . with property ( zway binding constants . device _ prop _ manufacturer _ id , manufacturer id ) . with property ( zway binding constants . device _ prop _ device _ type , device type ) . with property ( zway binding constants . device _ prop _ zddxmlfile , zddxmlfile ) . with property ( zway binding constants . device _ prop _ sdk , sdk ) . build ( ) ;
common tests ( resources ) ;
entity manager em = get entity manager ( ) ; em . get transaction ( ) . begin ( ) ; str test entity te = new str test entity ( x ) ; em . persist ( te ) ; id = te . get id ( ) ; em . get transaction ( ) . commit ( ) ; timestamp2 = system . current time millis ( ) ;
dfs . delete ( corrupt file , true ) ; log . info ( waiting for missing blocks count to be zero . . . ) ;
for ( legacy service loader sl : geo server extensions . extensions ( legacy service loader . class ) ) { try { sl . set reader ( reader ) ; service info service = sl . load ( geo server ) ; if ( service = null ) { logger . info ( loading service ' + service . get id ( ) + ' ) ; geo server . add ( service ) ; } } catch ( exception e ) { string msg = error occured loading service : + sl . get service class ( ) . get simple name ( ) ; logger . warning ( msg ) ; logger . log ( level . info , , e ) ; } }
this . is closed = true ;
this ( graph qlschema , query strategy , null ) ;
} } ) ; url text field = new text field ( url , new property model ( request model , request url ) ) ; url text field . set markup id ( request url ) ; url text field . set output markup id ( true ) ; demo requests form . add ( url text field ) ; body = new code mirror editor ( body , new property model ( request model , request body ) ) ;
string dest _ addr = null ;
am1 . allocate ( * , gb , 1 , new array list < container id > ( ) , x ) ; container id . new container id ( am1 . get application attempt id ( ) , 1 ) ; container id2 = container id . new container id ( am1 . get application attempt id ( ) , 2 ) ; assert . assert true ( rm . wait for state ( nm1 , container id2 , rmcontainer state . allocated ) ) ;
compute partition list ( hive conf , null , new hash set < integer > ( ) ) ;
for ( string block setting : arrays . as list ( setting _ read _ only , setting _ read _ only _ allow _ delete , setting _ blocks _ metadata ) ) { try { enable index block ( test , block setting ) ; assert blocked ( client ( ) . admin ( ) . indices ( ) . prepare open ( test ) ) ; assert index is closed ( test ) ; } finally { disable index block ( test , block setting ) ; } }
given ( connection . create session ( this . container . is session transacted ( ) , this . container . get session acknowledge mode ( ) ) ) . will return ( session ) ;
@ non null list < string > missing children names = lists . transform ( expected children , node _ to _ name ) ;
assert false ( hibernate . is initialized ( a2 . get b ( ) ) ) ;
context2 . get pending writes for test ( ) . put ( new offset range ( 0 , 100 ) , new write ctx ( null , 0 , 0 , 0 , null , null , null , 0 , false , null ) ) ; context4 . get pending commits for test ( ) . put ( new long ( 100 ) , new commit ctx ( 0 , null , 0 , attr ) ) ; thread . sleep ( nfs config keys . dfs _ nfs _ stream _ timeout _ min _ default ) ; ret = cache . put ( new file handle ( 5 ) , context5 ) ; assert false ( ret ) ; }
assert equals ( pauline , order . get first name ( ) ) ; assert equals ( m , order . get last name ( ) ) ; map < string , object > received header map = ( map < string , object > ) exchange . get in ( ) . get header ( bindy fixed length data format . camel _ bindy _ fixed _ length _ header ) ;
template . send body and header ( file : + ftp _ root _ dir , expected , exchange . file _ name , hello . txt ) ; template . send body and header ( file : + ftp _ root _ dir , expected2 , exchange . file _ name , goodbye . txt ) ; mock endpoint mock = get mock endpoint ( mock : result ) ;
system . set property ( context initializer . config _ file _ property , val ) ;
if ( persister . is versioned ( ) ) { substitute = versioning . seed version ( values , persister . get version property ( ) , persister . get version type ( ) , source ) | | substitute ; } return substitute ;
final xtsmanager service xts service = new xtsmanager service ( coordinator url ) ;
assert equals ( 0 , total calls . get ( ) ) ; fake pool . run all ( ) ; assert equals ( 2 , total calls . get ( ) ) ;
execute ( insert into % s ( a , b , c , d ) values ( ? , ? , ? , ? ) , 2 , 0 , 0 , 0 ) ;
mock message ( evt gs ) ; wait for sync ( ) ;
if ( unique terms . size ( ) < 1 ) { term attribute . set empty ( ) ; return false ; }
masked . append ( formatted message , last4pos , number end ) ;
if ( endpoint . equals ( fbutilities . get broadcast address ( ) ) ) continue ; but don ' t add localhost to the graph to avoid streaming locally
if ( searched bytes + + = = search limit bytes ) { if ( sniffing ) { throw new parser exception ( searched too many bytes . ) ; } return false ; }
verify zero measures ( measure query . builder ( ) . set component uuid ( c1 ) . set analysis uuid ( other _ analysis _ uuid ) . set metric id ( complexity _ metric _ id ) ) ;
assert true ( display list . size ( ) = = 2 ) ;
int meta column type = rs . get int ( data _ type ) ;
start repl producers ( ) ;
m remote service . on destroy ( ) ; super . on destroy ( ) ; log . d ( tag , tag + on destroy ) ; }
while ( ledger . get number of entries ( ) > 2 ) { thread . sleep ( 10 ) ; } }
iterator < intercept strategy > it = channel . get intercept strategies ( ) . iterator ( ) ;
taxo writer . add taxonomy ( input , new memory ordinal map ( ) ) ; assert equals ( no categories should have been added , 2 , taxo writer . get size ( ) ) ; root + ' a ' assert equals ( category ' a ' received new ordinal? , ord a , taxo writer . add category ( new facet label ( a ) ) ) ;
setup vector dimension ( resource info . time , time , dimension presentation . list , null , null , null ) ;
optional < path > compiler output path = module . get compiler output path ( ) ; if ( compiler output path . is present ( ) ) { android properties . put ( compiler _ output _ path , ij project paths . to module dir relative string ( compiler output path . get ( ) , module base path ) ) ; } }
m paint . set style ( paint . style . fill _ and _ stroke ) ; m paint . set color ( m water color ) ; canvas . draw path ( create water path ( m water bounds , m progress ) , m paint ) ;
return int digits ;
kie session . update ( fq2 , queen2 . set row ( row2 ) ) ; assert equals ( 1 , kie session . fire all rules ( ) ) ; }
list < put > puts = construct put requests ( ) ; table . batch ( puts , null ) ;
final count down latch background upload = new count down latch ( 1 ) ; final handler thread handler thread = new handler thread ( handler thread ) ; handler thread . start ( ) ; looper looper = handler thread . get looper ( ) ; handler handler = new handler ( looper ) ; handler . post ( new runnable ( ) { @ override public void run ( ) {
background flush commits ( true ) ;
assert not null ( invoice payment . get target invoice id ( ) ) ; final invoices invoices = kill bill client . get invoices for account ( account json . get account id ( ) , request options ) ;
if ( gpd = = spd ) { pd = gpd ; } else if ( spd instanceof indexed property descriptor ) { pd = merge property with indexed property ( gpd , ( indexed property descriptor ) spd ) ; } else if ( gpd instanceof indexed property descriptor ) { pd = merge property with indexed property ( spd , ( indexed property descriptor ) gpd ) ; } else { pd = merge property descriptor ( gpd , spd ) ; }
_ login service = new dummy login service ( ) ;
int ok plugin count = 0 ;
if ( sign < 0 ) { for ( node node : node set ) { values . put ( node , - values . get ( node ) ) ; } } return true ;
method call ret val p = do http call ( templeton base url + ddl database newdb , http _ method _ type . put , props , null ) ; assert . assert equals ( p . get assert msg ( ) , http status . ok _ 200 , p . http status code ) ; }
maybe schedule ping server task ( ) ; } } else {
m counting lru map . put ( key2 , 150 ) ;
e . print stack trace ( ) ; } catch ( number format exception e ) {
if ( stat . get state ( ) = = monitored task impl . state . running ) { log . warn ( status + stat + appears to have been leaked ) ; stat . cleanup ( ) ; }
file context . rename snapshot ( snap root path , s1 , s2 ) ;
custom type . set index options ( index options . docs ) ; final mock tokenizer doc1field1 = new mock tokenizer ( mock tokenizer . whitespace , false ) ; doc1field1 . set reader ( new string reader ( doc1field1 ) ) ; f . set token stream ( doc1field1 ) ; field type custom type2 = new field type ( text field . type _ stored ) ; field f2 = new field ( string , value , custom type2 ) ;
url = new url ( http : www . example . 2000 . hu ) ; assert . assert equals ( 2000 . hu , urlutil . get domain suffix ( url ) . get domain ( ) ) ;
return super . get trash root ( path ) . make qualified ( get uri ( ) , null ) ;
if ( ( stripped . starts with ( org . apache . struts . ) ) ) { properties . put ( stripped , parameter value ) ; } }
i from vertex . field ( i field name , out , out type ) ; return out ; }
confirm permission change ( 1777 , rwxrwxrwt , fs , shell , dir2 ) ;
filter = new dependent column filter ( families [ 0 ] , qualifier , false , compare op . equal , new binary comparator ( match _ val ) ) ; scan = new scan ( ) ; scan . set filter ( filter ) ; scan . set max versions ( integer . max _ value ) ;
protocol provider service sip impl target = current listeners copy . iterator ( ) . next ( ) ; if ( logger . is debug enabled ( ) ) logger . debug ( will randomly dispatch to \ + target . get account id ( ) + \ because the username in the request - uri + is unknown or empty ) ; if ( logger . is trace enabled ( ) ) logger . trace ( \ n + request ) ; return target ;
for ( string key : pref . keys ( ) ) { pref . remove ( context + _ + key ) ; }
url url = jar . to real path ( ) . to uri ( ) . to url ( ) ;
return new filtered data entry reader ( new data entry name filter ( new extension matcher ( jar extension ) ) , jar reader , reader ) ; }
throw new illegal state exception ( e ) ; } finally {
for ( zip in zip : inputs ) { zip . scan entries ( this ) ; }
node list nl = doc . get elements by tag name ns ( xmlsignature . xmlns , signature ) ; if ( nl . get length ( ) = = 0 ) { throw new xml signature format exception ( message is not a correct xml signature document : ' signature ' element is missing . check the sent message . ) ; } log . debug ( { } signature elements found , nl . get length ( ) ) ; return nl ;
if ( m helper = = null ) return ;
this . jetty server = new server ( 0 ) ; }
assert false ( names match , filter . accept ( ev ) ) ; }
bootstrap . connect ( ) ;
did not get preferred = true ; shared slot slot = remove from multi map ( slots for group , location . get resource id ( ) ) ; if ( slot = null & & slot . is alive ( ) ) { return new tuple2 < > ( slot , locality . local ) ; } } }
for ( node < e > p = prev ; ; + + hops ) { if ( p . item = null ) { active pred = p ; is first = false ; break ; } node < e > q = p . prev ; if ( q = = null ) { if ( p . next = = p ) return ; active pred = p ; is first = true ; break ; } else if ( p = = q ) return ; else p = q ; }
jnlp resource jnlpres = locate resource ( dreq ) ; log . debug ( jnlp resource : + jnlpres ) ; if ( log . is info enabled ( ) ) { log . info ( servlet . log . info . goodrequest , jnlpres . get path ( ) ) ; }
error correction level = error correction level . for bits ( ( format info > > 3 ) & 0x03 ) ;
attribute descriptor metadata descriptor = build simple descriptor ( metadata _ property _ name , string . class ) ; type builder . add ( metadata descriptor ) ;
type . source start = - 1 ; type . source end = - 2 ; field . type = type ;
local cluster config = null ; map < string , string > additional env = new hash map < string , string > ( ) ; additional env . put ( export data processor . export _ to _ type , org . voltdb . exportclient . rejecting export client ) ; final volt project builder project = new volt project builder ( ) ;
system . arraycopy ( buf , mark , buf , 0 , buf . length - mark ) ;
assert equals ( 0 , ksession . fire all rules ( ) ) ; }
string icq test agent name = system . get property ( testing _ impl _ user _ id _ prop _ name , null ) ;
return standalone test result . spawn results ( ) ; } catch ( ioexception e ) {
return class loader ;
bar buffer buffer = m bar buffers [ i ] ; final float phase y = m animator . get phase y ( ) ; mppoint f icons offset = mppoint f . get instance ( data set . get icons offset ( ) ) ; icons offset . x = utils . convert dp to pixel ( icons offset . x ) ; icons offset . y = utils . convert dp to pixel ( icons offset . y ) ;
final span event recorder recorder = async trace . current span event recorder ( ) ; recorder . record service type ( service type . async ) ; recorder . record api id ( async method api id ) ; return async trace ; }
url file url = ( get class ( ) . get class loader ( ) . get resource ( file path ) ) ; if ( file url = = null ) { throw new ioexception ( file not found : + file path ) ; } file keystore file = new file ( file url . get file ( ) ) ;
dbepersist action comment action = build comment action ( command . get object ( ) ) ;
shards stats . add ( new shard stats ( index shard . routing entry ( ) , index shard . shard path ( ) , new common stats ( indices service . get indices query cache ( ) , index shard , shard _ stats _ flags ) , index shard . commit stats ( ) , index shard . seq no stats ( ) ) ) ;
for ( host vo host : hosts ) { modify storage pool command ms pool cmd = new modify storage pool command ( true , primary storage ) ; final answer answer = _ agent mgr . easy send ( host . get id ( ) , ms pool cmd ) ; if ( answer = = null | | answer . get result ( ) ) { if ( s _ logger . is debug enabled ( ) ) { s _ logger . debug ( modify storage pool add failed due to + ( ( answer = = null ) ? answer null : answer . get details ( ) ) ) ; } } else { if ( s _ logger . is debug enabled ( ) ) { s _ logger . debug ( modify storage pool add secceeded ) ; } } }
multi . set type ( 0 , float ) ;
reader reader = resources . get resource as reader ( org apache ibatis submitted inheritance mybatis - config . xml ) ; sql session factory = new sql session factory builder ( ) . build ( reader ) ; reader . close ( ) ;
call state event collector call1 state collector = new call state event collector ( call at p1 , call state . call _ ended ) ;
if ( i > = super . length1 | | j > = super . length2 ) { this . matrix . set ( i , j , 0 ) ; } else {
get global visible rect ( visible ) ;
assert equals ( shard routing state . started , shard routing state ) ; assert not null ( current node ) ; assert equals ( replica node ( ) . get name ( ) , current node . get name ( ) ) ;
assert that ( e ) . has message ( unable to create mock instance of type ' uses two bases ' ) ;
merged anomaly = curr anomaly ; } else {
while ( depth > 0 ) { end tag ( el namespace [ depth ] , el name [ depth ] ) ; }
return error map . is empty ( ) ? null : error map . values ( ) . iterator ( ) . next ( ) ;
in . read ( ) ; fail ( expected a connection closed exception ) ; } catch ( ioexception expected ) {
{ match range ( ' \ u00 c0 ' , ' \ u00 d6 ' ) ; } break ; case 5 :
rval = domain . equals ( network utils . numeric to inet address ( domain ) . get host address ( ) ) ;
double distance = calculate distance ( location , home location ) ;
group membership1 . set contact email ( alfred + @ test . linkedin . com ) ;
simple feature type builder builder = new simple feature type builder ( ) ;
string query = select r1 . id as desc , ( p1 . id + 20 ) as thomas from p1 , r1 where p1 . num = r1 . num ;
response delegate = ( response ) value ;
ask for permissions ( new string [ ] { manifest . permission . camera } , 2 ) ;
if ( cursor < = limit _ backward ) { return false ; } cursor - - ;
map < variable , variable state > after finally = new hash map < variable , variable state > ( get state ( ) ) ;
for ( map . entry < object , object > entry : overrides . entry set ( ) ) { string extension = ( string ) entry . get key ( ) ; string mime type = ( string ) entry . get value ( ) ; add ( mime type , extension ) ; } } finally { stream . close ( ) ; } } catch ( ioexception ignored ) {
if ( type = null ) value = types . cast object ( value , type , context = = declaration ? types . cast : types . assignment ) ; this . value = value ; }
if ( matched cookies . is empty ( ) ) { list < header > headers = cookie spec . format cookies ( matched cookies ) ; for ( header header : headers ) { request . add header ( header ) ; } } int ver = cookie spec . get version ( ) ;
if ( force ) { log . w ( tag , forcing database upgrade ) ; copy database from assets ( ) ; db = return database ( ) ; } return db ;
xml element . get xml ( ) . remove child ( uses sdk . get xml ( ) ) ;
case primitive _ type : return specific > = keyword _ void & & specific < = keyword _ char ; case creatable _ type _ name :
vertx . file system ( ) . read file ( target classes readme . txt , result - > { if ( result . succeeded ( ) ) { system . out . println ( result . result ( ) ) ; } else { system . err . println ( oh oh . . . + result . cause ( ) ) ; } } ) ;
if ( memory string . matches ( . * \ \ d ) ) { return integer . value of ( memory string ) ; } else { long value = long . value of ( memory string . substring ( 0 , memory string . length ( ) - 1 ) ) ; string unit = memory string . substring ( memory string . length ( ) - 1 ) . to lower case ( ) ; if ( unit . equals ( k ) ) { return value * 1024 l ; } else if ( unit . equals ( m ) ) { return value * 1048576 l ; } else if ( unit . equals ( g ) ) { return value * 1073741824 l ; } }
assert true ( x > 3500 ) ; action flick = get builder ( driver ) . flick ( to flick , - 400 , 0 , flick action . speed _ fast ) . build ( ) ; flick . perform ( ) ; x = link . get location ( ) . x ;
max size property . get ( ) . unbind ( ) ; pref size property . get ( ) . unbind ( ) ; if ( size property . get ( ) . get ( ) > get default drawer size ( ) ) { temp drawer size = pref size property . get ( ) . get ( ) ; } else { temp drawer size = get default drawer size ( ) ; } if ( translate to = init translate . get ( ) ) { translate to = init translate . get ( ) ; translate timer . reverse and continue ( ) ; } translate timer . set on finished ( ( ) - > { overlay pane . set mouse transparent ( true ) ; fire event ( new jfxdrawer event ( jfxdrawer event . closed ) ) ; } ) ;
docx4j properties . set property ( docx4j . convert . out . html . output method xml , true ) ; docx4 j . to html ( html settings , os , docx4 j . flag _ export _ prefer _ xsl ) ; todo non _ xsl implementation system . out . println ( ( ( byte array output stream ) os ) . to string ( ) ) ;
resources . add ( build dir . get file ( new path ( obj ) . remove last segments ( 1 ) . append ( subdir . mk ) ) ) ;
record histogram . record enumerated histogram ( notifications . app notification status , notification system status util . determine app notification status ( m app context ) , notification system status util . app _ notifications _ status _ boundary ) ;
final htable table = new htable ( test _ util . get configuration ( ) , test _ table2 ) ;
assert false ( controller . request incoming ( request , 500 ) ) ;
logger . info ( string . format ( % s . % s does not specify an http method annotation defaulting to get . , method . get class ( ) . get name ( ) , method . get name ( ) ) ) ; return http method . get ;
object old aahint = g2d . get rendering hint ( rendering hints . key _ antialiasing ) ;
request . set media renderer ( renderer configuration . get default conf ( ) ) ;
if ( arrays . equals ( global color table , image metadata . local color table ) ) { image metadata . local color table = null ; }
status . set status ( fixing up missing daughters ) ; fixup daughters ( status ) ; if ( master recovery ) { start meta catalog janitor after meta and regions have been assigned . status . set status ( starting catalog janitor ) ; this . catalog janitor chore = new catalog janitor ( this , this ) ; start catalog janitor chore ( ) ; register mbean ( ) ; }
int [ ] vertex types = this . vertex types . items ; for ( int i = 0 ; i < vertex count ; i + + ) if ( vertex types [ i ] = concave ) return i ; return 0 ; if all vertices are concave , just return the first one . }
int remaining = middle - helper left ; for ( int i = 0 ; i < = remaining ; i + + ) { array [ current + i ] = helper [ helper left + i ] ; } }
return cl ;
test needed temps ( function foo ( a ) { a ; a ; } ; foo ( true ) ; , foo , empty _ string _ set ) ; }
router . on create options menu ( null , null ) ; expected call state . create options menu calls + + ; assert calls ( expected call state , controller ) ;
outcome = leader . handle ( new raft messages . timeout . election ( myself ) , state , log ( ) ) ;
client bootstrap = new client bootstrap ( new nio client socket channel factory ( executors . new single thread executor ( daemon ( cluster client boss , monitor ) ) , executors . new fixed thread pool ( 2 , daemon ( cluster client worker , monitor ) ) , 2 ) ) ; client bootstrap . set option ( tcp no delay , true ) ; client bootstrap . set pipeline factory ( new network node pipeline factory ( ) ) ; msg log . debug ( started network sender for + to string ( config ) ) ; }
assert equals ( 1 , reducer . get key columns ( 0 ) . length ) ; assert equals ( 0 , reducer . get key columns ( 0 ) [ 0 ] ) ; assert equals ( - 1 , reducer . get parallelism ( ) ) ; assert true ( reducer . is combinable ( ) ) ; assert true ( reducer . get input ( ) instanceof generic data source base < ? , ? > ) ;
finder descriptor . parameter annotations = discovered annotations ;
volt type partition param type1 = volt type . get ( ( byte ) procedure . get partitioncolumn ( ) . get type ( ) ) ; volt type partition param type2 = volt type . get ( ( byte ) procedure . get partitioncolumn2 ( ) . get type ( ) ) ; int p1 = get partition for procedure parameter ( procedure . get partitionparameter ( ) , partition param type1 , task ) ; int p2 = get partition for procedure parameter ( procedure . get partitionparameter2 ( ) , partition param type2 , task ) ; return new int [ ] { p1 , p2 } ;
marked char = invalidated ;
assert null ( request context . get ( out s ) ) ;
scan . set stop row ( hbase timeline storage utils . calculate the closest next row key for prefix ( sub application row key prefix . get row key prefix ( ) ) ) ;
try { object [ ] array = bean util . declared . get property ( value , hint property name ) ; if ( array = = null ) { array = ( object [ ] ) array . new instance ( hint property type . get component type ( ) , 1 ) ; bean util . declared silent . set property ( value , hint property name , array ) ; array [ 0 ] = data [ i ] ; } else { object [ ] new array = arrays util . append ( array , data [ i ] ) ; if ( new array = array ) { bean util . declared silent . set property ( value , hint property name , new array ) ; } } } catch ( exception ex ) { throw new db oom exception ( ex ) ; }
input stream is = kraken account jsontest . class . get resource as stream ( account example - balance - data . json ) ;
return md5hash + - + string key ;
hold append . count down ( ) ;
now = system . nano time ( ) ;
if ( tx object . is new entity manager holder ( ) ) { transaction synchronization manager . bind resource ( obtain entity manager factory ( ) , tx object . get entity manager holder ( ) ) ; } tx object . get entity manager holder ( ) . set synchronized with transaction ( true ) ; }
set < user > users = user manager service . get users ( null , null ) ; assert that ( users , contains ( crate _ user ) ) ; users = user manager service . get users ( new users meta data ( ) , new users privileges meta data ( ) ) ; assert that ( users , contains ( crate _ user ) ) ;
timer _ logger . logp ( level . finer , timer . class . get name ( ) , remove all notifications , removing all timer notifications ) ; timer table . clear ( ) ;
poll all to list ( ret list ) ; }
for ( string key : em . get entity manager factory ( ) . get properties ( ) . key set ( ) ) { key = key . to lower case ( ) ; for ( map . entry < string , jpqltemplates > entry : templates by name . entry set ( ) ) { if ( key . contains ( entry . get key ( ) ) ) { return entry . get value ( ) ; } } } return jpqltemplates . default ;
string uri = m _ prefix map . lookup namespace ( prefix from raw name ) ; if ( uri = null & & uri . equals ( ns ) ) {
throw new runtime exception ( database name + type is not support ) ;
rw lock . write lock ( ) . lock ( ) ; string hierarchy = c group prefix ;
if ( config . is convert lfto cr ( ) ) { log . debug ( replacing lf by cr ) ; for ( int i = 0 ; i < dst . length ; i + + ) { if ( dst [ i ] = = ( byte ) ' \ n ' ) { dst [ i ] = ( byte ) ' \ r ' ; } } } return dst ;
this . conf = conf ;
temp path = new path ( quota dir2 , nqdir33 ) ;
module specification . add system dependency ( new module dependency ( module loader , keycloak _ wildfly _ adapter , false , false , true , false ) ) ; module specification . add system dependency ( new module dependency ( module loader , keycloak _ undertow _ adapter , false , false , false , false ) ) ; }
linked hash set < di graph node < n , e > > work set = new linked hash set < > ( ) ; for ( n n : entry set ) { work set . add ( graph . get directed graph node ( n ) ) ; } for ( ; work set . is empty ( ) & & cycle count < max iterations ; cycle count + + ) { for every out edge in the work set , traverse that edge . if that edge updates the state of the graph , then add the destination node to the result set , so that we can update all of its out edges on the next iteration . di graph node < n , e > source = work set . iterator ( ) . next ( ) ; n source value = source . get value ( ) ; work set . remove ( source ) ; list < di graph edge < n , e > > out edges = source . get out edges ( ) ; for ( di graph edge < n , e > edge : out edges ) { n dest node = edge . get destination ( ) . get value ( ) ; if ( callback . traverse edge ( source value , edge . get value ( ) , dest node ) ) { work set . add ( edge . get destination ( ) ) ; } } } check state ( cycle count = max iterations , non _ halting _ error _ msg ) ;
string msg = null ;
assert equals ( execution state . canceled , task . get execution state ( ) ) ; assert true ( task . is canceled or failed ( ) ) ; assert null ( task . get failure cause ( ) ) ; validate task manager state change ( execution state . running , task , false ) ;
try { mid2 = 607 ; io . bytes . per . checksum bytes system . out . println ( writing + mid + bytes to file + file2 ) ; stm = fs . append ( file2 ) ; stm . write ( file contents , mid , mid2 - mid ) ; stm . close ( ) ; system . out . println ( wrote and closed second part of file . ) ; fail ( expected failure , becasue all datanodes are bad ) ; } catch ( ioexception ex ) { log . warn ( expected error . , ex ) ; } assert equals ( 1 , handler . failed times ) ;
int length = str . length ( ) ; expand if needed ( length ) ; for ( int i = 0 ; i < length ; i + + ) { char c = str . char at ( i ) ; if ( c < 128 ) { data [ idx + + ] = ( byte ) c ; } else { data [ idx + + ] = ( byte ) ' ? ' ; jdk uses ? to represent non ascii } } return this ;
custom categories = get custom categories ( ) ; map < string , tree node > categories = load tree nodes ( monitor , parent , property source ) ; if ( custom categories = null ) { for ( string custom category : custom categories ) { tree node node = categories . get ( custom category ) ; if ( node = = null ) { node = new tree node ( parent , property source , custom category ) ; categories . put ( custom category , node ) ; } } } object root ;
volt message m1 = trunc init msg ( 0 l , 1 l ) ;
warmed . add ( entry of ( new key , entry . get value ( ) ) ) ;
throw new runtime exception ( screen id should not be extra _ empty _ screen _ id ) ;
new illegal argument exception ( why is this here? ) ; int i = 1 ; system . out . println ( i = + i ) ; if ( true ) { bug : diagnostic contains : remove this line new runtime exception ( oops ) ; system . out . println ( another statement after exception ) ; }
test _ util . get admin ( ) . move ( bytes . to bytes ( region info . encode region name ( bytes . to bytes ( region ) ) ) , bytes . to bytes ( target server . get server name ( ) ) ) ; }
get mock endpoint ( mock : extra ) . expected bodies received ( bye world , yay bye world yay bye world ) ; template . send body ( direct : start , world ) ; assert mock endpoints satisfied ( ) ; }
final application attempt id app attempt id _ 0 _ 1 = test utils . get mock application attempt id ( 1 , 0 ) ; fi ca scheduler app app _ 0 _ 1 = new fi ca scheduler app ( app attempt id _ 0 _ 1 , user _ 0 , queue , queue . get active users manager ( ) , spy rmcontext ) ; queue . submit application attempt ( app _ 0 _ 1 , user _ 0 ) ; list < resource request > app _ 0 _ 1 _ requests = new array list < resource request > ( ) ;
set socket wrapper ( socket wrapper ) ; input buffer . init ( socket wrapper ) ; output buffer . init ( socket wrapper ) ;
disable normalize ( ) ;
ssl context ssl context = sslfactory . get ssl context ( encryption options , true , true ) ; channel channel = ctx . channel ( ) ; inet socket address peer = encryption options . require _ endpoint _ verification ? ( inet socket address ) channel . remote address ( ) : null ; ssl handler ssl handler = netty factory . new ssl handler ( channel , ssl context , peer ) ; ctx . pipeline ( ) . replace ( this , netty factory . ssl _ channel _ handler _ name , ssl handler ) ; }
assert product description ( ) ;
configuration props to skip compare . add ( yarn configuration . federation _ policy _ manager ) ;
sub . add ( 1 , two ) ;
filename = system . getenv ( driver . jdbc _ prop _ file _ env ) ; if ( filename = = null ) { filename = system . get property ( driver . jdbc _ prop _ file _ prop ) ; } if ( filename = = null ) { see if we can find a file in the default location url path to jar = this . get class ( ) . get protection domain ( ) . get code source ( ) . get location ( ) ; string tmp = null ; try { tmp = new file ( path to jar . to uri ( ) ) . get parent ( ) + file . separator + default _ prop _ filename ; } catch ( exception e ) { tmp = null ; } filename = tmp ; } if ( filename = null ) { file propfile = new file ( filename ) ; if ( propfile . exists ( ) & & propfile . is file ( ) ) { file input stream in = null ; try { in = new file input stream ( propfile ) ; fileprops . load ( in ) ; } catch ( file not found exception fnfe ) { } catch ( ioexception ioe ) { } finally { if ( in = null ) { try { in . close ( ) ; } catch ( ioexception e ) { } } } } } return fileprops ;
ticket answer2 = request body ( direct : getticket , answer . get id ( ) ) ;
if ( existing distance < distance ) { continue ; }
if ( i < filtered count ) { bean property writer w2 = _ filtered props [ i ] ; if ( w2 = null ) { _ filtered props [ i ] = w2 . with serializer ( ser ) ; } } }
try set st axproperty ( input factory , xmlinput factory . is _ validating , boolean . false ) ;
delete far months ( day ) ;
scheduler = new fair scheduler ( ) ;
map < string , string > escaped map = new hash map < string , string > ( ) ;
url empty url = new url ( http : localhost : + proxy port + proxy ) ;
json generator . write number field ( session counter , session counter . long value ( ) ) ; json generator . write end object ( ) ;
g = new get ( t1 ) ;
services . set need refresh ( ) ;
set features ( features ) ;
column vector tmp = batch1 . cols [ 0 ] ; batch1 . cols [ 0 ] = batch1 . cols [ 1 ] ; batch1 . cols [ 1 ] = tmp ; or expr . evaluate ( batch1 ) ;
if ( data [ offset ] < 0 ) { ret . append ( ( char ) ( base + ( data [ offset ] & 0x7 f ) ) ) ; offset + + ; len - - ; }
final view parent vp = get parent ( ) ;
this . geo server . save ( local object ) ; } catch ( exception e ) {
assert false ( wpurl utils . safe to add word press com auth token ( build uri ( not wpcom address3 ) ) ) ;
connection . disconnect ( ) ; assert that ( bad request expected , response , is ( 400 ) ) ;
boolean is distinct = qb . get parse info ( ) . get distinct func exprs for clause ( dest ) . is empty ( ) ;
check url is redirected to maintenance page ( ) ; check url is redirected to maintenance page ( issues index ) ; check url is redirected to maintenance page ( dashboard index org . apache . struts : struts - parent ) ; check url is redirected to maintenance page ( issues ) ; check url is redirected to maintenance page ( component index?id = org . apache . struts % 3 astruts - core % 3 asrc % 2 fmain % 2 fjava % 2 forg % 2 fapache % 2 fstruts % 2 fchain % 2 fcommands % 2 fgeneric % 2 fwrapping lookup command . java ) ; check url is redirected to maintenance page ( profiles ) ; }
assertions . assert that ( sender . get message context ( ) ) . is not null ( ) ;
key value seek key = make kv ( rowsize - 2 , qualsize - 2 ) ;
startable = ( ( stateful service ) consumer ) . get status ( ) . is startable ( ) ;
path subdir = path ( subdir ) ;
for ( int max size = 1 ; max size < 8 ; max size + + ) { check maximum size ( 1 , 8 , max size ) ; check maximum size ( 2 , 8 , max size ) ; check maximum size ( 4 , 8 , max size ) ; check maximum size ( 8 , 8 , max size ) ; }
xsltelement def xsl sort = new xsltelement def ( this , constants . s _ xslnamespaceurl , sort , null * alias * , null * elements * , new xsltattribute def [ ] { select attr def dot , lang attr , data type attr , order attr , case order attr } , new processor template elem ( ) , elem sort . class * class object * , 19 , true ) ; xsltelement def xsl with param = new xsltelement def ( this , constants . s _ xslnamespaceurl , with - param , null * alias * , template elements * elements * , % template ; > new xsltattribute def [ ] { name attr required , select attr opt } , new processor template elem ( ) , elem with param . class * class object * , 19 , true ) ; xsltelement def xsl apply templates = new xsltelement def ( this , constants . s _ xslnamespaceurl , apply - templates , null * alias * , new xsltelement def [ ] { xsl sort , xsl with param } * elements * , new xsltattribute def [ ] { select attr def node , mode attr } , new processor template elem ( ) , elem apply templates . class * class object * , 20 , true ) ; xsltelement def xsl apply imports = new xsltelement def ( this , constants . s _ xslnamespaceurl , apply - imports , null * alias * , null * elements * , new xsltattribute def [ ] { } , new processor template elem ( ) , elem apply import . class * class object * ) ;
plugins . add plugin load props ( job type name , plugin load props ) ; if ( plugin job props = null ) { plugins . add plugin job props ( job type name , plugin job props ) ; } final class loader job type loader = load job type class loader ( plugin dir , job type name , plugins ) ;
m _ yield = arg _ object ; m _ next coroutine = to coroutine ; m _ active ids . clear ( this coroutine ) ; notify ( ) ; }
final list < invoice item > children invoice items = invoice user api . get invoice items by parent invoice ( parent invoice . get id ( ) , call context ) ;
verify ( m mock data query callback ) . on error ( m queries [ 0 ] ) ; }
assert equals ( 0 , nn2 . get namesystem ( ) . get block manager ( ) . get pending deletion blocks count ( ) ) ; cluster . trigger heartbeats ( ) ;
realm realm = realm . get instance ( config ) ;
if ( new dmr path . starts with ( existing dmr path ) ) { return false ; }
unsafe . epoll in ready ( ) ;
int started = time . current time ( ) ; int server start time = session . get provider ( cluster provider . class ) . get cluster startup time ( ) ; for ( user session model orig session : orig sessions ) { user session model user session = session . sessions ( ) . get user session ( realm , orig session . get id ( ) ) ; for ( authenticated client session model client session : user session . get authenticated client sessions ( ) . values ( ) ) { session manager . create or update offline session ( client session , user session ) ; } } reset session ( ) ;
if ( is in edit mode ( ) ) init view ( ) ; }
conf . set ( angel conf . angel _ train _ data _ path , input path ) ;
int length = this . element changed listeners . length ; ielement changed listener [ ] new listeners = new ielement changed listener [ length ] ; system . arraycopy ( this . element changed listeners , 0 , new listeners , 0 , i ) ; int [ ] new masks = new int [ length ] ; system . arraycopy ( this . element changed listener masks , 0 , new masks , 0 , i ) ;
marshaller marshaller = create marshaller ( ) ; if ( is pretty print ( ) ) { marshaller . set property ( marshaller . jaxb _ formatted _ output , boolean . true ) ; }
assert equals ( original scrolling xy [ 0 ] , new scrolling xy [ 0 ] ) ;
evaluation result < string value > result = tester . eval ( * keep going = * false , error key , other error key ) ;
map < string , string > config = new hash map < > ( ) ; if ( filename = null ) config . put ( file _ config , filename ) ; config . put ( topic _ config , topic ) ; configs . add ( config ) ; return configs ; }
assert equals ( update transaction not executed properly . values did not change . , update value . to string ( ) , read value after update . to string ( ) ) ;
case token types . literal _ new :
int len = 0 ;
node grid offsets = xpath . get matching nodes ( wcs : coverage description wcs : coverage offering + wcs : domain set wcs : spatial domain gml : rectified grid gml : offset vector , dom ) . item ( 0 ) ; string [ ] offset strs low = grid offsets . get text content ( ) . split ( ) ; grid offsets = xpath . get matching nodes ( wcs : coverage description wcs : coverage offering + wcs : domain set wcs : spatial domain gml : rectified grid gml : offset vector , dom ) . item ( 1 ) ; string [ ] offset strs high = grid offsets . get text content ( ) . split ( ) ; assert equals ( 2 , offset strs low . length ) ; assert equals ( 2 , offset strs high . length ) ; double [ ] offsets = new double [ 4 ] ; for ( int i = 0 ; i < offset strs low . length ; i + + ) { offsets [ i ] = double . parse double ( offset strs low [ i ] ) ; } for ( int i = 2 ; i < 2 + offset strs high . length ; i + + ) { offsets [ i ] = double . parse double ( offset strs high [ i - 2 ] ) ; } assert true ( offsets [ 0 ] > 0 ) ;
assert jq ( req ( q , { join from = dept _ ss to = noexist _ s + whatever score ( ) + } * : * , fl , id ) , response = = { ' num found ' : 0 , ' start ' : 0 , ' docs ' : [ ] } ) ;
incremental rows with normalization incremental rows with normalization = new incremental rows with normalization ( mock beeline , mock result set ) ;
create new file ( path _ to _ files , new _ less _ file , test menu commands constants . project . new . less _ file , . less ) ;
final queued thread pool connector pool = new queued thread pool ( 4 , 4 ) ;
instance . get or create event data ( test , address , new heap data ( ) , new object ( ) , new object ( ) , new object ( ) , entry event type . added . get type ( ) , false ) ;
init eclass ( ecosystem eclass , ecosystem . class , ecosystem , is _ abstract , is _ interface , is _ generated _ instance _ class ) ; init eattribute ( get ecosystem _ logger ( ) , this . get mlogger ( ) , logger , null , 0 , 1 , ecosystem . class , is _ transient , is _ volatile , is _ changeable , is _ unsettable , is _ id , is _ unique , is _ derived , is _ ordered ) ; init ereference ( get ecosystem _ mbrickds ( ) , this . get mbrickd ( ) , this . get mbrickd _ ecosystem ( ) , mbrickds , null , 0 , - 1 , ecosystem . class , is _ transient , is _ volatile , is _ changeable , is _ composite , is _ resolve _ proxies , is _ unsettable , is _ unique , is _ derived , is _ ordered ) ; eoperation op = init eoperation ( get ecosystem _ _ get brickd _ _ string _ int ( ) , this . get mbrickd ( ) , get brickd , 0 , 1 , is _ unique , is _ ordered ) ;
em . get transaction ( ) . begin ( ) ; ing2 = em . find ( set ref ing mul id entity . class , ing2 _ id ) ; ed2 = em . find ( set ref ed mul id entity . class , ed2 _ id ) ; ing2 . set reference ( ed2 ) ;
segment completion mgr . _ secconds + = 1 ;
result = new http host ( get host ( isa ) , isa . get port ( ) ) ;
read test data ( test _ data , test _ data . length - 1 , 1 , 1 , 0 , 1 , false ) ;
if ( name . equals ( clinit ) ) { return null ; } return apply proxy ( msign ) ;
opt = name node . parse arguments ( new string [ ] { - upgrade } ) ;
message delayer . process message ( text , this , m idling resource ) ; }
return get tool dependency generator element ( ) ;
return new axiomatic f3 log ( 0 . 25f , 1 ) ;
reader . handle event ( eos ) ; fail ( did not throw expected exception when receiving too many end of superstep events . ) ;
format1 . apply pattern ( ' ' 0000 . ) ; assert true ( object ' s changed clone should not be equal , format . equals ( format1 ) ) ; }
assert equals ( jsontype . jsonp , response . get content type ( ) ) ;
if ( lowname . ends with ( . war ) ) { string name = file . get name ( ) ; string base = name . substring ( 0 , name . length ( ) - 4 ) ; string xmlname = base + . xml ; if ( exists ( xmlname ) ) { if a . xml file exists for it , then redeploy that instead file xml = new file ( parent , xmlname ) ; super . file changed ( xml . get canonical path ( ) ) ; return ; } xmlname = base + . xml ; if ( exists ( xmlname ) ) { if a . xml file exists for it , then redeploy that instead file xml = new file ( parent , xmlname ) ; super . file changed ( xml . get canonical path ( ) ) ; return ; } redeploy the changed war super . file changed ( filename ) ; return ; }
packet length = ( get short ( buffer , buffer . reader index ( ) + 3 ) & 0x ffff ) + 5 ; if ( packet length < = 5 ) {
htu . verify numeric rows ( table , f , start row , end row , replica id ) ;
v . add ( integer . value of ( rs . get int ( historyid ) ) ) ;
color = get current color ( ) ;
assert equals ( 3 , learner handler . get queued packets ( ) . size ( ) ) ;
fs . delete ( back ref path , false ) ;
try { realm . where ( null types . class ) . is not null ( null types . field _ object _ null + . + null types . field _ short _ not _ null ) ; fail ( ) ; } catch ( illegal argument exception ignored ) { }
finally { try { bais . close ( ) ; } catch ( exception e ) { }
byte [ ] actual = new byte [ num blocks * block size ] ; system . out . println ( verifying file ) ; stm . read fully ( 0 , actual ) ; stm . close ( ) ; check data ( actual , 0 , expected , read 1 ) ; }
int expected rows = nmap input format . get num map tasks ( conf ) * rowspersplit ;
for ( int j = 1 ; j < rg . length ; j + + ) { for ( int k = 0 ; k < j ; k + + ) { if ( rg [ j ] . next position ( ) ) { return false ; pps exhausted } } } } }
feature f = iterator . next ( ) ; assert not null ( f ) ; feature source mapped source = mapping it . get mapped source ( ) ;
time millis + = 1 ;
audited properties holder . add property auditing data ( property . get name ( ) , component data ) ; }
_ cisco nexus vsmdevice dao . remove ( vsm id ) ;
string encoded region name = regiondir . get name ( ) ; return hregion . get region dir ( archive dir , encoded region name ) ;
wfp = new hash broadcast policy manager ( ) ; wfp . set queue ( queue1 ) ;
log . debug ( message processing is paused , blocking until message processing is turned back on . ) ; uninterruptibles . await uninterruptibly ( paused latch ) ; }
for ( int k = 0 ; k < i ; k + + ) { plan node other bc source = broadcast channels combination . get ( k ) . get source ( ) ; if ( are branch compatible ( bc source , other bc source ) ) { valid combination = false ; break ; } }
. set discard ( new discard attribute checker . discard attribute value checker ( status _ interval . get default value ( ) ) , status _ interval ) . add reject check ( new reject attribute checker . simple accept attribute checker ( status _ interval . get default value ( ) ) , status _ interval )
new update request ( ) . add ( sdoc ( id , 999 , t tl _ s , + 30 seconds ) ) . commit ( cluster . get solr client ( ) , collection ) ;
set socket wrapper ( null ) ; }
file labels = new file ( base dir , get training file labels filename ( ) ) ; file labels test = new file ( base dir , get test file labels filename ( ) ) ; try downloading afew times ( new url ( get training file labels url ( ) ) , labels , get training file labels md5 ( ) ) ; try downloading afew times ( new url ( get test file labels url ( ) ) , labels test , get test file labels md5 ( ) ) ; archive utils . unzip file to ( labels . get absolute path ( ) , base dir . get absolute path ( ) ) ; archive utils . unzip file to ( labels test . get absolute path ( ) , base dir . get absolute path ( ) ) ;
data set < tuple2 < long , double > > pages with ranks = pages input . map ( new rank assigner ( ( 1 . 0d num pages ) ) ) ;
if ( gui activator . get configuration service ( ) . get boolean ( operation set video bridge . is _ video _ bridge _ disabled , false ) ) { return ; } if ( swing utilities . is event dispatch thread ( ) ) { swing utilities . invoke later ( new runnable ( ) { public void run ( ) { init video bridge menu ( ) ; } } ) ; return ; }
response = get as servlet response ( rest oseo collections sentinel2 layer ) ; assert equals ( 404 , response . get status ( ) ) ; }
string line = scanner . next line ( ) . trim ( ) ; if ( object helper . is empty ( line ) ) {
return strings . get string var name ( mod utf8 ) + _ ptr ;
tester . advance input watermark ( new instant ( 100 ) ) ; assert true ( tester . should fire ( first window ) ) ; assert false ( tester . should fire ( second window ) ) ;
final org . apache . hadoop . mapreduce . task attempt context tac = shim loader . get hadoop shims ( ) . new task attempt context ( job . get configuration ( ) , progressable ) ; final path outputdir = file output format . get output path ( tac ) ; final path task attempt outputdir = new file output committer ( outputdir , tac ) . get work path ( ) ;
for ( int i = 0 ; i < 4000 ; i + + ) { if ( ( i % 400 ) = = 0 ) { system . out . printf ( % d % % \ n , ( i 400 ) * 10 ) ; } cr = client . call procedure ( p1 . insert , i , data ) ; assert equals ( client response . success , cr . get status ( ) ) ; } system . out . println ( 100 % loaded . killing node 0 . ) ;
assert . assert equals ( local strategy . none , join . get input1 ( ) . get local strategy ( ) ) ;
to test . suspect ( instance b ) ;
job . set ( table _ props , new stringable map ( tblproperties ) . to string ( ) ) ; }
for ( iterator < simple name > iter = overlap names . iterator ( ) ; iter . has next ( ) ; ) { object o = iter . next ( ) ; if ( renamed names . contains ( o ) ) { return false ; } }
result + = sb . to string ( ) . hash code ( ) ; return result ; }
prepare source ( pkg , module name version , main file name ) ;
if ( camera . get facing ( ) = = camera facing . front ) { cw rotation from natural to camera = ( 360 - cw rotation from natural to camera ) % 360 ; log . i ( tag , front camera overriden to : + cw rotation from natural to camera ) ; }
frame frame = new frame ( key . < frame > make ( ) , training frame . names ( ) , training frame . vecs ( ) ) ; dkv . put ( frame . _ key , frame ) ; need to put the frame ( to be modified ) into dkv for missing inserter to pick up frame utils . missing inserter j = new frame utils . missing inserter ( frame . _ key , seed , missing _ fraction ) ; j . exec impl ( ) . get ( ) ; missing inserter is non - blocking , must block here explicitly dkv . remove ( frame . _ key ) ; delete the frame header ( not the data ) params impute missing = new pcaparameters ( ) ;
flow runner test util . start thread ( this . runner ) ;
line = reader . read line ( ) ; assert . assert that ( line , matchers . starts with ( http 1 . 1 200 ok ) ) ; string last = null ;
assert that ( order book . get bids ( ) . get ( 0 ) . get limit price ( ) . to string ( ) ) . is equal to ( 13 . 3 ) ; assert that ( order book . get bids ( ) . get ( 0 ) . get type ( ) ) . is equal to ( order type . bid ) ; assert that ( order book . get bids ( ) . get ( 0 ) . get original amount ( ) ) . is equal to ( new big decimal ( 0 . 00021609 ) ) ; assert that ( order book . get bids ( ) . get ( 0 ) . get currency pair ( ) ) . is equal to ( currency pair . btc _ usd ) ; }
db oom query = new db oom query ( q5 ) ; boy2 = db oom query . find ( boy2 . class , girl . class , integer . class ) ; assert equals ( 1 , boy2 . id ) ;
if ( has time ) { try { handle time dimension vector ( type info ) ; } catch ( ioexception e ) { throw new runtime exception ( failed to handle time attribute for layer , e ) ; } }
assert that ( adapter . from json ( - 3 . 4028235 e38 ) ) . is equal to ( - float . max _ value ) ; assert that ( adapter . to json ( - float . max _ value ) ) . is equal to ( - 3 . 4028235 e38 ) ; assert that ( adapter . from json ( 3 . 4028235 e38 ) ) . is equal to ( float . max _ value ) ; assert that ( adapter . to json ( float . max _ value ) ) . is equal to ( 3 . 4028235 e38 ) ;
if ( ( get screen id for page index ( get current page ( ) ) = = custom _ content _ screen _ id ) & & ( m custom content callbacks = null ) & & m custom content callbacks . is scrolling allowed ( ) ) { return false ; } return super . on generic motion event ( event ) ;
return is supported ( feature , version ) ? this : null ; }
if ( ( i % 2 ) = = 0 ) { subscription b . poll ( fragment handler b , 1 ) ; }
resource tot preemption needed = resource . new instance ( 0 , 0 ) ;
parent no cascade parent got = data . find by key ( parent no cascade . class , 1l ) ;
get menu inflater ( ) . inflate ( r . menu . android _ animations , menu ) ; return true ;
assert equals ( - 1 , adapter . get item view type ( 3 ) ) ;
dispatcher . dispatch ( user created event ) ; verify ( user created event handler ) . on event ( user created event ) ; verify ( dispatcher ) . dispatch ( user created event ) ;
ch = ( char ) ( ch + ( ' a ' - ' a ' ) ) ;
throw new runtime exception ( nsm ) ;
if ( node to be delete . color = = color . black ) { if it has one red child then change color of that child to be black . if ( child . color = = color . red ) { child . color = color . black ; } else { otherwise we have double black situation . delete case1 ( child , root reference ) ; } } }
object r3 = service . cache ( o1 ) ; assert same ( r1 , r3 ) ; }
key hint = cur key hint ;
for ( map . entry < integer , element > entry : interceptors . entry set ( ) ) { load into method of tollgate builder . add statement ( interceptors . put ( + entry . get key ( ) + , t . class ) , class name . get ( ( type element ) entry . get value ( ) ) ) ; } }
compaction request impl result = ( ( ratio based compaction policy ) store . store engine . get compaction policy ( ) ) . select compaction ( candidates , new array list < > ( ) , false , false , false ) ; assert . assert true ( result . get files ( ) . is empty ( ) ) ; store . set scan info ( old scan info ) ; }
tz rounding = rounding . builder ( date time unit . day _ of _ month ) . time zone ( tz ) . build ( ) ;
return ( ( single ) result ) . to observable ( ) . to blocking ( ) . first ( ) ; } else if ( is returns completable ( method ) ) { ( ( completable ) result ) . await ( ) ; return null ; } else { return result ; } } catch ( illegal access exception e ) {
boolean internal = false ;
if ( local buf = buf ) { local buf = buf ; if ( local buf = = null ) { throw stream closed ( ) ; } } read = count - pos > = required ? required : count - pos ;
plan sanity checker . validate final plan ( root , session , metadata , sql parser , symbol allocator . get types ( ) ) ; }
if ( cfg . is enabled ( deserialization config . feature . unwrap _ root _ value ) ) { result = _ unwrap and deserialize ( jp , value type , ctxt , deser ) ; } else { result = deser . deserialize ( jp , ctxt ) ; } }
rmapp app1 = rm1 . submit app ( 1 * gb , app , user , null , default ) ; mock am am1 = mock rm . launch and register am ( app1 , rm1 , nm1 ) ; container id container id1 = container id . new container id ( am1 . get application attempt id ( ) , 1 ) ; sent rmcontainer launched ( rm1 , container id1 ) ;
listener . events . remove ( i ) ;
assert equals ( 0 , calc msm ( 3 , \ n25 % \ n ) ) ;
prepared statement p stmt = connection . prepare statement ( delete from application _ key ) ;
new output writer ( configuration ) . execute ( program class pool ) ;
file root = classes directory . get parent file ( ) . get parent file ( ) ; file source file = new file ( root , src main resources camel - connector . json ) ; if ( source file . exists ( ) ) { get log ( ) . info ( updating git url to + git url + in + source file ) ; mapper . writer with default pretty printer ( ) . write value ( source file , dto ) ; } } return git url ; } catch ( ioexception e ) {
log . debug ( skipping { } as content has no fetch status , key ) ; return ; } else if ( integer . parse int ( fetch status ) = crawl datum . status _ fetch _ success ) {
fast item adapter = new fast item adapter ( ) ;
else { system . err . println ( bad base64 input character at + i + : + source [ i ] + ( decimal ) ) ; return null ;
alpha = ( int ) ( ( 1 - ratio ) * 255 ) ; start x + = ( 1 - ratio ) * dip2 ; break ; case arrow _ check : if ( is morphing forward ( ) ) {
return range ( path , to field ( path ) , operation . get arg ( 1 ) , operation . get arg ( 2 ) , true , true , metadata ) ;
endpoint helper . set reference properties ( context , data format , copy ) ; endpoint helper . set properties ( context , data format , copy ) ; }
map < ? , ? > map = exchange . get context ( ) . get type converter ( ) . try convert to ( map . class , exchange , data ) ; if ( map = null ) { return get map record values ( map ) ; } return exchange helper . convert to mandatory type ( exchange , list . class , data ) ; }
registry . put ( current category , collections . unmodifiable map ( readers ) ) ;
insert insert = request . create insert ( ) ; list < simple feature > features = new array list < > ( ) ; try { simple feature type schema = ( simple feature type ) catalog . get feature type by name ( mock data . road _ segments . get local part ( ) ) . get feature type ( ) ; geometry geometry = new wktreader ( ) . read ( multilinestring ( ( 0 0 , 1 1 ) ) ) ; simple feature feature = simple feature builder . build ( schema , new object [ ] { geometry , 107 , new road } , null ) ; features . add ( feature ) ; } catch ( exception e ) { throw new runtime exception ( e ) ; } insert . set features ( features ) ; transaction elements . add ( insert ) ; request . set elements ( transaction elements ) ; return request ;
if ( line . starts with ( package prefix ) ) { saw package line = true ; continue ; }
return new unknown length http input stream ( socket in , cache request , http engine ) ;
linked list ll2 = new linked list ( ) ; ll2 . add all ( ll ) ; test shuffle ( ll2 , random access , true ) ; mock _ array list mal = new mock _ array list ( ) ;
int highest id = ( int ) store . get highest possible id in use ( ) ; for ( record record : record access . records ( ) ) { store . update record ( record ) ; highest id = max ( highest id , record . get int id ( ) ) ; } store . set highest possible id in use ( highest id ) ; }
hdfs . delete snapshot ( dir , s2 ) ;
data index + + ;
writer . check size ( ) ;
byte [ ] class bytes = new byte [ 2048 ] ;
object mapper mapper = new object mapper ( ) ; coinbase button button = mapper . read value ( is , coinbase button . class ) ; assert that ( button . get code ( ) ) . is equal to ( 7e285152558af4ffdedf81c31c904119 ) ; assert that ( button . get type ( ) ) . is equal to ( coinbase button type . donation ) ; assert that ( button . get style ( ) ) . is equal to ( coinbase button style . donation _ large ) ; assert that ( button . get text ( ) ) . is equal to ( donate bitcoins ) ; assert that ( button . get name ( ) ) . is equal to ( demo button ) ; assert that ( button . get description ( ) ) . is equal to ( coinbase button demo for coinbase . ) ; assert that ( button . get custom ( ) ) . is empty ( ) ;
assert good ( die schlinge zieht sich zu . ) ;
request request = dispatcher . request . get ( ) ;
rules . clear selection ( ) ; return true ; } @ override public void on close ( ajax request target target ) {
try { provider . create credential entry ( pass , passwd ) ; } catch ( exception e ) { e . print stack trace ( ) ; throw e ; }
make child node ( ) ;
if ( last component instanceof contact node ) { uicontact ui contact = ( ( contact node ) last component ) . get contact descriptor ( ) ; if ( ( e . get modifiers ( ) & input event . button3 _ mask ) = 0 | | ( e . is control down ( ) & & e . is meta down ( ) ) ) { right button menu = ui contact . get right button menu ( ) ; open right button menu ( e . get point ( ) ) ; } } else if ( last component instanceof group node ) { uigroup ui group = ( ( group node ) last component ) . get group descriptor ( ) ; if ( ( e . get modifiers ( ) & input event . button3 _ mask ) = 0 | | ( e . is control down ( ) & & e . is meta down ( ) ) ) { right button menu = ui group . get right button menu ( ) ; open right button menu ( e . get point ( ) ) ; } }
event loop group group = new nio event loop group ( ) ;
conf . set ( compacting mem store . compacting _ memstore _ index _ key , string . value of ( compacting mem store . index type . chunk _ map ) ) ;
job conf . set int ( prefix + chain _ mapper _ size , index + 1 ) ;
if ( results [ 0 ] . get row count ( ) = expected _ entries ) { system . out . println ( results [ 0 ] ) ; } assert equals ( expected _ entries , results [ 0 ] . get row count ( ) ) ; while ( results [ 0 ] . advance row ( ) ) { assert equals ( results [ 0 ] . get string ( result ) , success ) ; }
message = parent . build ( ) ; assert equals ( 0 , message . get optional message ( ) . get int32 to int32 field ( ) . size ( ) ) ; }
try { if ( parallel aggregate ) { do aggregate internal ( get aggregation strategy ( sub exchange ) , result , sub exchange ) ; } else { do aggregate ( get aggregation strategy ( sub exchange ) , result , sub exchange ) ; } } catch ( throwable e ) {
assert equals ( 1 . 0 , info1 . map fair share , allow _ error ) ;
list < object > body children = content accessor . get content ( ) ;
if ( request path . starts with ( ) ) { request path = request path . substring ( 1 ) ; }
int insertion level = index level ;
file file = new file ( java file name ) ; if ( file . exists ( ) ) { if ( file . delete ( ) ) { log . warn ( localizer . get message ( jsp . warning . compiler . javafile . delete . fail , file . get absolute path ( ) ) ) ; } } throw e ; }
query query = new query ( http request . create test request ( ?x = x1 & model . default index = title , method . get ) , profile . compile ( null ) ) ;
app . get context ( ) . get event handler ( ) . handle ( new task attempt event ( task2 attempt1 . get id ( ) , task attempt event type . ta _ done ) ) ;
if ( danmaku . underline color = 0 ) { paint line paint = displayer config . get underline paint ( danmaku ) ; float bottom = top + danmaku . paint height - displayer config . underline _ height ; canvas . draw line ( left , bottom , left + danmaku . paint width , bottom , line paint ) ; }
assert equals ( 0 , query ( ) . any embedded ( user . addresses , address ) . on ( address . street . eq ( akatu ) ) . fetch count ( ) ) ;
string request = + options http 1 . 1 \ r \ n + host : localhost \ r \ n + connection : close \ r \ n + cross origin filter . access _ control _ request _ method _ header + : put \ r \ n + origin : http : localhost \ r \ n + \ r \ n ;
assert query ( query template . replace ( x plus yequals subquery join condition , type . of ( left ) ) , no output query ) ; assert query ( query template . replace ( x plus yequals subquery join condition , type . of ( right ) ) , values ( null , 1 ) ) ; assert query ( query template . replace ( x plus yequals subquery join condition , type . of ( full ) ) , values ( null , 1 ) ) ; }
linked list < tree node > current = new linked list < tree node > ( ) ; if ( root = null ) { current . add ( root ) ; } while ( current . size ( ) > 0 ) { result . add ( current ) ; add previous level linked list < tree node > parents = current ; go to next level current = new linked list < tree node > ( ) ; for ( tree node parent : parents ) { * visit the children * if ( parent . left = null ) { current . add ( parent . left ) ; } if ( parent . right = null ) { current . add ( parent . right ) ; } } }
aggregate aggrnode = ( aggregate ) gb node ; if ( aggrnode . get group set ( ) . is empty ( ) & & aggrnode . get agg call list ( ) . is empty ( ) ) { return true ; } return false ;
public void allow snapshot ( string snapshot root ) throws ioexception { check nnstartup ( ) ; metrics . incr allow snapshot ops ( ) ; namesystem . allow snapshot ( snapshot root ) ; }
throw new saxparse exception ( localizer . get message ( jsp . error . no . scriptlets , local name ) , locator ) ;
assert equals ( 1 , customers . size ( ) ) ; } ) ; }
unified set < integer > set = unified set . new set with ( collision _ 1 , collision _ 2 ) ; set . remove ( collision _ 2 ) ; counter counter = new counter ( ) ; set . for each with index ( ( each , index ) - > counter . increment ( ) ) ; assert . assert equals ( 1 , counter . get count ( ) ) ; }
data entry reader jar reader = new jar reader ( reader ) ; if ( is jar ) { always unzip . return jar reader ; } else { add a filter , if specified . if ( jar filter = null ) { jar reader = new filtered data entry reader ( new data entry name filter ( new list parser ( new file name parser ( ) ) . parse ( jar filter ) ) , jar reader ) ; } only unzip the right type of jars . return new filtered data entry reader ( new data entry name filter ( new extension matcher ( jar extension ) ) , jar reader , reader ) ; }
table = ( ( collection ) other side property . get value ( ) ) . get collection table ( ) ;
bris . close ( ) ; verify ( bris , times ( + + bris closes ) ) . close ( ) ; verify ( mock stream . in , times ( + + is closes ) ) . close ( ) ;
fold - level root for the given line return false ; } return false ; } } } }
return method . equals ( propfind ) ;
boolean success = trade service . cancel order ( limit order return value ) ;
test missing ( switch ( 1 ) { case 12 : return 5 ; } ) ;
byte [ ] q = column helper . get column qualifier ( flow run column prefix . metric . get column prefix bytes ( ) , metric1 ) ; assert true ( values . contains key ( q ) ) ; assert equals ( 141 l , bytes . to long ( values . get ( q ) ) ) ;
final value injection service < local transport provider > new default local transport provider service = new value injection service < local transport provider > ( ) ; final service builder < local transport provider > default local ejbreceiver service builder = service target . add service ( local transport provider . default _ local _ transport _ provider _ service _ name , new default local transport provider service ) ; default local ejbreceiver service builder . add dependency ( local transport provider service name , local transport provider . class , new default local transport provider service . get injector ( ) ) ;
if ( string utils . is blank ( upstream dependency ) | | metadata identification utils . is valid ( upstream dependency ) ) { return ; }
if ( channel . get ship strategy ( ) . requires comparator ( ) ) { channel . set ship strategy comparator ( create comparator ( type , channel . get ship strategy keys ( ) , get sort orders ( channel . get ship strategy keys ( ) , channel . get ship strategy sort order ( ) ) ) ) ; }
if ( o1 double ) { final double left = ( double ) o1 ; if ( o2 double ) {
long [ ] sizes = get block sizes ( file locs [ i ] ) ;
control point = request controller . get control point ( deployment name , batch - executor - service ) ;
m in hwaccelerated zoom = false ; } } else {
element template element = element . get owner document ( ) . create element ( consumer template ) ; template element . set attribute ( id , id ) ; bean definition parser parser = parser map . get ( consumer template ) ; bean definition definition = parser . parse ( template element , parser context ) ;
if ( + + failures > = max _ retries ) { throw new ioexception ( too many failures downloading events , ie ) ; }
get variant ( dimension values , true ) . set ( field name , value ) ;
if ( realm roles . get realm ( ) = null ) { realm roles for ( role representation role rep : realm roles . get realm ( ) ) { role model role = realm . get role ( role rep . get name ( ) ) ; add composites ( role , role rep , realm ) ; } }
log . info ( h3 heartbeat ( to re - schedule the containers ) ) ; node manager3 . node heartbeat ( true ) ; node heartbeat rm . drain events ( ) ; log . info ( rm heartbeat ( to process the re - scheduled containers for h3 ) ) ; assigned = allocator . schedule ( ) ; assert blacklist additions and removals ( 0 , 0 , rm ) ; rm . drain events ( ) ;
assert false ( mapper . writer ( ) . with ( serialization feature . fail _ on _ empty _ beans ) . can serialize ( empty bean . class ) ) ;
http request request = new default http request ( http version . http _ 1 _ 1 , http method . post , uri simple . to asciistring ( ) ) ;
string [ ] host groups = host matcher . get ( i ) . get host group list ( ) ;
indicator = get indicator ( pos ) ;
mock message ( evt ) ; } wait for sync ( ) ; verify ( info ) ; }
cyclical list hole polygon = new cyclical list ( ) ; for ( int i = 0 ; i < hole verts . get num points ( ) ; i + + ) hole polygon . add ( new vertex ( hole verts . get coordinate n ( i ) , i + polygon vertices . size ( ) ) ) ;
map < string , sorted set < segment name > > sorted segments by kafka partition = kafka low level routing table builder util . get sorted segments by kafka partition ( external view ) ;
if ( anchor item position > 0 & & ( refreshing lanes | | restoring lanes ) ) { move layout to position ( anchor item position , get pending scroll offset ( ) , recycler , state ) ; } m lanes . reset ( direction . start ) ; super . on layout children ( recycler , state ) ; }
double color map scaling = ( color map . length - 1 ) max ;
if ( common . is empty ( ) ) { desired partitioning = common ; } } }
throw new parse exception ( value , 0 ) ;
char s = instruction [ i + + ] ; char e = instruction [ i + + ] ; match = ( ( compare chars ( c , s , case fold ) > = 0 ) & & ( compare chars ( c , e , case fold ) < = 0 ) ) ; }
max idle millis = checked time ( max idle millis ) ; final long idle expiration time = sum for expiration ( max idle millis , get idleness start time ( record ) ) ;
return access pattern . constant ;
populate near cache ( second context ) ;
while ( client recv counter . get ( ) < data . length ) { if ( server exception . get ( ) = null ) { break ; } if ( server exception . get ( ) = null ) { break ; } try { thread . sleep ( 50 ) ; } catch ( interrupted exception e ) { ignore . } } while ( server recv counter . get ( ) < data . length ) { if ( server exception . get ( ) = null ) { break ; } if ( client exception . get ( ) = null ) { break ; } try { thread . sleep ( 50 ) ; } catch ( interrupted exception e ) { ignore . } }
{ eol9 = ( token ) match ( input , eol , follow _ eol _ in _ entry349 ) ; if ( state . failed ) return retval ; if ( state . backtracking = = 0 ) stream _ eol . add ( eol9 ) ; } break ;
list < file status > region files = new array list < file status > ( region dirs . length ) ; for ( file status region dir : region dirs ) { file status [ ] fams = fsutils . list status ( fs , region dir . get path ( ) , family filter ) ; if no families , then we are done again if ( fams = = null | | fams . length = = 0 ) continue ; add all the hfiles under the family region files . add all ( snapshot testing utils . get hfiles in region ( fams , fs , file filter ) ) ; } file status [ ] files = new file status [ region files . size ( ) ] ; region files . to array ( files ) ; return files ;
sb . append ( ( char ) ( ( eiscp data size > > 24 ) & 0x ff ) ) ;
env . get config ( ) . set restart strategy ( restart strategies . fixed delay restart ( no _ of _ retries , 0 ) ) ; env . enable checkpointing ( 10 ) ;
case reg ops . new _ array : case reg ops . filled _ new _ array : prev source = prev ssa insn . get sources ( ) . get ( 0 ) ; if ( prev source . get type bearer ( ) . is constant ( ) ) {
int index = int array [ bytes _ offset ] ; int i = from byte ; int max word ; int n bytes ; int word index = index > > 2 ; int byte index = index & 0x03 ;
int word num = precision less one longword _ decimal _ digits ; int digit in word = precision less one % longword _ decimal _ digits ;
int rc = get url ( http : localhost : + get port ( ) + test bug49922 foo , result , null ) ; assert equals ( http servlet response . sc _ not _ found , rc ) ; assert true ( result . get length ( ) > 0 ) ;
string version1 = mi band fwhelper . format firmware version ( calculated version fw1 ) ;
pool config . set block when exhausted ( true ) ;
jetty home = env . get ( jetty . home ) ; jetty base = env . get ( jetty . base ) ; war = env . get ( war ) ;
segment generator config config = column metadata test . create segment config without creator ( ) ;
expected . expect message ( 401 unauthorized ) ;
assert . assert true ( expected auth time to change . old auth time : + old id token . get auth time ( ) + , new auth time : + new id token . get auth time ( ) , old id token . get auth time ( ) + 20 < = new id token . get auth time ( ) ) ;
consumer . get netty server bootstrap factory ( ) . remove channel ( ctx . channel ( ) ) ; super . channel inactive ( ctx ) ; }
souliss generic typical t = souliss generic binding provider . souliss typicals recipients . get typical from item ( item name ) ;
immutable set < path fragment > mixed = to paths set ( a b , a c , b c ) ;
if ( metric index > - 1 ) { sorted metric aggs [ metric index ] = metric agg ; } }
if ( hash id < 0 ) { hash id + = _ table . size ( ) ; }
return get internal state ( ) ;
long anim set id = dis . read unsigned int ( ) ; m anim set = lookup animation set ( block header , anim set id ) ;
if ( are branch compatible ( bc source , input source ) ) { valid combination = false ; break ; }
set state ( state . workspace ) ;
string prop value = ( string ) access controller . do privileged ( new privileged action ( ) { public java . lang . object run ( ) { return system . get property ( name ) ; } } ) ; return prop value ;
register descr build error ( context , pattern descr , a sliding window can only be assigned to types declared with @ role ( event ) . the type ' + pattern . get object type ( ) + ' in ' + context . get rule ( ) . get name ( ) + ' is not declared as an event . ) ; } }
value deser = find converting content deserializer ( ctxt , property , value deser ) ;
if ( this . spring remote cache manager = null ) { this . spring remote cache manager . stop ( ) ; } }
completable future < multiple jobs details > job details future = leader gateway . request job details ( true , true , timeout ) ; job details future . when complete async ( ( multiple jobs details job details , throwable throwable ) - > { if ( throwable = null ) { log . debug ( fetching of job details failed . , throwable ) ; } else { array list < string > active jobs = new array list < > ( ) ; for ( job details job : job details . get running ( ) ) { active jobs . add ( job . get job id ( ) . to string ( ) ) ; } for ( job details job : job details . get finished ( ) ) { active jobs . add ( job . get job id ( ) . to string ( ) ) ; } metrics . retain jobs ( active jobs ) ; } } , executor ) ;
parent dir . mkdirs ( ) ;
file existing file = new file ( test _ build _ data , testjournalnodefile ) ; assert true ( existing file . create new file ( ) ) ; try { conf . set ( dfsconfig keys . dfs _ journalnode _ edits _ dir _ key , existing file . get absolute path ( ) ) ; assert jnfails to start ( conf , not a directory ) ; } finally { existing file . delete ( ) ; }
no _ entry _ key = in . read double ( ) ;
string delete query = delete from cassandra entity sample c where c . key = k ; q = em . create query ( delete query ) ;
message set = message set . to builder ( ) . merge from ( data , extension registry ) . build ( ) ; assert equals ( 123 , message set . get extension ( test message set extension1 . message set extension ) . get i ( ) ) ; }
body . add part ( part ) ;
for ( int i = 1 ; i < last array index - first array index ; i + + ) { new bits [ i ] = bits [ first array index + i ] ; }
buffer = new int [ bytes _ offset + 6 ] ; one byte = new byte [ 1 ] ; engine reset ( ) ; }
service builder < embedded cache manager > builder = new alias service builder < > ( service name , container service name , embedded cache manager . class ) . build ( target ) . set initial mode ( service controller . mode . active ) ; embedded cache manager = service container helper . get value ( builder . install ( ) ) ; } else {
int region action index = - 1 ;
get task response response = expect finished task ( new task id ( fake : 1 ) ) ;
m gbdevice . send device update intent ( this ) ; } return start _ sticky ; } }
assert true ( can access ( manager , mil user , named tree a , access mode . read ) ) ;
props . remove ( property _ prefix + maxwidth ) ; props . store ( out , bee line . get application title ( ) ) ; } catch ( exception e ) {
queue accessible node labels . clear ( ) ; queue accessible node labels . add all ( arrays . as list ( x , y ) ) ; rm context . get node label manager ( ) . add to cluser node labels ( immutable set . of ( node label . new instance ( x ) , node label . new instance ( y ) ) ) ; resource resource = resources . create resource ( 0 , yarn configuration . default _ rm _ scheduler _ minimum _ allocation _ vcores ) ; resource request res req = builder utils . new resource request ( mock ( priority . class ) , resource request . any , resource , 1 ) ; res req . set node label expression ( x ) ; scheduler utils . normalize andvalidate request ( res req , max resource , queue , scheduler , rm context ) ; res req . set node label expression ( y ) ; scheduler utils . normalize andvalidate request ( res req , max resource , queue , scheduler , rm context ) ; res req . set node label expression ( ) ;
roll writer ( ) ;
status line = response . get status line ( ) ;
result = services a . execute operation ( write cache container default cache op ) ;
json = get json ( http client , get url , attempts , false ) ; } else {
position . length = 0 ; position . set text ( edit . get original text ( ) ) ; } else refactoring core plugin . log error message ( dubious undo edit found : + undo . to string ( ) ) ; non - nls - 1 } else if ( length = = 0 ) { position . offset = offset ;
params . append ( papplet . args _ stop _ color + = + preferences . get ( run . present . stop . color ) ) ;
holder . set max left swipe amount ( - 0 . 5f ) ;
map < string , simple feature > old features = new linked hash map < string , simple feature > ( ) ; simple feature iterator it = features . features ( ) ;
m chart . set data ( data ) ;
try { new stanza type filter ( mock packet . class ) ; } catch ( illegal argument exception e ) { fail ( ) ; }
list < build job > next jobs = build system . take jobs to run ( ) ;
assert . assert equals ( task count - 1 , executor . get queue ( ) . size ( ) ) ; for ( int i = 0 ; i < task count ; i + + ) { if ( executor . get completed task count ( ) < task count ) { sleep ( 100 ) ; } } assert . assert equals ( task count , executor . get completed task count ( ) ) ; }
valid encoding with unknown alg oid [ 18 ] = 0 ; encrypted private key info epki = new encrypted private key info ( valid encoding with unknown alg oid ) ; assert null ( epki . get alg parameters ( ) ) ; }
_ out = get context ( ) . message registry ( ) . register pending ( _ reply selector , _ on reply , _ on timeout , _ timeout ms ) ;
assert . assert true ( iterator . has next ( ) ) ;
s . set cache blocks ( false ) ;
for ( int j = 0 ; j < curr dist . length ; j + + ) { system . arraycopy ( curr dist [ j ] , 0 , dist [ j ] , 0 , dist [ j ] . length ) ; }
if ( this . equals ( request ) ) { return 0 ; they are the same request } int compare val ; compare val = p - request . p ; compare priority
int [ ] pi tri list in ;
long file pointer = dict out . get file pointer ( ) ;
expected dow = ( ( ( expected dow + 1 ) - 1 ) % 7 ) + 1 ; expected day + + ; expected doy + + ; if ( expected day = = 31 & & expected month < 13 ) { expected day = 1 ; expected month + + ; } else if ( expected month = = 13 ) { if ( expected year % 4 = = 3 & & expected day = = 7 ) { expected day = 1 ; expected month = 1 ; expected year + + ; expected doy = 1 ; } else if ( expected year % 4 = 3 & & expected day = = 6 ) { expected day = 1 ; expected month = 1 ; expected year + + ; expected doy = 1 ; } } millis + = skip ;
if ( oparray list = null & & oparray list . size ( ) = 0 ) { oparray list list = new array list < > ( ) ; oparray list list . add ( oparray list ) ; oparray list = null ; oppathe list = new array list < > ( ) ; oppathe list . add ( oppathe ) ; oppathe = ; } new move files ( oparray list list , get current main fragment ( ) , get current main fragment ( ) . get activity ( ) , open mode . file ) . execute on executor ( async task . thread _ pool _ executor , oppathe list ) ;
pns = compile to fragments ( select a4 , count ( distinct b4 ) from t4 group by a4 ) ; p = pns . get ( 0 ) . get child ( 0 ) ; assert true ( p instanceof receive plan node ) ; p = pns . get ( 1 ) . get child ( 0 ) ; assert true ( p instanceof abstract scan plan node ) ;
if ( m seconds tens = null ) { m seconds tens . set typeface ( m android clock mono thin ) ; m seconds tens . update padding ( ) ; }
try { int [ ] data = new int [ 8 ] ; ib . position ( 0 ) ; ib . put ( data , - 1 , 2 ) ; fail ( expected exception not thrown ) ; } catch ( index out of bounds exception e ) { expected }
for ( int i = 0 ; i < num _ to _ write ; i + + ) { write to file ( base . get relative ( file + i ) , test _ file _ data ) ; }
set = enum set . range ( huge enum count . no1 , huge enum count . no130 ) ; array = set . to array ( ) ; for ( huge enum count count : set ) { assert equals ( count , ( huge enum count ) array [ count . ordinal ( ) ] ) ; } }
final execution environment env = execution environment . get execution environment ( ) ; graph < long , boolean , long > graph = graph . from collection ( test graph utils . get long boolean vertices ( ) , test graph utils . get long long edges ( ) , env ) ;
if ( configuration = = null ) { throw new illegal argument exception ( a non - null realm configuration must be provided ) ; } return realm cache . create realm or get from cache ( configuration , dynamic realm . class ) ; }
verify allowed ( exec endpoint action , user a , user b ) ; revoke from namespace ( test _ util , user b . get short name ( ) , namespace , permission . action . exec ) ;
assert xpath exists ( base + input [ 2 ] , d ) ;
list < user to > users = read web server users ( daemon config to ) ;
if ( snmp _ adaptor _ logger . is loggable ( level . finer ) ) { snmp _ adaptor _ logger . logp ( level . finer , snmp sub request handler . class . get name ( ) , run , [ + thread . current thread ( ) + ] : get operation on + agent . get mib name ( ) ) ; } agent . get ( create mib request ( var bind , version , data ) ) ;
if ( pwd = null ) { hive conf . set var ( job , hive conf . conf vars . metastorepwd , pwd ) ; }
builder . maximum weight ( 16 ) ; fail ( ) ; } catch ( illegal state exception expected ) { }
if ( diff scale < 0 ) { this unscaled = this unscaled . multiply ( multiplication . power of10 ( - diff scale ) ) ; } else if ( diff scale > 0 ) { val unscaled = val unscaled . multiply ( multiplication . power of10 ( diff scale ) ) ; } return this unscaled . compare to ( val unscaled ) ;
remote session first session = activate and assert ok ( 90l , 0l , clock ) ;
if ( ( center offset + center offset ) > max line ) { href width = max line 2 ; } else { href width = center offset ; }
for ( int m = 0 ; m < first row ; m + + ) { rs . next ( ) ; }
file input format . add input path ( conf , new path ( unused ) ) ; input split [ ] splits = inputformat . get splits ( conf , 0 ) ; assert equals ( splits . length , 1 ) ; record reader < text , accumulo hive row > reader = inputformat . get record reader ( splits [ 0 ] , conf , null ) ; text key = reader . create key ( ) ; accumulo hive row value = reader . create value ( ) ;
if ( string utils . is not empty ( loop characteristics . get input data item ( ) ) ) { if ( loop characteristics . get input data item ( ) . contains ( { ) ) { mi activity behavior . set collection expression ( expression manager . create expression ( loop characteristics . get input data item ( ) ) ) ; } else { mi activity behavior . set collection variable ( loop characteristics . get input data item ( ) ) ; } }
process instance pi = runtime service . start process instance by key ( test join ) ; task task1 = task service . create task query ( ) . single result ( ) ; assert equals ( main task , task1 . get name ( ) ) ; timer job query job query = management service . create timer job query ( ) . process instance id ( pi . get id ( ) ) ;
create node ( path , zkretries ) ; return true ;
assert that ( term : + string0 , iter0 . doc freq ( ) , equal to ( iter1 . doc freq ( ) ) ) ; assert that ( term : + string0 , iter0 . total term freq ( ) , equal to ( iter1 . total term freq ( ) ) ) ;
if ( _ kind = = tckind . _ tk _ native ) throw wrapper . cannot marshal native ( ) ; type code output stream top stream = tcos . get top level stream ( ) ;
throw new ioexception ( no namenode for + logical name ) ;
account manager . remove ( account . get id ( ) ) ;
final int num leaves = integer . highest one bit ( ( num docs - 1 ) actual max points in leaf node ) < < 1 ;
assert . assert false ( async thread . is alive ( ) ) ;
if ( wps = = null ) { throw new service exception ( wps config not loaded . check logs for details . ) ; } si . get title ( ) . add ( ows11 util . language string ( wps . get title ( ) ) ) ; si . get abstract ( ) . add ( ows11 util . language string ( wps . get abstract ( ) ) ) ; keywords type kw = ows11 util . keywords ( wps . keyword values ( ) ) ; ;
string input separator = sep = = null ? \ t : sep ; string input = data1 + input separator + 12 + input separator + data3 ; try { prepare options ( sep , - 1 , 0 , 0 , 0 , true , false ) ; parse one file ( sut , new string reader ( input ) ) ; } catch ( exception e ) { assert . fail ( exception during file parse , e ) ; } assert . assert equals ( project . column model . columns . size ( ) , 3 ) ;
return n _ cleared | m _ shifted ; }
return query . query from ( this ) ;
float scale x = get scale x ( ) ;
c map legend creator = cmap legend builder . create ( ) ;
final int mask = include final methods ? modifier . public : modifier . public | modifier . final ; if ( ( method . get modifiers ( ) & mask ) = = opcodes . acc _ public ) { if ( method . get parameter types ( ) . length = = 0 & & method . get name ( ) . equals ( < init > ) & & method . get name ( ) . equals ( < clinit > ) & & method . get return type ( ) = void . class & & method . is default ( ) ) {
file status [ ] file status = fs . list status ( table dir ) ;
report fatal error ( msg _ space _ required _ before _ entity _ name _ in _ entitydecl , null ) ;
boundary = extract boundary ( content type ) ; if ( boundary = null ) { br = new buffered reader ( new string reader ( msg . get request body ( ) . to string ( ) ) ) ;
switch ( direction ) { case direction _ start : m first visible position - - ; break ; case direction _ end : m first visible position + + ; break ; case direction _ up : m first visible position - = get total column count ( ) ; break ; case direction _ down : m first visible position + = get total column count ( ) ; break ; }
test set permission ( test set permission positive owner , null , null , null , false , false ) ;
message . put ( message . content _ type , ct ) ; return ct ; }
final map file . writer out = new map file . writer ( job , fs , file . to string ( ) , job . get output key class ( ) . as subclass ( writable comparable . class ) , job . get output value class ( ) . as subclass ( writable . class ) , compression type , codec , progress ) ; return new record writer < writable comparable , writable > ( ) { public void write ( writable comparable key , writable value ) throws ioexception { out . append ( key , value ) ; } public void close ( reporter reporter ) throws ioexception { out . close ( ) ; } } ;
charset charset = resources . get charset ( ) ;
new create index task ( run data ) . do logic ( ) ; add indexes task task = new add indexes task ( run data ) ;
directory reader . open ( dir ) . close ( ) ;
text = text . to lower case ( ) . trim ( ) ; text = text . replace all ( ( \ \ ' | \ \ \ | \ \ ` | \ \ _ ) , ) ; text = snowball stemmer . stem all tokens ( text ) ;
final pending registration promise promise = new pending registration promise ( channel ) ;
while ( deadline . has time left ( ) & & stats . get num successful ( ) = total queries ) { thread . sleep ( 100 l ) ; } assert equals ( total queries , stats . get num requests ( ) ) ;
integer hash = null ; int [ ] hashes = cr . get hashes ( ) ; if ( hashes = null & & hashes . length > 0 ) { hash = hashes [ 0 ] ; } m _ txn state . set hash ( hash ) ;
0x17 , 0x0 d , 0x30 , 0x30 , 0x30 , 0x31 , 0x30 , 0x31 , 0x30 , 0x30 , 0x30 , 0x30 , 0x30 , 0x30 , 0x5 a , 01 jan 2000 00 : 00 : 00
return type . get kind ( ) = type kind . void & & element . get parameters ( ) . is empty ( ) & & ( is immutable ( ) | | is interface | | element . get modifiers ( ) . contains ( modifier . final ) ) & & ( is immutable ( ) | | type . equals ( element ( ) . as type ( ) ) ) & & type . equals ( builder type ( ) . or else ( null ) ) & & element . get modifiers ( ) . contains ( modifier . static ) & & element . get modifiers ( ) . contains ( modifier . default ) & & ( is transient | | is interface ) & & name . equals ( to string ) & & name . equals ( hash code ) ;
this . cached executor = null ;
clients . remove ( cr index ) ;
execution execution = runtime service . create execution query ( ) . activity id ( wait state1 ) . process definition key ( child process ) . single result ( ) ;
process engine configuration . get clock ( ) . set current time ( new date ( start time . get time ( ) + ( ( 60 * 60 * 1000 ) + 5000 ) ) ) ; job job = management service . create timer job query ( ) . executable ( ) . single result ( ) ; assert not null ( job ) ; management service . move timer to executable job ( job . get id ( ) ) ; management service . execute job ( job . get id ( ) ) ;
layout = new foldable item layout ( get context ( ) ) ;
session config cfg = new session config ( in . get destination ( ) ) ; cfg . set signature ( in . get signature ( ) ) ; properties props = new properties ( ) ; props . put all ( in . get options ( ) ) ; cfg . set options ( props ) ; _ runner . session established ( cfg ) ; if ( _ log . should log ( log . debug ) ) _ log . debug ( after session established for + _ runner . get dest hash ( ) ) ;
message set = message set . to builder ( ) . merge from ( data , extension registry ) . build ( ) ; assert equals ( 123 , message set . get extension ( test message set extension1 . message set extension ) . get i ( ) ) ; }
if ( container iterator . has next ( ) ) { return false ; }
f locator . set system id ( system . get property ( user . dir ) + file . separator + dummy . xsl ) ;
string root relative path = file . separator + . + file . separator ; if ( rel path . equals ( root relative path ) ) { list < history entry > entries = new array list < history entry > ( ) ; entries . add ( new history entry ( , new date ( ) , open grok , null , workspace root , true ) ) ; history = new history ( entries ) ; } else { try { * * errors will be logged , so not bothering to add to the output . * executor executor = repository . get history log executor ( file ) ; executor . exec ( true , this ) ; } catch ( ioexception e ) { throw new history exception ( failed to get history for : \ + file . get absolute path ( ) + \ + e ) ; } }
u . set ( u . get protocol ( ) , host , port , authority , user info , path , query , ref ) ;
append ( xml , < , remote control extension provider . element _ key _ type ) ;
base iter = new test iterator ( size , 100 ) ; async = new async data set iterator ( base iter , 100 ) ; for ( int i = 0 ; i < size ; i + + ) { assert true ( async . has next ( ) ) ; data set ds = async . next ( ) ; while ( ds = = null ) ds = async . next ( ) ; assert equals ( ds . get feature matrix ( ) . get double ( 0 ) , i , 0 . 0 ) ; assert equals ( ds . get labels ( ) . get double ( 0 ) , i , 0 . 0 ) ; } assert false ( async . has next ( ) ) ; async . reset ( ) ;
m _ path cache . put ( immediate parent path , immediate parent ) ; return get item for path part ( immediate parent , sub path ) ;
concurrent gcevent event = new concurrent gcevent ( ) ; event . set type ( type . cms _ concurrent _ mark _ start ) ; assert equals ( generation , generation . tenured , event . get generation ( ) ) ;
dashboard workspace . click open in ide ws btn ( ) ; selenium web driver . switch from dashboard iframe to ide ( ) ; project explorer . wait project explorer ( ) ; project explorer . wait item ( project _ name ) ; project explorer . wait folder defined type of folder by path ( template . web _ java _ petclinic . value ( ) , project _ folder ) ; notifications popup panel . wait pop up panels is closed ( ) ;
try { image io . write ( split image , output _ type , img output ) ; } catch ( exception e ) { print exception and exit ( e ) ; }
m adapter . add scrollable header ( scrollable header ) ; m adapter . add scrollable footer ( scrollable footer ) ; assert equals ( 37 , m adapter . get item count ( ) ) ; assert equals ( 35 , m adapter . get main item count ( ) ) ;
params [ 0 ] = ; params [ 1 ] = pkey . increment and get ( ) ; for ( int i = 0 ; i < cols ; i + + ) { params [ i + 2 ] = m _ mid values [ i ] ; assert ( params [ i + 2 ] = null ) ; } params [ 0 ] = allow _ nulls ; client . call procedure ( insert , params ) ; for ( int i = 0 ; i < cols ; i + + ) { params [ i + 2 ] = ( i = = k ) ? m _ null values [ i ] : m _ mid values [ i ] ; assert ( params [ i + 2 ] = null ) ; }
for ( int i = 0 ; i < strlen ; i + + ) { c = str . char at ( i ) ; if ( ( c > = 0x0001 ) & & ( c < = 0x007 f ) ) utflen + + ; else if ( c > 0x07 ff ) utflen + = 3 ; else utflen + = 2 ; } if ( utflen > 65535 ) throw new illegal argument exception ( encoded string too long : + utflen + bytes ) ;
task info iterator . remove ( ) ;
strings . remove ( var ) ; super . comment ( var ) ; }
float wiper = ( float ) 0 . 0 ; for ( int s = 0 ; s < get series count ( ) ; s + + ) { this . value history [ s ] . enter data ( this . newest at , wiper ) ; }
assert equals ( baos . to string ( ) , hello ) ;
final custom property old cp = super . remove ( old id ) ; super . put ( id key , cp ) ; return old cp ; }
if ( time format . equals ( time format . double ) ) { window time unit combo . set visible ( false ) ; tick time unit combo . set visible ( false ) ; }
insert node ( node ) ; entries + + ; return value ; }
} } } } ; background operation pool . execute ( timeout checker ) ; }
counter c = h . get core container ( ) . get metric manager ( ) . counter ( null , solr . jvm , foo ) ;
flush manager . build flush stack ( node , com . impetus . kundera . persistence . context . event log . event type . insert ) ;
string body code = can ' t call an abstract method \ n + [ self does not recognize selector : _ cmd ] ; ;
em . get transaction ( ) . begin ( ) ; ing2 = em . find ( set ref ing mul id entity . class , ing2 _ id ) ; ed2 = em . find ( set ref ed mul id entity . class , ed2 _ id ) ; ing2 . set reference ( ed2 ) ; em . get transaction ( ) . commit ( ) ; }
int act ;
set content cache ( true ) ; }
result . append ( ' a ' ) ;
assert equals ( local [ * ] , props . get spark master ( ) ) ;
return cv . get type ( ) ;
assert not equal ( message . hash code ( ) , lazy field . hash code ( ) ) ;
paint . set shader ( null ) ;
toast . make text ( m context , r . string . playlist _ created , toast . length _ short ) . show ( ) ; break ; case 1 :
return invoke superclass method impl ( bcm , instance , method name , args ) ; }
return ( float ) ( tab base + ( ( ( int ) x 72 + 1 ) * 72 ) ) ;
when ( mock connection . get auto commit ( ) ) . then return ( true ) ;
more asserts . assert contains sublist ( get generating spawn action args ( artifact ) , - obfuscationdictionary , java com google android dictionary . txt ) ;
string relative name = file . get relative file path ( ) ; temp = new file ( local , relative name + . inprogress ) ;
typed value tv = new typed value ( ) ; int action bar height = 0 ; if ( get theme ( ) . resolve attribute ( android . r . attr . action bar size , tv , true ) ) { action bar height = typed value . complex to dimension pixel size ( tv . data , get resources ( ) . get display metrics ( ) ) ; } if ( activity view = null ) { activity view . set padding ( 0 , top padding + action bar height , 0 , 0 ) ; }
if ( split type = split type . all ) { add stats for split type ( split type . all , split size , host count , block count ) ; }
controller . initial window size ( 10 ) ; data . assert fully written ( ) ; assert writability changed ( 0 , false ) ; }
assert jdelete ( endpoint + fröhlich , error code = = 404 ) ;
map < string , string > empty guava = maps . new hash map ( ) ; using guava
router . get ( ) . route ( filter ) . with ( filter controller : : filter ) ; router . get ( ) . route ( teapot ) . with ( filter controller : : teapot ) ;
stop scroll ( ) ; int row count = m adapter . get item count ( ) ;
db query . close ( ) ;
if ( basedir = null & & selector utils . match pattern start ( includes [ i ] , basedir . get absolute path ( ) , is case sensitive ( ) ) ) { continue ; }
security context holder . get context ( ) . set authentication ( new testing authentication token ( someone , passwd , role _ b ) ) ;
pair . set left ( column . substring ( 1 , column . length ( ) - 1 ) ) ;
return t1 ; }
partition = p . get partition ( c , hconstants . empty _ byte _ array , 3 ) ;
int flags = current entry . get method ( ) = = stored ? 0 : zip file . gpbf _ data _ descriptor _ flag ;
return new account ( account id , name , length , external key , email , null , currency , parent account id , is payment delegated to parent , null , time zone , address1 , address2 , postal code , company , city , state , country , locale , phone , notes , false , false , null , null ) ;
field name = string from bytes ( bytes . bytes , bytes . offset , len ) . intern ( ) ;
if ( ex instanceof servlet exception ) { throw ( servlet exception ) ex ; } else if ( ex instanceof runtime exception ) { throw ( runtime exception ) ex ; }
set server property ( orchestrator , sonar . auth . fake - base - id - provider . enabled , true ) ; }
set < integer > copy set = new hash set < > ( set ) ; for ( int prev vertex : set ) { int cost = distance [ prev vertex ] [ current vertex ] + get cost ( copy set , prev vertex , min cost dp ) ; if ( cost < min cost ) { min cost = cost ; min prev vertex = prev vertex ; } }
create button ( parent , idialog constants . close _ id , idialog constants . close _ label , true ) ;
scm material config othermaterial = new git material config ( http : myother . git ) ; cruise config . set config repos ( new config repos config ( new config repo config ( othermaterial , myplugin ) ) ) ; config watch list . on config change ( cruise config ) ; assert that ( partial config . last partials ( ) . size ( ) , is ( 0 ) ) ;
object a = s . read fields ( ) . get ( array , null ) ; if ( a = = null | | a . get class ( ) . is array ( ) ) throw new java . io . invalid object exception ( not array type ) ; if ( a . get class ( ) = object [ ] . class ) a = arrays . copy of ( ( object [ ] ) a , array . get length ( a ) , object [ ] . class ) ; u . put object volatile ( this , array , a ) ; }
assert on commit ( utx , false ) ;
if ( failure instanceof index population failed kernel exception ) { throwable cause = failure . get cause ( ) ; if ( cause instanceof index entry conflict exception ) { failure = cause ; } }
assert equals ( 1 , matches1 . length ) ;
if ( id = group _ by _ missing _ value ) { final string value = dictionary . get ( id ) ; result map . put ( selector plus . get output name ( ) , value ) ; } else { result map . put ( selector plus . get output name ( ) , ) ; } }
system store repository sys repository = new system store repository ( client config ) ; string cluster xml = store client factory . bootstrap metadata with retries ( metadata store . cluster _ key ) ; sys repository . create system stores ( client config , cluster xml , store client factory . get failure detector ( ) ) ;
final int end index = math . min ( ( ( int ) start ) + length , string . length ( ) ) ;
assert equals ( [ \ yes \ ] , serialize as string ( input ) ) ; assert equals ( [ \ maybe \ ] , serialize as string ( input2 ) ) ;
if ( tmp . exists ( ) & & tmp . delete ( ) ) { logger . log ( level . warning , failed to remove temporary file used by history cache ) ; } string decorated = filename + @ @ + rev ;
assert true ( failed to convert integer return to boolean true , lib . return int32 argument ( true ) ) ;
if ( _ header string = null | | _ value string = null ) _ handler . parsed trailer ( _ field = null? _ field : new http field ( _ header , _ header string , _ value string ) ) ; _ header string = _ value string = null ; _ header = null ; _ value = null ; _ field = null ; }
final int flushed docs = 10 ; final int non flushed docs = random int between ( 0 , 10 ) ; final int num docs = flushed docs + non flushed docs ; shards . index docs ( flushed docs ) ; shards . flush ( ) ; shards . index docs ( non flushed docs ) ; index shard replica = shards . get replicas ( ) . get ( 0 ) ;
out = current . do forward ( false ) ;
weights [ f ] [ c ] = math . log ( numc [ c ] num ) ; } else {
modify entity ( a ) ; s = open session ( ) ;
if ( errsock = null ) { one time attempt a socket close final server socket channel tmp2 = errsock ; errsock = null ; tmp2 . close ( ) ; could throw , but errsock cleared for next pass }
m _ sax handler . start element ( emptystring , m _ elem context . m _ element name , m _ elem context . m _ element name , m _ attributes ) ; m _ attributes . clear ( ) ;
assert equals ( flds [ 0 ] . get field ( ) , pow ( float ( weight ) , const ( 2 ) ) ) ;
final int end = ( get top ( ) - get bottom ( ) ) - get list padding bottom ( ) ;
vt = client . call procedure ( @ ad hoc , select v _ g1 , v _ cnt from + tb + where v _ g1 = ( v _ sum _ rent - 7 ) order by v _ cnt ; ) . get results ( ) [ 0 ] ;
element interests = root . add element ( interests ) ; interests . add element ( interest ) . add text ( movie ) ; interests . add element ( interest ) . add text ( sports ) ; return document . as xml ( ) ;
node method name node = this arg . get next ( ) ; if ( method name node = = null | | method name node . is string ( ) ) { report bad goog base use ( t , n , second argument must name a method . ) ; return ; } string method name = method name node . get string ( ) ; string ending = . prototype . + method name ;
final generic type < ? > entity type = new generic type ( get entity type ( ) ) ; final list < media type > media types = workers . get message body writer media types ( entity type . get raw type ( ) , entity type . get type ( ) , get entity annotations ( ) ) ; set media type ( get media type ( media types ) ) ;
system . arraycopy ( original fields , 0 , fields , 0 , fields . length ) ; throw new illegal argument exception ( get field name ( field ) + = + wrong value + , expected + original fields [ field ] ) ; } } }
if ( obj instanceof group ) { final group group = ( group ) obj ; return get name ( ) . equals ( group . get name ( ) ) ; } return false ; }
volt table [ ] results = client . call procedure ( constants . stock _ level , ( byte ) 3 , ( byte ) 7 , 1 ) . get results ( ) ;
set < string > artifact ids = new hash set < string > ( ) ; for ( object o : props . key set ( ) ) { string k = ( string ) o ; int dot index = k . index of ( ' . ' ) ; if ( dot index < = 0 ) { continue ; } string artifact id = k . substring ( 0 , dot index ) ; skip the entries without required information . if ( props . contains key ( artifact id + prop _ version ) | | props . contains key ( artifact id + prop _ build _ date ) | | props . contains key ( artifact id + prop _ commit _ date ) | | props . contains key ( artifact id + prop _ short _ commit _ hash ) | | props . contains key ( artifact id + prop _ long _ commit _ hash ) | | props . contains key ( artifact id + prop _ repo _ status ) ) { continue ; } artifact ids . add ( artifact id ) ; } map < string , version > versions = new tree map < string , version > ( ) ;
if ( this . get parallelism ( ) > 0 ) { use specified parallelism po . set parallelism ( this . get parallelism ( ) ) ; } else { if no parallelism has been specified , use parallelism of input operator to enable chaining po . set parallelism ( input . get parallelism ( ) ) ; } return po ;
long pause base = this . pause ;
if ( non _ file _ editor _ keys . contains ( key stroke ) & & editor data . is file editor ( editor ) ) { return false ; }
int sequence length = max literal length multiplication ( get sequence count ( w ) + 1 ) ;
if ( have integer ) { return false ; }
int v = ( buf [ src pos [ i ] ] > > src off [ i ] ) & 1 ;
path p = new path ( empty - file ) ; dfstest util . create file ( cluster . get file system ( ) , p , 0 , ( short ) 1 , 0 l ) ;
ce . last accessed copy = ce . last accessed ;
buf . append ( ( ( word1 ( d ) = = 0 ) & & ( ( word0 ( d ) & frac _ mask ) = = 0 ) ) ? infinity : na n ) ; return 9999 ;
get data frame of elements df operation = new get data frame of elements . builder ( ) . view ( new view . builder ( ) . edge ( edge _ group ) . build ( ) ) . build ( ) ;
assert false ( persister . get property nullability ( ) [ entity metamodel . get property index ( naturalid ) ] ) ; persister = session factory ( ) . get entity persister ( c . class . get name ( ) ) ; entity metamodel = persister . get entity metamodel ( ) ; assert true ( persister . get property nullability ( ) [ entity metamodel . get property index ( name ) ] ) ; persister = session factory ( ) . get entity persister ( d . class . get name ( ) ) ;
mask = ( 1 < < w ) - 1 ; needed on hp , cc - o bug
populate near cache ( map , map size ) ; long owned entry count = get near cache stats ( map ) . get owned entry count ( ) ; assert true ( format ( near cache should be populated but current size is % d , owned entry count ) , owned entry count > 0 ) ; }
if ( f last modified > = 0 ) { if ( properties file exists & & ( f last modified < ( f last modified = ss . get last modified ( properties file ) ) ) ) { load properties = true ; } else {
hash map < block , binfo > blk map = get block map ( namespace id ) ; binfo binfo = blk map . get ( b ) ; if ( binfo = = null ) { return false ; } return binfo . is finalized ( ) ;
assert equals ( normalize conjuncts ( effective predicate ) , normalize conjuncts ( less than ( be , ae ) , less than ( ce , bigint literal ( 10 ) ) , or ( equals ( ae , de ) , is null ( de ) ) ) ) ;
boolean skip first = false ; do { try { if ( skip first ) {
context ctx = driver context . get ctx ( ) ; string hive jar = conf . get jar ( ) ; string hadoop exec = conf . get var ( hive conf . conf vars . hadoopbin ) ; conf . set var ( conf vars . hiveaddedjars , utilities . get resource files ( conf , session state . resource type . jar ) ) ;
set domain crosshair value ( crosshair state . get crosshair x ( ) , false ) ; if ( is domain crosshair visible ( ) ) { draw vertical line ( g2 , data area , get domain crosshair value ( ) , get domain crosshair stroke ( ) , get domain crosshair paint ( ) ) ; }
assert that ( entity . field , is ( 80 ) ) ;
buf [ i + + ] = ( byte ) ( olen & 0x ff00 ) ;
system . out . printf ( deleting all even rows \ n ) ;
if ( table model . get row count ( ) > 0 ) { if ( anchor selection > = table model . get row count ( ) ) { anchor selection = table model . get row count ( ) - 1 ; } header table . set row selection interval ( anchor selection , anchor selection ) ; } check buttons status ( ) ;
test kill job ( conf ) ;
assert equals ( 10 l , sql ( ) . from ( product ) . where ( filter ) . distinct ( ) . fetch count ( ) ) ;
crawl dbtest util . create crawl db ( conf , fs , db dir , list ) ; }
return undefined ;
admin . enable table ( cloned table name2 ) ;
create on file system ( new file ( tgt , . fs - ignore ) ) ; create on page cache ( new file ( tgt , . pc - ignore ) ) ; store files . move to ( src , tgt ) ; assert false ( fs . file exists ( a ) ) ; assert false ( pc . file exists ( b ) ) ;
if ( cloned . starts with ( md _ link _ slash ) ) { return cloned . substring ( 1 ) ; } else { return cloned ; } }
postings enum tp = multi fields . get term positions enum ( reader , terms [ 0 ] . field ( ) , new bytes ref ( terms [ 0 ] . text ( ) ) ) ;
name space ns = namespace ; while ( ns = null ) {
stream expression expression = new stream expression ( factory . get function name ( this . get class ( ) ) ) ; expression . add parameter ( \ + echo . replace ( \ , \ \ \ ) + \ ) ; return expression ; }
whitebox . invoke method ( this , test method runner . class , run with timeout , timeout ) ;
cell scanner cell scanner = next [ 0 ] . cell scanner ( ) ; cell scanner . advance ( ) ; cell current = cell scanner . current ( ) ; assert true ( bytes . equals ( current . get row array ( ) , current . get row offset ( ) , current . get row length ( ) , row2 , 0 , row2 . length ) ) ; }
object val = agg . get ( ) ;
prefix flags [ 2 ] = data [ end offset - 1 ] = = 0 ;
repr url = args [ 0 ] ;
arrays . sort ( _ blocklist , 0 , count ) ;
playback info = new playback info ( 0 , c . time _ unset ) ;
int flags = format _ show _ time ; result = format date range ( c , millis , millis , flags ) ; preposition id = r . string . preposition _ for _ time ; } else if ( s now time . year = s then time . year ) {
final int width3 = canvas _ width 10 ; verify ( canvas ) . draw widget ( item at1x1 , rect2i . create from min and size ( 0 , 0 , width1 , canvas _ height ) ) ;
if ( max > = 0 & & ( included count - first ) > = ( max - 1 ) ) { break ; }
system . arraycopy ( tribes _ mbr _ begin , 0 , data , pos , tribes _ mbr _ begin . length ) ; pos + = tribes _ mbr _ begin . length ;
int p w = ( int ) ( hash & ( ( 1 < < ( 32 - p prime ) ) - 1 ) ) > > > 1 ;
type type = test to type ( dpt , new byte [ ] { ( byte ) 0x7 f , ( byte ) 0x ff , ( byte ) 0x ff , ( byte ) 0x ff , ( byte ) 0x ff } , decimal type . class ) ; test to dptvalue ( dpt , type , 2147483647 ) ; type = test to type ( dpt , new byte [ ] { 0x00 , 0x00 , 0x00 , 0x00 } , decimal type . class ) ; test to dptvalue ( dpt , type , 0 ) ; type = test to type ( dpt , new byte [ ] { ( byte ) 0x ff , ( byte ) 0x ff , ( byte ) 0x ff , ( byte ) 0x ff } , decimal type . class ) ; test to dptvalue ( dpt , type , - 1 ) ; type = test to type ( dpt , new byte [ ] { ( byte ) 0x80 , 0x00 , 0x00 , 0x00 } , decimal type . class ) ; test to dptvalue ( dpt , type , - 2147483648 ) ;
string buffer top = 0 ; this . string = null ; parser . add error ( msg . xml . bad . form ) ; return token . error ;
get ( cdf locks wfs?request = release lock & version = 2 . 0 & lock id = + lock id ) ; assert equals ( wfs : transaction response , dom . get document element ( ) . get node name ( ) ) ;
try ( final admin admin = test _ util . get admin ( ) ) { admin . flush ( table name ) ; test _ util . wait for ( 60000 , new waiter . predicate < exception > ( ) { @ override public boolean evaluate ( ) throws exception { return region server . get regions ( table name ) . get ( 0 ) . get max flushed seq id ( ) > 3 ; } } ) ; } list < get > gets = new array list < > ( 2 ) ;
assert tree model equals ( model , loaded model ) ;
database . remove ( id ) ;
owner document . inserted text ( this , offset , data . length ( ) ) ;
if ( has node args ( ) ) { if ( tleft instanceof boolean type ) { _ right = new cast expr ( _ right , type . boolean ) ; tright = type . boolean ; } if ( tright instanceof boolean type ) { _ left = new cast expr ( _ left , type . boolean ) ; tleft = type . boolean ; } }
from ( direct : exec ant ) . to ( exec : ant . bat?args = - f + ant _ build _ file _ name ) ;
else if ( within domain ( sub , constraint ) ) { return true ; }
long total used space = total capacity * 3 10 ; long length = total used space num of datanodes ; test balancer . create file ( cluster , file path , length , ( short ) num of datanodes , 0 ) ; located blocks lbs = client . get block locations ( file path . to uri ( ) . get path ( ) , 0 , length ) ;
dynamic ser de extends jjtn000 = new dynamic ser de extends ( jjtextends ) ; boolean jjtc000 = true ; jjtree . open node scope ( jjtn000 ) ; try { switch ( ( jj _ ntk = = - 1 ) ? jj _ ntk ( ) : jj _ ntk ) { case tok _ extends : jj _ consume _ token ( tok _ extends ) ; jj _ consume _ token ( identifier ) ; jjtree . close node scope ( jjtn000 , true ) ; jjtc000 = false ; { if ( true ) { return jjtn000 ; } } break ; default : jj _ la1 [ 21 ] = jj _ gen ; jjtree . close node scope ( jjtn000 , true ) ; jjtc000 = false ; { if ( true ) { return jjtn000 ; } } } } finally { if ( jjtc000 ) { jjtree . close node scope ( jjtn000 , true ) ; } } throw new error ( missing return statement in function ) ;
verify ( table . get name ( ) ) ; } finally {
int min cost [ ] = new int [ words . length ] ; int result [ ] = new int [ words . length ] ; for ( int i = words . length - 1 ; i > = 0 ; i - - ) { min cost [ i ] = cost [ i ] [ words . length - 1 ] ; result [ i ] = words . length ; for ( int j = words . length - 1 ; j > i ; j - - ) { if ( cost [ i ] [ j - 1 ] = = integer . max _ value ) { continue ; } if ( min cost [ i ] > min cost [ j ] + cost [ i ] [ j - 1 ] ) { min cost [ i ] = min cost [ j ] + cost [ i ] [ j - 1 ] ; result [ i ] = j ; } } } int i = 0 ; int j ; system . out . println ( minimum cost is + min cost [ 0 ] ) ;
throw new illegal state exception ( unrecognized + schema action . class . get simple name ( ) + : + update action ) ;
out . write short ( no _ entry _ value ) ;
assert true ( request listener stub . is complete ( ) ) ;
execution context context = new execution context ( true ) ; request < ? > tested repeatable request = get sample request with repeatable content ( original request ) ;
file utils . copy file ( get file ( solr collection1 conf solrconfig - basic . xml ) , new file ( conf dir , solrconfig . xml ) ) ; file utils . copy file ( get file ( solr collection1 conf solrconfig . snippet . randomindexconfig . xml ) , new file ( conf dir , solrconfig . snippet . randomindexconfig . xml ) ) ; file utils . copy file ( get file ( solr collection1 conf schema - collate . xml ) , new file ( conf dir , schema . xml ) ) ;
assert equals ( 1 , query . find ( ) ) ; assert equals ( 1 , query . find ( ) ) ; assert equals ( 1 , query . find ( 0 ) ) ; assert equals ( 1 , query . find ( 1 ) ) ;
int offset = thread local random . current ( ) . next int ( num segments ) ; for ( int i = 0 ; i < num segments ; + + i ) { int segment = ( offset + i ) % num segments ; if ( predicate . test ( segment ) ) { return segment ; } } return - 1 ;
double endpoint vertices = 0 ; double range vertices = 0 ; for ( vertex vertex : graph . get vertices ( ) ) { if ( vertex . is endpoint vertex ( ) ) { endpoint vertices + + ; } else if ( vertex . is range vertex ( ) ) { range vertices + + ; } } return ( int ) math . ceil ( range vertices endpoint vertices ) ;
int sort length = 0 ;
if ( text utils . is empty ( content ) & & state . get current item ( ) = null ) { state . get current item ( ) . set item identifier ( content ) ; }
if ( sds . is empty ( ) ) { if ( this . get num storage dirs ( ) = = 0 ) throw new ioexception ( no more storage directories left ) ; check image directories , edits are checked withing fsedit log . check journals if ( get num storage dirs ( name node dir type . image ) = = 0 ) throw new ioexception ( no more image storage directories left ) ; } }
if ( item status . get playback state ( ) = = media item status . playback _ state _ playing ) { m position extrapolator . on resumed ( ) ; } else if ( item status . get playback state ( ) = = media item status . playback _ state _ finished ) { m position extrapolator . on finished ( ) ; } else { m position extrapolator . on paused ( ) ; }
reloadable type rt = rtype . get type registry ( ) . get reloadable type ( fieldmember . get declaring type name ( ) ) ;
timer job = management service . create timer job query ( ) . process instance id ( process instance . get id ( ) ) . single result ( ) ; assert not null ( timer job ) ;
while ( info list . length > 0 ) { start = info list [ info list . length - 1 ] . file path ; info list = cluster . get name node ( ) . iterative get open files ( dir . to string ( ) , 0 , start ) ; count + = info list . length ; } system . err . println ( count = = + count ) ;
filter list item ( ev . get y ( ) ) ; return true ;
a . switch to sample state ( ) ;
long count = task service . create task query ( ) . task definition key like ( % unexisting key % ) . count ( ) ; assert equals ( 0 l , count . long value ( ) ) ;
boolean empty = effective range . is empty ( ) | | range . compare or throw ( range . lower bound . least value above ( domain ) , range . upper bound . greatest value below ( domain ) ) > 0 ; return empty ? new empty contiguous set < c > ( domain ) : new regular contiguous set < c > ( effective range , domain ) ;
if ( check connection ( ) ) { permission perm = _ connection . get permission ( ) ; if ( perm instanceof java . io . file permission ) return new file ( perm . get name ( ) ) ; }
list < row > puts = construct put requests ( ) ; table . batch ( puts ) ;
simple list m list = new simple list ( ) ; m list . add ( new object ( ) ) ; m list . add ( new object ( ) ) ; list s list = m list . sub list ( 0 , 2 ) ; s list . add ( new object ( ) ) ; calls add ( int , object ) s list . get ( 0 ) ; s list . add ( 0 , new object ( ) ) ; s list . get ( 0 ) ; s list . add all ( arrays . as list ( new string [ ] { 1 , 2 } ) ) ; s list . get ( 0 ) ; s list . add all ( 0 , arrays . as list ( new string [ ] { 3 , 4 } ) ) ; s list . get ( 0 ) ; s list . remove ( 0 ) ; s list . get ( 0 ) ; list iterator lit = s list . list iterator ( ) ;
timeline metric m3 = new timeline metric ( ) ; m3 . set id ( unrelated _ values ) ; m3 . add value ( ts - 20000 , 3 l ) ; metrics . add ( m3 ) ; timeline metric m4 = new timeline metric ( ) ;
preconditions . check state ( this . last changed version . at most ( version ) , % s % s % s , this , version , value ) ; preconditions . check state ( this . last evaluated version . at most ( version ) , % s % s % s , this , version , value ) ; this . last evaluated version = version ; if ( is dirty ( ) & & get dirty building state ( ) . unchanged from last build ( value ) ) { if the value is the same as before , just use the old value . note that we don ' t use the new value , because preserving = = equality is even better than . equals ( ) equality . this . value = get dirty building state ( ) . get last build value ( ) ; } else { if this is a new value , or it has changed since the last build , set the version to the current graph version . this . last changed version = version ; this . value = value ; }
f = create function ( keyspace , int , int , create function % s ( k int , c int ) + called on null input + returns int + language java as return k + c ; ) ;
throw new illegal state exception ( multiple kvp parsers : + parser + , + candidate ) ;
storage type = shared ;
log . debug ( web socket upgrade filter is not operational - missing + native web socket configuration . class . get name ( ) ) ; chain . do filter ( request , response ) ; return ; }
add view ( centre background view , centre background view params ) ;
infer this type ( info ) ; if ( this type = = null ) { object type obj type = object type . cast ( type ) ; if ( obj type = null & & ( info = = null | | info . has type ( ) ) ) { this type = obj type ; } }
get url ( http : localhost : + get port ( ) + test bug36923 . jsp ) ;
preconditions . check not null ( message . get message ( ) , new object ( ) ) ;
set priority ( get priority ( ) + 1 ) ; log . info ( truncate table loader table : + table name + target count : + target count ) ;
exchange . set in ( get in ( ) . copy ( ) ) ; if ( has out ( ) ) { exchange . set out ( get out ( ) . copy ( ) ) ; } }
assert invalid message ( order by is only supported when the partition key is restricted by an eq or an in , select a , b , s , count ( b ) , count ( s ) from % s group by a order by b desc , c desc ) ;
if ( symbol . equals ( m ) ) return task type . map ;
final view view = get view by position ( mobile view current pos ) ; if ( view = null & & mobile view = null ) { float y = get view raw coords ( view ) [ 1 ] ; mobile view . animate ( ) . y ( y ) . set duration ( move _ duration ) . set listener ( new animator listener adapter ( ) { @ override public void on animation end ( animator animation ) { view . set visibility ( view . visible ) ; if ( mobile view = null ) { view group parent = ( view group ) mobile view . get parent ( ) ; parent . remove view ( mobile view ) ; mobile view = null ; } } } ) ; } dragging = false ;
return ( string [ ] ) result . to array ( new string [ result . size ( ) ] ) ;
if ( attribute . has split configuration transition ( ) ) { current transition = split ( current transition , ( split transition < build options > ) attribute . get split transition ( attribute map ) ) ; } else { iii . attributes determine configurations . the configuration of a prerequisite is determined by the attribute . current transition = compose transitions ( current transition , attribute . get configuration transition ( ) ) ; }
node grandparent = parent . get parent ( ) ;
string target name = str val . substring ( 1 ) ;
if ( size < 0 ) continue ; if ( input . remaining ( ) < size ) throw new marshal exception ( string . format ( not enough bytes to read % dth field % s , i , entry . get key ( ) ) ) ;
_ line height = get float property proportional height ( cssname . line _ height , 0 , ctx ) ; } else {
endpoint info info = new endpoint info ( ) ;
tests . put ( header , new uni vocity fixed width data format ( ) . set field lengths ( new int [ ] { 3 , 5 } ) . set headers ( new string [ ] { a , c } ) ) ;
production _ tab = production _ table ( ) ; action _ tab = action _ table ( ) ; reduce _ tab = reduce _ table ( ) ;
coordinate . set field index ( math . max ( coordinate . get field index ( ) - 1 , 0 ) ) ; if ( comment index > = 0 ) {
long long value = ( long ) s . create criteria ( human . class ) . set projection ( projections . row count ( ) ) . unique result ( ) ;
url builder . resize ( request . target width , request . target height ) ; new request . clear resize ( ) ;
system . arraycopy ( interfaces , interface index + 1 , interfaces , interface index , interfaces count - interface index - 1 ) ;
wrapper servlet = add servlet ( ctx , default , org . apache . catalina . servlets . default servlet ) ; servlet . set load on startup ( 1 ) ; servlet . set overridable ( true ) ;
list < path filter > filters = new array list < path filter > ( ) ; filters . add ( hidden file filter ) ; path filter job filter = get input path filter ( job ) ; if ( job filter = null ) { filters . add ( job filter ) ; } path filter input filter = new multi path filter ( filters ) ; list < file status > result = null ;
const utils . app _ secret _ base _ key = map utils . get string ( config map , cachecloud . app . secret . base . key , const utils . default _ app _ secret _ base _ key ) ;
if ( ( parent flow instanceof executable flow ) ) { out node ids = parent flow . get out nodes ( ) ; parent flow = parent flow . get parent flow ( ) ; }
joined rooms = multi user chat . get joined rooms ( get connection ( 1 ) , get full jid ( 0 ) ) ; assert false ( joined rooms should be empty , joined rooms . has next ( ) ) ; muc . join ( testbot ) ;
byte array = new byte array ( new byte [ ] { 0x00 , 0x00 , 0x00 , 0x00 , 0x31 } ) ;
robot rules = empty _ rules ;
remove symbol ( old prop ) ;
simple configurator . set context ( context ) ; simple configurator . do configure ( args [ 0 ] ) ;
prepare listeners ( post _ commit _ delete , listener array ) ;
assert null ( user . get auth data ( ) . get ( facebook ) ) ;
snap _ log . warn ( string . format ( failed to load % d of % d hashinator snapshot data files . , io errors , results [ 0 ] . get row count ( ) ) ) ; }
slice1 . seek ( test util . next long ( random ( ) , 0 , slice1 . length ( ) ) ) ;
if ( _ parms . _ mtries < 1 & & _ parms . _ mtries = - 1 & & _ parms . _ mtries = - 2 ) error ( _ mtries , mtries must be - 1 ( converted to sqrt ( features ) ) or - 2 ( all features ) or > = 1 but it is + _ parms . _ mtries ) ;
unicode property dump . dump properties ( 0x c5 , 0x c5 + 1 , true , out ) ;
if ( head = null ) { head . next = null ; head . prev = null ; } if ( tail = null ) { tail . next = null ; tail . prev = null ; }
sub menu sub = menu . get menu ( ) . find item ( r . id . add to playlist ) . get sub menu ( ) ;
m = ( method ) get declared method ( method name ) . return value ;
int [ ] array = { a , b } ; return array ;
string type = reader . next token ( ) . to string ( ) ; string sub type = * ;
sum + = long . parse long ( var name ) ;
if ( string utils . is not blank ( destination ) ) { result . set destination ( destination ) ; } return result ;
to result = processor . apply ( job , thread local state ) ;
for ( artifact artifact : flow elements container . get artifacts ( ) ) { if ( artifact instanceof association ) { handle association ( ( association ) artifact ) ; } else if ( artifact instanceof text annotation ) { handle text annotation ( ( text annotation ) artifact ) ; } handled artifacts . put ( artifact . get id ( ) , artifact ) ; }
scheduler . handle ( update event ) ;
if ( m ni notification = = null ) { m ni notification = new notification ( ) ; m ni notification . icon = com . android . internal . r . drawable . stat _ sys _ gps _ on ; * change notification icon here * m ni notification . when = 0 ; } if ( m play sounds ) { m ni notification . defaults | = notification . default _ sound ; } else { m ni notification . defaults & = notification . default _ sound ; }
vt = c . call procedure ( @ ad hoc , select a from + tb + where a > - 3 and a < - 2 order by a desc ) . get results ( ) [ 0 ] ;
sb . append ( ' - ' ) ; sb . append ( last code ) ; sb . append ( ' ' ) ; sb . append ( code ) ; in block = false ; } else {
support _ resources . copy file ( resources , null , jar name3 ) ; jar file jar file = new jar file ( new file ( resources , jar name3 ) ) ; assert not null ( should find manifest without verifying , jar file . get manifest ( ) ) ; jar file . close ( ) ; } catch ( exception e ) {
if ( cursor = null ) { cursor . close ( ) ; } return ; }
if ( array utils . contains ( nature ids , dbeaver nature . nature _ id ) ) { description . set nature ids ( array utils . remove ( string . class , nature ids , dbeaver nature . nature _ id ) ) ; project . set description ( description , new null progress monitor ( ) ) ; } } else {
byte [ ] u = new byte [ max length ] ; int i = 0 ;
count down latches [ count down latches . length - 1 ] . count down ( ) ;
knowledge base . add ( test _ key , test _ object _ 1 ) ;
try { realm . where ( null types . class ) . is null ( null types . field _ object _ null + . + null types . field _ float _ not _ null ) ; fail ( ) ; } catch ( illegal argument exception ignored ) { }
m audio handler . send message ( m audio handler . obtain message ( msg _ persist _ mediabuttonreceiver , 0 , 0 , null ) ) ; } else if ( old top = m rcstack . peek ( ) ) {
assert false ( p . is bucket finished ( new bucket id ( 32 , 1 < < 3 ) ) ) ;
int pos = st . length ;
m status bar height = m launcher . get drag layer ( ) . get insets ( ) . top ;
mutation [ ] cp mutations = mini batch op . get operations from coprocessors ( i - first index ) ; if ( cp mutations = = null ) { continue ; } mutation mutation = batch op . get mutation ( i ) ; boolean skip wal = get effective durability ( mutation . get durability ( ) ) = = durability . skip _ wal ;
final file dest = new file ( del , dest ) ; boolean result = file util . copy ( fs , src path , dest , false , conf ) ; assert true ( result ) ; assert true ( dest . exists ( ) ) ; assert equals ( content . get bytes ( ) . length + system . get property ( line . separator ) . get bytes ( ) . length , dest . length ( ) ) ; assert true ( src file . exists ( ) ) ; should not be deleted
mock class a old = weak set . remove ( a2 ) ;
if ( resulting collections = = null ) { return true ; } ast ast = infix expression . get ast ( ) ; astrewrite rewrite = astrewrite . create ( ast ) ;
file util . copy file ( new file ( src test data message1 . xml ) , new file ( target stream in message1 . xml ) ) ; assert mock endpoints satisfied ( ) ;
completable future < zoo keeper > zk future = zk client factory . create ( zk connect , session type . read write , ( int ) zk session timeout millis ) ; try { local zoo keeper = zk future . get ( zk session timeout millis , time unit . milliseconds ) ; local zoo keeper session watcher = new zoo keeper session watcher ( local zoo keeper , zk session timeout millis , shutdown service ) ; local zoo keeper session watcher . start ( ) ; local zoo keeper . register ( local zoo keeper session watcher ) ; } catch ( exception e ) { throw new ioexception ( failed to establish session with local zk , e ) ; }
for ( int i = 0 ; i < 2 ; i + + ) { mt [ i ] . shutdown ( ) ; zk [ i ] . close ( ) ; } for ( int i = 0 ; i < 2 ; i + + ) { assert . assert true ( waiting for server + i + being up , client base . wait for server down ( 127 . 0 . 0 . 1 : + old client ports [ i ] , connection _ timeout * 2 ) ) ; }
if ( ( cm . get radio state ( ) . is on ( ) ) | | ( cm . get radio state ( ) . is cdma ( ) ) ) {
dashboard workspace . click open in ide ws btn ( ) ; selenium web driver . switch from dashboard iframe to ide ( ) ; project explorer . wait project explorer ( ) ; project explorer . wait item ( project _ name ) ; project explorer . wait folder defined type of folder by path ( template . web _ java _ petclinic . value ( ) , project _ folder ) ; notifications popup panel . wait pop up panels is closed ( ) ;
test activiti event listener listener = ( test activiti event listener ) process engine configuration . get beans ( ) . get ( event listener ) ;
resource manager resource manager = new mock rm ( ) ; ( ( async dispatcher ) resource manager . get rmcontext ( ) . get dispatcher ( ) ) . start ( ) ; resource manager . get rmcontext ( ) . get state store ( ) . start ( ) ; resource manager . get rmcontext ( ) . get container token secret manager ( ) . roll master key ( ) ; final rmcritical thread uncaught exception handler ex handler = new rmcritical thread uncaught exception handler ( resource manager . get rmcontext ( ) ) ; final rmcritical thread uncaught exception handler spy rtehandler = spy ( ex handler ) ;
toggle doc outline button _ . set visible ( file type . can show scope tree ( ) ) ; if ( file type . can show scope tree ( ) ) { editor panel _ . set widget size ( doc outline widget _ , 0 ) ; toggle doc outline button _ . set latched ( false ) ; } toolbar _ . invalidate separators ( ) ;
atom . leaf atom ctts atom = stbl atom . get leaf atom of type ( atom . type _ ctts ) ;
session manager hs2 . shutdown ( ) ; hive conf hive conf = new hive conf ( ) ;
instructions . add ( reil helpers . create and ( base offset + + , bt , msb vara , bt , string . value of ( 1 ) , bt , msb vara ) ) ;
assert . assert null ( class loader . get parent ( ) ) ; assert . assert false ( class loader instanceof application class loader ) ; assert . assert true ( class loader instanceof urlclass loader ) ; final class loader app loader = hadoop druid converter config . class . get class loader ( ) ; assert . assert not equals ( string utils . format ( class loader [ % s ] is not isolated , class loader ) , app loader , class loader ) ; }
string first component = cname . get ( 0 ) ; object ctx = null ; if ( first component . equals ( ) ) ctx = this ; else { binding binding = get binding ( first component ) ; if ( binding = = null ) throw new name not found exception ( first component + is not bound ) ; ctx = binding . get object ( ) ; if ( ctx instanceof reference ) { deference the object if ( _ _ log . is debug enabled ( ) ) _ _ log . debug ( object bound at + first component + is a reference ) ; try { ctx = naming manager . get object instance ( ctx , get name parser ( ) . parse ( first component ) , this , _ env ) ; } catch ( naming exception e ) { throw e ; } catch ( exception e ) { _ _ log . warn ( , e ) ; throw new naming exception ( e . get message ( ) ) ; } } }
ctx . begin path ( ) ;
int alt46 = 2 ;
container container = get parent container from child ( oname ) ;
final dbsentity table = viewer . get model ( ) . get single source ( ) ;
cache0 . put ( new magic key ( cache ( 1 ) , cache ( 2 ) ) , not - local ) ; cache0 . put ( new magic key ( cache ( 0 ) , cache ( 1 ) ) , local ) ; check point iterator cp = new check point ( ) ;
if ( get count ( ) > 0 & & m position data . size ( ) > 0 ) { on column sync ( ) ; } request layout ( ) ;
request . headers ( ) . set ( http header names . content _ type . to string ( ) , content type ) ; log . trace ( content - type : { } , content type ) ; }
thread . sleep ( 1000 ) ; template . request body and header ( server uri , hello world , exchange . http _ query , one = uno & two = dos ) ;
message sender . send message ( new complete message ( ) ) ; complete sent = true ; state ( state . wait _ complete ) ; } }
versioned < byte [ ] > v3 conflict late = new versioned < byte [ ] > ( value , vc1 ) ; n0store . add ( pair . create ( k3 , v3 conflict late ) ) ; n1store . add ( pair . create ( k3 , v3 conflict late ) ) ; n2store . add ( pair . create ( k3 , v3 conflict late ) ) ; n3store . add ( pair . create ( k3 , v3 conflict late ) ) ;
test query ( select count ( distinct trim ( both ' ' from dim1 ) ) from druid . foo where trim ( dim1 ) < > ' ' , immutable list . of ( druids . new timeseries query builder ( ) . data source ( calcite tests . datasource1 ) . intervals ( qss ( filtration . eternity ( ) ) ) . filters ( not ( selector ( dim1 , , null ) ) ) . granularity ( granularities . all ) . virtual columns ( expression _ virtual _ column ( a0 : v , trim ( \ dim1 \ , ' ' ) , value type . string ) ) . filters ( expression _ filter ( ( trim ( \ dim1 \ , ' ' ) = ' ' ) ) ) . aggregators ( aggs ( new cardinality aggregator factory ( a0 , null , dims ( new default dimension spec ( a0 : v , a0 : v , value type . string ) ) , false , true ) ) ) . context ( timeseries _ context _ default ) . build ( ) ) , immutable list . of ( new object [ ] { 5 l } ) ) ;
jsonobject cache = get cache data for blog ( site . get site id ( ) , current date ) ;
int index to check = m _ simple config . m _ target header . attribute ( m _ instances . attribute ( i ) . name ( ) ) . index ( ) ; boolean ok = true ;
this . zk server set = dlzk server set . of ( uri , 60000 ) ;
byte b = din . read byte ( ) ; if ( b = 19 ) throw new ioexception ( handshake failure , expected 19 , got + ( b & 0xff ) + on + sock ) ; byte [ ] bs = new byte [ 19 ] ;
string rcbs applicability str = element . get attribute ( iresource configuration . rcbs _ applicability ) ;
string storage string = journal . get journal storage ( ) . to colon separated string ( ) ; system . err . println ( storage string : + storage string ) ; journal . close ( ) ; close to unlock the storage dir
assert that ( jorphan utils . split ( , , a , bc , , , false ) , core matchers . equal to ( new string [ ] { , , a , bc } ) ) ; }
if ( dis . read ( buf ) = = - 1 ) { break ; }
zk cache . get zoo keeper ( ) . delete ( service unit zk utils . path ( test bundle ) , - 1 ) ;
if ( atlas proguard constants . any _ class _ member _ keyword . equals ( next word ) ) { check field access flags ( required set member access flags , required unset member access flags ) ; check method access flags ( required set member access flags , required unset member access flags ) ; class specification . add field ( new member specification ( required set member access flags , required unset member access flags , annotation type , null , null ) ) ; class specification . add method ( new member specification ( required set member access flags , required unset member access flags , annotation type , null , null ) ) ; } else if ( atlas proguard constants . any _ field _ keyword . equals ( next word ) ) { check field access flags ( required set member access flags , required unset member access flags ) ; class specification . add field ( new member specification ( required set member access flags , required unset member access flags , annotation type , null , null ) ) ; } else if ( atlas proguard constants . any _ method _ keyword . equals ( next word ) ) { check method access flags ( required set member access flags , required unset member access flags ) ; class specification . add method ( new member specification ( required set member access flags , required unset member access flags , annotation type , null , null ) ) ; }
partition matching partition = hive . get partition ( index table , part spec , false ) ;
pos inc att . set position increment ( final pos inc ) ;
verify ( response , times ( 0 ) ) . set status ( http servlet response . sc _ service _ unavailable ) ;
string error code = parse error code ( node ) ; if ( error code = = null | | error code . equals ( duplicate certificate ) ) return null ; duplicate certificate exception e = ( duplicate certificate exception ) super . unmarshall ( node ) ;
assert true ( expression util . is null rejecting expression ( expr9 , t ) ) ;
list < serialized page reference > serialized page references = pages . stream ( ) . map ( page split - > new serialized page reference ( page split , 1 , ( ) - > memory manager . update memory usage ( - page split . get retained size in bytes ( ) ) ) ) . collect ( to immutable list ( ) ) ;
req = new read input discretes request ( ref , count ) ; req . set unit id ( unitid ) ; req . set headless ( ) ; if ( modbus . debug ) { system . out . println ( request : + req . get hex message ( ) ) ; }
throw new backend exception ( ( hcat fs . get name ( ) = = null ? : hcat fs . get name ( ) + . ) + e . get message ( ) , e ) ;
word . set length ( j + 1 ) ; word . append ( ation ) ; k = old _ k ;
db = good ddlagainst simple schema ( create table pkey _ integer ( pkey integer not null , descr varchar ( 128 ) , primary key ( pkey ) ) ; + partition table pkey _ integer on column pkey ; + cre ate pr oc ed ur e fr om clas s org . voltdb . compiler . procedures . add book ; + create procedure from class org . voltdb . compiler . procedures . not annotated add book ; + drop procedure org . voltdb . compiler . procedures . add book ; ) ;
handshake timeout . cancel ( ) ;
query = select lhs . a , lhs . c , rhs . a , rhs . c + from p1 lhs full join p1 rhs + on lhs . a + join op + rhs . a and + lhs . a = 1 and rhs . c = 1 + order by 1 , 2 , 3 , 4 ;
throw new org . apache . axis2 . databinding . adbexception ( product description cannot be null ) ;
test listener notify later ( 2 ) ; }
assert . assert true ( resp . get content as string ( ) . matches ( 312 \ \ . . * ) ) ;
method visitor mv = class visitor . visit method ( context . access , context . name , context . desc , signature , exceptions ) ; if ( mv = = null ) { return u ; }
abstract floating view . close all open views ( this , already on home ) ;
storage = nd4j . create ( shape , ordering ) ;
base . default file menu = file menu ;
it = admin client . bulk fetch ops . fetch entries ( 1 , system store constants . system store name . voldsys _ client _ registry . name ( ) , empty partition list , null , false ) ; info list = get client registry content ( it ) ; assert true ( client registry not updated . , info list . get ( 0 ) . get bootstrap time ( ) < info list . get ( 0 ) . get update time ( ) ) ; assert true ( client config received from the client registry system store is incorrect . , is config equal ( info list . get ( 0 ) . get client config ( ) , client config ) ) ;
class definition page projection output definition = define page project output class ( result . get rewritten expression ( ) , call site binder , class name suffix ) ; class < ? extends page projection output > page projection output class ; try { page projection output class = define class ( page projection output definition , page projection output . class , call site binder . get bindings ( ) , get class ( ) . get class loader ( ) ) ; } catch ( exception e ) { throw new presto exception ( compiler _ error , e ) ; } return ( ) - > new generated page projection ( result . get rewritten expression ( ) , determinism evaluator . is deterministic ( result . get rewritten expression ( ) ) , result . get input channels ( ) , constructor method handle ( page projection output class , block builder . class , connector session . class , driver yield signal . class , page . class , selected positions . class ) ) ;
assert equals ( java + + logfile + + logback + + log4j + + jvm opts + + jm jvm opts + + krb5 + jvm opts + jvmmem + + main class + + args + + redirects , cluster descriptor . setup application master container ( main class , true , true , true , job manager memory ) . get commands ( ) . get ( 0 ) ) ;
job . set ( table _ props , new stringable map ( tblproperties ) . to string ( ) ) ; }
batch = wait for next events ( eis ) ;
super . do stop ( ) ; }
try { t configuration = get configuration ( ) ; endpoint helper . set reference properties ( get camel context ( ) , configuration , options ) ; endpoint helper . set properties ( get camel context ( ) , configuration , options ) ; } catch ( exception e ) { throw new illegal argument exception ( e ) ; }
entry = new zip entry ( jar file . manifest _ name ) ;
assert . assert equals ( 5 , f . vec ( 2 ) . at8 ( 3 ) ) ; assert . assert equals ( 5 , f . vec ( 2 ) . na cnt ( ) ) ; assert . assert equals ( e , string . value of ( f . vec ( 3 ) . at str ( new buffered string ( ) , 3 ) ) ) ; assert . assert equals ( 5 , f . vec ( 3 ) . na cnt ( ) ) ; } finally {
if ( time in nano = = 0 ) return na n ki b s ; long rate = ( long ) ( ( ( double ) bytes time in nano ) * 1000 * 1000 * 1000 ) ;
service discovery manager . get instance for ( connection ) . add feature ( namespace ) ;
configuration conf = new hdfs configuration ( ) ;
ctxt . generate java source ( org . apache . jasper . tagplugins . jstl . util . import response wrapper + irw name + = new org . apache . jasper . tagplugins . jstl . util . import response wrapper ( ( http servlet response ) page context . get response ( ) ) ; ) ;
int offset = 0 ; while ( offset < value . length ( ) ) { final int unicode char = value . code point at ( offset ) ; if ( character . is isocontrol ( unicode char ) ) { throw failure ( string . format ( % s cannot contain iso control character ' \ \ u % 04x ' . , name , unicode char ) ) ; } if ( ' \ \ ' = = unicode char | | ( ' ' = = unicode char & & allow slash ) ) { throw failure ( string . format ( % s cannot contain ' % c ' . , name , ( char ) unicode char ) ) ; } offset + = character . char count ( unicode char ) ; } return type . cast ( this ) ;
web socket frame actual = capture . get frames ( ) . poll ( ) ;
execute ( delete from % s where a = ? and b = ? and c = ? , 1 , 1 , 0 ) ;
timestamped value . of ( 14 , new instant ( 60 ) ) ) ; dropped elements = container . get counter ( metric name . named ( reduce fn runner . class , reduce fn runner . dropped _ due _ to _ closed _ window ) ) . get cumulative ( ) . long value ( ) ; assert equals ( 1 , dropped elements ) ; tester . advance input watermark ( new instant ( 130 ) ) ;
request = create request ( foo bar ) ; response = new mock http servlet response ( ) ; chain = new mock filter chain ( ) ; request . add header ( authorization , basic + new string ( base64 . encode bytes ( ( test user name + : wrongpass ) . get bytes ( ) ) ) ) ;
features in tile = get features for tile ( data dir , tile ) ;
boolean caught exception = false ; try { stream . write ( input [ 0 ] ) ; } catch ( exception e ) { caught exception = true ; }
assert equals ( 1 , history service . create historic task instance query ( ) . process definition id ( finished instance . get process definition id ( ) ) . count ( ) ) ; assert equals ( 0 , history service . create historic task instance query ( ) . process definition id ( unexistingdefinitionid ) . count ( ) ) ;
if ( simulation start time > 0 ) { process ( item ) ; total simulation time = system . current time millis ( ) - get simulation start time ( ) ; }
env . kafka client ( ) . prepare response ( new create acls response ( 0 , as list ( new acl creation response ( api error . none ) , new acl creation response ( api error . none ) ) ) ) ; create acls result results = env . admin client ( ) . create acls ( as list ( acl1 , acl2 ) ) ; assert collection is ( results . values ( ) . key set ( ) , acl1 , acl2 ) ; for ( kafka future < void > future : results . values ( ) . values ( ) ) future . get ( ) ; results . all ( ) . get ( ) ;
continue ; } if ( runnable . is alive ( ) & & runnable . get id ( ) = exclude id & & temp file path . equals ( runnable . get temp file path ( ) ) ) { return runnable . get id ( ) ; } }
calc follow list ( ( ( cmbin op ) node cur ) . get left ( ) ) ; calc follow list ( ( ( cmbin op ) node cur ) . get right ( ) ) ;
return fbx null attribute . class ; } else if ( subclass name . equals ( limb node ) ) {
loader = new application class loader ( client classpath , get class ( ) . get class loader ( ) , system classes list ) ;
label label = ( label ) container . get children ( ) . get ( 0 ) ;
last idx = idx ;
meta class . invoke method ( object , main , null ) ;
thumb . image = general utils . generate circular bitmap ( thumb . image ) ;
float radius = dp2px ( m corner radius ) ;
properties startup props = server container . process command line args ( args ) ; bootstrap server config config = new bootstrap server config ( ) ;
in . mark ( 9999 ) ; while ( true ) { int next char = in . read ( ) ; if ( next char = = - 1 ) { trailing = true ; break ; } else if ( next char = = ' ' ) { continue ; } else if ( next char = = ' \ \ ' ) { int following char = in . read ( ) ; if ( following char = ' ' ) { trailing = false ; break ; } } else { trailing = false ; break ; } } in . reset ( ) ;
v doc a _ version = v doc a _ db1 . get version ( ) ;
mockito . verify ( committer , mockito . timeout ( 2000 ) . times ( 1 ) ) . abort job ( ( job context ) mockito . any ( ) , ( state ) mockito . any ( ) ) ; assert job state ( job , job state internal . failed ) ; dispatcher . stop ( ) ;
assert null ( mapper . convert value ( null , integer . class ) ) ; assert null ( mapper . convert value ( null , string . class ) ) ; assert null ( mapper . convert value ( null , byte [ ] . class ) ) ; }
final named cache . lrunode head = cache . head ( ) ;
lock . release ( ) ; resuming thread . join ( ) ; }
client . call procedure ( r1 . insert , 10 , 100 , 1 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r1 . insert , 100 , 1000 , 2 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r1 . insert , 300 , 3000 , 3 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r2 . insert , 100 , null , 2 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r2 . insert , 101 , null , 2 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r2 . insert , 102 , 1001 , 2 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r2 . insert , 103 , 1003 , 2 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r2 . insert , 104 , 1000 , 2 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; client . call procedure ( r2 . insert , 105 , 1000 , 2 , 2013 - 07 - 18 02 : 00 : 00 . 123457 ) ; string sql ;
local copy source if unmodified since tracker = true ; } else {
css = css . replace all ( [ ^ \ \ } ] + \ \ { ; \ \ } , ) ; if ( linebreakpos > = 0 ) { some source control tools don ' t like it when files containing lines longer than , say 8000 characters , are checked in . the linebreak option is used in that case to split long lines after a specific column . int i = 0 ; int linestartpos = 0 ; sb = new string buffer ( css ) ; while ( i < sb . length ( ) ) { final char c = sb . char at ( i + + ) ; if ( c = = ' } ' & & i - linestartpos > linebreakpos ) { sb . insert ( i , ' \ n ' ) ; linestartpos = i ; } } css = sb . to string ( ) ; }
final model node operation = create describe operation ( ) ; final model node result = services a . execute operation ( operation ) ; assert . assert true ( the subsystem describe operation has to generate a list of operations to recreate the subsystem , result . has defined ( model description constants . failure _ description ) ) ; final list < model node > operations = result . get ( model description constants . result ) . as list ( ) ; services a . shutdown ( ) ; final kernel services services c = create kernel services builder ( create additional initialization ( ) ) . set boot operations ( operations ) . build ( ) ;
int j = 0 ; string results [ ] = new string [ welcome files . length - 1 ] ; for ( int i = 0 ; i < welcome files . length ; i + + ) { if ( i = n ) results [ j + + ] = welcome files [ i ] ; } welcome files = results ; }
server connector http = new server connector ( server , new http connection factory ( http config ) ) ; http . set port ( redirect port ) ; server . add connector ( http ) ; server . start ( ) ; }
list < mutable host > full hosts in order = eligible hosts . values ( ) . stream ( ) . filter ( h - > h . free space ( ) = = 0 ) full hosts . filter ( h - > h . target site count > 0 ) not slotless hosts . sorted ( ( h1 , h2 ) - > compute hadistance ( starter host . ha group . token , h1 . ha group . token ) - compute hadistance ( starter host . ha group . token , h2 . ha group . token )
conn . close ( ) ; try { meta . get user name ( ) ; fail ( sqlexception not thrown ) ; } catch ( sqlexception e ) { ok }
return property . ordinal ( ) ;
string view name = get views folder ( module name ) . concat ( ctx . get controller path ( ) ) . concat ( ) . concat ( controller metadata . get details path as string ( ) ) . concat ( list delete modal batch ) . concat ( get views extension ( ) ) ; entity item entity item = create entity item ( entity metadata , ctx , table _ suffix ) ;
frontend request received request = request1 . get value ( ) ;
return new build target ( target os . linux , false , new string [ ] { * * * . c } , new string [ 0 ] , new string [ ] { * * * . cpp } , new string [ 0 ] , new string [ 0 ] , , - c - wall - o2 - mfpmath = sse - msse - fmessage - length = 0 - m32 - f pic , - c - wall - o2 - mfpmath = sse - msse - fmessage - length = 0 - m32 - f pic , - shared - m32 ) ;
verify ( topic , times ( 1 ) ) . post ( message ) ; }
throw new ioexception ( permissions error : make sure that + app data roaming + or + app data local + is writable . ) ;
block location [ ] locations = fs . get file block locations ( part status , hstatus . get start index ( ) + start , len ) ; return fix block locations ( locations , start , len , hstatus . get start index ( ) ) ; }
return get current bucket ( ) ;
ret . put ( new pair < > ( key . get doctype ( ) , e . get value ( ) ) , key . get in document ( ) ) ;
final default entitlement bp entitlement = create base entitlement and check for completion ( account . get id ( ) , external key , product name , product category . base , term , next event . create , next event . block , next event . invoice ) ; assert not null ( bp entitlement ) ; assert equals ( invoice user api . get invoices by account ( account . get id ( ) , false , call context ) . size ( ) , 1 ) ; assert equals ( bp entitlement . get subscription base ( ) . get current plan ( ) . get recurring billing period ( ) , billing period . annual ) ;
wait for pages ( operator , 1 ) ;
int mode = get arg0 ( 0 ) ;
final stateful session component instance stateful component instance = ( stateful session component instance ) context . get private data ( component instance . class ) ;
assert equals ( wrapped name , wrapped dim . get description ( ) . to string ( ) ) ;
if ( block = = 0 ) { return ( w & ( 1 < < bit ) ) = 0 ; } block - - ; break ; case 0x00000000 : zero sequence if ( simulate wah ) { if ( block = = 0 & & ( ( w > > 25 ) - 1 ) = = bit ) { return true ; } }
file status status of s1 = hdfs . get file status ( new path ( sub , hdfs constants . dot _ snapshot _ dir + s1 ) ) ; assert equals ( user1 , status of s1 . get owner ( ) ) ; assert equals ( group1 , status of s1 . get group ( ) ) ; }
assert . assert true ( idle latch . await ( 5 , time unit . seconds ) ) ;
if ( transaction = = null ) { throw new illegal argument exception ( transaction should not be null ) ; }
return assign multiple enabled & & ( max assign per heartbeat = = - 1 | | assigned containers < max assign per heartbeat ) ;
return search mapped by key ( referenced class , collection value ) ; }
assert that ( new entry . state ) . is equal to ( evaluation state . built ) ;
uploaded resource . delete ( ) ;
assert true ( fs . exists ( mp5 path ) ) ; assert false ( fs . exists ( new path ( mpart4 . get sd ( ) . get location ( ) ) ) ) ;
byte prev flag = nul ; if ( entry start > 1 ) { prev flag = mmap . get ( entry start - 2 ) ; } if ( prev flag = removed ) {
long [ ] exp tswid0 = new long [ ] { 12345 , 12346 } ; long [ ] act tswid0 = ss . get all update times ( sid0 , tid0 , wid0 ) ; assert array equals ( exp tswid0 , act tswid0 ) ; long [ ] exp tswid1 = new long [ ] { 12345 } ;
track . on chang video quality end ( m activity ) ; if ( track . m is changing language ) { track . m is changing language = false ; } }
twitter exception twitter exception = ( twitter exception ) throwable ;
secret key secret key = encryption . generate secret key ( ) ;
file download service proxy . get connection listener ( ) . on connected ( this ) ; }
if ( ch > = 128 ) break ;
text paint . set color ( context . get resources ( ) . get color ( r . color . white ) ) ; } else {
scan = new scan ( rows [ 3 ] ) ; result = get single scan result ( ht , scan ) ; assert null result ( result ) ; scan = new scan ( rows [ 0 ] , rows [ 2 ] ) ; result = get single scan result ( ht , scan ) ; assert null result ( result ) ;
string fname = frame splitter test1 . hex ;
assert null ( interpreter factory . get interpreter ( user1 , note1 , ) ) ; interpreter setting manager . set interpreter binding ( user1 , note1 , interpreter setting manager . get setting ids ( ) ) ;
if ( is statement block ( parent ) & & can merge ) { node previous = block ; while ( block . has children ( ) ) { node child = block . remove first child ( ) ; parent . add child after ( child , previous ) ; previous = child ; } parent . remove child ( block ) ; return true ; } else { return false ; }
if ( cookie data codec . safe equals ( sign , crypto . sign hmac sha1 ( payload ) ) ) { payload = encryption . decrypt ( payload ) ; cookie data codec . decode ( data , payload ) ; }
assert that ( security context holder . get context ( ) ) . is same as ( ctx ) ;
hdfs . rename snapshot ( sub1 , s22 , s0 ) ;
node = unit ; } new node . set javadoc ( ( javadoc ) get associated java doc ( node , pkg ) ) ; }
path to snapshots map . get ( snapshot path ) . remove ( snapshot old name ) ;
try { new settings module ( settings . empty , setting . simple string ( foo . bar ) ) ; fail ( no scope should fail ) ; } catch ( illegal argument exception e ) { assert that ( e . get message ( ) , contains string ( no scope found for setting ) ) ; }
if ( ( horizon = = 0 ) | | ( search limit = horizon limit ) ) need input = true ; return null ; }
map < string , object > mapping = merge template mapping ( index template meta data , new mappings ) ;
int length = this . element changed listeners . length ; ielement changed listener [ ] new listeners = new ielement changed listener [ length ] ; system . arraycopy ( this . element changed listeners , 0 , new listeners , 0 , i ) ; int [ ] new masks = new int [ length ] ; system . arraycopy ( this . element changed listener masks , 0 , new masks , 0 , i ) ;
do return ( true ) . when ( parent ) . accept ( any ( resource . class ) , any ( resource commit request . class ) ) ; do nothing ( ) . when ( parent ) . apply ( any ( resource . class ) , any ( resource commit request . class ) ) ; return queue ;
for ( int i = 0 ; i < items _ to _ load ; i + + ) { resource resource = new url resource ( url ) { @ override public boolean equals ( object obj ) { return ( obj = = this ) ; } @ override public int hash code ( ) { return system . identity hash code ( this ) ; } } ; metadata reader reader = mrf . get metadata reader ( resource ) ; assert that ( reader , not null value ( ) ) ; }
string protocol qualifer = have insecure mirror ? https : ; set text ( choose + protocol qualifer + cran mirror ) ;
int line = slide navigation _ . get items ( ) . get ( index ) . get line ( ) ;
if ( process tree . is setsid available ) { string child pid = utils for tests . get pid from pid file ( script dir name + child pid file + 0 ) ; while ( child pid = = null ) { log . warn ( script dir name + child pid file + 0 + is null ; sleeping . . . ) ; try { thread . sleep ( 500 ) ; } catch ( interrupted exception ie ) { log . warn ( sleep is interrupted : + ie ) ; break ; } child pid = utils for tests . get pid from pid file ( script dir name + child pid file + 0 ) ; } as child pid file0 ( leaf process in the subtree of processes with map task as root ) is created , all other child pid files should have been created already ( see the script for details ) . now check if the descendants of map task are alive . for ( int i = 0 ; i < = num levels of sub processes ; i + + ) { child pid = utils for tests . get pid from pid file ( script dir name + child pid file + i ) ; log . info ( pid of the descendant process at level + i + in the subtree of processes ( with the map task as the root ) + is + child pid ) ; assert true ( unexpected : the subprocess at level + i + in the subtree is not alive before job completion , is alive ( child pid ) ) ; } } return job ;
this . application context . add application listener ( ( application listener < ? > ) bean ) ;
memory records builder builder = memory records . builder ( byte buffer . allocate ( 1024 ) , compression type . none , timestamp type . create _ time , 0 l ) ; for ( int v = 0 ; v < 3 ; v + + ) builder . append with offset ( v , record batch . no _ timestamp , key . get bytes ( ) , ( value - + v ) . get bytes ( ) ) ; fetch records ( tp0 , builder . build ( ) , errors . none , 200 l , 0 ) ; assert equals ( 197 , records fetch lag max . value ( ) , epsilon ) ; assert equals ( 197 , partition lag . value ( ) , epsilon ) ;
accumulo store . update configuration ( conf , derived operation , user ) ;
list < string > configs = new array list < string > ( ) ; configs . add ( this . hadoop ver ) ; deque < string > stack = new linked list < string > ( ) ;
final executor current parent = dead lock checker . get ( ) ;
check one term ( a , μέσον , μεσον ) ;
services . set need refresh ( ) ;
component description . get configurators ( ) . add ( new ejb jacc configurator ( ) ) ;
count down latch consumers latch = new count down latch ( streams . size ( ) ) ; for ( final kafka stream stream : streams ) { system . out . println ( creating consumer for + topic ) ; export consumer consumer = new export consumer ( stream , false , skinny , consumers latch ) ; executor . submit ( consumer ) ; } map < string , integer > topic count map2 = new hash map < > ( ) ;
throw new comparison failure ( null , expected . to string ( ) , actual . to string ( ) ) ;
current long | = 1 l < < doc ;
assert equals ( 3 , test helpers . filter native registers ( interpreter . get defined registers ( ) ) . size ( ) ) ; assert equals ( big integer . value of ( 0x12345678 l ) , interpreter . get variable value ( v1 ) ) ; assert equals ( big integer . value of ( 0x12345678 l ) , interpreter . get variable value ( hi ) ) ; assert equals ( big integer . zero , big integer . value of ( interpreter . get memory size ( ) ) ) ;
conn = send request ( server , get , db _ design design _ view view , headers , null ) ;
final string loaded master coprocessors verify = [ + master coprocessor . get simple name ( ) + ] ;
int min cost [ ] = new int [ words . length ] ; int result [ ] = new int [ words . length ] ; for ( int i = words . length - 1 ; i > = 0 ; i - - ) { min cost [ i ] = cost [ i ] [ words . length - 1 ] ; result [ i ] = words . length ; for ( int j = words . length - 1 ; j > i ; j - - ) { if ( cost [ i ] [ j - 1 ] = = integer . max _ value ) { continue ; } if ( min cost [ i ] > min cost [ j ] + cost [ i ] [ j - 1 ] ) { min cost [ i ] = min cost [ j ] + cost [ i ] [ j - 1 ] ; result [ i ] = j ; } } } int i = 0 ; int j ; system . out . println ( minimum cost is + min cost [ 0 ] ) ;
consumer configuration consumer config = new consumer configuration ( ) ; consumer config . set receiver queue size ( 7 ) ; consumer config . set subscription type ( subscription type . failover ) ; consumer config . set ack timeout ( ack time out millis , time unit . milliseconds ) ; consumer config . set consumer name ( consumer - 1 ) ; consumer consumer1 = pulsar client . subscribe ( topic name , subscription name , consumer config ) ; consumer config . set consumer name ( consumer - 2 ) ; consumer consumer2 = pulsar client . subscribe ( topic name , subscription name , consumer config ) ;
encrypted data copy [ 0 ] = ( byte ) 6 ;
assert equals ( new expected content , zip source file . get code ( ) ) ;
do in jpa ( this : : entity manager factory , entity manager - > { list < account > accounts = entity manager . create query ( select a from account a , account . class ) . get result list ( ) ; assert equals ( 2 , accounts . size ( ) ) ; } ) ;
meta . put ( new put ( bytes . to bytes ( table name + , , 1361911384013 . 810e28f59a57da91c66 ) ) . add column ( hconstants . catalog _ family , hconstants . server _ qualifier , bytes . to bytes ( node1 : 60020 ) ) ) ; meta . put ( new put ( bytes . to bytes ( table name + , , 1361911384013 . 810e28f59a57da91c66 ) ) . add column ( hconstants . catalog _ family , hconstants . startcode _ qualifier , bytes . to bytes ( 1362150791183 l ) ) ) ; meta . close ( ) ; hbase fsck hbck = do fsck ( conf , false ) ;
return evaluated queries rect ; }
string [ ] method signature = { @ java . lang . override , @ java . lang . override , public string to string ( ) { , } ;
final int n = 17 ;
assert that ( m session detail model . get tag metadata ( ) , not ( null value ( ) ) ) ; assert that ( success , is ( true ) ) ; }
list < received deleted block info > rdbi list = new array list < > ( ) ;
get instrumentation ( ) . get ui automation ( ) . execute shell command ( pm grant + package name + manifest . permission . write _ external _ storage ) ;
assert equals ( new block ( blocks [ i ] ) , blk ) ; i + + ; }
incr backup file list = filter missing files ( incr backup file list ) ;
input buffer . put ( received byte ) ;
} else { for ( int i = 0 ; i < 16 ; i + + ) { stmt . set string ( i + 4 , null ) ; } } stmt . execute ( ) ; dbutils . close stmt ( stmt ) ; } } catch ( exception e ) {
try { rsmd . is searchable ( 0 ) ; fail ( sqlexception is not thrown ) ; } catch ( sqlexception e ) { expected }
this . inputs . put ( spout . get comp ( ) . get name ( ) , new linked list < topology api . input stream > ( ) ) ;
map < string , load balancer strategy factory < ? extends load balancer strategy > > load balancer strategy factories = new hash map < > ( ) ; map < string , transport client factory > client factories = new hash map < > ( ) ; load balancer strategy factories . put ( degrader , new degrader load balancer strategy factory v3 ( null , null , event emitter ) ) ;
tx = db . begin tx ( ) ;
system . arraycopy ( current chunk , current chunk read pos , buf , offset , length ) ; current chunk read pos + = length ; return length ;
if ( table name = = null ) { if ( column name . equals ( select alias ) ) { found names . add ( new select list alias resolution ( columns [ i ] , select table alias , select column name , select alias , i ) ) ; if ( first found expr = = null ) { first found expr = columns [ i ] ; } } }
set eager check completion ( true ) ; return this ; }
color highlight shadow = get display ( ) . get system color ( swt . color _ widget _ highlight _ shadow ) ; color normal shadow = get display ( ) . get system color ( swt . color _ widget _ normal _ shadow ) ; gc . set foreground ( highlight shadow ) ; gc . draw line ( sash loc [ x _ index ] , sash loc [ y _ index ] + sash loc [ height _ index ] , sash loc [ x _ index ] , sash loc [ y _ index ] ) ; gc . draw line ( sash loc [ x _ index ] , sash loc [ y _ index ] , sash loc [ x _ index ] + sash loc [ width _ index ] , sash loc [ y _ index ] ) ; gc . set foreground ( normal shadow ) ;
assert equals ( key extracting mapper . class , key extractor . get user code wrapper ( ) . get user code class ( ) ) ; assert true ( key extractor . get input ( ) instanceof generic data source base < ? , ? > ) ;
if ( state . has tx state with changes ( ) ) { if ( check index state ( descriptor , state . tx state ( ) . index diff sets by label ( descriptor . schema ( ) . get label id ( ) ) ) ) { return population progress . none ; } } return store layer . index get population progress ( descriptor . schema ( ) ) ;
final inode file file node = cluster . get namesystem ( ) . get fsdirectory ( ) . get inode4 write ( file path . to string ( ) ) . as file ( ) ; assert false ( file node . is under construction ( ) ) ; assert true ( file node . is striped ( ) ) ; block info [ ] blocks = file node . get blocks ( ) ; assert equals ( num blocks , blocks . length ) ; for ( block info blk : blocks ) { assert true ( blk . is striped ( ) ) ; assert true ( blk . is complete ( ) ) ; assert equals ( cell size * data blocks , blk . get num bytes ( ) ) ; final block info striped sb = ( block info striped ) blk ; assert equals ( group size , sb . num nodes ( ) ) ; } final block manager bm = cluster . get namesystem ( ) . get block manager ( ) ;
chmod ( 300 , a ) ;
int pos = ( ( integer ) other properties [ 0 ] ) . int value ( ) ; assert equals ( did not get correct position reported in error , pos , ex . get position ( ) ) ; if ( other properties . length > 1 ) {
string initial string = url string ; for ( int k = 0 ; k < loop count ; k + + ) { for ( int i = 0 ; i < this . normalizers . length ; i + + ) { if ( url string = = null ) return null ; url string = this . normalizers [ i ] . normalize ( url string , scope ) ; } if ( initial string . equals ( url string ) ) break ; initial string = url string ; } return url string ;
if ( node util . constructor call has side effects ( node ) ) { return true ; } accumulator . keep sub tree ( node ) ; return false ; }
file utils . write ( new file ( tmp conf dir , configsetprops . json ) , new string builder ( { \ immutable \ : \ true \ } ) , standard charsets . utf _ 8 ) ; system . set property ( managed . schema . mutable , true ) ; create jetty and harness ( tmp solr home . get absolute path ( ) , solrconfig - schemaless . xml , schema - rest . xml , solr , true , null ) ; }
configuration conf = configuration factory . parse configuration ( default cache manager factory . class . get resource ( test - ehcache . xml ) ) ; assert not null ( conf ) ; conf . set name ( other cache ) ; cache manager other = cache manager . create ( conf ) ; assert equals ( status . status _ alive , other . get status ( ) ) ;
if ( this . aggregators . contains key ( operator key ) ) { continue ; } this . operator conversions . put if absent ( operator key , operator conversion ) ;
int last slash = path . last index of ( ' ' ) ;
assert print ( var x = ' \ \ 2400 ' ; , var x = \ \ \ u00a00 \ ) ;
binary . binary inputs ( task . get outputs ( ) . get files ( ) . get as file tree ( ) . matching ( new pattern set ( ) . include ( * * * . obj , * * * . o ) ) ) ; pre compiled header pch = binary . get prefix file to pch ( ) . get ( source set . get prefix header file ( ) ) ;
check dirty tracking ( bob , rate , oca ) ;
scheduler . job completed ( job ) ;
if ( status = = null ) return ; status = create apiviolation status ( sort ) ;
task task = mock ( task . class ) ; when ( task . get produced partitions ( ) ) . then return ( result partitions ) ; when ( task . get all writers ( ) ) . then return ( result partition writers ) ; when ( task . get all input gates ( ) ) . then return ( input gates ) ; network . register task ( task ) ; assert equals ( integer . max _ value , rp1 . get buffer pool ( ) . get max number of memory segments ( ) ) ;
stack = stack . copy ( ) ;
placement monitor . check file ( src fs , src status , parity fs , har index . part file path ( entry ) , entry , codec , policy ) ;
int younger = peoples . stream ( ) . filter ( ( p ) - > p . get name ( ) . contains ( e ) ) . map to int ( people : : get age ) . reduce ( ( s1 , s2 ) - > s1 < s2 ? s1 : s2 ) . or else ( 0 ) ;
utils . make call with basic authn ( servlet url , marcus , marcus , 403 ) ;
if ( tile groups . contains key ( level scale ) ) { . . . we ' re done . return cached level . return tile groups . get ( level scale ) ; }
log . debug ( message processing is paused , blocking until message processing is turned back on . ) ; uninterruptibles . await uninterruptibly ( paused latch ) ; }
un init reply manager ( ) ;
assert true ( get file system ( ) . create new file ( file path ) ) ;
file keytab file = new file ( kerberos test utils . get keytab file ( ) ) ;
scan = new scan ( start row ) ;
when ( material repository . find material instance ( git config ) ) . then return ( git material instance ) ; when ( material repository . find modification with revision ( git material , r1 ) ) . then return ( null ) ; value stream map service . get value stream map ( git material . get fingerprint ( ) , r1 , new username ( new case insensitive string ( user name ) ) , result ) ; assert result ( sc _ not _ found , material _ modification _ not _ found ) ;
authentication target auth = security context holder . get context ( ) . get authentication ( ) ;
for ( int y = 0 ; y < 240 ; y + + ) { for ( int x = 0 ; x < 320 ; x + + ) { assert equals ( y > = 22 & & y < 34 & & x > = 105 & & x < 185 , matrix . get ( x , y ) ) ; } }
int data until next header = ( value [ 9 ] & 0xff ) | ( ( value [ 10 ] & 0xff ) < < 8 ) ;
if ( cluster = = null ) { servlet context sc = evt . get session ( ) . get servlet context ( ) ; application context ac = web application context utils . get required web application context ( sc ) ; cluster = ac . get bean ( hz cluster , hz cluster . class ) ; } return cluster ; }
this . channel1 . configure blocking ( false ) ; try { channel1 . read ( null , 0 , 1 ) ; fail ( should throw npe ) ; } catch ( null pointer exception e ) { correct } this . channel1 . connect ( local addr1 ) ; if ( try finish ( ) ) { try { channel1 . read ( null , 0 , 1 ) ; fail ( should throw npe ) ; } catch ( null pointer exception e ) { correct } try { channel1 . read ( read buf , 0 , 2 ) ; fail ( should throw npe ) ; } catch ( null pointer exception e ) { correct } assert equals ( 0 , this . channel1 . read ( read buf , 0 , 1 ) ) ; } this . channel1 . close ( ) ;
text = ris . get text ( 64 ) ;
prev1 = null ;
student oracle no sqlinteger student max = new student oracle no sqlinteger ( ) ;
command . execute ( ) ; if ( command . is last stage ( ) ) {
set < list < node > > paths = new hash set < list < node > > ( ) ; for ( node middle node : found paths middle nodes ) { list < list < node > > paths1 = util . construct all paths to node as nodes ( middle node , predecessors1 , true , false ) ; list < list < node > > paths2 = util . construct all paths to node as nodes ( middle node , predecessors2 , false , true ) ; for all combinations . . . for ( list < node > part1 : paths1 ) { for ( list < node > part2 : paths2 ) { combine them linked list < node > path = new linked list < node > ( ) ; path . add all ( part1 ) ; path . add all ( part2 ) ; add to collection paths . add ( path ) ; } } } return new linked list < list < node > > ( paths ) ;
return versions reader . create query ( ) . for entities at revision ( referenced entity . get entity class ( ) , referenced entity . get entity name ( ) , revision ) . add ( audit entity . id ( ) . eq ( primary key ) ) . get single result ( ) ;
if ( serializers . is enabled ( serialization feature . write _ enums _ using _ to _ string ) ) { gen . write string ( en . to string ( ) ) ; return ; }
int access = read unsigned short ( u ) ;
is paging enabled = true ; }
if ( results . length > 0 & & pattern = null ) { string first answer = results [ 0 ] . get answer ( ) ; for ( string regex : pattern . get regexs ( ) ) if ( first answer . matches ( . * ? + regex + . * + ) ) { answer correct if it matches one of the patterns factoid question scores . add ( 1f ) ; return new boolean [ ] { true } ; } answer wrong if it does not match one of the patterns factoid question scores . add ( 0f ) ; return new boolean [ ] { false } ; } else if ( results . length = = 0 & & pattern = = null ) { answer correct if neither result nor pattern available factoid question scores . add ( 1f ) ; return new boolean [ ] { true } ; } else { answer wrong if either result or pattern available factoid question scores . add ( 0f ) ; return new boolean [ ] { false } ; }
return matched constant indices [ constant index2 ] = = constant index1 ;
{ error msg . illegal _ attribute _ err , attribut ' ' { 0 } ' ' non admis . } ,
if ( success count < = count 2 ) { assert . fail ( fewer than a a majority has joined ) ; }
primary sample queue . discard to end ( ) ;
if ( elements to refresh = null ) { create external archive delta ( elements to refresh , null ) ; }
| | ( decl type . get fun type ( ) = null & & decl type . get fun type ( ) . is some constructor or interface ( ) & & decl type . get fun type ( ) . get return type ( ) . is unknown ( ) ) ) { return true ; }
assert null ( historic variable update . get activity instance id ( ) ) ; historic variable update = ( historic variable update ) historic details . get ( 3 ) ; assert equals ( number , historic variable update . get variable name ( ) ) ; assert equals ( one , historic variable update . get value ( ) ) ; assert equals ( 0 , historic variable update . get revision ( ) ) ;
boolean final sub batch = is final sql & & ( sub size = = m _ batch . size ( ) ) ;
hex . set ( 57686174207765726520796 f7520686 f70696 e6720666 f723 f ) ; hex . set ( 737472696 e67 ) ; byte [ ] expected = string . get bytes ( ) ;
string start = < xml - fragment > ; string end = < xml - fragment > ; if ( result . starts with ( start ) ) { result = result . substring ( start . length ( ) ) ; }
list state1 . add ( mutable type . of ( 77 ) ) ; int n = 0 ;
final string scheme = https ; final int default port = 443 ; string path = + method descriptor . extract full service name ( method . get full method name ( ) ) ; uri uri ; try { uri = new uri ( scheme , authority , path , null , null ) ; } catch ( urisyntax exception e ) { throw status . unauthenticated . with description ( unable to construct service uri for auth ) . with cause ( e ) . as exception ( ) ; }
try { tex small id = create texture ( res ball _ sm . png ) ; tex big id = create texture ( res ball . png ) ; } catch ( ioexception e ) { e . print stack trace ( ) ; system . exit ( - 1 ) ; } tex id = tex big id ;
host to key result < integer > third iteration = result . get result ( 2 ) ;
builder . clustering ( ) . cache mode ( cache mode . repl _ sync ) . sync ( ) . state transfer ( ) . fetch in memory state ( true ) . await initial transfer ( false ) ;
double v ratio = 0 . 1 ;
log unexpected cdma method call ( get cdma prl version ) ; return null ;
logger . start ( trace , addresses , 1 ) ; logger . stop ( ) ;
try { configuration c = new configuration ( conf ) ; c . set boolean ( common configuration keys . ipc _ client _ ping _ key , true ) ; c . set int ( common configuration keys . ipc _ ping _ interval _ key , 800 ) ; c . set int ( common configuration keys . ipc _ client _ rpc _ timeout _ key , 1000 ) ; proxy = get client ( addr , c ) ; try {
local timestamp tracker = true ;
config = this ;
inject element ( tester , 1 ) ;
try { string welcome = shell . get welcome ( ) ; log . log ( level . fine , writing welcome message to term ) ; term . append ( welcome ) ; log . log ( level . fine , wrote welcome message to term ) ; write prompt flush ( ) ; } catch ( ioexception e ) { e . print stack trace ( ) ; }
for ( int i = 0 ; i < ( test _ chunk _ size * 120 ) ; i + + ) { randomly populate char c = ( char ) ( rand . next int ( 26 ) + ' a ' ) ; builder . append ( c ) ; } final byte [ ] large input data = builder . to string ( ) . get bytes ( ) ;
column mappings = hbase ser de . parse columns mapping ( column mapping string , do column regex matching , do column prefix cut ) ;
object . put ( foo , bar ) ;
if ( i longer > = shorter . number length ) { return longer ; } int res length ;
list < string > suffixes = new array list < string > ( ) ; int start = - 1 ; int last rev no = - 1 ; for ( tdrevision rev : history ) { int rev no = parse rev idnumber ( rev . get rev id ( ) ) ; string suffix = parse rev idsuffix ( rev . get rev id ( ) ) ; if ( rev no > 0 & & suffix . length ( ) > 0 ) { if ( start < 0 ) { start = rev no ; } else if ( rev no = last rev no - 1 ) { start = - 1 ; break ; } last rev no = rev no ; suffixes . add ( suffix ) ; } else { start = - 1 ; break ; } } map < string , object > result = new hash map < string , object > ( ) ;
if ( idlentity . class . is assignable from ( cls ) ) return cls . is interface ( ) ; else return cls . is interface ( ) & & all methods throw remote exception ( cls ) ;
this . context buffer = new char [ context buffer size ] ;
rounded true crop . offset ( 0 , - ( rounded true crop . bottom - full size . get height ( ) ) ) ;
assert false ( clone . get ranking ( ) . get features ( ) = = query . get ranking ( ) . get features ( ) ) ;
clock . set time ( initial creation date ) ; log . info ( beginning test with bcd of + billing day ) ; final account parent account = create account with non osgi payment method ( get account data ( billing day ) ) ; final account child account = create account with non osgi payment method ( get child account data ( billing day , parent account . get id ( ) , true ) ) ; create base entitlement and check for completion ( child account . get id ( ) , bundle key1 , pistol , product category . base , billing period . monthly , next event . create , next event . block , next event . invoice ) ;
cust _ proj _ file = override _ epsg . netcdf . properties ; return net cdfcrsoverriding authority factory . class . get resource ( cust _ proj _ file ) ;
if ( c paths . size ( ) > 0 ) notify path change ( c paths , begin lead path ) ;
string keywords = exchange . get in ( ) . get header ( twitter constants . twitter _ keywords , string . class ) ; if ( keywords = = null ) { keywords = this . keywords ; } if ( keywords = = null ) { throw new camel exchange exception ( no keywords to use for query , exchange ) ; } query query = new query ( keywords ) ;
int p50 = times [ ( times . length + 1 ) 2 ] ; int p75 = times [ ( times . length * 3 ) 4 ] ; for ( entry e : entries ) { int time = e . results . get ( round trip column index ) ; if ( time < = p50 ) { e . properties . add ( property . fast ) ; } if ( time > p75 ) { e . properties . add ( property . slow ) ; } }
connection = pooled data source . get connection ( ) ;
return replication partitions list ; }
int new buffer index = m current adapter index + m side buffer ;
assert exact permissions ( new file permission ( environment . lib file ( ) . to string ( ) , read , readlink ) , permissions ) ;
record factory record factory = record factory provider . get record factory ( null ) ; priority priority = test utils . create mock priority ( 1 ) ;
list < material revision > revisions for upstream2 = new array list < > ( ) ; add revision with2 mods ( revisions for upstream2 , git ) ; pipeline upstream2 = db helper . checkin revisions to build ( new manual build ( username ) , upstream pipeline , revisions for upstream2 ) ; assert pipeline material revisions ( upstream2 ) ; list < material revision > revisions for upstream3 = new array list < > ( ) ; add revision with2 mods ( revisions for upstream3 , git ) ;
finally { try { if ( bis = null ) bis . close ( ) ; } catch ( exception e ) { }
if ( can use google play services ( context ) ) { m gcmenabled = false ; log . i ( tag , disabling snippets launcher because play services is not up to date . ) ; } }
reduced prec = true ;
this . timer injected value . get value ( ) . schedule at fixed rate ( task , delay , interval duration ) ;
else { result = rparen ; }
double val = ( ( integer ) foo2 ) . double value ( ) ; }
object to add = field type from stream ( i document , otype . embedded , item ) ;
for ( string attr : attr names to del ) { this . attribute defs . remove ( attr ) ; }
string [ ] my data = { 1 , 1 , 1 , 11111111 , test , 1 . 10 , 1 . 11 , , , \ n , 2 , 2 , 1 , 11111111 , \ test \ , 1 . 10 , 1 . 11 , , , \ n , 3 , 3 , 1 , 11111111 , testme , 1 . 10 , 1 . 11 , , , \ n , 4 , 4 , 1 , 11111111 , iamtest , 1 . 10 , 1 . 11 , , , \ n , 5 , 5 , 5 , 5 , \ \ n , 1 . 10 , 1 . 11 , 7777 - 12 - 25 14 : 35 : 26 , point ( 1 1 ) , \ polygon ( ( 0 0 , 1 0 , 0 1 , 0 0 ) ) \ \ n } ; count down latch latch = push data async ( 7001 , my data ) ;
find iterable = collection . find ( eq ( status , a ) ) . projection ( fields ( include ( item , status ) , exclude id ( ) ) ) ;
object r3 = service . cache ( o1 ) ; assert same ( r1 , r3 ) ; }
float impulse = k > 0 . 0f ? - c k : 0 . 0f ; float px = normal . x * impulse ; float py = normal . y * impulse ; c a . x - = px * m a ;
